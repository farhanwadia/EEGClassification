{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG_Classification_Model_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAtHtAy9i7bERw0IxHNU3r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhanwadia/EEGClassification/blob/master/EEG_Classification_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNGbjcY_pmoW"
      },
      "source": [
        "# EEG Classification Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R2YgRFEXx6I"
      },
      "source": [
        "## 1. Clone the GitHub Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXv7k4iwXM4j",
        "outputId": "bd62d5d4-5cea-4189-b83f-1a034fb8514e"
      },
      "source": [
        "!git clone https://github.com/farhanwadia/EEGClassification\n",
        "!cd EEGClassification && git checkout Farhan\n",
        "\n",
        "#Change the working directory to the EEGClassification folder \n",
        "%cd EEGClassification\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EEGClassification'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 10593 (delta 19), reused 2 (delta 0), pack-reused 10538\u001b[K\n",
            "Receiving objects: 100% (10593/10593), 3.97 GiB | 25.43 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n",
            "Checking out files: 100% (10468/10468), done.\n",
            "Branch 'Farhan' set up to track remote branch 'Farhan' from 'origin'.\n",
            "Switched to a new branch 'Farhan'\n",
            "/content/EEGClassification\n",
            "/content/EEGClassification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-nWvGasqRnV"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J1KleV0pxZ8"
      },
      "source": [
        "#!pip install mne\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "#import mne\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pickle\n",
        "\n",
        "import csv\n",
        "import json\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNa6GwZGrGil"
      },
      "source": [
        "## 2. Split data into training, validation, and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mub_0BwqqLoG"
      },
      "source": [
        "def loadCSV(filename):\n",
        "    # Takes in a string of the csv file name where the EEG data is (# of measurements by 4 channels)\n",
        "    # Returns the data as an np array, transposed, with all values /10**6\n",
        "    data = np.loadtxt(filename, delimiter=',')\n",
        "    data = data.T / 10**6\n",
        "    return data\n",
        "\n",
        "def jsonToNp(pathToJSON):\n",
        "    with open(pathToJSON, \"r\") as f:\n",
        "        data = np.array(json.load(f))\n",
        "    return data \n",
        "\n",
        "def getFiles(parentPath):\n",
        "    # Returns all files in the folder and its subfolders as a list\n",
        "    listOfFiles = list()\n",
        "    for (dirpath, dirnames, filenames) in os.walk(parentPath):\n",
        "        listOfFiles += [os.path.join(dirpath, file) for file in filenames]\n",
        "    return listOfFiles\n",
        "\n",
        "def createDataset(openFiles, closedFiles):\n",
        "    n = len(openFiles) + len(closedFiles)\n",
        "    w = loadCSV(openFiles[0]).shape[0]\n",
        "    h = loadCSV(openFiles[0]).shape[1]\n",
        "\n",
        "    X = np.zeros((n, w, h))\n",
        "    y = np.zeros((n))\n",
        "    filenames = []\n",
        "\n",
        "    # Put files into np arrays. \n",
        "    #Assumes all data has already been cut to correct lengths, with no inconsistincies in the numper of data points between files\n",
        "    i = 0\n",
        "    for lst in [openFiles, closedFiles]:\n",
        "        for file in lst:\n",
        "            data = loadCSV(file)\n",
        "            X[i] = data\n",
        "            if lst == openFiles:\n",
        "                y[i] = 1            #Label 1: Open\n",
        "            else:\n",
        "                y[i] = 0            #Label 0: Closed\n",
        "\n",
        "            name = file.split(r\"\\\\\")[-1].split(\".\")[0]\n",
        "            filenames.append(name)\n",
        "            i = i+1\n",
        "    return X, y, filenames\n",
        "\n",
        "def createDatasetFromJSON(openFiles, closedFiles):\n",
        "    n = len(openFiles) + len(closedFiles)\n",
        "    c = jsonToNp(openFiles[0]).shape[0]\n",
        "    h = jsonToNp(openFiles[0]).shape[1]\n",
        "    w = jsonToNp(openFiles[0]).shape[2]\n",
        "\n",
        "    X = np.zeros((n, c, h, w))\n",
        "    y = np.zeros((n))\n",
        "    filenames = []\n",
        "    \n",
        "    # Put files into np arrays.\n",
        "    i = 0\n",
        "    for lst in [openFiles, closedFiles]:\n",
        "        for file in lst:\n",
        "            data = jsonToNp(file)\n",
        "            X[i] = data\n",
        "            if lst == openFiles:\n",
        "                y[i] = 1            #Label 1: Open\n",
        "            else:\n",
        "                y[i] = 0            #Label 0: Closed\n",
        "\n",
        "            name = file.split(r\"\\\\\")[-1].split(\".\")[0]\n",
        "            filenames.append(name)\n",
        "            i = i+1\n",
        "    return X, y, filenames\n",
        "\n",
        "\n",
        "def shuffleDataset(X, y, filenames):\n",
        "    indices = np.arange(X.shape[0])\n",
        "    seed = 21 \n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(indices)\n",
        "    X = X[indices]\n",
        "    y = y[indices]\n",
        "    filenames = np.array(filenames)\n",
        "    filenames = filenames[indices]\n",
        "    return X, y, filenames\n",
        "\n",
        "def splitDataset(X, y, filenames, percent_train):\n",
        "    n = X.shape[0]\n",
        "    X_train = X[:int(percent_train*n)]\n",
        "    X_val = X[int(percent_train*n):]\n",
        "    y_train = y[:int(percent_train*n)]\n",
        "    y_val = y[int(percent_train*n):]\n",
        "    filenames_train = filenames[:int(percent_train*n)]\n",
        "    filenames_val = filenames[int(percent_train*n):]\n",
        "    return X_train, y_train, filenames_train, X_val, y_val, filenames_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdgHI_1wU0dh"
      },
      "source": [
        "### Time Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZBg0Y3RUhW6"
      },
      "source": [
        "#### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBLWqP6bYKW2",
        "outputId": "07d72d85-8da9-4e9a-f57c-5918bd76345c"
      },
      "source": [
        "openPath = os.getcwd() + r\"//Nov 2020 Filtered Data//5s//OPEN//\"\n",
        "closedPath = os.getcwd() + r\"//Nov 2020 Filtered Data//5s//CLOSE//\"\n",
        "openPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//5s//OPEN//\"\n",
        "closedPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//5s//CLOSE//\"\n",
        "openFiles = getFiles(openPath) + getFiles(openPath2)\n",
        "closedFiles = getFiles(closedPath) + getFiles(closedPath2) \n",
        "\n",
        "X, y, filenames = createDataset(openFiles, closedFiles)\n",
        "X, y, filenames = shuffleDataset(X, y, filenames)\n",
        "X_train, y_train, filenames_train, X_other, y_other, filenames_other = splitDataset(X, y, filenames, percent_train=0.7)\n",
        "X_val, y_val, filenames_val, X_test, y_test, filenames_test = splitDataset(X_other, y_other, filenames_other, percent_train=0.5) \n",
        "\n",
        "print(\"X_train Shape: \", X_train.shape)\n",
        "print(\"y_train Shape: \", y_train.shape)\n",
        "print(\"X_val Shape: \", X_val.shape)\n",
        "print(\"y_val Shape: \", y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape:  (350, 4, 1280)\n",
            "y_train Shape:  (350,)\n",
            "X_val Shape:  (75, 4, 1280)\n",
            "y_val Shape:  (75,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr_7NSx4RpRR"
      },
      "source": [
        "Print the filenames for each dataset (verify with testing notebook after)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_gxnNDiRzn-",
        "outputId": "85a15431-4ccd-43b8-ce5b-3fef02af128b"
      },
      "source": [
        "print(filenames_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T5 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T38 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T9 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T38 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T12 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ2_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T39 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T16 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T35 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T75 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T26 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ2_T1 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T18 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP2_T4 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T27 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ2_T3 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP2_T13 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T14 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T75 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T40 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T14 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T13 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T21 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T20 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T55 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T25 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T57 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T11 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T38 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T32 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T37 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ2_T9 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T4 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T30 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T70 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T22 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T46 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T36 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T39 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T35 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T24 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T24 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T34 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T84 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T17 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T65 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T1 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T28 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T5 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T12 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T28 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T20 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T20 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T45 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T70 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T35 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T70 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T36 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T19 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T13 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T17 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T58 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T20 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T56 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T32 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T30 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T29 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T48 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T9 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T62 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T13 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T7 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T51 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T12 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T7 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T14 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T24 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T29 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ2_T6 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T60 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T23 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T76 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T23 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T25 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T38 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T43 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T8 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T31 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T37 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T6 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T1 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T38 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T17 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T10 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T22 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T32 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T1 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T24 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T40 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP2_T11 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T24 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T14 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T43 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T23 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T44 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T2 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T18 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T39 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T35 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T34 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T26 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T3 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T6 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T5 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T12 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T71 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T6 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T16 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T3 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T52 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T31 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T17 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T6 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T14 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T9 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T25 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP2_T8 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T8 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T25 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T25 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T19 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T13 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T11 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T21 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T17 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T26 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T30 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T13 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T28 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T8 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T71 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T6 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T39 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T26 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T9 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T15 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T66 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T44 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T11 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T28 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T50 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T26 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T23 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T3 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T8 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T14 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T12 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ2_T11 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T24 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T33 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T5 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T9 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T38 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T81 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T13 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T20 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T65 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T10 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T37 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T25 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T17 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ2_T8 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T31 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T7 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T3 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T18 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T19 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T13 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T5 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T14 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T19 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T7 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T18 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T10 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T8 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ2_T4 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ2_T7 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T1 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T7 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T22 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T12 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T61 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T28 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T18 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T40 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T39 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T22 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T9 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T4 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T24 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T10 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T29 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T41 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T7 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T21 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T64 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T29 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T51 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T8 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T24 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T55 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T26 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T22 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T31 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T23 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T23 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T1 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T17 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T1 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T58 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T12 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T54 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T9 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T29 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T3 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T18 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T53 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T29 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T14 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T27 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T32 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T26 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T30 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T28 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T24 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T31 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T26 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T22 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP2_T19 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T20 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP2_T3 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T8 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T53 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T26 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T18 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T19 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T22 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ2_T12 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T34 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T16 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T32 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T39 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T13 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T35 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T2 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T1 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T26 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T17 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T1 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T33 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T87 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T21 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T77 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T1 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T28 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T36 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T31 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T1 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T11 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T10 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T8 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T25 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T3 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T7 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T39 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T13 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T28 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T35 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T21 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T10 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T43 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T27 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T13 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T25 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T32 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T40 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T14 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T27 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T6 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T30 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T13 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T15 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T16 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T33 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T2 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T5 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T40 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T14 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T22 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP2_T6 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T23 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T39 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T12 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T22 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T35 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T27 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T34 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T14 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T9 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T27 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T21 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP2_T14 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T38 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T11 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T26 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T16 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T32 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T6 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T59 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T13 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T18 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T12 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T6 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T34 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T8 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T33 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T6 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T32 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T78 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T7 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T10 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T20 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T5 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T40 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T7 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T12 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T8 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T31 Open (valve) - Filtered']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx7fF512R2uv",
        "outputId": "e627c402-8980-4592-de72-f7a8f66daca3"
      },
      "source": [
        "print(filenames_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T24 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T32 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T15 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T16 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T17 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T34 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T34 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T3 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T30 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T22 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T27 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T33 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T37 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T10 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T33 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T34 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T12 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T27 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T16 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T41 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T10 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T57 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T28 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T4 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T4 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP2_T18 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T21 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T4 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T19 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW3_T30 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T10 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T1 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T38 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T4 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T17 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T12 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T4 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T5 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T80 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T3 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T7 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T30 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T52 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T40 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T12 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T23 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T29 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T22 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T3 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T78 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T50 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T62 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T33 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T47 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T29 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T23 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T7 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T27 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T31 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T37 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T61 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T23 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T9 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T61 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//AZ_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//FW_T6 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T1 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ2_T5 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T35 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP2_T1 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T34 Close (valve) - Filtered']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9onlDlER23Y",
        "outputId": "9e40db73-7e2d-4cff-e488-1ef705053d77"
      },
      "source": [
        "print(filenames_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T36 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T17 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T15 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW3_T39 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T30 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T35 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T75 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T20 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T16 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T21 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T20 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T11 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP2_T2 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T16 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T11 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP2_T7 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ2_T10 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T32 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T4 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T36 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T29 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T73 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T26 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T22 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T78 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T36 Close (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T20 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T77 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T22 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T26 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T36 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T76 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T37 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T85 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T46 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T18 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW2_T39 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP2_T12 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//CJ_T69 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//AZ_T32 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T18 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//FW_T17 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP2_T9 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T11 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T19 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T5 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T30 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T11 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T15 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP_T17 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T4 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T13 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T32 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//AZ_T11 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//SD_T31 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T2 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T5 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//FW_T43 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T33 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T10 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW_T24 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T27 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//SD_T14 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T31 Open (valve)_(2) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//AZ_T5 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP2_T17 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//SD_T25 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//CJ_T18 Close (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//CJ_T17 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//JP_T40 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//OPEN//SD_T19 Open (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T53 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Nov 2020 Filtered Data//5s//CLOSE//CJ_T7 Close (valve) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//OPEN//JP2_T15 Open (valve)_(1) - Filtered'\n",
            " '/content/EEGClassification//Feb 2021 Filtered Data//5s//CLOSE//FW2_T4 Close (valve) - Filtered']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tUAxmirUmcC"
      },
      "source": [
        "#### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMUajSIm9BHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf49402b-a563-40e8-d9e4-954b076b0581"
      },
      "source": [
        "openPath = os.getcwd() + r\"//Nov 2020 Filtered Data//2x3_5s//OPEN//\"\n",
        "closedPath = os.getcwd() + r\"//Nov 2020 Filtered Data//2x3_5s//CLOSE//\"\n",
        "openPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//2x3_5s//OPEN//\"\n",
        "closedPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//2x3_5s//CLOSE//\"\n",
        "openFiles = getFiles(openPath) + getFiles(openPath2)\n",
        "closedFiles = getFiles(closedPath) + getFiles(closedPath2) \n",
        "\n",
        "X, y, filenames = createDataset(openFiles, closedFiles)\n",
        "X, y, filenames = shuffleDataset(X, y, filenames)\n",
        "X2_train, y2_train, filenames2_train, X_other, y_other, filenames_other = splitDataset(X, y, filenames, percent_train=0.7)\n",
        "X2_val, y2_val, filenames2_val, X2_test, y2_test, filenames2_test = splitDataset(X_other, y_other, filenames_other, percent_train=0.5) \n",
        "\n",
        "print(\"X2_train Shape: \", X2_train.shape)\n",
        "print(\"y2_train Shape: \", y2_train.shape)\n",
        "print(\"X2_val Shape: \", X2_val.shape)\n",
        "print(\"y2_val Shape: \", y2_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X2_train Shape:  (700, 4, 896)\n",
            "y2_train Shape:  (700,)\n",
            "X2_val Shape:  (150, 4, 896)\n",
            "y2_val Shape:  (150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr3XXCrvU8Po"
      },
      "source": [
        "### Frequency Domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3i-vD1YQRd"
      },
      "source": [
        "Due to frequency domain models having the worst accuracies in the initial training on only the Nov 2020 data, they are not considered here for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxLuUoi-VBxI"
      },
      "source": [
        "### Time-Frequency (Wavelets Transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdNQyUkJSijY"
      },
      "source": [
        "#### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FpqhWuIX0g-",
        "outputId": "2058554c-0cab-4ff9-c91c-73040586dc99"
      },
      "source": [
        "openPath = os.getcwd() + r\"//Nov 2020 Filtered Data//5s//Spectograms//OPEN//\"\n",
        "closedPath = os.getcwd() + r\"//Nov 2020 Filtered Data//5s//Spectograms//CLOSE//\"\n",
        "openPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//5s//Spectograms//OPEN//\"\n",
        "closedPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//5s//Spectograms//CLOSE//\"\n",
        "openFiles = getFiles(openPath) + getFiles(openPath2)\n",
        "closedFiles = getFiles(closedPath) + getFiles(closedPath2) \n",
        "\n",
        "X, y, filenames = createDatasetFromJSON(openFiles, closedFiles)\n",
        "X, y, filenames = shuffleDataset(X, y, filenames)\n",
        "X_train_wv, y_train_wv, filenames_train_wv, X_other, y_other, filenames_other = splitDataset(X, y, filenames, percent_train=0.7)\n",
        "X_val_wv, y_val_wv, filenames_val_wv, X_test_wv, y_test_wv, filenames_test_wv = splitDataset(X_other, y_other, filenames_other, percent_train=0.5) \n",
        "\n",
        "print(\"X_train_wv Shape: \", X_train_wv.shape)\n",
        "print(\"y_train_wv Shape: \", y_train_wv.shape)\n",
        "print(\"X_val_wv Shape: \", X_val_wv.shape)\n",
        "print(\"y_val_wv Shape: \", y_val_wv.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_wv Shape:  (350, 4, 60, 1280)\n",
            "y_train_wv Shape:  (350,)\n",
            "X_val_wv Shape:  (75, 4, 60, 1280)\n",
            "y_val_wv Shape:  (75,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1REZ0W2SlLv"
      },
      "source": [
        "#### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cyKm9DLYtZD",
        "outputId": "3fd05e18-bb25-4e3e-c890-7295b8fd3fa8"
      },
      "source": [
        "openPath = os.getcwd() + r\"//Nov 2020 Filtered Data//2x3_5s//Spectograms//OPEN//\"\n",
        "closedPath = os.getcwd() + r\"//Nov 2020 Filtered Data//2x3_5s//Spectograms//CLOSE//\"\n",
        "openPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//2x3_5s//Spectograms//OPEN//\"\n",
        "closedPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//2x3_5s//Spectograms//CLOSE//\"\n",
        "openFiles = getFiles(openPath) + getFiles(openPath2)\n",
        "closedFiles = getFiles(closedPath) + getFiles(closedPath2) \n",
        "\n",
        "X, y, filenames = createDatasetFromJSON(openFiles, closedFiles)\n",
        "X, y, filenames = shuffleDataset(X, y, filenames)\n",
        "X2_train_wv, y2_train_wv, filenames2_train_wv, X_other, y_other, filenames_other = splitDataset(X, y, filenames, percent_train=0.7)\n",
        "X2_val_wv, y2_val_wv, filenames2_val_wv, X2_test_wv, y2_test_wv, filenames2_test_wv = splitDataset(X_other, y_other, filenames_other, percent_train=0.5) \n",
        "\n",
        "print(\"X2_train_wv Shape: \", X2_train_wv.shape)\n",
        "print(\"y2_train_wv Shape: \", y2_train_wv.shape)\n",
        "print(\"X2_val_wv Shape: \", X2_val_wv.shape)\n",
        "print(\"y2_val_wv Shape: \", y2_val_wv.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X2_train_wv Shape:  (700, 4, 60, 896)\n",
            "y2_train_wv Shape:  (700,)\n",
            "X2_val_wv Shape:  (150, 4, 60, 896)\n",
            "y2_val_wv Shape:  (150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVxIqqkFxbpJ"
      },
      "source": [
        "## 3. Time Series Baseline Models\n",
        "As a baseline, try using a linear SVM and some non-linear SVMs with different amounts of regularization to try and classify the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hnV_fRfWgSx"
      },
      "source": [
        "def get_accuracy_svm(model, X, y):\n",
        "    predictions = model.predict(X)\n",
        "    num_correct = np.sum((predictions - y) == 0)\n",
        "    n = X.shape[0]\n",
        "    accuracy = num_correct/n\n",
        "    print(\"The number of correct predictions is: \", num_correct)\n",
        "    print(\"The number of files is: \", n)\n",
        "    print(\"The accuracy is: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd26AnVtVE1b"
      },
      "source": [
        "### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZkEQAAPq6UV",
        "outputId": "1ffb54d0-261d-4247-811e-72e6e283a901"
      },
      "source": [
        "# Stack channels and datapoints into one dimension for sklearn to work\n",
        "X_train_svm = X_train.reshape(X_train.shape[0], 4*(256*5))\n",
        "X_val_svm = X_val.reshape(X_val.shape[0], 4*(256*5))\n",
        "\n",
        "# Fit the models\n",
        "# Nonlinear model 1 has a higher regularization (1) than model 2 (1/10)\n",
        "# Higher regularization helps to increase variance and reduce overfitting   \n",
        "model_linear = svm.LinearSVC()\n",
        "model_linear.fit(X_train_svm, y_train)\n",
        "\n",
        "model_nonlinear_1 = svm.SVC(kernel='sigmoid', C=1)\n",
        "model_nonlinear_1.fit(X_train_svm, y_train)\n",
        "\n",
        "model_nonlinear_2 = svm.SVC(kernel='sigmoid', C=10)\n",
        "model_nonlinear_2.fit(X_train_svm, y_train)\n",
        "\n",
        "model_nonlinear_3 = svm.SVC(kernel='sigmoid', C=100)\n",
        "model_nonlinear_3.fit(X_train_svm, y_train)\n",
        "\n",
        "model_nonlinear_4 = svm.SVC(kernel='rbf', C=1)\n",
        "model_nonlinear_4.fit(X_train_svm, y_train)\n",
        "\n",
        "model_nonlinear_5 = svm.SVC(kernel='rbf', C=10)\n",
        "model_nonlinear_5.fit(X_train_svm, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLNQLfcKyxDJ"
      },
      "source": [
        "#### Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "byQwGmwhyZVY",
        "outputId": "2d420968-ec5a-4565-afaa-03083c6ea26d"
      },
      "source": [
        "# Linear model accuracies\n",
        "print(\"Linear Model \\n\")\n",
        "print(\"Training Accuracy\")\n",
        "get_accuracy_svm(model_linear, X_train_svm, y_train)\n",
        "print(\"\\nValidation Accuracy\")\n",
        "get_accuracy_svm(model_linear, X_val_svm, y_val)\n",
        "\n",
        "# Linear model coefficients\n",
        "coefs = model_linear.coef_[0]\n",
        "intercept = model_linear.intercept_\n",
        "#print(\"The coefficients of the hyperplane are: \", coefs)\n",
        "print(\"The shape of the coefficients vector is: \", coefs.shape)\n",
        "print(\"The intercept of the hyperplane is: \", intercept, \"\\n\")\n",
        "\n",
        "#Plot the coefficients of the linear SVM\n",
        "x = np.array(range(1, len(coefs)+1))\n",
        "plt.plot(x, coefs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Model \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  178\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.5085714285714286\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  37\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.49333333333333335\n",
            "The shape of the coefficients vector is:  (5120,)\n",
            "The intercept of the hyperplane is:  [-0.01712113] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE23_lhQy2zh"
      },
      "source": [
        "#### Non-Linear Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwJriIRUW8Ux",
        "outputId": "8a24544c-1f5d-488e-d337-3a8edee9da1c"
      },
      "source": [
        "#Non-Linear Model 1 Accuracies\n",
        "print(\"\\nNon-Linear Model 1 \\n\")\n",
        "print(\"Training Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_1, X_train_svm, y_train)\n",
        "print(\"\\nValidation Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_1, X_val_svm, y_val)\n",
        "\n",
        "#Non-Linear Model 2 Accuracies\n",
        "print(\"\\nNon-Linear Model 2 \\n\")\n",
        "print(\"Training Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_2, X_train_svm, y_train)\n",
        "print(\"\\nValidation Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_2, X_val_svm, y_val)\n",
        "\n",
        "#Non-Linear Model 3 Accuracies\n",
        "print(\"\\nNon-Linear Model 3 \\n\")\n",
        "print(\"Training Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_3, X_train_svm, y_train)\n",
        "print(\"\\nValidation Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_3, X_val_svm, y_val)\n",
        "\n",
        "#Non-Linear Model 4 Accuracies\n",
        "print(\"\\nNon-Linear Model 4 \\n\")\n",
        "print(\"Training Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_4, X_train_svm, y_train)\n",
        "print(\"\\nValidation Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_4, X_val_svm, y_val)\n",
        "\n",
        "#Non-Linear Model 5 Accuracies\n",
        "print(\"\\nNon-Linear Model 5 \\n\")\n",
        "print(\"Training Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_5, X_train_svm, y_train)\n",
        "print(\"\\nValidation Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_5, X_val_svm, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Non-Linear Model 1 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  252\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.72\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  42\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.56\n",
            "\n",
            "Non-Linear Model 2 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  252\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.72\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  44\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.5866666666666667\n",
            "\n",
            "Non-Linear Model 3 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  258\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.7371428571428571\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  47\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.6266666666666667\n",
            "\n",
            "Non-Linear Model 4 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  323\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.9228571428571428\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  42\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.56\n",
            "\n",
            "Non-Linear Model 5 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  350\n",
            "The number of files is:  350\n",
            "The accuracy is:  1.0\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  40\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.5333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2ilhY-6VIsE"
      },
      "source": [
        "### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7HHJoq7VX1E",
        "outputId": "32d6546f-b0a0-4bfe-d120-1666481fe0a1"
      },
      "source": [
        "# Stack channels and datapoints into one dimension for sklearn to work\n",
        "X_train_svm = X2_train.reshape(X2_train.shape[0], 4*int(256*3.5))\n",
        "X_val_svm = X2_val.reshape(X2_val.shape[0], 4*int(256*3.5))\n",
        "\n",
        "# Fit the models\n",
        "# Nonlinear model 1 has a higher regularization (1) than model 2 (1/10)\n",
        "# Higher regularization helps to increase variance and reduce overfitting   \n",
        "model_linear = svm.LinearSVC()\n",
        "model_linear.fit(X_train_svm, y2_train)\n",
        "\n",
        "model_nonlinear_1 = svm.SVC(kernel='sigmoid')\n",
        "model_nonlinear_1.fit(X_train_svm, y2_train)\n",
        "\n",
        "model_nonlinear_2 = svm.SVC(kernel='sigmoid', C=10)\n",
        "model_nonlinear_2.fit(X_train_svm, y2_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='sigmoid',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSO3XLiAVX1F"
      },
      "source": [
        "#### Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "hbSTmKACVX1F",
        "outputId": "9f2e4527-799d-4a92-f631-25b9cfcd4e4c"
      },
      "source": [
        "# Linear model accuracies\n",
        "print(\"Linear Model \\n\")\n",
        "print(\"Training Accuracy\")\n",
        "get_accuracy_svm(model_linear, X_train_svm, y2_train)\n",
        "print(\"\\nValidation Accuracy\")\n",
        "get_accuracy_svm(model_linear, X_val_svm, y2_val)\n",
        "\n",
        "# Linear model coefficients\n",
        "coefs = model_linear.coef_[0]\n",
        "intercept = model_linear.intercept_\n",
        "#print(\"The coefficients of the hyperplane are: \", coefs)\n",
        "print(\"The shape of the coefficients vector is: \", coefs.shape)\n",
        "print(\"The intercept of the hyperplane is: \", intercept, \"\\n\")\n",
        "\n",
        "#Plot the coefficients of the linear SVM\n",
        "x = np.array(range(1, len(coefs)+1))\n",
        "plt.plot(x, coefs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Model \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  367\n",
            "The number of files is:  700\n",
            "The accuracy is:  0.5242857142857142\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  77\n",
            "The number of files is:  150\n",
            "The accuracy is:  0.5133333333333333\n",
            "The shape of the coefficients vector is:  (3584,)\n",
            "The intercept of the hyperplane is:  [-0.04853466] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwvP6Y2rVX1G"
      },
      "source": [
        "#### Non-Linear Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vLgOBz0VX1G",
        "outputId": "7b2ef993-e92e-48bc-b7e8-48e62f7c346c"
      },
      "source": [
        "#Non-Linear Model 1 Accuracies\n",
        "print(\"\\nNon-Linear Model 1 \\n\")\n",
        "print(\"Training Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_1, X_train_svm, y2_train)\n",
        "print(\"\\nValidation Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_1, X_val_svm, y2_val)\n",
        "\n",
        "#Non-Linear Model 2 Accuracies\n",
        "print(\"\\nNon-Linear Model 2 \\n\")\n",
        "print(\"Training Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_2, X_train_svm, y2_train)\n",
        "print(\"\\nValidation Accuracy\")\n",
        "get_accuracy_svm(model_nonlinear_2, X_val_svm, y2_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Non-Linear Model 1 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  413\n",
            "The number of files is:  700\n",
            "The accuracy is:  0.59\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  77\n",
            "The number of files is:  150\n",
            "The accuracy is:  0.5133333333333333\n",
            "\n",
            "Non-Linear Model 2 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  436\n",
            "The number of files is:  700\n",
            "The accuracy is:  0.6228571428571429\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  64\n",
            "The number of files is:  150\n",
            "The accuracy is:  0.4266666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo6z_u30jzen"
      },
      "source": [
        "### Discussion\n",
        "The best model so far seems to be with 5s data using nonlinear model 3, which was a SVM using sigmoid kernel and regularization of 1/100. The validation accuracy for this model was 63%, which is the benchmark that any deep learning model should exceed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSyMaqQpnA7Y"
      },
      "source": [
        "# Saving model to file\n",
        "filename = 'svm_kernel-sigmoid_C-100_5s.sav'\n",
        "pickle.dump(model_nonlinear_3, open(filename, 'wb'))\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RsjsUTMY-e3"
      },
      "source": [
        "# some time later...\n",
        "# load the model\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test_svm, Y_test_svm)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr-Ma-KmzUAB"
      },
      "source": [
        "## 4. Deep Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMKJ04BXx9SN"
      },
      "source": [
        "### Training Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Hcneb4pPdE"
      },
      "source": [
        "torch.manual_seed(21) # set the random seed\n",
        "\n",
        "def createTensorDataset(data, labels):\n",
        "    # Returns a tensor dataset object given np arrays of the data and labels\n",
        "    data_tensor = torch.tensor(data)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "    dataset = TensorDataset(data_tensor, labels_tensor)\n",
        "    return dataset\n",
        "\n",
        "def addDimensionForCNNModels(dataset):\n",
        "# Takes in a pytorch dataset with data of size [N, C, H]\n",
        "# Returns a pytorch dataset with data of size [N, 1, C, H]\n",
        "# This allows us to treat the multiple EEG channnels like a 2D image of 1 channel\n",
        "    data = dataset.tensors[0]\n",
        "    labels = dataset.tensors[1]\n",
        "    data = torch.unsqueeze(data, 1)\n",
        "    return TensorDataset(data, labels)\n",
        "\n",
        "def downsampleTensorHW(dataset, factor):\n",
        "    # Given a tensor dataset of data, labels, takes data of shape [N, C, H, W]\n",
        "    # Returns the dataset, but with data of shape [N, C, H/factor, W/factor]\n",
        "    data = dataset.tensors[0]\n",
        "    labels = dataset.tensors[1]\n",
        "    data_new = F.interpolate(data, size=(int(data.shape[-2] /factor), int(data.shape[-1] /factor)), mode='bicubic', align_corners=False)\n",
        "    return TensorDataset(data_new, labels)\n",
        "\n",
        "def get_accuracy(model, data_loader, train=False, use_cuda=True):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for file, labels in iter(data_loader):\n",
        "        file = file.float()\n",
        "        labels = labels.long()\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            file = file.cuda()\n",
        "            labels = labels.cuda()\n",
        "        output = model(file)\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += file.shape[0]\n",
        "    return correct / total\n",
        "\n",
        "def plot_training_curve(iters, losses, train_acc, val_acc):\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "    print(\"Maximum Training Accuracy: {}\".format(max(train_acc)))\n",
        "    print(\"Maximum Validation Accuracy: {}\".format(max(val_acc)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Q3lvRV2dbK"
      },
      "source": [
        "def train(model, train_dataset, val_dataset, batch_size=100, num_epochs=1, learning_rate=0.01, momen=0.9, use_cuda=True, use_adam=True, save_weights=True):\n",
        "    # Create folder to save the weights in\n",
        "    now = datetime.now()\n",
        "    folder_name = model.name + ' Weights ' + now.strftime(\"%Y-%m-%d %H-%M\")\n",
        "    save_path = os.getcwd() + \"//\" + folder_name + \"//\"\n",
        "    if save_weights and not os.path.exists(folder_name):\n",
        "        os.makedirs(folder_name)\n",
        "    \n",
        "    # Make dataloader objects to iterate over\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    #Define loss functions and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if use_adam:\n",
        "        optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    else:\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momen)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for file, labels in iter(train_loader):\n",
        "            \n",
        "            file = file.float()\n",
        "            labels = labels.long()\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                file = file.cuda()\n",
        "                labels = labels.cuda()\n",
        "            \n",
        "            out = model(file)             # forward pass\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "            train_acc.append(get_accuracy(model, train_loader, train=True)) # compute training accuracy \n",
        "            val_acc.append(get_accuracy(model, val_loader, train=False))  # compute validation accuracy\n",
        "            print(\"Iteration: \", str(n), \"| Train Loss: \", losses[n], \"| Train Accuracy: \", train_acc[n], \"| Validation Accuracy: \", val_acc[n])\n",
        "            n += 1\n",
        "            model_path = \"model_{0}_bs{1}_lr{2}_epoch{3}_iteration{4}_val-acc{5}\".format(model.name, \n",
        "                                                                                         batch_size, \n",
        "                                                                                         str(learning_rate).replace('.', '-'), \n",
        "                                                                                         epoch, n, str(round(val_acc[-1]*100, 4)).replace('.', '-'))\n",
        "            if save_weights:\n",
        "                if val_acc[-1] == max(val_acc) and val_acc.count(val_acc[-1]) == 1:\n",
        "                    torch.save(model.state_dict(), save_path + model_path + \".pth\") #save weights at new maximum for validation accuracy\n",
        "    if save_weights:\n",
        "        torch.save(model.state_dict(), save_path + model_path + \".pth\") #Save the very last iteration\n",
        "        #Write the train loss and train/val accuracies to CSV file\n",
        "        epochs = np.arange(1, num_epochs + 1)\n",
        "        np.savetxt(save_path + \"{}_train_loss.csv\".format(model_path), losses)\n",
        "        np.savetxt(save_path + \"{}_train_acc.csv\".format(model_path), train_acc)\n",
        "        np.savetxt(save_path + \"{}_val_acc.csv\".format(model_path), val_acc) \n",
        "\n",
        "    # plotting\n",
        "    plot_training_curve(iters, losses, train_acc, val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZX-kvza2F4S"
      },
      "source": [
        "### Model Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvktHMTuxpKW"
      },
      "source": [
        "#### Time Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buKLe1VA14yL"
      },
      "source": [
        "class ANN_TS_2L(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANN_TS_2L, self).__init__()\n",
        "        self.name = \"ANN_TS_2L\"\n",
        "        self.layer1 = nn.Linear((256*5)*4, 200)\n",
        "        self.layer2 = nn.Linear(200, 50)\n",
        "        self.layer3 = nn.Linear(50, 2)\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, (256*5)*4)\n",
        "        activation1 = F.relu(self.layer1(flattened))\n",
        "        activation2 = F.relu(self.layer2(activation1))\n",
        "        output = self.layer3(activation2)\n",
        "        return output\n",
        "\n",
        "class ANN_TS2_2L(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANN_TS2_2L, self).__init__()\n",
        "        self.name = \"ANN_TS2_2L\"\n",
        "        self.layer1 = nn.Linear(int(256*3.5)*4, 200)\n",
        "        self.layer2 = nn.Linear(200, 50)\n",
        "        self.layer3 = nn.Linear(50, 2)\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, int(256*3.5)*4)\n",
        "        activation1 = F.relu(self.layer1(flattened))\n",
        "        activation2 = F.relu(self.layer2(activation1))\n",
        "        output = self.layer3(activation2)\n",
        "        return output\n",
        "\n",
        "class ANN_TS_3L(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANN_TS_3L, self).__init__()\n",
        "        self.name = \"ANN_TS_3L\"\n",
        "        self.layer1 = nn.Linear((256*5)*4, 500)\n",
        "        self.layer2 = nn.Linear(500, 200)\n",
        "        self.layer3 = nn.Linear(200, 50)\n",
        "        self.layer4 = nn.Linear(50, 2)\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, (256*5)*4)\n",
        "        activation1 = F.relu(self.layer1(flattened))\n",
        "        activation2 = F.relu(self.layer2(activation1))\n",
        "        activation3 = F.relu(self.layer3(activation2))\n",
        "        output = self.layer4(activation3)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8rMoL8jj5N"
      },
      "source": [
        "#### Time-Frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCvrJQaYjn6D"
      },
      "source": [
        "class CNN_WV(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_WV, self).__init__()\n",
        "        self.name = \"CNN_WV\"\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(4, 8, 4) #in_channels, out_channels (# of kernels to try), kernel_size. Size in is 4x30x640\n",
        "        self.pool = nn.MaxPool2d(2, 2) #kernel_size (for the pool), stride. Size in should be 8x26x636 \n",
        "        self.conv2 = nn.Conv2d(8, 16, 4) #size in should be 8x13x318\n",
        "        self.pool = nn.MaxPool2d(2, 2) # size in should be 16x9x314\n",
        "        \n",
        "        self.fc1 = nn.Linear(16*5*157, 2500) #size in should be 16x5x157\n",
        "        self.fc2 = nn.Linear(2500, 500)\n",
        "        self.fc3 = nn.Linear(500, 50)\n",
        "        self.fc4 = nn.Linear(50, 2)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1) #flatten the input\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x)) \n",
        "        x = self.fc4(x)\n",
        "        x = x.squeeze(1)\n",
        "        return x\n",
        "\n",
        "class CNN2_WV(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN2_WV, self).__init__()\n",
        "        self.name = \"CNN2_WV\"\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(4, 8, 4) #in_channels, out_channels (# of kernels to try), kernel_size. Size in is 4x30x448\n",
        "        self.pool = nn.MaxPool2d(2, 2) #kernel_size (for the pool), stride. Size in should be 8x26x444 \n",
        "        self.conv2 = nn.Conv2d(8, 16, 4) #size in should be 8x13x222\n",
        "        self.pool = nn.MaxPool2d(2, 2) # size in should be 16x9x218\n",
        "        \n",
        "        self.fc1 = nn.Linear(16*5*109, 2000) #size in should be 16x5x109\n",
        "        self.fc2 = nn.Linear(2000, 500)\n",
        "        self.fc3 = nn.Linear(500, 50)\n",
        "        self.fc4 = nn.Linear(50, 2)\n",
        " \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1) #flatten the input\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x)) \n",
        "        x = self.fc4(x)\n",
        "        x = x.squeeze(1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgACcb09yVQF"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAhDmTVnyZyc"
      },
      "source": [
        "#### Time Series Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNsh9odqWCFi"
      },
      "source": [
        "##### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt1pmqAy-auw"
      },
      "source": [
        "train_dataset = createTensorDataset(X_train, y_train)\n",
        "val_dataset = createTensorDataset(X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PiTeHZ_alZvV",
        "outputId": "2269f0ba-14aa-464e-abac-09d697dff919"
      },
      "source": [
        "model = ANN_TS_2L()\n",
        "train(model, train_dataset, val_dataset, batch_size = 50, num_epochs=150, learning_rate = 0.01, momen = 0.7, use_adam = True, save_weights=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.013867669105529785 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1 | Train Loss:  0.01394626498222351 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2 | Train Loss:  0.013866736888885497 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3 | Train Loss:  0.01386300563812256 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  4 | Train Loss:  0.013856523036956787 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  5 | Train Loss:  0.013967663049697876 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  6 | Train Loss:  0.013789061307907104 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  7 | Train Loss:  0.013879748582839966 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  8 | Train Loss:  0.01383630871772766 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  9 | Train Loss:  0.013867698907852173 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  10 | Train Loss:  0.013868592977523804 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  11 | Train Loss:  0.013849188089370728 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  12 | Train Loss:  0.013995842933654785 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  13 | Train Loss:  0.013747704029083253 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  14 | Train Loss:  0.013886005878448486 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  15 | Train Loss:  0.01383212924003601 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  16 | Train Loss:  0.013868364095687867 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  17 | Train Loss:  0.013868540525436401 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  18 | Train Loss:  0.013849591016769408 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  19 | Train Loss:  0.013983136415481568 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  20 | Train Loss:  0.013757350444793702 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  21 | Train Loss:  0.013882962465286254 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  22 | Train Loss:  0.013835422992706299 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  23 | Train Loss:  0.013866974115371704 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  24 | Train Loss:  0.01386702537536621 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  25 | Train Loss:  0.013850867748260498 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  26 | Train Loss:  0.013964184522628785 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  27 | Train Loss:  0.013773677349090576 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  28 | Train Loss:  0.013879324197769166 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  29 | Train Loss:  0.013839046955108642 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  30 | Train Loss:  0.013865901231765747 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  31 | Train Loss:  0.013865989446640015 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  32 | Train Loss:  0.013851886987686158 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  33 | Train Loss:  0.013952342271804809 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  34 | Train Loss:  0.0137834894657135 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  35 | Train Loss:  0.013877407312393189 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  36 | Train Loss:  0.013840835094451904 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  37 | Train Loss:  0.01386547565460205 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  38 | Train Loss:  0.013865607976913451 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  39 | Train Loss:  0.013852195739746094 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  40 | Train Loss:  0.013949141502380372 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  41 | Train Loss:  0.013785254955291749 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  42 | Train Loss:  0.013877121210098266 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  43 | Train Loss:  0.013840800523757935 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  44 | Train Loss:  0.013865485191345214 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  45 | Train Loss:  0.01386562705039978 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  46 | Train Loss:  0.01385195016860962 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  47 | Train Loss:  0.013951253890991212 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  48 | Train Loss:  0.013782382011413574 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  49 | Train Loss:  0.013877646923065185 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  50 | Train Loss:  0.013839889764785767 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  51 | Train Loss:  0.013865662813186646 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  52 | Train Loss:  0.013865771293640137 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  53 | Train Loss:  0.013851498365402221 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  54 | Train Loss:  0.013954644203186034 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  55 | Train Loss:  0.013778764009475707 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  56 | Train Loss:  0.013878196477890015 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  57 | Train Loss:  0.013838953971862793 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  58 | Train Loss:  0.013865793943405152 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  59 | Train Loss:  0.01386582612991333 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  60 | Train Loss:  0.013851054906845094 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  61 | Train Loss:  0.013956905603408813 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  62 | Train Loss:  0.013776501417160034 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  63 | Train Loss:  0.01387833833694458 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  64 | Train Loss:  0.013838294744491577 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  65 | Train Loss:  0.013865798711776733 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  66 | Train Loss:  0.013865706920623779 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  67 | Train Loss:  0.013850631713867188 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  68 | Train Loss:  0.013957765102386475 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  69 | Train Loss:  0.013775614500045776 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  70 | Train Loss:  0.013878053426742554 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  71 | Train Loss:  0.013837815523147582 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  72 | Train Loss:  0.013865673542022705 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  73 | Train Loss:  0.013865411281585693 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  74 | Train Loss:  0.013850101232528687 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  75 | Train Loss:  0.013957810401916505 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  76 | Train Loss:  0.01377552628517151 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  77 | Train Loss:  0.013877367973327637 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  78 | Train Loss:  0.013837329149246215 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  79 | Train Loss:  0.013865416049957275 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  80 | Train Loss:  0.013864898681640625 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  81 | Train Loss:  0.013849354982376098 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  82 | Train Loss:  0.013957374095916748 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  83 | Train Loss:  0.013775764703750611 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  84 | Train Loss:  0.013876322507858276 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  85 | Train Loss:  0.013836560249328613 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  86 | Train Loss:  0.013865057229995727 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  87 | Train Loss:  0.013864206075668335 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  88 | Train Loss:  0.013848164081573487 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  89 | Train Loss:  0.013957850933074951 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  90 | Train Loss:  0.013775017261505127 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  91 | Train Loss:  0.013875007629394531 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  92 | Train Loss:  0.013835254907608032 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  93 | Train Loss:  0.013864526748657227 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  94 | Train Loss:  0.013863105773925782 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  95 | Train Loss:  0.013846412897109986 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  96 | Train Loss:  0.01395782470703125 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  97 | Train Loss:  0.013774940967559815 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  98 | Train Loss:  0.01387276291847229 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  99 | Train Loss:  0.013833508491516114 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  100 | Train Loss:  0.013863638639450074 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  101 | Train Loss:  0.01386137843132019 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  102 | Train Loss:  0.013843798637390136 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  103 | Train Loss:  0.013957840204238892 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  104 | Train Loss:  0.013774399757385253 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  105 | Train Loss:  0.013869420289993287 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  106 | Train Loss:  0.013830413818359375 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  107 | Train Loss:  0.013862330913543702 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  108 | Train Loss:  0.013858749866485595 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  109 | Train Loss:  0.013839249610900878 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  110 | Train Loss:  0.01395991325378418 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  111 | Train Loss:  0.013772889375686645 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  112 | Train Loss:  0.013863873481750489 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  113 | Train Loss:  0.013825629949569701 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  114 | Train Loss:  0.013859981298446655 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  115 | Train Loss:  0.013854109048843384 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  116 | Train Loss:  0.013832216262817382 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  117 | Train Loss:  0.013959987163543701 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  118 | Train Loss:  0.013772238492965699 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  119 | Train Loss:  0.013854304552078247 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  120 | Train Loss:  0.013816932439804077 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  121 | Train Loss:  0.0138560152053833 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  122 | Train Loss:  0.013846267461776734 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  123 | Train Loss:  0.013819061517715454 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  124 | Train Loss:  0.013963110446929931 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  125 | Train Loss:  0.013769983053207398 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  126 | Train Loss:  0.01383732795715332 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  127 | Train Loss:  0.01380221128463745 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  128 | Train Loss:  0.013848434686660766 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  129 | Train Loss:  0.01383188009262085 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  130 | Train Loss:  0.013796675205230712 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  131 | Train Loss:  0.01396040678024292 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  132 | Train Loss:  0.013774374723434448 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  133 | Train Loss:  0.013806099891662598 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  134 | Train Loss:  0.013778365850448608 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  135 | Train Loss:  0.01383398175239563 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  136 | Train Loss:  0.013805698156356811 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  137 | Train Loss:  0.013757480382919312 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  138 | Train Loss:  0.01395727276802063 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  139 | Train Loss:  0.013773999214172362 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  140 | Train Loss:  0.01375316023826599 | Train Accuracy:  0.6 | Validation Accuracy:  0.48\n",
            "Iteration:  141 | Train Loss:  0.01373634934425354 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  142 | Train Loss:  0.013808457851409913 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  143 | Train Loss:  0.013759710788726807 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  144 | Train Loss:  0.013692796230316162 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  145 | Train Loss:  0.013937537670135497 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  146 | Train Loss:  0.013777574300765991 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  147 | Train Loss:  0.013667881488800049 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  148 | Train Loss:  0.013662121295928954 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  149 | Train Loss:  0.013766272068023682 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  150 | Train Loss:  0.013690255880355835 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  151 | Train Loss:  0.013589873313903808 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  152 | Train Loss:  0.01388228178024292 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  153 | Train Loss:  0.013809186220169068 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  154 | Train Loss:  0.013530081510543824 | Train Accuracy:  0.72 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  155 | Train Loss:  0.013555822372436523 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  156 | Train Loss:  0.013698424100875855 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  157 | Train Loss:  0.013590105772018433 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  158 | Train Loss:  0.013435462713241577 | Train Accuracy:  0.6 | Validation Accuracy:  0.48\n",
            "Iteration:  159 | Train Loss:  0.013801175355911254 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  160 | Train Loss:  0.013858555555343629 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  161 | Train Loss:  0.013341033458709716 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  162 | Train Loss:  0.013393833637237548 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  163 | Train Loss:  0.013608251810073852 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  164 | Train Loss:  0.01347609519958496 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  165 | Train Loss:  0.013233284950256347 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  166 | Train Loss:  0.013638726472854613 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  167 | Train Loss:  0.013995916843414306 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  168 | Train Loss:  0.013116718530654907 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  169 | Train Loss:  0.013192790746688842 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  170 | Train Loss:  0.013502476215362548 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  171 | Train Loss:  0.01337369203567505 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  172 | Train Loss:  0.012999593019485474 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  173 | Train Loss:  0.013508375883102417 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  174 | Train Loss:  0.01406531572341919 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  175 | Train Loss:  0.012881146669387817 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  176 | Train Loss:  0.012984374761581421 | Train Accuracy:  0.62 | Validation Accuracy:  0.48\n",
            "Iteration:  177 | Train Loss:  0.013360921144485473 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  178 | Train Loss:  0.013208771944046021 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  179 | Train Loss:  0.01276421308517456 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  180 | Train Loss:  0.013406646251678467 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  181 | Train Loss:  0.013970389366149902 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  182 | Train Loss:  0.012619681358337402 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  183 | Train Loss:  0.012738773822784424 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  184 | Train Loss:  0.013197054862976074 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  185 | Train Loss:  0.012998509407043456 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  186 | Train Loss:  0.012510724067687988 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  187 | Train Loss:  0.01327265977859497 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  188 | Train Loss:  0.013816627264022828 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  189 | Train Loss:  0.012336641550064087 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  190 | Train Loss:  0.01245212197303772 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  191 | Train Loss:  0.01302361249923706 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  192 | Train Loss:  0.012775242328643799 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  193 | Train Loss:  0.012216249704360962 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  194 | Train Loss:  0.013000324964523316 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  195 | Train Loss:  0.013768821954727173 | Train Accuracy:  0.64 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  196 | Train Loss:  0.01204705834388733 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  197 | Train Loss:  0.012098246812820434 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  198 | Train Loss:  0.012885552644729615 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  199 | Train Loss:  0.012575132846832275 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  200 | Train Loss:  0.011896903514862061 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  201 | Train Loss:  0.012571020126342774 | Train Accuracy:  0.6 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  202 | Train Loss:  0.01394044518470764 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  203 | Train Loss:  0.01176634907722473 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  204 | Train Loss:  0.011697392463684082 | Train Accuracy:  0.64 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  205 | Train Loss:  0.01284701943397522 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  206 | Train Loss:  0.012455979585647583 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  207 | Train Loss:  0.011573848724365234 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  208 | Train Loss:  0.012069404125213623 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  209 | Train Loss:  0.014315617084503175 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  210 | Train Loss:  0.0115199875831604 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  211 | Train Loss:  0.011318867206573486 | Train Accuracy:  0.62 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  212 | Train Loss:  0.012910956144332885 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  213 | Train Loss:  0.012401988506317138 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  214 | Train Loss:  0.011298955678939819 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  215 | Train Loss:  0.011697735786437988 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  216 | Train Loss:  0.01458241581916809 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  217 | Train Loss:  0.011336345672607422 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  218 | Train Loss:  0.011029571294784546 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  219 | Train Loss:  0.012869522571563721 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  220 | Train Loss:  0.012387166023254395 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  221 | Train Loss:  0.01111985206604004 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  222 | Train Loss:  0.01148650884628296 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  223 | Train Loss:  0.014581053256988526 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  224 | Train Loss:  0.011273099184036255 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  225 | Train Loss:  0.010917398929595947 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  226 | Train Loss:  0.012490706443786621 | Train Accuracy:  0.6 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  227 | Train Loss:  0.01227879524230957 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  228 | Train Loss:  0.011095378398895264 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  229 | Train Loss:  0.011515542268753051 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  230 | Train Loss:  0.013942794799804687 | Train Accuracy:  0.62 | Validation Accuracy:  0.52\n",
            "Iteration:  231 | Train Loss:  0.011178622245788574 | Train Accuracy:  0.74 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  232 | Train Loss:  0.011001131534576415 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  233 | Train Loss:  0.011905225515365601 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  234 | Train Loss:  0.011834924221038818 | Train Accuracy:  0.66 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  235 | Train Loss:  0.011073222160339355 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  236 | Train Loss:  0.011775201559066773 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  237 | Train Loss:  0.012919173240661622 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  238 | Train Loss:  0.010882809162139892 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  239 | Train Loss:  0.011056523323059082 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  240 | Train Loss:  0.011437114477157593 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  241 | Train Loss:  0.011232894659042359 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  242 | Train Loss:  0.010837808847427369 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  243 | Train Loss:  0.011877331733703613 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  244 | Train Loss:  0.012140777111053467 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  245 | Train Loss:  0.010466582775115967 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  246 | Train Loss:  0.010806665420532227 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  247 | Train Loss:  0.011157011985778809 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  248 | Train Loss:  0.01077921748161316 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  249 | Train Loss:  0.010469939708709717 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  250 | Train Loss:  0.01154090166091919 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  251 | Train Loss:  0.01186526656150818 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.6\n",
            "Iteration:  252 | Train Loss:  0.010118046998977661 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  253 | Train Loss:  0.010362339019775391 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  254 | Train Loss:  0.010990344285964966 | Train Accuracy:  0.74 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  255 | Train Loss:  0.010515239238739014 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  256 | Train Loss:  0.010131763219833374 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  257 | Train Loss:  0.010961358547210693 | Train Accuracy:  0.72 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  258 | Train Loss:  0.012001610994338989 | Train Accuracy:  0.74 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  259 | Train Loss:  0.009841240644454956 | Train Accuracy:  0.8 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  260 | Train Loss:  0.009896910190582276 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  261 | Train Loss:  0.0109907066822052 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  262 | Train Loss:  0.010352495908737182 | Train Accuracy:  0.76 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  263 | Train Loss:  0.009813143014907837 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  264 | Train Loss:  0.01033295750617981 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  265 | Train Loss:  0.012380554676055908 | Train Accuracy:  0.74 | Validation Accuracy:  0.56\n",
            "Iteration:  266 | Train Loss:  0.00955892026424408 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  267 | Train Loss:  0.009441125392913818 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  268 | Train Loss:  0.011213316917419433 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  269 | Train Loss:  0.010227855443954468 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  270 | Train Loss:  0.00951783061027527 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  271 | Train Loss:  0.00982195496559143 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  272 | Train Loss:  0.012824106216430663 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  273 | Train Loss:  0.009256302714347839 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  274 | Train Loss:  0.009099485278129578 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  275 | Train Loss:  0.011564675569534302 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  276 | Train Loss:  0.01003795862197876 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  277 | Train Loss:  0.009301177263259887 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  278 | Train Loss:  0.009516180157661439 | Train Accuracy:  0.66 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  279 | Train Loss:  0.013073132038116456 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  280 | Train Loss:  0.008962178230285644 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  281 | Train Loss:  0.008909893035888673 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  282 | Train Loss:  0.011845622062683105 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  283 | Train Loss:  0.00980786681175232 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  284 | Train Loss:  0.009162495136260987 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  285 | Train Loss:  0.009348188042640686 | Train Accuracy:  0.66 | Validation Accuracy:  0.6\n",
            "Iteration:  286 | Train Loss:  0.013137733936309815 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  287 | Train Loss:  0.008729800581932068 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  288 | Train Loss:  0.008775898218154908 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  289 | Train Loss:  0.011908470392227173 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  290 | Train Loss:  0.009619476199150085 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  291 | Train Loss:  0.009007787108421325 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  292 | Train Loss:  0.009193985462188721 | Train Accuracy:  0.66 | Validation Accuracy:  0.6\n",
            "Iteration:  293 | Train Loss:  0.013164384365081787 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  294 | Train Loss:  0.00854829490184784 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  295 | Train Loss:  0.008596534729003907 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  296 | Train Loss:  0.011853052377700806 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  297 | Train Loss:  0.009562239050865173 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  298 | Train Loss:  0.008793936967849731 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  299 | Train Loss:  0.009016422033309936 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  300 | Train Loss:  0.013316524028778077 | Train Accuracy:  0.82 | Validation Accuracy:  0.56\n",
            "Iteration:  301 | Train Loss:  0.00842716932296753 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  302 | Train Loss:  0.0083684903383255 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  303 | Train Loss:  0.011748485565185547 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  304 | Train Loss:  0.00967857301235199 | Train Accuracy:  0.84 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  305 | Train Loss:  0.008569164872169495 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  306 | Train Loss:  0.00880422830581665 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  307 | Train Loss:  0.013557031154632568 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  308 | Train Loss:  0.008422744274139405 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  309 | Train Loss:  0.008142449855804444 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  310 | Train Loss:  0.011508896350860595 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  311 | Train Loss:  0.009939891695976257 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  312 | Train Loss:  0.008447659015655518 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  313 | Train Loss:  0.00857301652431488 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  314 | Train Loss:  0.013732244968414306 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  315 | Train Loss:  0.008595415353775025 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  316 | Train Loss:  0.008038588166236878 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  317 | Train Loss:  0.01102561354637146 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  318 | Train Loss:  0.010226479768753051 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  319 | Train Loss:  0.008558698296546936 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  320 | Train Loss:  0.008405754566192627 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.56\n",
            "Iteration:  321 | Train Loss:  0.013569694757461549 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  322 | Train Loss:  0.008926168084144592 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  323 | Train Loss:  0.008238819241523743 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  324 | Train Loss:  0.010217949151992797 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  325 | Train Loss:  0.010282732248306274 | Train Accuracy:  0.74 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  326 | Train Loss:  0.008941437602043151 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  327 | Train Loss:  0.008507584929466247 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  328 | Train Loss:  0.01275777816772461 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  329 | Train Loss:  0.009204323291778565 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  330 | Train Loss:  0.008871042132377625 | Train Accuracy:  0.78 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  331 | Train Loss:  0.009258670210838317 | Train Accuracy:  0.7 | Validation Accuracy:  0.52\n",
            "Iteration:  332 | Train Loss:  0.009864264130592347 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  333 | Train Loss:  0.009384824633598328 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  334 | Train Loss:  0.009101235270500184 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  335 | Train Loss:  0.011394832134246826 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  336 | Train Loss:  0.009144148230552674 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  337 | Train Loss:  0.009744764566421508 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  338 | Train Loss:  0.008548109531402589 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  339 | Train Loss:  0.008999241590499878 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  340 | Train Loss:  0.009518789649009705 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  341 | Train Loss:  0.010050837993621825 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  342 | Train Loss:  0.010002636909484863 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  343 | Train Loss:  0.008635265827178955 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  344 | Train Loss:  0.01034113645553589 | Train Accuracy:  0.88 | Validation Accuracy:  0.56\n",
            "Iteration:  345 | Train Loss:  0.008312190771102906 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  346 | Train Loss:  0.008123406767845153 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  347 | Train Loss:  0.009166905283927917 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  348 | Train Loss:  0.01079350233078003 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  349 | Train Loss:  0.00911037802696228 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  350 | Train Loss:  0.007955605983734132 | Train Accuracy:  0.72 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  351 | Train Loss:  0.010313060283660889 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  352 | Train Loss:  0.008318591117858886 | Train Accuracy:  0.84 | Validation Accuracy:  0.56\n",
            "Iteration:  353 | Train Loss:  0.00760682463645935 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  354 | Train Loss:  0.008565624952316284 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  355 | Train Loss:  0.010919198989868165 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  356 | Train Loss:  0.00870334804058075 | Train Accuracy:  0.8 | Validation Accuracy:  0.56\n",
            "Iteration:  357 | Train Loss:  0.0074371033906936645 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  358 | Train Loss:  0.009831193685531616 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  359 | Train Loss:  0.008239907026290894 | Train Accuracy:  0.86 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  360 | Train Loss:  0.0073765373229980466 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  361 | Train Loss:  0.008011616468429565 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  362 | Train Loss:  0.010522425174713135 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  363 | Train Loss:  0.008503519296646118 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  364 | Train Loss:  0.00712820291519165 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  365 | Train Loss:  0.00922140598297119 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  366 | Train Loss:  0.008002837896347046 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  367 | Train Loss:  0.007219714522361756 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  368 | Train Loss:  0.0076170766353607176 | Train Accuracy:  0.78 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  369 | Train Loss:  0.009934484362602233 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  370 | Train Loss:  0.008354697227478027 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  371 | Train Loss:  0.00691969633102417 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  372 | Train Loss:  0.00871926486492157 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  373 | Train Loss:  0.007708362340927124 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  374 | Train Loss:  0.007040193080902099 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  375 | Train Loss:  0.0073399519920349125 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  376 | Train Loss:  0.009354740381240845 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  377 | Train Loss:  0.008234763145446777 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  378 | Train Loss:  0.00673321545124054 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  379 | Train Loss:  0.008347740769386292 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  380 | Train Loss:  0.007427085638046265 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  381 | Train Loss:  0.0068444740772247315 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  382 | Train Loss:  0.007121980786323547 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  383 | Train Loss:  0.008842612504959107 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  384 | Train Loss:  0.008157182931900025 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  385 | Train Loss:  0.006551873683929443 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  386 | Train Loss:  0.008047912120819092 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  387 | Train Loss:  0.007183454632759094 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  388 | Train Loss:  0.0066625005006790165 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  389 | Train Loss:  0.006923478841781616 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  390 | Train Loss:  0.008353707194328309 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  391 | Train Loss:  0.008136455416679383 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  392 | Train Loss:  0.006375681161880493 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  393 | Train Loss:  0.007741988897323609 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  394 | Train Loss:  0.006991710662841797 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  395 | Train Loss:  0.006508416533470154 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  396 | Train Loss:  0.006715654134750366 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  397 | Train Loss:  0.007835952639579773 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  398 | Train Loss:  0.008175686597824097 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  399 | Train Loss:  0.006193932890892029 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  400 | Train Loss:  0.007370690703392029 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  401 | Train Loss:  0.006873027682304383 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  402 | Train Loss:  0.006372458934783935 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  403 | Train Loss:  0.006485868692398072 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  404 | Train Loss:  0.007305442094802856 | Train Accuracy:  0.88 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  405 | Train Loss:  0.00824317455291748 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  406 | Train Loss:  0.0059909564256668095 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  407 | Train Loss:  0.006934056878089905 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  408 | Train Loss:  0.006831157803535461 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  409 | Train Loss:  0.006214601993560791 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  410 | Train Loss:  0.006243431568145752 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  411 | Train Loss:  0.006819989085197448 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  412 | Train Loss:  0.008251242637634278 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  413 | Train Loss:  0.005773124694824219 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.56\n",
            "Iteration:  414 | Train Loss:  0.006492393612861633 | Train Accuracy:  0.88 | Validation Accuracy:  0.56\n",
            "Iteration:  415 | Train Loss:  0.006810362339019775 | Train Accuracy:  0.88 | Validation Accuracy:  0.56\n",
            "Iteration:  416 | Train Loss:  0.0059954035282135006 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  417 | Train Loss:  0.006036400198936463 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  418 | Train Loss:  0.006446149945259094 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  419 | Train Loss:  0.008088057041168212 | Train Accuracy:  0.9 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  420 | Train Loss:  0.005592910647392273 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  421 | Train Loss:  0.006132289171218872 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  422 | Train Loss:  0.0066847002506256106 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  423 | Train Loss:  0.0057268404960632326 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  424 | Train Loss:  0.005901195406913758 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  425 | Train Loss:  0.006193445920944214 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  426 | Train Loss:  0.007727322578430176 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  427 | Train Loss:  0.005492427945137024 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  428 | Train Loss:  0.005883551836013794 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  429 | Train Loss:  0.006383720636367798 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  430 | Train Loss:  0.0054856836795806885 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  431 | Train Loss:  0.005780067443847656 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  432 | Train Loss:  0.006030560135841369 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  433 | Train Loss:  0.007308146953582764 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  434 | Train Loss:  0.005402207970619201 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  435 | Train Loss:  0.005724118351936341 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  436 | Train Loss:  0.006007663607597351 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  437 | Train Loss:  0.0052967768907547 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  438 | Train Loss:  0.005577574968338012 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  439 | Train Loss:  0.005931159853935242 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  440 | Train Loss:  0.007003241777420044 | Train Accuracy:  0.92 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  441 | Train Loss:  0.005219771265983581 | Train Accuracy:  0.92 | Validation Accuracy:  0.56\n",
            "Iteration:  442 | Train Loss:  0.005623320937156677 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  443 | Train Loss:  0.005711395144462585 | Train Accuracy:  0.92 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  444 | Train Loss:  0.005109474658966064 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  445 | Train Loss:  0.005332031846046447 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  446 | Train Loss:  0.005803145170211792 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.6\n",
            "Iteration:  447 | Train Loss:  0.0068445885181427 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  448 | Train Loss:  0.004995022118091583 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  449 | Train Loss:  0.005490450859069824 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  450 | Train Loss:  0.0055274093151092525 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  451 | Train Loss:  0.004922950863838196 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  452 | Train Loss:  0.005125726461410522 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  453 | Train Loss:  0.005586293339729309 | Train Accuracy:  0.92 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  454 | Train Loss:  0.006710668206214905 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  455 | Train Loss:  0.004828530251979828 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  456 | Train Loss:  0.005283427834510804 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  457 | Train Loss:  0.005357267260551453 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  458 | Train Loss:  0.004742425084114075 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  459 | Train Loss:  0.00495827168226242 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  460 | Train Loss:  0.005381702184677124 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  461 | Train Loss:  0.006473612785339355 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  462 | Train Loss:  0.004705664813518524 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  463 | Train Loss:  0.0051050370931625365 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  464 | Train Loss:  0.0051123350858688354 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  465 | Train Loss:  0.004569679200649261 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  466 | Train Loss:  0.004772641658782959 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  467 | Train Loss:  0.005230305194854737 | Train Accuracy:  0.94 | Validation Accuracy:  0.6\n",
            "Iteration:  468 | Train Loss:  0.006234889030456543 | Train Accuracy:  0.94 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  469 | Train Loss:  0.004537002444267273 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  470 | Train Loss:  0.0049738892912864685 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  471 | Train Loss:  0.00488220751285553 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  472 | Train Loss:  0.0043952944874763485 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  473 | Train Loss:  0.004570587873458863 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  474 | Train Loss:  0.005057834982872009 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  475 | Train Loss:  0.006060122847557068 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  476 | Train Loss:  0.004360473155975342 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  477 | Train Loss:  0.0048095440864562985 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  478 | Train Loss:  0.004697806239128113 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  479 | Train Loss:  0.004225086569786072 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  480 | Train Loss:  0.004393373727798462 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  481 | Train Loss:  0.0048665648698806765 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  482 | Train Loss:  0.005854431986808777 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  483 | Train Loss:  0.004220954477787018 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  484 | Train Loss:  0.004640945196151733 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  485 | Train Loss:  0.004487488865852356 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  486 | Train Loss:  0.0040617424249649045 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  487 | Train Loss:  0.004214993715286255 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  488 | Train Loss:  0.004701200425624847 | Train Accuracy:  0.96 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  489 | Train Loss:  0.00564273476600647 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  490 | Train Loss:  0.00406006246805191 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  491 | Train Loss:  0.004495922923088074 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  492 | Train Loss:  0.004288858771324158 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  493 | Train Loss:  0.003898467719554901 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  494 | Train Loss:  0.0040355494618415835 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  495 | Train Loss:  0.004523793160915375 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  496 | Train Loss:  0.005455057024955749 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  497 | Train Loss:  0.00390765905380249 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  498 | Train Loss:  0.004331047832965851 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  499 | Train Loss:  0.004103598296642304 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  500 | Train Loss:  0.0037407997250556947 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  501 | Train Loss:  0.0038683167099952697 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  502 | Train Loss:  0.00435135155916214 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  503 | Train Loss:  0.005249399542808533 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  504 | Train Loss:  0.0037622153759002686 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  505 | Train Loss:  0.004179565012454986 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  506 | Train Loss:  0.003913667798042297 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  507 | Train Loss:  0.003586046099662781 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  508 | Train Loss:  0.0037006911635398864 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  509 | Train Loss:  0.004182514250278473 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  510 | Train Loss:  0.005058439970016479 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  511 | Train Loss:  0.003613185882568359 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  512 | Train Loss:  0.004023222625255585 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  513 | Train Loss:  0.003737890124320984 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  514 | Train Loss:  0.0034352669119834898 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  515 | Train Loss:  0.0035421791672706603 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  516 | Train Loss:  0.0040144860744476315 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  517 | Train Loss:  0.0048622727394104 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  518 | Train Loss:  0.0034725913405418397 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  519 | Train Loss:  0.0038721388578414916 | Train Accuracy:  0.96 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  520 | Train Loss:  0.0035625758767127993 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  521 | Train Loss:  0.003288401663303375 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  522 | Train Loss:  0.0033872097730636595 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  523 | Train Loss:  0.003851642906665802 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  524 | Train Loss:  0.0046736630797386165 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  525 | Train Loss:  0.0033303359150886535 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  526 | Train Loss:  0.0037215346097946166 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  527 | Train Loss:  0.00339711457490921 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  528 | Train Loss:  0.003145507574081421 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  529 | Train Loss:  0.0032392922043800354 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  530 | Train Loss:  0.0036915412545204165 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  531 | Train Loss:  0.00448491245508194 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  532 | Train Loss:  0.003193408250808716 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  533 | Train Loss:  0.003574844002723694 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  534 | Train Loss:  0.003236442506313324 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  535 | Train Loss:  0.0030066898465156556 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  536 | Train Loss:  0.0030963757634162904 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  537 | Train Loss:  0.00353581041097641 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  538 | Train Loss:  0.004302004873752594 | Train Accuracy:  0.98 | Validation Accuracy:  0.56\n",
            "Iteration:  539 | Train Loss:  0.003058590292930603 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  540 | Train Loss:  0.003429037034511566 | Train Accuracy:  0.98 | Validation Accuracy:  0.56\n",
            "Iteration:  541 | Train Loss:  0.003083142936229706 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  542 | Train Loss:  0.0028722298145294188 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  543 | Train Loss:  0.0029597508907318114 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  544 | Train Loss:  0.003385050594806671 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  545 | Train Loss:  0.00412166029214859 | Train Accuracy:  0.98 | Validation Accuracy:  0.56\n",
            "Iteration:  546 | Train Loss:  0.002925642132759094 | Train Accuracy:  0.98 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  547 | Train Loss:  0.003287689685821533 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  548 | Train Loss:  0.002936563491821289 | Train Accuracy:  0.98 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  549 | Train Loss:  0.0027420884370803833 | Train Accuracy:  0.98 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  550 | Train Loss:  0.002828747630119324 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  551 | Train Loss:  0.0032387906312942505 | Train Accuracy:  0.98 | Validation Accuracy:  0.6\n",
            "Iteration:  552 | Train Loss:  0.003946069478988647 | Train Accuracy:  0.98 | Validation Accuracy:  0.56\n",
            "Iteration:  553 | Train Loss:  0.002796073257923126 | Train Accuracy:  0.98 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  554 | Train Loss:  0.0031486445665359496 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  555 | Train Loss:  0.002796366214752197 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  556 | Train Loss:  0.0026164665818214417 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  557 | Train Loss:  0.002703332006931305 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  558 | Train Loss:  0.003097703456878662 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  559 | Train Loss:  0.0037747824192047117 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  560 | Train Loss:  0.0026689934730529784 | Train Accuracy:  0.98 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  561 | Train Loss:  0.003012789785861969 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  562 | Train Loss:  0.0026628926396369936 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  563 | Train Loss:  0.0024954448640346527 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  564 | Train Loss:  0.002583487033843994 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  565 | Train Loss:  0.0029616692662239076 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  566 | Train Loss:  0.0036082801222801207 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  567 | Train Loss:  0.0025448623299598695 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  568 | Train Loss:  0.0028806763887405397 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  569 | Train Loss:  0.0025356721878051756 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  570 | Train Loss:  0.002379110902547836 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  571 | Train Loss:  0.0024688999354839326 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  572 | Train Loss:  0.002830827832221985 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  573 | Train Loss:  0.0034473639726638793 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  574 | Train Loss:  0.002423715740442276 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  575 | Train Loss:  0.0027509620785713196 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  576 | Train Loss:  0.0024147842824459075 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  577 | Train Loss:  0.002267446517944336 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  578 | Train Loss:  0.0023595532774925232 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  579 | Train Loss:  0.0027052003145217897 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  580 | Train Loss:  0.0032913312315940857 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  581 | Train Loss:  0.002305282652378082 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  582 | Train Loss:  0.0026254689693450926 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  583 | Train Loss:  0.002299891710281372 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  584 | Train Loss:  0.002160492539405823 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  585 | Train Loss:  0.002255048751831055 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  586 | Train Loss:  0.002584555149078369 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  587 | Train Loss:  0.003141361474990845 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  588 | Train Loss:  0.002190652042627335 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  589 | Train Loss:  0.0025027912855148317 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  590 | Train Loss:  0.0021905553340911864 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  591 | Train Loss:  0.0020580759644508364 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  592 | Train Loss:  0.0021552643179893493 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  593 | Train Loss:  0.0024689826369285583 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  594 | Train Loss:  0.0029972314834594725 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  595 | Train Loss:  0.0020785064995288848 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  596 | Train Loss:  0.0023837991058826445 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  597 | Train Loss:  0.0020870888233184815 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  598 | Train Loss:  0.001960202753543854 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  599 | Train Loss:  0.002060072720050812 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  600 | Train Loss:  0.0023581641912460327 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  601 | Train Loss:  0.0028583869338035584 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  602 | Train Loss:  0.0019707344472408295 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  603 | Train Loss:  0.002268911749124527 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  604 | Train Loss:  0.0019884608685970307 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  605 | Train Loss:  0.0018667827546596527 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  606 | Train Loss:  0.0019690580666065216 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  607 | Train Loss:  0.0022520570456981658 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  608 | Train Loss:  0.002725801169872284 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  609 | Train Loss:  0.0018671506643295288 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  610 | Train Loss:  0.0021572910249233247 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  611 | Train Loss:  0.0018948335945606232 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  612 | Train Loss:  0.0017775999009609223 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  613 | Train Loss:  0.0018820914626121522 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  614 | Train Loss:  0.0021505384147167206 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  615 | Train Loss:  0.0025987428426742553 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  616 | Train Loss:  0.0017667886614799498 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  617 | Train Loss:  0.0020501114428043365 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  618 | Train Loss:  0.0018062120676040649 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  619 | Train Loss:  0.001692664921283722 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  620 | Train Loss:  0.0017990097403526306 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  621 | Train Loss:  0.002053464651107788 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  622 | Train Loss:  0.0024772509932518005 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  623 | Train Loss:  0.0016710245609283447 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  624 | Train Loss:  0.0019469787180423736 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  625 | Train Loss:  0.0017219579219818115 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  626 | Train Loss:  0.0016118091344833373 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  627 | Train Loss:  0.0017196053266525268 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  628 | Train Loss:  0.0019607357680797577 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  629 | Train Loss:  0.0023612165451049804 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  630 | Train Loss:  0.0015794581174850464 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  631 | Train Loss:  0.001848437488079071 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  632 | Train Loss:  0.001642087697982788 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  633 | Train Loss:  0.0015349388122558594 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  634 | Train Loss:  0.0016437120735645293 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  635 | Train Loss:  0.00187224879860878 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  636 | Train Loss:  0.0022504226863384246 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  637 | Train Loss:  0.0014925123751163482 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  638 | Train Loss:  0.0017544978857040405 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  639 | Train Loss:  0.0015662774443626405 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  640 | Train Loss:  0.0014619213342666627 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  641 | Train Loss:  0.0015711434185504912 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  642 | Train Loss:  0.0017879077792167665 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  643 | Train Loss:  0.002144826650619507 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  644 | Train Loss:  0.0014100386202335357 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  645 | Train Loss:  0.0016649335622787476 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  646 | Train Loss:  0.0014943677186965943 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  647 | Train Loss:  0.0013925927877426149 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  648 | Train Loss:  0.0015017974376678467 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  649 | Train Loss:  0.0017076089978218078 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  650 | Train Loss:  0.0020441947877407073 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  651 | Train Loss:  0.0013321100175380707 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  652 | Train Loss:  0.001579975336790085 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  653 | Train Loss:  0.0014261694252490997 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  654 | Train Loss:  0.0013268591463565826 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  655 | Train Loss:  0.0014355550706386566 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  656 | Train Loss:  0.0016312365233898162 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  657 | Train Loss:  0.0019483157992362975 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  658 | Train Loss:  0.0012582460045814515 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  659 | Train Loss:  0.0014996810257434845 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  660 | Train Loss:  0.0013616007566452026 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  661 | Train Loss:  0.0012646089494228363 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  662 | Train Loss:  0.0013723422586917877 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  663 | Train Loss:  0.0015586599707603454 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  664 | Train Loss:  0.0018569256365299225 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  665 | Train Loss:  0.0011887628585100173 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  666 | Train Loss:  0.0014240676164627075 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  667 | Train Loss:  0.0013004010915756226 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  668 | Train Loss:  0.0012057285010814668 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  669 | Train Loss:  0.0013120530545711517 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  670 | Train Loss:  0.001489732712507248 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  671 | Train Loss:  0.0017699243128299713 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  672 | Train Loss:  0.001123644858598709 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  673 | Train Loss:  0.001352783739566803 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  674 | Train Loss:  0.0012422986328601837 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  675 | Train Loss:  0.0011500471085309982 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  676 | Train Loss:  0.001254553496837616 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  677 | Train Loss:  0.0014243045449256898 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  678 | Train Loss:  0.0016873258352279664 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  679 | Train Loss:  0.0010625999420881271 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  680 | Train Loss:  0.0012854336202144624 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  681 | Train Loss:  0.0011872120946645737 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  682 | Train Loss:  0.0010973815619945526 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  683 | Train Loss:  0.0011997754871845246 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  684 | Train Loss:  0.0013622242212295533 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  685 | Train Loss:  0.0016089814901351928 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  686 | Train Loss:  0.0010055330395698546 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  687 | Train Loss:  0.0012217691540718078 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  688 | Train Loss:  0.0011349648237228393 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  689 | Train Loss:  0.0010475601255893708 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  690 | Train Loss:  0.0011476142704486846 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  691 | Train Loss:  0.0013033430278301238 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  692 | Train Loss:  0.001534736156463623 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  693 | Train Loss:  0.0009518282860517502 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  694 | Train Loss:  0.0011617469042539596 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  695 | Train Loss:  0.0010855137556791306 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  696 | Train Loss:  0.0010004625469446182 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  697 | Train Loss:  0.0010980561375617981 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  698 | Train Loss:  0.0012475024908781053 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  699 | Train Loss:  0.001464175581932068 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  700 | Train Loss:  0.0009015969932079315 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  701 | Train Loss:  0.0011053900420665741 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  702 | Train Loss:  0.0010386105626821519 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  703 | Train Loss:  0.0009559788554906845 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  704 | Train Loss:  0.0010509070754051207 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  705 | Train Loss:  0.0011945468932390213 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  706 | Train Loss:  0.0013973462581634523 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  707 | Train Loss:  0.0008547341078519821 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  708 | Train Loss:  0.0010522146522998809 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  709 | Train Loss:  0.000994121804833412 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  710 | Train Loss:  0.0009139157086610794 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  711 | Train Loss:  0.0010060902684926986 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  712 | Train Loss:  0.0011443337798118592 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  713 | Train Loss:  0.0013340738415718078 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  714 | Train Loss:  0.0008108384907245636 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  715 | Train Loss:  0.0010020868480205536 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  716 | Train Loss:  0.0009519805014133454 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  717 | Train Loss:  0.0008741505444049835 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  718 | Train Loss:  0.0009635602682828903 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  719 | Train Loss:  0.0010967203974723816 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  720 | Train Loss:  0.0012740960717201233 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  721 | Train Loss:  0.0007697246968746185 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  722 | Train Loss:  0.0009549522399902344 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  723 | Train Loss:  0.0009120535105466843 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  724 | Train Loss:  0.0008365777134895325 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  725 | Train Loss:  0.0009231777489185334 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  726 | Train Loss:  0.0010515554249286652 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  727 | Train Loss:  0.001217290610074997 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  728 | Train Loss:  0.0007313729077577591 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  729 | Train Loss:  0.0009105458110570908 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  730 | Train Loss:  0.0008741626143455505 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  731 | Train Loss:  0.0008010466396808625 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  732 | Train Loss:  0.0008848122507333756 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  733 | Train Loss:  0.0010087119042873382 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  734 | Train Loss:  0.001163569986820221 | Train Accuracy:  1.0 | Validation Accuracy:  0.48\n",
            "Iteration:  735 | Train Loss:  0.0006955046951770782 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  736 | Train Loss:  0.0008686232566833496 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  737 | Train Loss:  0.000838252529501915 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  738 | Train Loss:  0.0007674241811037063 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  739 | Train Loss:  0.0008484291285276413 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  740 | Train Loss:  0.0009680662304162979 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  741 | Train Loss:  0.0011126704514026642 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  742 | Train Loss:  0.0006618985533714295 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  743 | Train Loss:  0.0008291769772768021 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  744 | Train Loss:  0.0008041974157094956 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  745 | Train Loss:  0.0007356281578540802 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  746 | Train Loss:  0.0008139009773731232 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  747 | Train Loss:  0.0009294895082712174 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  748 | Train Loss:  0.00106447696685791 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  749 | Train Loss:  0.0006304627656936645 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  750 | Train Loss:  0.000792006254196167 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  751 | Train Loss:  0.0007718835026025772 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  752 | Train Loss:  0.0007055427879095078 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  753 | Train Loss:  0.0007811003923416138 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  754 | Train Loss:  0.0008928706496953965 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  755 | Train Loss:  0.0010188954323530196 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  756 | Train Loss:  0.0006010474264621735 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  757 | Train Loss:  0.000756860226392746 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  758 | Train Loss:  0.0007412305474281311 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  759 | Train Loss:  0.0006770414113998414 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  760 | Train Loss:  0.0007500291615724564 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  761 | Train Loss:  0.0008581076562404632 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  762 | Train Loss:  0.0009756714105606079 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  763 | Train Loss:  0.0005733755603432655 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  764 | Train Loss:  0.0007238105684518815 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  765 | Train Loss:  0.0007121552526950836 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  766 | Train Loss:  0.0006500721722841263 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  767 | Train Loss:  0.000720546692609787 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  768 | Train Loss:  0.0008250728249549865 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  769 | Train Loss:  0.0009347285330295563 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  770 | Train Loss:  0.00054757971316576 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  771 | Train Loss:  0.0006925807148218155 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  772 | Train Loss:  0.0006845356523990632 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  773 | Train Loss:  0.0006245069578289986 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  774 | Train Loss:  0.0006925485283136367 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  775 | Train Loss:  0.0007936923205852509 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  776 | Train Loss:  0.0008959568291902542 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  777 | Train Loss:  0.0005233112722635269 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  778 | Train Loss:  0.0006631114333868027 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  779 | Train Loss:  0.0006583159416913986 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  780 | Train Loss:  0.0006002793833613395 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  781 | Train Loss:  0.0006659874320030213 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  782 | Train Loss:  0.0007638540863990783 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  783 | Train Loss:  0.0008592145889997482 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  784 | Train Loss:  0.0005006132274866104 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  785 | Train Loss:  0.0006352515518665314 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  786 | Train Loss:  0.0006333958357572555 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  787 | Train Loss:  0.0005772967636585236 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  788 | Train Loss:  0.0006407486647367478 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  789 | Train Loss:  0.0007354828715324402 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  790 | Train Loss:  0.0008243972808122635 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  791 | Train Loss:  0.0004792775958776474 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  792 | Train Loss:  0.0006089286878705024 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  793 | Train Loss:  0.0006097284331917763 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  794 | Train Loss:  0.0005554958805441857 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  795 | Train Loss:  0.0006167931854724884 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  796 | Train Loss:  0.0007084915786981583 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  797 | Train Loss:  0.0007913719117641449 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  798 | Train Loss:  0.0004592377319931984 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  799 | Train Loss:  0.0005840344727039337 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  800 | Train Loss:  0.0005872334539890289 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  801 | Train Loss:  0.0005348028987646103 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  802 | Train Loss:  0.0005940315127372742 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  803 | Train Loss:  0.0006828046590089798 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  804 | Train Loss:  0.000760069340467453 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  805 | Train Loss:  0.00044040173292160035 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  806 | Train Loss:  0.0005604580417275429 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  807 | Train Loss:  0.0005658537521958351 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  808 | Train Loss:  0.0005151486024260521 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  809 | Train Loss:  0.0005724302306771279 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  810 | Train Loss:  0.0006583519279956818 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  811 | Train Loss:  0.0007303390651941299 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  812 | Train Loss:  0.0004226400703191757 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  813 | Train Loss:  0.0005381976440548896 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  814 | Train Loss:  0.0005455131083726883 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  815 | Train Loss:  0.0004964887723326683 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  816 | Train Loss:  0.0005518738180398941 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  817 | Train Loss:  0.0006350518018007279 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  818 | Train Loss:  0.0007021500170230865 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  819 | Train Loss:  0.00040603205561637876 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  820 | Train Loss:  0.0005170365422964096 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  821 | Train Loss:  0.0005261518061161041 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  822 | Train Loss:  0.00047873295843601225 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  823 | Train Loss:  0.0005323576554656029 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  824 | Train Loss:  0.0006128633394837379 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  825 | Train Loss:  0.0006753680109977722 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  826 | Train Loss:  0.00039025600999593736 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  827 | Train Loss:  0.0004970426857471466 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  828 | Train Loss:  0.0005077376961708068 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  829 | Train Loss:  0.00046186413615942004 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  830 | Train Loss:  0.0005138153955340385 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  831 | Train Loss:  0.0005916951596736908 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  832 | Train Loss:  0.0006499212235212326 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  833 | Train Loss:  0.00037554282695055006 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  834 | Train Loss:  0.00047803770750761034 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  835 | Train Loss:  0.0004901895672082901 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  836 | Train Loss:  0.0004458026960492134 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  837 | Train Loss:  0.0004961664974689483 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  838 | Train Loss:  0.0005715209618210792 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  839 | Train Loss:  0.0006257528066635131 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  840 | Train Loss:  0.0003615458682179451 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  841 | Train Loss:  0.00046001985669136047 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  842 | Train Loss:  0.0004734871909022331 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  843 | Train Loss:  0.0004305209219455719 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  844 | Train Loss:  0.0004794158041477203 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  845 | Train Loss:  0.0005522674694657326 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  846 | Train Loss:  0.0006027374416589737 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  847 | Train Loss:  0.00034841392189264295 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  848 | Train Loss:  0.0004429413378238678 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  849 | Train Loss:  0.0004575559496879578 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  850 | Train Loss:  0.00041597094386816027 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  851 | Train Loss:  0.0004634169116616249 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  852 | Train Loss:  0.0005338906869292259 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  853 | Train Loss:  0.0005808879435062409 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  854 | Train Loss:  0.0003360269591212273 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  855 | Train Loss:  0.00042666565626859666 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  856 | Train Loss:  0.00044238071888685226 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  857 | Train Loss:  0.0004021034762263298 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  858 | Train Loss:  0.00044828690588474276 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  859 | Train Loss:  0.0005163470283150673 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  860 | Train Loss:  0.0005600534752011299 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  861 | Train Loss:  0.00032427802681922913 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  862 | Train Loss:  0.000411255843937397 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  863 | Train Loss:  0.0004279012978076935 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  864 | Train Loss:  0.0003888943791389465 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  865 | Train Loss:  0.0004338228702545166 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  866 | Train Loss:  0.0004995788633823395 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  867 | Train Loss:  0.0005402444675564766 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  868 | Train Loss:  0.0003132888302206993 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  869 | Train Loss:  0.00039655432105064394 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  870 | Train Loss:  0.00041408304125070575 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  871 | Train Loss:  0.00037629388272762297 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  872 | Train Loss:  0.0004201145097613335 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  873 | Train Loss:  0.0004835602268576622 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  874 | Train Loss:  0.0005213521420955658 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  875 | Train Loss:  0.00030281562358140944 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  876 | Train Loss:  0.00038260791450738906 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  877 | Train Loss:  0.0004008955880999565 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  878 | Train Loss:  0.00036427810788154603 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  879 | Train Loss:  0.0004070559144020081 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  880 | Train Loss:  0.0004682367295026779 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  881 | Train Loss:  0.0005033571645617485 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  882 | Train Loss:  0.000293023157864809 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  883 | Train Loss:  0.00036931194365024566 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  884 | Train Loss:  0.0003882952779531479 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  885 | Train Loss:  0.0003528112173080444 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  886 | Train Loss:  0.0003946245461702347 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  887 | Train Loss:  0.00045358404517173765 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  888 | Train Loss:  0.0004861971363425255 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  889 | Train Loss:  0.00028369519859552386 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  890 | Train Loss:  0.00035666387528181075 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  891 | Train Loss:  0.0003762615099549293 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  892 | Train Loss:  0.0003418637067079544 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  893 | Train Loss:  0.00038279112428426745 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  894 | Train Loss:  0.0004395600780844688 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  895 | Train Loss:  0.00046983469277620313 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  896 | Train Loss:  0.00027494532987475394 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  897 | Train Loss:  0.00034460067749023435 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  898 | Train Loss:  0.0003647620230913162 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  899 | Train Loss:  0.0003314114734530449 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  900 | Train Loss:  0.0003715830296278 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  901 | Train Loss:  0.00042613573372364045 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  902 | Train Loss:  0.0004542091861367226 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  903 | Train Loss:  0.0002666699886322021 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  904 | Train Loss:  0.00033312059938907625 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  905 | Train Loss:  0.00035376068204641343 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  906 | Train Loss:  0.0003214263543486595 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  907 | Train Loss:  0.0003608657047152519 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  908 | Train Loss:  0.00041328094899654386 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  909 | Train Loss:  0.0004393010213971138 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  910 | Train Loss:  0.00025883326306939123 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  911 | Train Loss:  0.0003221707418560982 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  912 | Train Loss:  0.00034324798732995984 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  913 | Train Loss:  0.00031188657507300375 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  914 | Train Loss:  0.0003507497161626816 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  915 | Train Loss:  0.0004009667783975601 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  916 | Train Loss:  0.0004250530153512955 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  917 | Train Loss:  0.0002514912374317646 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  918 | Train Loss:  0.00031173473224043846 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  919 | Train Loss:  0.00033318709582090376 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  920 | Train Loss:  0.0003027608804404736 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  921 | Train Loss:  0.000341062992811203 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  922 | Train Loss:  0.0003891681507229805 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  923 | Train Loss:  0.00041145071387290957 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  924 | Train Loss:  0.0002445696294307709 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  925 | Train Loss:  0.00030178332701325417 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  926 | Train Loss:  0.0003235619515180588 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  927 | Train Loss:  0.0002940511144697666 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  928 | Train Loss:  0.00033198613673448565 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  929 | Train Loss:  0.0003778572380542755 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  930 | Train Loss:  0.00039843607693910597 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  931 | Train Loss:  0.00023800553753972054 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  932 | Train Loss:  0.0002923000603914261 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  933 | Train Loss:  0.0003143397718667984 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  934 | Train Loss:  0.0002857113443315029 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  935 | Train Loss:  0.00032327000051736833 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  936 | Train Loss:  0.00036701589822769166 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  937 | Train Loss:  0.0003860010951757431 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  938 | Train Loss:  0.00023185187950730324 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  939 | Train Loss:  0.000283261314034462 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  940 | Train Loss:  0.0003055126219987869 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  941 | Train Loss:  0.0002777468226850033 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  942 | Train Loss:  0.0003151333332061768 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  943 | Train Loss:  0.0003566211462020874 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  944 | Train Loss:  0.0003741007670760155 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  945 | Train Loss:  0.000226104948669672 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  946 | Train Loss:  0.0002746418863534927 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  947 | Train Loss:  0.00029704684391617775 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  948 | Train Loss:  0.00027012815698981287 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  949 | Train Loss:  0.00030736666172742844 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  950 | Train Loss:  0.00034665118902921677 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  951 | Train Loss:  0.0003627163916826248 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  952 | Train Loss:  0.00022068327292799948 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  953 | Train Loss:  0.0002664310857653618 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  954 | Train Loss:  0.0002889377065002918 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  955 | Train Loss:  0.00026284337043762206 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  956 | Train Loss:  0.00030008623376488687 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  957 | Train Loss:  0.0003370943292975426 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  958 | Train Loss:  0.00035182029008865354 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  959 | Train Loss:  0.00021565981209278106 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  960 | Train Loss:  0.0002586149610579014 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  961 | Train Loss:  0.0002811607904732227 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  962 | Train Loss:  0.0002558840252459049 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  963 | Train Loss:  0.0002932230941951275 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  964 | Train Loss:  0.0003279266506433487 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  965 | Train Loss:  0.00034138839691877365 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  966 | Train Loss:  0.00021095436066389083 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  967 | Train Loss:  0.0002511725202202797 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  968 | Train Loss:  0.00027370523661375047 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  969 | Train Loss:  0.0002492254041135311 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  970 | Train Loss:  0.0002867712825536728 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  971 | Train Loss:  0.0003191396594047546 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  972 | Train Loss:  0.0003313974291086197 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  973 | Train Loss:  0.00020660454407334328 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  974 | Train Loss:  0.00024410862475633623 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  975 | Train Loss:  0.0002665564976632595 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  976 | Train Loss:  0.00024287110194563864 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  977 | Train Loss:  0.0002807725593447685 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  978 | Train Loss:  0.0003107147663831711 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  979 | Train Loss:  0.0003218307718634605 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  980 | Train Loss:  0.00020258860662579535 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  981 | Train Loss:  0.00023739539086818694 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  982 | Train Loss:  0.0002597006782889366 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  983 | Train Loss:  0.00023679360747337342 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  984 | Train Loss:  0.000275160763412714 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  985 | Train Loss:  0.000302644744515419 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  986 | Train Loss:  0.000312664732336998 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  987 | Train Loss:  0.0001989094540476799 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  988 | Train Loss:  0.00023104045540094375 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  989 | Train Loss:  0.0002531233802437782 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  990 | Train Loss:  0.00023100104182958604 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  991 | Train Loss:  0.0002699622884392738 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  992 | Train Loss:  0.0002949093654751778 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  993 | Train Loss:  0.0003038818761706352 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  994 | Train Loss:  0.00019551457837224006 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  995 | Train Loss:  0.00022502340376377106 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  996 | Train Loss:  0.00024682158604264257 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  997 | Train Loss:  0.00022545576095581055 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  998 | Train Loss:  0.0002651848830282688 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  999 | Train Loss:  0.00028751805424690244 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1000 | Train Loss:  0.00029546260833740234 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1001 | Train Loss:  0.0001925046741962433 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1002 | Train Loss:  0.00021937055513262748 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1003 | Train Loss:  0.0002407761663198471 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1004 | Train Loss:  0.00022018680348992348 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1005 | Train Loss:  0.00026086807250976564 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1006 | Train Loss:  0.00028044383972883227 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1007 | Train Loss:  0.00028740229085087775 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1008 | Train Loss:  0.00018980149179697036 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1009 | Train Loss:  0.00021403171122074126 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1010 | Train Loss:  0.0002349766343832016 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1011 | Train Loss:  0.0002151532843708992 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1012 | Train Loss:  0.00025690235197544097 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1013 | Train Loss:  0.00027368752285838126 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1014 | Train Loss:  0.00027966687455773355 | Train Accuracy:  1.0 | Validation Accuracy:  0.48\n",
            "Iteration:  1015 | Train Loss:  0.0001874156855046749 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1016 | Train Loss:  0.00020905202254652976 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1017 | Train Loss:  0.00022942395880818368 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1018 | Train Loss:  0.00021036392077803613 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1019 | Train Loss:  0.0002534201368689537 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1020 | Train Loss:  0.0002672501653432846 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1021 | Train Loss:  0.00027226006612181665 | Train Accuracy:  1.0 | Validation Accuracy:  0.48\n",
            "Iteration:  1022 | Train Loss:  0.00018538374453783035 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1023 | Train Loss:  0.0002044045925140381 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1024 | Train Loss:  0.00022410035133361818 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1025 | Train Loss:  0.00020580664277076722 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1026 | Train Loss:  0.0002503238618373871 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1027 | Train Loss:  0.00026111103594303133 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1028 | Train Loss:  0.0002651576325297356 | Train Accuracy:  1.0 | Validation Accuracy:  0.48\n",
            "Iteration:  1029 | Train Loss:  0.00018365688621997832 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1030 | Train Loss:  0.00020010178908705712 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1031 | Train Loss:  0.0002190069667994976 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1032 | Train Loss:  0.00020146993920207025 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1033 | Train Loss:  0.0002476736716926098 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1034 | Train Loss:  0.00025528853759169577 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1035 | Train Loss:  0.00025834864005446433 | Train Accuracy:  1.0 | Validation Accuracy:  0.48\n",
            "Iteration:  1036 | Train Loss:  0.00018228061497211457 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1037 | Train Loss:  0.00019614072516560555 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1038 | Train Loss:  0.00021412920206785203 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1039 | Train Loss:  0.00019735626876354217 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1040 | Train Loss:  0.00024545274674892426 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1041 | Train Loss:  0.0002497640624642372 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1042 | Train Loss:  0.00025182070210576056 | Train Accuracy:  1.0 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  1043 | Train Loss:  0.0001812373846769333 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1044 | Train Loss:  0.00019254036247730256 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1045 | Train Loss:  0.0002094685472548008 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1046 | Train Loss:  0.00019345642998814584 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1047 | Train Loss:  0.00024370033293962478 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  1048 | Train Loss:  0.0002445453591644764 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1049 | Train Loss:  0.00024556925520300863 | Train Accuracy:  1.0 | Validation Accuracy:  0.48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 1.0\n",
            "Final Validation Accuracy: 0.48\n",
            "Maximum Training Accuracy: 1.0\n",
            "Maximum Validation Accuracy: 0.6266666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "glA2f6kCywgj",
        "outputId": "84be1ab5-503c-4e52-d04b-ff7910973caa"
      },
      "source": [
        "model = ANN_TS_3L()\n",
        "train(model, train_dataset, val_dataset, batch_size = 50, num_epochs=100, learning_rate = 0.001, momen = 0.4, use_adam = True, save_weights=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.013847697973251343 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1 | Train Loss:  0.013943192958831787 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2 | Train Loss:  0.013874461650848388 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3 | Train Loss:  0.013870998620986938 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  4 | Train Loss:  0.013886497020721436 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  5 | Train Loss:  0.013785279989242553 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  6 | Train Loss:  0.013964804410934449 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  7 | Train Loss:  0.013853031396865844 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  8 | Train Loss:  0.013886026144027709 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  9 | Train Loss:  0.013864097595214843 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  10 | Train Loss:  0.01386360764503479 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  11 | Train Loss:  0.013868191242218018 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  12 | Train Loss:  0.013845429420471192 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  13 | Train Loss:  0.013885079622268677 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  14 | Train Loss:  0.01386128544807434 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  15 | Train Loss:  0.013863587379455566 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  16 | Train Loss:  0.013862920999526978 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  17 | Train Loss:  0.013862937688827515 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  18 | Train Loss:  0.01385898232460022 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  19 | Train Loss:  0.013896238803863526 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  20 | Train Loss:  0.013828201293945313 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  21 | Train Loss:  0.01386958122253418 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  22 | Train Loss:  0.013849444389343261 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  23 | Train Loss:  0.013863908052444458 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  24 | Train Loss:  0.013864068984985352 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  25 | Train Loss:  0.013854167461395263 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  26 | Train Loss:  0.013930484056472778 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  27 | Train Loss:  0.013792991638183594 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  28 | Train Loss:  0.013875576257705689 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  29 | Train Loss:  0.013841640949249268 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  30 | Train Loss:  0.01386520743370056 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  31 | Train Loss:  0.013865307569503785 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  32 | Train Loss:  0.013851799964904786 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  33 | Train Loss:  0.013950581550598145 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  34 | Train Loss:  0.013773690462112426 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  35 | Train Loss:  0.013879098892211915 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  36 | Train Loss:  0.013837692737579345 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  37 | Train Loss:  0.013866052627563477 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  38 | Train Loss:  0.013866031169891357 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  39 | Train Loss:  0.013850719928741454 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  40 | Train Loss:  0.013959648609161377 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  41 | Train Loss:  0.013765422105789184 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  42 | Train Loss:  0.013880493640899659 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  43 | Train Loss:  0.013836183547973634 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  44 | Train Loss:  0.013866342306137085 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  45 | Train Loss:  0.013866201639175416 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  46 | Train Loss:  0.013850337266921997 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  47 | Train Loss:  0.01396141767501831 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  48 | Train Loss:  0.013763952255249023 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  49 | Train Loss:  0.013880515098571777 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  50 | Train Loss:  0.01383603572845459 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  51 | Train Loss:  0.013866262435913086 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  52 | Train Loss:  0.013866037130355835 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  53 | Train Loss:  0.013850289583206176 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  54 | Train Loss:  0.013959537744522094 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  55 | Train Loss:  0.013765721321105958 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  56 | Train Loss:  0.013879904747009278 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  57 | Train Loss:  0.013836467266082763 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  58 | Train Loss:  0.013866037130355835 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  59 | Train Loss:  0.013865749835968017 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  60 | Train Loss:  0.013850361108779907 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  61 | Train Loss:  0.013956621885299683 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  62 | Train Loss:  0.013768316507339477 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  63 | Train Loss:  0.013879176378250122 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  64 | Train Loss:  0.013836984634399413 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  65 | Train Loss:  0.013865807056427003 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  66 | Train Loss:  0.013865474462509155 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  67 | Train Loss:  0.013850417137145996 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  68 | Train Loss:  0.013954076766967773 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  69 | Train Loss:  0.013770495653152465 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  70 | Train Loss:  0.013878564834594726 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  71 | Train Loss:  0.013837355375289916 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  72 | Train Loss:  0.01386562705039978 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  73 | Train Loss:  0.013865249156951904 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  74 | Train Loss:  0.013850398063659668 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  75 | Train Loss:  0.013952404260635376 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  76 | Train Loss:  0.013771815299987793 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  77 | Train Loss:  0.01387814164161682 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  78 | Train Loss:  0.013837502002716065 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  79 | Train Loss:  0.01386550784111023 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  80 | Train Loss:  0.013865079879760742 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  81 | Train Loss:  0.013850289583206176 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  82 | Train Loss:  0.013951628208160401 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  83 | Train Loss:  0.013772283792495727 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  84 | Train Loss:  0.013877888917922973 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  85 | Train Loss:  0.013837450742721557 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  86 | Train Loss:  0.013865437507629395 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  87 | Train Loss:  0.0138649582862854 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  88 | Train Loss:  0.013850107192993164 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  89 | Train Loss:  0.013951547145843506 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  90 | Train Loss:  0.013772103786468506 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  91 | Train Loss:  0.013877757787704469 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  92 | Train Loss:  0.013837249279022216 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  93 | Train Loss:  0.013865398168563843 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  94 | Train Loss:  0.013864856958389283 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  95 | Train Loss:  0.013849865198135376 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  96 | Train Loss:  0.01395191192626953 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  97 | Train Loss:  0.013771510124206543 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  98 | Train Loss:  0.013877689838409424 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  99 | Train Loss:  0.01383694887161255 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  100 | Train Loss:  0.013865376710891724 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  101 | Train Loss:  0.013864773511886596 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  102 | Train Loss:  0.013849586248397827 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  103 | Train Loss:  0.013952507972717285 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  104 | Train Loss:  0.013770720958709716 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  105 | Train Loss:  0.013877646923065185 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  106 | Train Loss:  0.013836607933044434 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  107 | Train Loss:  0.013865355253219604 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  108 | Train Loss:  0.013864680528640747 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  109 | Train Loss:  0.0138492751121521 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  110 | Train Loss:  0.013953146934509277 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  111 | Train Loss:  0.013769892454147338 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  112 | Train Loss:  0.013877590894699096 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  113 | Train Loss:  0.013836239576339721 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  114 | Train Loss:  0.01386533260345459 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  115 | Train Loss:  0.01386457085609436 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  116 | Train Loss:  0.013848942518234254 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  117 | Train Loss:  0.013953754901885987 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  118 | Train Loss:  0.013769134283065795 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  119 | Train Loss:  0.013877485990524291 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  120 | Train Loss:  0.013835880756378174 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  121 | Train Loss:  0.013865287303924561 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  122 | Train Loss:  0.013864437341690064 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  123 | Train Loss:  0.01384859561920166 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  124 | Train Loss:  0.013954259157180786 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  125 | Train Loss:  0.013768424987792969 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  126 | Train Loss:  0.013877360820770264 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  127 | Train Loss:  0.01383551001548767 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  128 | Train Loss:  0.013865240812301637 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  129 | Train Loss:  0.013864293098449706 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  130 | Train Loss:  0.013848216533660888 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  131 | Train Loss:  0.013954787254333497 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  132 | Train Loss:  0.013767704963684083 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  133 | Train Loss:  0.013877183198928833 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  134 | Train Loss:  0.013835099935531616 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  135 | Train Loss:  0.013865176439285278 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  136 | Train Loss:  0.01386411190032959 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  137 | Train Loss:  0.013847788572311401 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  138 | Train Loss:  0.0139552640914917 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  139 | Train Loss:  0.01376700758934021 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  140 | Train Loss:  0.013876981735229492 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  141 | Train Loss:  0.013834681510925293 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  142 | Train Loss:  0.013865104913711547 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  143 | Train Loss:  0.013863921165466309 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  144 | Train Loss:  0.013847334384918213 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  145 | Train Loss:  0.013955764770507813 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  146 | Train Loss:  0.013766266107559204 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  147 | Train Loss:  0.013876748085021973 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  148 | Train Loss:  0.013834218978881836 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  149 | Train Loss:  0.013865022659301758 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  150 | Train Loss:  0.013863699436187744 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  151 | Train Loss:  0.013846807479858399 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  152 | Train Loss:  0.013956308364868164 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  153 | Train Loss:  0.013765476942062378 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  154 | Train Loss:  0.013876469135284423 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  155 | Train Loss:  0.01383370041847229 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  156 | Train Loss:  0.013864904642105103 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  157 | Train Loss:  0.013863390684127808 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  158 | Train Loss:  0.013846186399459838 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  159 | Train Loss:  0.013956141471862794 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  160 | Train Loss:  0.013765721321105958 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  161 | Train Loss:  0.013875812292098999 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  162 | Train Loss:  0.013833363056182862 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  163 | Train Loss:  0.013864691257476807 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  164 | Train Loss:  0.013862994909286499 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  165 | Train Loss:  0.013845605850219727 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  166 | Train Loss:  0.013956066370010376 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  167 | Train Loss:  0.013765344619750977 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  168 | Train Loss:  0.013875306844711303 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  169 | Train Loss:  0.01383278489112854 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  170 | Train Loss:  0.013864521980285644 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  171 | Train Loss:  0.013862611055374145 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  172 | Train Loss:  0.01384485125541687 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  173 | Train Loss:  0.013956493139266968 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  174 | Train Loss:  0.01376447319984436 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  175 | Train Loss:  0.01387479305267334 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  176 | Train Loss:  0.0138319730758667 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  177 | Train Loss:  0.013864375352859497 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  178 | Train Loss:  0.013862210512161254 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  179 | Train Loss:  0.013843826055526733 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  180 | Train Loss:  0.013958300352096558 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  181 | Train Loss:  0.013762567043304443 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  182 | Train Loss:  0.0138743257522583 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  183 | Train Loss:  0.013830924034118652 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  184 | Train Loss:  0.01386417269706726 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  185 | Train Loss:  0.013861684799194337 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  186 | Train Loss:  0.01384274959564209 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  187 | Train Loss:  0.01395875096321106 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  188 | Train Loss:  0.013761444091796875 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  189 | Train Loss:  0.013873554468154907 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  190 | Train Loss:  0.01382989764213562 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  191 | Train Loss:  0.013863891363143921 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  192 | Train Loss:  0.01386102795600891 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  193 | Train Loss:  0.013841488361358643 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  194 | Train Loss:  0.013959197998046876 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  195 | Train Loss:  0.013760533332824707 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  196 | Train Loss:  0.013872504234313965 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  197 | Train Loss:  0.01382878065109253 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  198 | Train Loss:  0.01386350154876709 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  199 | Train Loss:  0.013860174417495728 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  200 | Train Loss:  0.013839999437332154 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  201 | Train Loss:  0.013958985805511475 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  202 | Train Loss:  0.013760102987289429 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  203 | Train Loss:  0.013870998620986938 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  204 | Train Loss:  0.013827532529830933 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  205 | Train Loss:  0.01386297345161438 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  206 | Train Loss:  0.013859074115753173 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  207 | Train Loss:  0.013838174343109131 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  208 | Train Loss:  0.013958914279937744 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  209 | Train Loss:  0.013759156465530395 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  210 | Train Loss:  0.013869324922561646 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  211 | Train Loss:  0.013825839757919312 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  212 | Train Loss:  0.013862342834472656 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  213 | Train Loss:  0.013857711553573609 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  214 | Train Loss:  0.013835870027542115 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  215 | Train Loss:  0.013958910703659058 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  216 | Train Loss:  0.013758070468902588 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  217 | Train Loss:  0.013867143392562866 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  218 | Train Loss:  0.013823727369308472 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  219 | Train Loss:  0.013861514329910278 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  220 | Train Loss:  0.013855949640274048 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  221 | Train Loss:  0.013832974433898925 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  222 | Train Loss:  0.013958777189254762 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  223 | Train Loss:  0.013756734132766724 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  224 | Train Loss:  0.013864283561706542 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  225 | Train Loss:  0.013820956945419311 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  226 | Train Loss:  0.013860411643981933 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  227 | Train Loss:  0.013853635787963867 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  228 | Train Loss:  0.013829158544540405 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  229 | Train Loss:  0.013958635330200196 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  230 | Train Loss:  0.01375510573387146 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  231 | Train Loss:  0.013860450983047485 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  232 | Train Loss:  0.013817360401153564 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  233 | Train Loss:  0.013858892917633057 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  234 | Train Loss:  0.013850500583648681 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  235 | Train Loss:  0.013824212551116943 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  236 | Train Loss:  0.013957818746566772 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  237 | Train Loss:  0.013753440380096436 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  238 | Train Loss:  0.01385522961616516 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  239 | Train Loss:  0.013812589645385741 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  240 | Train Loss:  0.013856784105300904 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  241 | Train Loss:  0.013846211433410645 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  242 | Train Loss:  0.013817497491836549 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  243 | Train Loss:  0.013957219123840332 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  244 | Train Loss:  0.013750464916229247 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  245 | Train Loss:  0.013848437070846558 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  246 | Train Loss:  0.013805919885635376 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  247 | Train Loss:  0.013853801488876343 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  248 | Train Loss:  0.013840267658233643 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  249 | Train Loss:  0.013808619976043702 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  250 | Train Loss:  0.013954128026962281 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  251 | Train Loss:  0.01374880075454712 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  252 | Train Loss:  0.013838351964950561 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  253 | Train Loss:  0.01379726767539978 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  254 | Train Loss:  0.013849382400512695 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  255 | Train Loss:  0.013831733465194703 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  256 | Train Loss:  0.013796240091323853 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  257 | Train Loss:  0.01395086407661438 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  258 | Train Loss:  0.013744125366210938 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  259 | Train Loss:  0.013825039863586425 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  260 | Train Loss:  0.013783944845199585 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  261 | Train Loss:  0.013843156099319458 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  262 | Train Loss:  0.013819935321807862 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  263 | Train Loss:  0.013778566122055054 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  264 | Train Loss:  0.013942352533340453 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  265 | Train Loss:  0.013746905326843261 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  266 | Train Loss:  0.013802056312561034 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  267 | Train Loss:  0.013767552375793458 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  268 | Train Loss:  0.013832452297210694 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  269 | Train Loss:  0.01380098819732666 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  270 | Train Loss:  0.013753666877746581 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  271 | Train Loss:  0.013926244974136352 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  272 | Train Loss:  0.01374422550201416 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  273 | Train Loss:  0.013772931098937988 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  274 | Train Loss:  0.013738665580749512 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  275 | Train Loss:  0.01381816267967224 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  276 | Train Loss:  0.013778355121612549 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  277 | Train Loss:  0.013716212511062621 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  278 | Train Loss:  0.013898643255233765 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  279 | Train Loss:  0.013758071660995484 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.44\n",
            "Iteration:  280 | Train Loss:  0.013723950386047363 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  281 | Train Loss:  0.01370705008506775 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  282 | Train Loss:  0.013793983459472657 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  283 | Train Loss:  0.01373752236366272 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  284 | Train Loss:  0.013661099672317505 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  285 | Train Loss:  0.013899314403533935 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  286 | Train Loss:  0.013716202974319459 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  287 | Train Loss:  0.01366491436958313 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  288 | Train Loss:  0.013640849590301514 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  289 | Train Loss:  0.013760228157043457 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  290 | Train Loss:  0.013685146570205689 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  291 | Train Loss:  0.013586587905883789 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  292 | Train Loss:  0.01383831024169922 | Train Accuracy:  0.7 | Validation Accuracy:  0.52\n",
            "Iteration:  293 | Train Loss:  0.013727869987487793 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  294 | Train Loss:  0.013572148084640502 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  295 | Train Loss:  0.013555893898010254 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  296 | Train Loss:  0.013709514141082764 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  297 | Train Loss:  0.013620362281799317 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  298 | Train Loss:  0.01347788691520691 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  299 | Train Loss:  0.01374496340751648 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  300 | Train Loss:  0.013786636590957642 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  301 | Train Loss:  0.013450186252593994 | Train Accuracy:  0.72 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  302 | Train Loss:  0.013447607755661012 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  303 | Train Loss:  0.01363663911819458 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  304 | Train Loss:  0.013555182218551636 | Train Accuracy:  0.6 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  305 | Train Loss:  0.013339632749557495 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  306 | Train Loss:  0.013703510761260987 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  307 | Train Loss:  0.013764311075210572 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  308 | Train Loss:  0.01330594539642334 | Train Accuracy:  0.72 | Validation Accuracy:  0.56\n",
            "Iteration:  309 | Train Loss:  0.013309041261672974 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  310 | Train Loss:  0.013533190488815308 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  311 | Train Loss:  0.013438429832458496 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  312 | Train Loss:  0.013167146444320679 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  313 | Train Loss:  0.01364843249320984 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  314 | Train Loss:  0.0136714768409729 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  315 | Train Loss:  0.013123948574066163 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  316 | Train Loss:  0.013116424083709716 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  317 | Train Loss:  0.01340145468711853 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  318 | Train Loss:  0.013285527229309082 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  319 | Train Loss:  0.012948310375213623 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  320 | Train Loss:  0.013474290370941161 | Train Accuracy:  0.64 | Validation Accuracy:  0.52\n",
            "Iteration:  321 | Train Loss:  0.013641222715377807 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  322 | Train Loss:  0.012893580198287964 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  323 | Train Loss:  0.012815022468566894 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  324 | Train Loss:  0.01328691840171814 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  325 | Train Loss:  0.013151816129684447 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  326 | Train Loss:  0.012678179740905762 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  327 | Train Loss:  0.013158668279647828 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  328 | Train Loss:  0.01381076216697693 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  329 | Train Loss:  0.012635869979858399 | Train Accuracy:  0.74 | Validation Accuracy:  0.56\n",
            "Iteration:  330 | Train Loss:  0.012438727617263794 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  331 | Train Loss:  0.013264967203140259 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  332 | Train Loss:  0.013072111606597901 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  333 | Train Loss:  0.01237557888031006 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  334 | Train Loss:  0.012787356376647949 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  335 | Train Loss:  0.014134893417358399 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  336 | Train Loss:  0.012447574138641358 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  337 | Train Loss:  0.012100656032562256 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  338 | Train Loss:  0.013269641399383546 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  339 | Train Loss:  0.013141026496887207 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  340 | Train Loss:  0.012146524190902709 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  341 | Train Loss:  0.012562347650527954 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  342 | Train Loss:  0.014252699613571167 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  343 | Train Loss:  0.012428288459777831 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  344 | Train Loss:  0.012035588026046753 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  345 | Train Loss:  0.012856254577636719 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  346 | Train Loss:  0.012992150783538818 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  347 | Train Loss:  0.012099902629852295 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  348 | Train Loss:  0.012705833911895751 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  349 | Train Loss:  0.013507624864578247 | Train Accuracy:  0.62 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  350 | Train Loss:  0.01218735933303833 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  351 | Train Loss:  0.012128115892410278 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  352 | Train Loss:  0.012312142848968506 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  353 | Train Loss:  0.012370483875274658 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  354 | Train Loss:  0.011934894323348998 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  355 | Train Loss:  0.013052456378936768 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  356 | Train Loss:  0.012546759843826295 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  357 | Train Loss:  0.01170711636543274 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  358 | Train Loss:  0.012020035982131957 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  359 | Train Loss:  0.012008731365203857 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  360 | Train Loss:  0.01171416163444519 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  361 | Train Loss:  0.011439571380615235 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  362 | Train Loss:  0.012790347337722779 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  363 | Train Loss:  0.012094060182571411 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  364 | Train Loss:  0.011236968040466309 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  365 | Train Loss:  0.011402122974395752 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  366 | Train Loss:  0.0117255437374115 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  367 | Train Loss:  0.011333070993423462 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  368 | Train Loss:  0.010937336683273315 | Train Accuracy:  0.74 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  369 | Train Loss:  0.011986578702926637 | Train Accuracy:  0.74 | Validation Accuracy:  0.56\n",
            "Iteration:  370 | Train Loss:  0.012293790578842162 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  371 | Train Loss:  0.010865417718887329 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  372 | Train Loss:  0.010659793615341187 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  373 | Train Loss:  0.011722713708877563 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  374 | Train Loss:  0.011132895946502686 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  375 | Train Loss:  0.010425777435302734 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  376 | Train Loss:  0.01094435453414917 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  377 | Train Loss:  0.013043076992034911 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  378 | Train Loss:  0.0103755521774292 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  379 | Train Loss:  0.009889626502990722 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  380 | Train Loss:  0.012447435855865479 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  381 | Train Loss:  0.010718624591827392 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  382 | Train Loss:  0.010239862203598023 | Train Accuracy:  0.72 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  383 | Train Loss:  0.010424668788909913 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  384 | Train Loss:  0.012941600084304809 | Train Accuracy:  0.8 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  385 | Train Loss:  0.009952875375747681 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  386 | Train Loss:  0.009784448146820068 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  387 | Train Loss:  0.012485311031341553 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  388 | Train Loss:  0.009824562668800354 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  389 | Train Loss:  0.01068758726119995 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  390 | Train Loss:  0.010177509784698486 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  391 | Train Loss:  0.011706503629684449 | Train Accuracy:  0.74 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  392 | Train Loss:  0.010083446502685547 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  393 | Train Loss:  0.009685859084129333 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  394 | Train Loss:  0.011643959283828735 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  395 | Train Loss:  0.009325528144836425 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  396 | Train Loss:  0.010821540355682373 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  397 | Train Loss:  0.00972329318523407 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  398 | Train Loss:  0.010820026397705079 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  399 | Train Loss:  0.010045466423034667 | Train Accuracy:  0.7 | Validation Accuracy:  0.52\n",
            "Iteration:  400 | Train Loss:  0.009176957607269286 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  401 | Train Loss:  0.010835485458374023 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  402 | Train Loss:  0.009038878679275513 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  403 | Train Loss:  0.010276340246200562 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  404 | Train Loss:  0.009283749461174011 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  405 | Train Loss:  0.010363856554031372 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  406 | Train Loss:  0.009541615843772888 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  407 | Train Loss:  0.00853524923324585 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  408 | Train Loss:  0.010236332416534424 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  409 | Train Loss:  0.00867612361907959 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  410 | Train Loss:  0.009561946988105774 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  411 | Train Loss:  0.008976067900657653 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  412 | Train Loss:  0.010090029239654541 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  413 | Train Loss:  0.00896467387676239 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  414 | Train Loss:  0.008034967780113221 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  415 | Train Loss:  0.009856630563735962 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  416 | Train Loss:  0.00823803186416626 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  417 | Train Loss:  0.008986759781837463 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  418 | Train Loss:  0.008643409609794617 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  419 | Train Loss:  0.009870240688323975 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  420 | Train Loss:  0.008473982214927673 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  421 | Train Loss:  0.00763806939125061 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  422 | Train Loss:  0.009578195214271546 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  423 | Train Loss:  0.007808586955070496 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  424 | Train Loss:  0.008559919595718384 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  425 | Train Loss:  0.008300888538360595 | Train Accuracy:  0.84 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  426 | Train Loss:  0.00957907795906067 | Train Accuracy:  0.82 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  427 | Train Loss:  0.00804238736629486 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  428 | Train Loss:  0.007277896404266357 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  429 | Train Loss:  0.009215739369392396 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  430 | Train Loss:  0.00741777777671814 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  431 | Train Loss:  0.00814927339553833 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  432 | Train Loss:  0.008034353852272033 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  433 | Train Loss:  0.00927197277545929 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  434 | Train Loss:  0.007551588416099549 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  435 | Train Loss:  0.006949416399002075 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  436 | Train Loss:  0.008912006616592407 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  437 | Train Loss:  0.007017108798027039 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  438 | Train Loss:  0.00779022216796875 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  439 | Train Loss:  0.007717257738113404 | Train Accuracy:  0.86 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  440 | Train Loss:  0.008976075649261474 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  441 | Train Loss:  0.007127283215522766 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  442 | Train Loss:  0.0066474777460098266 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  443 | Train Loss:  0.008551904559135437 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  444 | Train Loss:  0.006633039116859436 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  445 | Train Loss:  0.007401744723320007 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  446 | Train Loss:  0.007437469959259033 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  447 | Train Loss:  0.00872499406337738 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  448 | Train Loss:  0.0066808021068572995 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  449 | Train Loss:  0.006361674070358276 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  450 | Train Loss:  0.008275762796401978 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  451 | Train Loss:  0.0062565678358078 | Train Accuracy:  0.82 | Validation Accuracy:  0.56\n",
            "Iteration:  452 | Train Loss:  0.007105048894882202 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  453 | Train Loss:  0.007121307253837586 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  454 | Train Loss:  0.00839482545852661 | Train Accuracy:  0.88 | Validation Accuracy:  0.52\n",
            "Iteration:  455 | Train Loss:  0.00625536561012268 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  456 | Train Loss:  0.0061129873991012575 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  457 | Train Loss:  0.007916859984397888 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  458 | Train Loss:  0.005873587131500244 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  459 | Train Loss:  0.006770572662353516 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  460 | Train Loss:  0.006734913587570191 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  461 | Train Loss:  0.00807924747467041 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  462 | Train Loss:  0.005878994464874268 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  463 | Train Loss:  0.005874708890914917 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  464 | Train Loss:  0.00750470221042633 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  465 | Train Loss:  0.005504074096679687 | Train Accuracy:  0.84 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  466 | Train Loss:  0.0063651114702224735 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  467 | Train Loss:  0.006368494033813477 | Train Accuracy:  0.9 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  468 | Train Loss:  0.00779764711856842 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  469 | Train Loss:  0.005510754585266113 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  470 | Train Loss:  0.0056325185298919675 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  471 | Train Loss:  0.007130303382873535 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  472 | Train Loss:  0.005142982602119445 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  473 | Train Loss:  0.006056144833564758 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  474 | Train Loss:  0.005977993607521057 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  475 | Train Loss:  0.007430741786956787 | Train Accuracy:  0.9 | Validation Accuracy:  0.52\n",
            "Iteration:  476 | Train Loss:  0.005162128210067749 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  477 | Train Loss:  0.005486226081848145 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  478 | Train Loss:  0.0066993218660354615 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.6\n",
            "Iteration:  479 | Train Loss:  0.004772573113441468 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  480 | Train Loss:  0.005744571089744568 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  481 | Train Loss:  0.005523632168769836 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  482 | Train Loss:  0.007062225341796875 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  483 | Train Loss:  0.00488514244556427 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  484 | Train Loss:  0.005400755405426025 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  485 | Train Loss:  0.006214613914489746 | Train Accuracy:  0.92 | Validation Accuracy:  0.56\n",
            "Iteration:  486 | Train Loss:  0.004429837465286255 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  487 | Train Loss:  0.005395170450210571 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  488 | Train Loss:  0.005086972117424011 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  489 | Train Loss:  0.006747780442237854 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  490 | Train Loss:  0.0046664360165596 | Train Accuracy:  0.92 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  491 | Train Loss:  0.005291710495948791 | Train Accuracy:  0.9 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  492 | Train Loss:  0.005670440196990967 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  493 | Train Loss:  0.004120663404464721 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  494 | Train Loss:  0.0049872401356697085 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  495 | Train Loss:  0.0047146260738372804 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  496 | Train Loss:  0.006474028825759887 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  497 | Train Loss:  0.004460094869136811 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  498 | Train Loss:  0.005137180685997009 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  499 | Train Loss:  0.005170738697052002 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  500 | Train Loss:  0.003833240568637848 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  501 | Train Loss:  0.004622533917427063 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  502 | Train Loss:  0.004388851523399353 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  503 | Train Loss:  0.006215021014213562 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  504 | Train Loss:  0.004250905215740204 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  505 | Train Loss:  0.004990430772304535 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  506 | Train Loss:  0.00468522310256958 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  507 | Train Loss:  0.003583685755729675 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  508 | Train Loss:  0.00426556944847107 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.6533333333333333\n",
            "Iteration:  509 | Train Loss:  0.004121531546115875 | Train Accuracy:  0.94 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  510 | Train Loss:  0.005987000465393066 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  511 | Train Loss:  0.004090782105922699 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.64\n",
            "Iteration:  512 | Train Loss:  0.0048813953995704654 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  513 | Train Loss:  0.004180054366588593 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  514 | Train Loss:  0.0034182143211364748 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  515 | Train Loss:  0.0038767692446708677 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  516 | Train Loss:  0.003979794383049011 | Train Accuracy:  0.94 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  517 | Train Loss:  0.005779597759246826 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  518 | Train Loss:  0.004114363491535187 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.64\n",
            "Iteration:  519 | Train Loss:  0.00462171733379364 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  520 | Train Loss:  0.0036416029930114746 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  521 | Train Loss:  0.0032737335562705995 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  522 | Train Loss:  0.0034193456172943114 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  523 | Train Loss:  0.003969970941543579 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  524 | Train Loss:  0.005538222789764405 | Train Accuracy:  0.88 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  525 | Train Loss:  0.004266337454319 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.64\n",
            "Iteration:  526 | Train Loss:  0.004052453935146332 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  527 | Train Loss:  0.0031996554136276244 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  528 | Train Loss:  0.002971755266189575 | Train Accuracy:  0.96 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  529 | Train Loss:  0.003034959137439728 | Train Accuracy:  0.92 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  530 | Train Loss:  0.003851931691169739 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  531 | Train Loss:  0.005321259498596191 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  532 | Train Loss:  0.004238357245922089 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  533 | Train Loss:  0.0033674412965774537 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  534 | Train Loss:  0.0029157239198684694 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  535 | Train Loss:  0.0025658559799194335 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  536 | Train Loss:  0.002853405773639679 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  537 | Train Loss:  0.0034538328647613524 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  538 | Train Loss:  0.005221406817436218 | Train Accuracy:  0.88 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  539 | Train Loss:  0.0038371995091438294 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  540 | Train Loss:  0.0028300774097442627 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  541 | Train Loss:  0.002643607258796692 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  542 | Train Loss:  0.0022720187902450562 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  543 | Train Loss:  0.0027043408155441283 | Train Accuracy:  0.96 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  544 | Train Loss:  0.0029475194215774535 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  545 | Train Loss:  0.005146068334579468 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  546 | Train Loss:  0.003147386610507965 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  547 | Train Loss:  0.0025018614530563353 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  548 | Train Loss:  0.002366952449083328 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  549 | Train Loss:  0.0021359531581401827 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  550 | Train Loss:  0.0024720005691051482 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  551 | Train Loss:  0.0025780314207077028 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.64\n",
            "Iteration:  552 | Train Loss:  0.0049406874179840085 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  553 | Train Loss:  0.002433991879224777 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  554 | Train Loss:  0.0022737808525562287 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  555 | Train Loss:  0.002171625196933746 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  556 | Train Loss:  0.0020448458194732666 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  557 | Train Loss:  0.0022288437187671663 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  558 | Train Loss:  0.0023513442277908326 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.64\n",
            "Iteration:  559 | Train Loss:  0.004672248065471649 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  560 | Train Loss:  0.001871424913406372 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  561 | Train Loss:  0.002070285975933075 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  562 | Train Loss:  0.002106841057538986 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  563 | Train Loss:  0.001944851130247116 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  564 | Train Loss:  0.0020817643404006957 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  565 | Train Loss:  0.0022474969923496247 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  566 | Train Loss:  0.0043826189637184145 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  567 | Train Loss:  0.0014868652820587158 | Train Accuracy:  0.98 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  568 | Train Loss:  0.0018756775557994842 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  569 | Train Loss:  0.00221702978014946 | Train Accuracy:  0.96 | Validation Accuracy:  0.6\n",
            "Iteration:  570 | Train Loss:  0.0017959682643413544 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.6\n",
            "Iteration:  571 | Train Loss:  0.0021647705137729646 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  572 | Train Loss:  0.0022983290255069733 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  573 | Train Loss:  0.004112890958786011 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  574 | Train Loss:  0.0013127192854881287 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  575 | Train Loss:  0.001706387847661972 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  576 | Train Loss:  0.002573344111442566 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  577 | Train Loss:  0.001628727912902832 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  578 | Train Loss:  0.002659008502960205 | Train Accuracy:  0.98 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  579 | Train Loss:  0.00251975417137146 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  580 | Train Loss:  0.0038921040296554564 | Train Accuracy:  0.98 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  581 | Train Loss:  0.0013842061161994934 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  582 | Train Loss:  0.001661093533039093 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  583 | Train Loss:  0.00326651930809021 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  584 | Train Loss:  0.0013415907323360444 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  585 | Train Loss:  0.003852794170379639 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  586 | Train Loss:  0.0024064649641513825 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  587 | Train Loss:  0.004185319542884826 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  588 | Train Loss:  0.0013591645658016206 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  589 | Train Loss:  0.002546072602272034 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  590 | Train Loss:  0.003635837137699127 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  591 | Train Loss:  0.001461283564567566 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  592 | Train Loss:  0.004339105486869812 | Train Accuracy:  0.98 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  593 | Train Loss:  0.0016272975504398345 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  594 | Train Loss:  0.006108958721160889 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  595 | Train Loss:  0.001183130070567131 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  596 | Train Loss:  0.003481208384037018 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  597 | Train Loss:  0.0013486529886722566 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  598 | Train Loss:  0.004466234445571899 | Train Accuracy:  0.92 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  599 | Train Loss:  0.0020605313777923586 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  600 | Train Loss:  0.006880153417587281 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  601 | Train Loss:  0.004500052332878113 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  602 | Train Loss:  0.007298756241798401 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  603 | Train Loss:  0.001987052708864212 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  604 | Train Loss:  0.006855972409248352 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  605 | Train Loss:  0.0014996425807476043 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  606 | Train Loss:  0.006350716352462768 | Train Accuracy:  0.98 | Validation Accuracy:  0.6\n",
            "Iteration:  607 | Train Loss:  0.001684100329875946 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  608 | Train Loss:  0.010998892784118652 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  609 | Train Loss:  0.003286222517490387 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  610 | Train Loss:  0.008840522170066834 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  611 | Train Loss:  0.002072979360818863 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  612 | Train Loss:  0.004035963416099548 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  613 | Train Loss:  0.004878742098808289 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  614 | Train Loss:  0.0012867709994316102 | Train Accuracy:  0.86 | Validation Accuracy:  0.48\n",
            "Iteration:  615 | Train Loss:  0.005961078405380249 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  616 | Train Loss:  0.002170614004135132 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  617 | Train Loss:  0.0012790687382221223 | Train Accuracy:  0.96 | Validation Accuracy:  0.6\n",
            "Iteration:  618 | Train Loss:  0.0023628439009189604 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  619 | Train Loss:  0.0011095289140939713 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  620 | Train Loss:  0.0014645697176456452 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  621 | Train Loss:  0.0013322784006595612 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  622 | Train Loss:  0.0034075140953063964 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  623 | Train Loss:  0.0007978496700525284 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  624 | Train Loss:  0.001040263921022415 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  625 | Train Loss:  0.0014893436431884766 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  626 | Train Loss:  0.0012959282100200654 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  627 | Train Loss:  0.0011183064430952071 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  628 | Train Loss:  0.0029035595059394835 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  629 | Train Loss:  0.003451586663722992 | Train Accuracy:  0.94 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  630 | Train Loss:  0.0014879658818244934 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  631 | Train Loss:  0.0029264867305755617 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  632 | Train Loss:  0.0014931459724903107 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  633 | Train Loss:  0.0012225202471017839 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  634 | Train Loss:  0.0030831980705261232 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  635 | Train Loss:  0.0017254182696342468 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  636 | Train Loss:  0.0034575653076171875 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  637 | Train Loss:  0.0022091314196586607 | Train Accuracy:  0.96 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  638 | Train Loss:  0.0012350285798311234 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  639 | Train Loss:  0.0009794736653566361 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  640 | Train Loss:  0.001141119673848152 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  641 | Train Loss:  0.0013017840683460236 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  642 | Train Loss:  0.0012078401446342468 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  643 | Train Loss:  0.0029692661762237547 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  644 | Train Loss:  0.0009064128994941711 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  645 | Train Loss:  0.0011492760479450226 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  646 | Train Loss:  0.001169913113117218 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  647 | Train Loss:  0.0007862740755081177 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  648 | Train Loss:  0.0013921889662742615 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  649 | Train Loss:  0.0021256011724472045 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  650 | Train Loss:  0.0029080218076705934 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  651 | Train Loss:  0.0013043464720249177 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  652 | Train Loss:  0.002018897235393524 | Train Accuracy:  0.98 | Validation Accuracy:  0.52\n",
            "Iteration:  653 | Train Loss:  0.001310136616230011 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  654 | Train Loss:  0.0008515885472297668 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  655 | Train Loss:  0.0025054141879081726 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  656 | Train Loss:  0.0018854399025440215 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  657 | Train Loss:  0.002882574796676636 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  658 | Train Loss:  0.0018480823934078218 | Train Accuracy:  0.9 | Validation Accuracy:  0.48\n",
            "Iteration:  659 | Train Loss:  0.001479075849056244 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  660 | Train Loss:  0.0009258242696523666 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  661 | Train Loss:  0.0008379319310188294 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  662 | Train Loss:  0.0017474578320980073 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  663 | Train Loss:  0.0015931710600852965 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  664 | Train Loss:  0.0027458426356315613 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  665 | Train Loss:  0.0012302231043577194 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  666 | Train Loss:  0.0015981365740299226 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  667 | Train Loss:  0.0012545040249824523 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  668 | Train Loss:  0.0007094586640596389 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  669 | Train Loss:  0.002109799236059189 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  670 | Train Loss:  0.002145388275384903 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  671 | Train Loss:  0.002694562077522278 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  672 | Train Loss:  0.0017070892453193666 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  673 | Train Loss:  0.0018745988607406616 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  674 | Train Loss:  0.0011047326773405074 | Train Accuracy:  0.98 | Validation Accuracy:  0.6\n",
            "Iteration:  675 | Train Loss:  0.0007584983110427856 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  676 | Train Loss:  0.002301495522260666 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  677 | Train Loss:  0.001860428750514984 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  678 | Train Loss:  0.0026560524106025696 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  679 | Train Loss:  0.0015795345604419709 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  680 | Train Loss:  0.0017693901062011718 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  681 | Train Loss:  0.0011816565692424775 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  682 | Train Loss:  0.0006907682865858078 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  683 | Train Loss:  0.0022562067210674286 | Train Accuracy:  0.92 | Validation Accuracy:  0.56\n",
            "Iteration:  684 | Train Loss:  0.0021079063415527345 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  685 | Train Loss:  0.0026237142086029054 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  686 | Train Loss:  0.0016305316984653474 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  687 | Train Loss:  0.0020232731103897094 | Train Accuracy:  0.96 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  688 | Train Loss:  0.001291956752538681 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  689 | Train Loss:  0.0006886051595211029 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  690 | Train Loss:  0.0025781673192977906 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  691 | Train Loss:  0.0021722032129764556 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  692 | Train Loss:  0.002595434784889221 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  693 | Train Loss:  0.001742292195558548 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  694 | Train Loss:  0.002061317265033722 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  695 | Train Loss:  0.0013126108050346376 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  696 | Train Loss:  0.0006674234569072723 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  697 | Train Loss:  0.0025739786028862 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  698 | Train Loss:  0.002358653247356415 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  699 | Train Loss:  0.002585064768791199 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.49333333333333335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.8628571428571429\n",
            "Final Validation Accuracy: 0.49333333333333335\n",
            "Maximum Training Accuracy: 0.9971428571428571\n",
            "Maximum Validation Accuracy: 0.6533333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VIMIxA_Gdr-g",
        "outputId": "0df8d61f-d313-4843-a46c-882a959abfdc"
      },
      "source": [
        "model = ANN_TS_2L()\n",
        "train(model, train_dataset, val_dataset, batch_size = 75, num_epochs=150, learning_rate = 0.01, momen = 0.8, use_adam = True, save_weights=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.009313767751057942 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1 | Train Loss:  0.009224606355031332 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2 | Train Loss:  0.009262767632802328 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3 | Train Loss:  0.009241723219553629 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  4 | Train Loss:  0.009318497975667318 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  5 | Train Loss:  0.009235340754191081 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  6 | Train Loss:  0.009242260456085205 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  7 | Train Loss:  0.009252349535624186 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  8 | Train Loss:  0.009248763720194498 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  9 | Train Loss:  0.009196062882741293 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  10 | Train Loss:  0.009261990388234456 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  11 | Train Loss:  0.009215534528096517 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  12 | Train Loss:  0.009283842245737712 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  13 | Train Loss:  0.009264711538950603 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  14 | Train Loss:  0.009132530689239502 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  15 | Train Loss:  0.009281655152638754 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  16 | Train Loss:  0.009204506079355875 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  17 | Train Loss:  0.00930299441019694 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  18 | Train Loss:  0.009274554252624512 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  19 | Train Loss:  0.00910464604695638 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  20 | Train Loss:  0.009291338920593261 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  21 | Train Loss:  0.00920064608256022 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  22 | Train Loss:  0.009310425917307536 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  23 | Train Loss:  0.00927793025970459 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  24 | Train Loss:  0.009097209771474202 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  25 | Train Loss:  0.009293152491251627 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  26 | Train Loss:  0.009200261433919272 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  27 | Train Loss:  0.009309923648834229 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  28 | Train Loss:  0.009276990890502929 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  29 | Train Loss:  0.00910106102625529 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  30 | Train Loss:  0.009290575981140137 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  31 | Train Loss:  0.009201622804005941 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  32 | Train Loss:  0.00930553674697876 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  33 | Train Loss:  0.009274118741353353 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  34 | Train Loss:  0.009110158284505208 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  35 | Train Loss:  0.009286410013834635 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  36 | Train Loss:  0.009203599294026693 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  37 | Train Loss:  0.009300297101338704 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  38 | Train Loss:  0.009271001815795899 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  39 | Train Loss:  0.009118781884511313 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  40 | Train Loss:  0.009282437960306804 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  41 | Train Loss:  0.00920548677444458 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  42 | Train Loss:  0.009295786221822103 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  43 | Train Loss:  0.009268432458241781 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  44 | Train Loss:  0.00912614107131958 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  45 | Train Loss:  0.009279421170552572 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  46 | Train Loss:  0.009206837813059488 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  47 | Train Loss:  0.009292764663696289 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  48 | Train Loss:  0.009266769886016846 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  49 | Train Loss:  0.009130462805430095 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  50 | Train Loss:  0.00927766482035319 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  51 | Train Loss:  0.009207409222920735 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  52 | Train Loss:  0.009291376272837321 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  53 | Train Loss:  0.009265998204549153 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  54 | Train Loss:  0.009131708145141602 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  55 | Train Loss:  0.009277010758717855 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  56 | Train Loss:  0.009207262198130289 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  57 | Train Loss:  0.009291262626647949 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  58 | Train Loss:  0.009265847206115722 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  59 | Train Loss:  0.009130772749582926 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  60 | Train Loss:  0.009277021090189616 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  61 | Train Loss:  0.009206647078196208 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  62 | Train Loss:  0.009291815757751464 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  63 | Train Loss:  0.009265937010447185 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  64 | Train Loss:  0.009128886063893636 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  65 | Train Loss:  0.009277158578236898 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  66 | Train Loss:  0.009205842812856038 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  67 | Train Loss:  0.009292353789011637 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  68 | Train Loss:  0.009265841643015544 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  69 | Train Loss:  0.00912729581197103 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  70 | Train Loss:  0.009276847839355468 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  71 | Train Loss:  0.009205052852630615 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  72 | Train Loss:  0.009292394320170084 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  73 | Train Loss:  0.009265302817026774 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  74 | Train Loss:  0.009126444657643637 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  75 | Train Loss:  0.009275885423024495 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  76 | Train Loss:  0.009204267660776774 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  77 | Train Loss:  0.009291771252950033 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  78 | Train Loss:  0.009264195760091146 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  79 | Train Loss:  0.009126397768656412 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  80 | Train Loss:  0.009274115562438965 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  81 | Train Loss:  0.009203386306762696 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  82 | Train Loss:  0.009290417035420736 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  83 | Train Loss:  0.009262384573618571 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  84 | Train Loss:  0.009127044677734375 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  85 | Train Loss:  0.009271414279937744 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  86 | Train Loss:  0.009202129046122233 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  87 | Train Loss:  0.009288549423217773 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  88 | Train Loss:  0.009259893099466959 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  89 | Train Loss:  0.009127092361450196 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  90 | Train Loss:  0.009267569382985433 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  91 | Train Loss:  0.009200233618418376 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  92 | Train Loss:  0.009285671710968018 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  93 | Train Loss:  0.009256008466084799 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  94 | Train Loss:  0.009128024578094482 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  95 | Train Loss:  0.009261612097422283 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  96 | Train Loss:  0.009197373390197754 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  97 | Train Loss:  0.009281171957651773 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  98 | Train Loss:  0.00925035317738851 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  99 | Train Loss:  0.009128326574961345 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  100 | Train Loss:  0.009253539244333904 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  101 | Train Loss:  0.009192011356353759 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  102 | Train Loss:  0.00927658478418986 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  103 | Train Loss:  0.009242862860361734 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  104 | Train Loss:  0.009124499162038167 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  105 | Train Loss:  0.00924124797185262 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  106 | Train Loss:  0.00918380578358968 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  107 | Train Loss:  0.009267570972442627 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  108 | Train Loss:  0.009230377674102784 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  109 | Train Loss:  0.009120763937632243 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  110 | Train Loss:  0.009223965009053548 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  111 | Train Loss:  0.00916809320449829 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  112 | Train Loss:  0.00926355759302775 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  113 | Train Loss:  0.009215021133422851 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  114 | Train Loss:  0.009102847576141358 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  115 | Train Loss:  0.00919512430826823 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  116 | Train Loss:  0.009148228963216145 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  117 | Train Loss:  0.009237945874532064 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  118 | Train Loss:  0.009183910687764486 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  119 | Train Loss:  0.009092667897542317 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  120 | Train Loss:  0.009153887430826823 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  121 | Train Loss:  0.009112099011739094 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  122 | Train Loss:  0.00922385295232137 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  123 | Train Loss:  0.009143792788187662 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  124 | Train Loss:  0.009068618615468343 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  125 | Train Loss:  0.009084849357604981 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  126 | Train Loss:  0.009066075483957926 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  127 | Train Loss:  0.009172053337097167 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  128 | Train Loss:  0.009075188636779785 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  129 | Train Loss:  0.00904786189397176 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  130 | Train Loss:  0.008988942305246989 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  131 | Train Loss:  0.008995110193888347 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  132 | Train Loss:  0.00912794828414917 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  133 | Train Loss:  0.008983065287272135 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  134 | Train Loss:  0.00903183380762736 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  135 | Train Loss:  0.008850987752278645 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  136 | Train Loss:  0.00890384833017985 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  137 | Train Loss:  0.009051094055175781 | Train Accuracy:  0.64 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  138 | Train Loss:  0.008865511417388916 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  139 | Train Loss:  0.008953787485758464 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  140 | Train Loss:  0.008688628673553467 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  141 | Train Loss:  0.008784573872884114 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  142 | Train Loss:  0.008947348594665528 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  143 | Train Loss:  0.008704866568247477 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  144 | Train Loss:  0.008933295408884684 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  145 | Train Loss:  0.008488714694976807 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  146 | Train Loss:  0.008637808958689371 | Train Accuracy:  0.6 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  147 | Train Loss:  0.008885040283203124 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  148 | Train Loss:  0.008524418671925863 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  149 | Train Loss:  0.008941032886505128 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  150 | Train Loss:  0.008256093660990397 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  151 | Train Loss:  0.008477048873901367 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  152 | Train Loss:  0.008826498985290527 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  153 | Train Loss:  0.008342813650767009 | Train Accuracy:  0.62 | Validation Accuracy:  0.52\n",
            "Iteration:  154 | Train Loss:  0.008817792733510335 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  155 | Train Loss:  0.008026970227559408 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  156 | Train Loss:  0.008303938706715901 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  157 | Train Loss:  0.008668177922566732 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  158 | Train Loss:  0.008152210712432861 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  159 | Train Loss:  0.008576324780782064 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  160 | Train Loss:  0.00781731128692627 | Train Accuracy:  0.7 | Validation Accuracy:  0.52\n",
            "Iteration:  161 | Train Loss:  0.008121645450592041 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  162 | Train Loss:  0.008486177921295166 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  163 | Train Loss:  0.007933091322580974 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  164 | Train Loss:  0.008494816621144612 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  165 | Train Loss:  0.007606408596038818 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  166 | Train Loss:  0.007950849533081054 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  167 | Train Loss:  0.008415247599283854 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  168 | Train Loss:  0.00772464116414388 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  169 | Train Loss:  0.00853654146194458 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  170 | Train Loss:  0.007390407721201578 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  171 | Train Loss:  0.00779207706451416 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  172 | Train Loss:  0.008431613445281982 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  173 | Train Loss:  0.00752753734588623 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  174 | Train Loss:  0.008447955449422201 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  175 | Train Loss:  0.007205341657002767 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  176 | Train Loss:  0.007580929597218831 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  177 | Train Loss:  0.008346120516459147 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  178 | Train Loss:  0.0073571157455444335 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  179 | Train Loss:  0.008069466749827068 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  180 | Train Loss:  0.007045694986979167 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  181 | Train Loss:  0.0073653244972229 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  182 | Train Loss:  0.00804826021194458 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  183 | Train Loss:  0.0071813249588012695 | Train Accuracy:  0.7 | Validation Accuracy:  0.56\n",
            "Iteration:  184 | Train Loss:  0.007677023410797119 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  185 | Train Loss:  0.006870435873667399 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  186 | Train Loss:  0.007187952200571696 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  187 | Train Loss:  0.007769160270690918 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  188 | Train Loss:  0.006981836954752604 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  189 | Train Loss:  0.007538916269938151 | Train Accuracy:  0.8 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  190 | Train Loss:  0.006703619162241618 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  191 | Train Loss:  0.00706113338470459 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  192 | Train Loss:  0.007630041440327962 | Train Accuracy:  0.78 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  193 | Train Loss:  0.006807955900828043 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  194 | Train Loss:  0.00759130875269572 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  195 | Train Loss:  0.006542342106501261 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  196 | Train Loss:  0.0069811383883158365 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  197 | Train Loss:  0.00763355573018392 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  198 | Train Loss:  0.006638967593510945 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  199 | Train Loss:  0.007672061125437418 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  200 | Train Loss:  0.006393754879633585 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  201 | Train Loss:  0.0068419988950093585 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  202 | Train Loss:  0.0076962637901306155 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  203 | Train Loss:  0.006450101137161255 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  204 | Train Loss:  0.007524637381235758 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  205 | Train Loss:  0.006292295853296916 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  206 | Train Loss:  0.006593800783157348 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  207 | Train Loss:  0.00761879046758016 | Train Accuracy:  0.82 | Validation Accuracy:  0.52\n",
            "Iteration:  208 | Train Loss:  0.006297344366709391 | Train Accuracy:  0.72 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  209 | Train Loss:  0.007080291112263997 | Train Accuracy:  0.8 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  210 | Train Loss:  0.006197285254796346 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  211 | Train Loss:  0.006356941064198812 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  212 | Train Loss:  0.007306069533030192 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  213 | Train Loss:  0.006161170800526937 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  214 | Train Loss:  0.00660191814104716 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  215 | Train Loss:  0.006047213474909464 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  216 | Train Loss:  0.006185227632522583 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  217 | Train Loss:  0.006952710151672363 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  218 | Train Loss:  0.005989993810653686 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  219 | Train Loss:  0.0063186939557393395 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  220 | Train Loss:  0.005882025957107544 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  221 | Train Loss:  0.00605096697807312 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  222 | Train Loss:  0.006712238788604736 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  223 | Train Loss:  0.005820188522338867 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  224 | Train Loss:  0.006221540768941243 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  225 | Train Loss:  0.005732563734054566 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  226 | Train Loss:  0.00596304456392924 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  227 | Train Loss:  0.006578554312388102 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  228 | Train Loss:  0.00568547526995341 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  229 | Train Loss:  0.006239147583643596 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  230 | Train Loss:  0.005594338973363241 | Train Accuracy:  0.78 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  231 | Train Loss:  0.005919919808705648 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  232 | Train Loss:  0.006514231363932292 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  233 | Train Loss:  0.005574145317077637 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  234 | Train Loss:  0.006300010283788045 | Train Accuracy:  0.84 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  235 | Train Loss:  0.005461237827936808 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  236 | Train Loss:  0.005877906084060669 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  237 | Train Loss:  0.00652845581372579 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  238 | Train Loss:  0.005440185070037842 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  239 | Train Loss:  0.006349981625874837 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  240 | Train Loss:  0.0053406445185343425 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  241 | Train Loss:  0.005768218437830607 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  242 | Train Loss:  0.006604906717936198 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  243 | Train Loss:  0.005261240800221761 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  244 | Train Loss:  0.006292126576105754 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  245 | Train Loss:  0.005262671709060669 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  246 | Train Loss:  0.005554126501083374 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  247 | Train Loss:  0.0066588234901428225 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  248 | Train Loss:  0.005080607334772746 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  249 | Train Loss:  0.006042574246724447 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  250 | Train Loss:  0.005238817532857259 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  251 | Train Loss:  0.0052827306588490806 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  252 | Train Loss:  0.006571759780248006 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  253 | Train Loss:  0.004955851236979167 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  254 | Train Loss:  0.005616876681645711 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  255 | Train Loss:  0.005217938423156738 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  256 | Train Loss:  0.005046588977177938 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  257 | Train Loss:  0.0063169169425964355 | Train Accuracy:  0.86 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  258 | Train Loss:  0.004874116182327271 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  259 | Train Loss:  0.005138473113377889 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  260 | Train Loss:  0.005129648049672445 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  261 | Train Loss:  0.004880618254343668 | Train Accuracy:  0.8 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  262 | Train Loss:  0.0059476041793823245 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  263 | Train Loss:  0.004771730899810791 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  264 | Train Loss:  0.004729224840799968 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  265 | Train Loss:  0.0049633661905924475 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  266 | Train Loss:  0.004745291074117025 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  267 | Train Loss:  0.005582537651062012 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  268 | Train Loss:  0.00462347944577535 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  269 | Train Loss:  0.004434234301249187 | Train Accuracy:  0.86 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  270 | Train Loss:  0.004767299890518189 | Train Accuracy:  0.88 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  271 | Train Loss:  0.004604815642038981 | Train Accuracy:  0.84 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  272 | Train Loss:  0.005271372795104981 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  273 | Train Loss:  0.004452948570251465 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  274 | Train Loss:  0.004220964511235555 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  275 | Train Loss:  0.004573235114415487 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  276 | Train Loss:  0.004460628430048625 | Train Accuracy:  0.86 | Validation Accuracy:  0.56\n",
            "Iteration:  277 | Train Loss:  0.005002397696177165 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  278 | Train Loss:  0.004293882052103679 | Train Accuracy:  0.86 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  279 | Train Loss:  0.004044031302134196 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  280 | Train Loss:  0.004395269950230916 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  281 | Train Loss:  0.004326695203781128 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  282 | Train Loss:  0.004734864234924316 | Train Accuracy:  0.9 | Validation Accuracy:  0.52\n",
            "Iteration:  283 | Train Loss:  0.004173969427744548 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  284 | Train Loss:  0.003854923645655314 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.56\n",
            "Iteration:  285 | Train Loss:  0.0042510120073954265 | Train Accuracy:  0.88 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  286 | Train Loss:  0.00420443852742513 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  287 | Train Loss:  0.00444389541943868 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  288 | Train Loss:  0.004106342792510986 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  289 | Train Loss:  0.0036194324493408203 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  290 | Train Loss:  0.004174435138702392 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  291 | Train Loss:  0.0040703256924947105 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  292 | Train Loss:  0.004148310820261638 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  293 | Train Loss:  0.0040546154975891115 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  294 | Train Loss:  0.003335656722386678 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  295 | Train Loss:  0.004172124067942301 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  296 | Train Loss:  0.003902533451716105 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  297 | Train Loss:  0.003918460210164388 | Train Accuracy:  0.9 | Validation Accuracy:  0.56\n",
            "Iteration:  298 | Train Loss:  0.003928018013636271 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  299 | Train Loss:  0.003085352579752604 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  300 | Train Loss:  0.004160204331080119 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  301 | Train Loss:  0.0037469144662221274 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  302 | Train Loss:  0.003774848381678263 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  303 | Train Loss:  0.0036970281600952146 | Train Accuracy:  0.92 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  304 | Train Loss:  0.0029332631826400756 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  305 | Train Loss:  0.004007407426834106 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  306 | Train Loss:  0.0036831466356913247 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  307 | Train Loss:  0.0036269891262054443 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  308 | Train Loss:  0.003470805486043294 | Train Accuracy:  0.92 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  309 | Train Loss:  0.002806799610455831 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  310 | Train Loss:  0.0037107177575429282 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  311 | Train Loss:  0.0036295131842295327 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  312 | Train Loss:  0.0034441236654917397 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  313 | Train Loss:  0.003322555224100749 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  314 | Train Loss:  0.0026428550481796265 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  315 | Train Loss:  0.003449919621149699 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  316 | Train Loss:  0.003440996805826823 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  317 | Train Loss:  0.0033027678728103638 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  318 | Train Loss:  0.0032007296880086264 | Train Accuracy:  0.94 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  319 | Train Loss:  0.002497497399648031 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  320 | Train Loss:  0.0033163696527481077 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  321 | Train Loss:  0.0032421247164408367 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  322 | Train Loss:  0.0031438867251078286 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  323 | Train Loss:  0.0031019145250320433 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  324 | Train Loss:  0.0023648168643315634 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  325 | Train Loss:  0.0032527788480122884 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  326 | Train Loss:  0.0031581787268320717 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  327 | Train Loss:  0.0029901750882466633 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  328 | Train Loss:  0.002950006127357483 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  329 | Train Loss:  0.0022508901357650756 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  330 | Train Loss:  0.00306811253229777 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.6\n",
            "Iteration:  331 | Train Loss:  0.0031022465229034422 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  332 | Train Loss:  0.002851308782895406 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  333 | Train Loss:  0.0028170424699783324 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  334 | Train Loss:  0.002109141747156779 | Train Accuracy:  0.94 | Validation Accuracy:  0.56\n",
            "Iteration:  335 | Train Loss:  0.002881824771563212 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  336 | Train Loss:  0.002921405633290609 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  337 | Train Loss:  0.0027195064226786295 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  338 | Train Loss:  0.0027147992451985676 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  339 | Train Loss:  0.0019903584321339924 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  340 | Train Loss:  0.002802215019861857 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  341 | Train Loss:  0.002837697267532349 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  342 | Train Loss:  0.002576438585917155 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  343 | Train Loss:  0.0025821508963902793 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  344 | Train Loss:  0.0018816665808359782 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  345 | Train Loss:  0.002637409170468648 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  346 | Train Loss:  0.0027427401145299277 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  347 | Train Loss:  0.0024560330311457317 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  348 | Train Loss:  0.0024691198269526163 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  349 | Train Loss:  0.0017639734347661335 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  350 | Train Loss:  0.002513814369837443 | Train Accuracy:  0.96 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  351 | Train Loss:  0.0026089827219645183 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  352 | Train Loss:  0.0023270658651987713 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  353 | Train Loss:  0.0023602288961410522 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  354 | Train Loss:  0.0016690870126088461 | Train Accuracy:  0.96 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  355 | Train Loss:  0.0024028841654459634 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  356 | Train Loss:  0.00254055380821228 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  357 | Train Loss:  0.002209320267041524 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  358 | Train Loss:  0.0022440816958745322 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  359 | Train Loss:  0.0015644918878873189 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  360 | Train Loss:  0.0022625078757603965 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  361 | Train Loss:  0.0023958186308542886 | Train Accuracy:  0.98 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  362 | Train Loss:  0.0020926451683044435 | Train Accuracy:  0.98 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  363 | Train Loss:  0.0021453988552093506 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  364 | Train Loss:  0.00148269385099411 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  365 | Train Loss:  0.0021697280804316202 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  366 | Train Loss:  0.002337710658709208 | Train Accuracy:  0.98 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  367 | Train Loss:  0.001982757647832235 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  368 | Train Loss:  0.0020338370402654014 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  369 | Train Loss:  0.001386359930038452 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  370 | Train Loss:  0.0020318955183029177 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  371 | Train Loss:  0.002179676691691081 | Train Accuracy:  0.98 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  372 | Train Loss:  0.0018733177582422893 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  373 | Train Loss:  0.0019415809710820516 | Train Accuracy:  0.96 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  374 | Train Loss:  0.00132208913564682 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  375 | Train Loss:  0.0019491451978683471 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  376 | Train Loss:  0.002143947680791219 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  377 | Train Loss:  0.0017745542526245118 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  378 | Train Loss:  0.0018379058440526326 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  379 | Train Loss:  0.0012272517879803975 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  380 | Train Loss:  0.001819797158241272 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  381 | Train Loss:  0.001965745488802592 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  382 | Train Loss:  0.0016741897662480671 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  383 | Train Loss:  0.0017512877782185873 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  384 | Train Loss:  0.00118398388226827 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  385 | Train Loss:  0.0017435328165690104 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  386 | Train Loss:  0.001956371267636617 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  387 | Train Loss:  0.001584454874197642 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  388 | Train Loss:  0.0016584283113479615 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  389 | Train Loss:  0.0010872569680213928 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  390 | Train Loss:  0.0016287126143773396 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  391 | Train Loss:  0.0017654287815093994 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  392 | Train Loss:  0.001500691076119741 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  393 | Train Loss:  0.0015774574875831605 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  394 | Train Loss:  0.001064376433690389 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  395 | Train Loss:  0.0015555402636528014 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  396 | Train Loss:  0.0017737342913945516 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  397 | Train Loss:  0.0014134259025255838 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  398 | Train Loss:  0.00149640162785848 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  399 | Train Loss:  0.0009682275851567587 | Train Accuracy:  0.98 | Validation Accuracy:  0.52\n",
            "Iteration:  400 | Train Loss:  0.0014626801013946534 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  401 | Train Loss:  0.0015919093290964763 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  402 | Train Loss:  0.0013530049721399943 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  403 | Train Loss:  0.001421791116396586 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  404 | Train Loss:  0.0009582229455312093 | Train Accuracy:  0.98 | Validation Accuracy:  0.52\n",
            "Iteration:  405 | Train Loss:  0.0013908214370409648 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  406 | Train Loss:  0.0015981261928876241 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  407 | Train Loss:  0.001264935334523519 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  408 | Train Loss:  0.0013512430588404338 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  409 | Train Loss:  0.0008710317810376485 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  410 | Train Loss:  0.0013175857067108153 | Train Accuracy:  0.98 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  411 | Train Loss:  0.0014442765712738036 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  412 | Train Loss:  0.0012273594737052917 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  413 | Train Loss:  0.0012846724192301432 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  414 | Train Loss:  0.0008666166663169861 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  415 | Train Loss:  0.0012523970007896424 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  416 | Train Loss:  0.0014411801099777223 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.6\n",
            "Iteration:  417 | Train Loss:  0.0011436207095781963 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  418 | Train Loss:  0.0012225474913914998 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  419 | Train Loss:  0.000794072449207306 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  420 | Train Loss:  0.00119475523630778 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  421 | Train Loss:  0.0013178164760271709 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.6\n",
            "Iteration:  422 | Train Loss:  0.0011235945423444112 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  423 | Train Loss:  0.0011640465259552001 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  424 | Train Loss:  0.0007947213451067606 | Train Accuracy:  0.98 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  425 | Train Loss:  0.001144185165564219 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  426 | Train Loss:  0.0013145042459170024 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.6\n",
            "Iteration:  427 | Train Loss:  0.0010506484905878702 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  428 | Train Loss:  0.0011095850666364034 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  429 | Train Loss:  0.0007350617647171021 | Train Accuracy:  0.98 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  430 | Train Loss:  0.0010972926020622253 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  431 | Train Loss:  0.0012106921275456747 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  432 | Train Loss:  0.0010488541920979817 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  433 | Train Loss:  0.0010581933458646139 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  434 | Train Loss:  0.0007464669148127238 | Train Accuracy:  0.98 | Validation Accuracy:  0.52\n",
            "Iteration:  435 | Train Loss:  0.0010655269026756287 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  436 | Train Loss:  0.0012185139457384746 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  437 | Train Loss:  0.0009871626893679301 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  438 | Train Loss:  0.0010112516085306804 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  439 | Train Loss:  0.0006962921718756357 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  440 | Train Loss:  0.0010306879878044129 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  441 | Train Loss:  0.001126003364721934 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  442 | Train Loss:  0.001010209321975708 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  443 | Train Loss:  0.0009663290778795878 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  444 | Train Loss:  0.000725129892428716 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  445 | Train Loss:  0.001018373966217041 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  446 | Train Loss:  0.0011497207482655844 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  447 | Train Loss:  0.0009604291121164957 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  448 | Train Loss:  0.0009264040986696879 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  449 | Train Loss:  0.0006853463252385457 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  450 | Train Loss:  0.0010005375742912293 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  451 | Train Loss:  0.0010667660832405091 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  452 | Train Loss:  0.0010176978508631388 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  453 | Train Loss:  0.0008874311049779256 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  454 | Train Loss:  0.0007395160694917043 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  455 | Train Loss:  0.0010163378715515137 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  456 | Train Loss:  0.0011136237780253093 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  457 | Train Loss:  0.0009877108534177145 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  458 | Train Loss:  0.0008545587460199992 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  459 | Train Loss:  0.0007152201731999715 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  460 | Train Loss:  0.0010260541240374246 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  461 | Train Loss:  0.0010449401537577312 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  462 | Train Loss:  0.0010939340790112814 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  463 | Train Loss:  0.000822218656539917 | Train Accuracy:  0.9 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  464 | Train Loss:  0.0008032793800036112 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  465 | Train Loss:  0.001062708298365275 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  466 | Train Loss:  0.001105944017569224 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  467 | Train Loss:  0.001098183790842692 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  468 | Train Loss:  0.0007941730817159017 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  469 | Train Loss:  0.0008144380152225495 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  470 | Train Loss:  0.0011289748549461365 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  471 | Train Loss:  0.0010830183823903401 | Train Accuracy:  0.92 | Validation Accuracy:  0.56\n",
            "Iteration:  472 | Train Loss:  0.0012611504395802816 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  473 | Train Loss:  0.0007714602847894033 | Train Accuracy:  0.86 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  474 | Train Loss:  0.0009337478876113892 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  475 | Train Loss:  0.0011887969573338827 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.6\n",
            "Iteration:  476 | Train Loss:  0.0011320993304252624 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  477 | Train Loss:  0.0013636506597201029 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  478 | Train Loss:  0.0007482038935025533 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  479 | Train Loss:  0.0010275128483772278 | Train Accuracy:  0.9 | Validation Accuracy:  0.44\n",
            "Iteration:  480 | Train Loss:  0.0013388179739316304 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  481 | Train Loss:  0.0011867832144101462 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  482 | Train Loss:  0.0015995236237843831 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  483 | Train Loss:  0.0007349782188733419 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  484 | Train Loss:  0.0011974738041559856 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  485 | Train Loss:  0.0014755633473396302 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  486 | Train Loss:  0.0012320102254549663 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  487 | Train Loss:  0.0019192487001419068 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  488 | Train Loss:  0.0007218897342681884 | Train Accuracy:  0.78 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  489 | Train Loss:  0.0014437719186147053 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  490 | Train Loss:  0.0017200050751368205 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  491 | Train Loss:  0.0013421804706255595 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  492 | Train Loss:  0.002362229824066162 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  493 | Train Loss:  0.0007142656048138937 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  494 | Train Loss:  0.0017776614427566528 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  495 | Train Loss:  0.0021082232395807903 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  496 | Train Loss:  0.0014816240469614666 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  497 | Train Loss:  0.0031019562482833864 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  498 | Train Loss:  0.0007120803991953532 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  499 | Train Loss:  0.0023093517621358235 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  500 | Train Loss:  0.002808953324953715 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  501 | Train Loss:  0.0017077688376108805 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  502 | Train Loss:  0.00437205712000529 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  503 | Train Loss:  0.0007214027643203735 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  504 | Train Loss:  0.003112013538678487 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  505 | Train Loss:  0.004523746967315674 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  506 | Train Loss:  0.0019953376054763793 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  507 | Train Loss:  0.007394688924153646 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  508 | Train Loss:  0.0008810073137283325 | Train Accuracy:  0.66 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  509 | Train Loss:  0.004418031374613444 | Train Accuracy:  0.66 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  510 | Train Loss:  0.009869816303253174 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.6\n",
            "Iteration:  511 | Train Loss:  0.0011508285999298096 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  512 | Train Loss:  0.01703031380971273 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  513 | Train Loss:  0.007025993665059407 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  514 | Train Loss:  0.006034430265426636 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  515 | Train Loss:  0.03229428927103679 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  516 | Train Loss:  0.02356887181599935 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  517 | Train Loss:  0.002002029021581014 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  518 | Train Loss:  0.02998965581258138 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  519 | Train Loss:  0.02846782684326172 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  520 | Train Loss:  0.0026217955350875855 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  521 | Train Loss:  0.028164409001668295 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  522 | Train Loss:  0.04214179674784342 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  523 | Train Loss:  0.03750758171081543 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  524 | Train Loss:  0.023911039034525555 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  525 | Train Loss:  0.029357868830362954 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  526 | Train Loss:  0.021669675509134928 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  527 | Train Loss:  0.020414230028788248 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  528 | Train Loss:  0.011394622325897217 | Train Accuracy:  0.94 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  529 | Train Loss:  0.004973740577697754 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  530 | Train Loss:  0.008651324113210042 | Train Accuracy:  0.49714285714285716 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  531 | Train Loss:  0.011024783452351888 | Train Accuracy:  0.4942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  532 | Train Loss:  0.006876386006673177 | Train Accuracy:  0.4942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  533 | Train Loss:  0.007346540292104085 | Train Accuracy:  0.4942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  534 | Train Loss:  0.00799885114034017 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  535 | Train Loss:  0.0072546990712483725 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  536 | Train Loss:  0.007970640659332276 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  537 | Train Loss:  0.008322388331095377 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  538 | Train Loss:  0.008141573270161946 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  539 | Train Loss:  0.008136228720347086 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  540 | Train Loss:  0.007213504314422608 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  541 | Train Loss:  0.007531728744506836 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  542 | Train Loss:  0.00681920051574707 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  543 | Train Loss:  0.0070750061670939125 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  544 | Train Loss:  0.008463428815205893 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  545 | Train Loss:  0.005882820685704549 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  546 | Train Loss:  0.006127582391103109 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  547 | Train Loss:  0.006299453973770142 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  548 | Train Loss:  0.005821899970372518 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  549 | Train Loss:  0.005167380968729655 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  550 | Train Loss:  0.004496615727742513 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  551 | Train Loss:  0.005243563652038574 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  552 | Train Loss:  0.004838994344075521 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  553 | Train Loss:  0.005166706244150798 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  554 | Train Loss:  0.005566682815551758 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  555 | Train Loss:  0.0040821611881256105 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  556 | Train Loss:  0.005374298095703125 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  557 | Train Loss:  0.0063480019569396974 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  558 | Train Loss:  0.004708215395609538 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  559 | Train Loss:  0.005209760665893555 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.6\n",
            "Iteration:  560 | Train Loss:  0.004136703014373779 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  561 | Train Loss:  0.004413433074951172 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  562 | Train Loss:  0.0043973974386850995 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  563 | Train Loss:  0.00394896666208903 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  564 | Train Loss:  0.0040855717658996584 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  565 | Train Loss:  0.0031968716780344645 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  566 | Train Loss:  0.004397274255752564 | Train Accuracy:  0.92 | Validation Accuracy:  0.48\n",
            "Iteration:  567 | Train Loss:  0.0048162106672922774 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  568 | Train Loss:  0.003849474589029948 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  569 | Train Loss:  0.004799412091573079 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  570 | Train Loss:  0.0033034809430440267 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  571 | Train Loss:  0.003909982045491536 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  572 | Train Loss:  0.004961666663487753 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  573 | Train Loss:  0.00367087721824646 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  574 | Train Loss:  0.003815510670344035 | Train Accuracy:  0.98 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  575 | Train Loss:  0.0031436336040496825 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  576 | Train Loss:  0.0035988509654998778 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  577 | Train Loss:  0.004089423020680745 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  578 | Train Loss:  0.0035148123900095624 | Train Accuracy:  0.98 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  579 | Train Loss:  0.003544595241546631 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  580 | Train Loss:  0.002892713149388631 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  581 | Train Loss:  0.0036474943161010744 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  582 | Train Loss:  0.00420108437538147 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  583 | Train Loss:  0.0034256617228190104 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.6\n",
            "Iteration:  584 | Train Loss:  0.0038589115937550864 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  585 | Train Loss:  0.0029249040285746256 | Train Accuracy:  0.96 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  586 | Train Loss:  0.0034987759590148926 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  587 | Train Loss:  0.00428791602452596 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  588 | Train Loss:  0.003297345240910848 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  589 | Train Loss:  0.003512105941772461 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  590 | Train Loss:  0.002859280308087667 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  591 | Train Loss:  0.003285357753435771 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  592 | Train Loss:  0.003920090595881144 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  593 | Train Loss:  0.0031913868586222333 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  594 | Train Loss:  0.003248373071352641 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  595 | Train Loss:  0.002699408729871114 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  596 | Train Loss:  0.003228061596552531 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  597 | Train Loss:  0.003793463706970215 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  598 | Train Loss:  0.0030993964274724324 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  599 | Train Loss:  0.0032802351315816243 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  600 | Train Loss:  0.002640937368075053 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  601 | Train Loss:  0.0031482499837875368 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  602 | Train Loss:  0.0038234349091847736 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  603 | Train Loss:  0.002985381484031677 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  604 | Train Loss:  0.003150354226430257 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  605 | Train Loss:  0.0025968984762827557 | Train Accuracy:  0.98 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  606 | Train Loss:  0.0029992852608362835 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  607 | Train Loss:  0.0036525805791219074 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  608 | Train Loss:  0.002883178393046061 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  609 | Train Loss:  0.002937962611516317 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  610 | Train Loss:  0.0024916815757751467 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  611 | Train Loss:  0.0029055853684743244 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  612 | Train Loss:  0.0034840381145477294 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  613 | Train Loss:  0.0027945123116175333 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  614 | Train Loss:  0.002861422300338745 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  615 | Train Loss:  0.002409633994102478 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  616 | Train Loss:  0.002836012641588847 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  617 | Train Loss:  0.0034355711936950683 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  618 | Train Loss:  0.0027014960845311484 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  619 | Train Loss:  0.0027921303113301594 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  620 | Train Loss:  0.0023595434427261352 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  621 | Train Loss:  0.0027304275830586752 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  622 | Train Loss:  0.0033475550015767417 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  623 | Train Loss:  0.002607413132985433 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  624 | Train Loss:  0.00264776349067688 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  625 | Train Loss:  0.0022907106081644694 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  626 | Train Loss:  0.0026270230611165363 | Train Accuracy:  0.98 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  627 | Train Loss:  0.0032034230232238768 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  628 | Train Loss:  0.002523414889971415 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  629 | Train Loss:  0.0025260549783706664 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  630 | Train Loss:  0.002213557561238607 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  631 | Train Loss:  0.0025444215536117552 | Train Accuracy:  0.98 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  632 | Train Loss:  0.0030946820974349976 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  633 | Train Loss:  0.0024438450733820596 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  634 | Train Loss:  0.0024407710631688434 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  635 | Train Loss:  0.0021505395571390787 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  636 | Train Loss:  0.0024613030751546223 | Train Accuracy:  0.98 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  637 | Train Loss:  0.003009276588757833 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  638 | Train Loss:  0.0023631727695465087 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  639 | Train Loss:  0.002345922390619914 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  640 | Train Loss:  0.0020928873618443807 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  641 | Train Loss:  0.0023714683453241983 | Train Accuracy:  0.98 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  642 | Train Loss:  0.0029078219334284466 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  643 | Train Loss:  0.0022848089536031085 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  644 | Train Loss:  0.002238541841506958 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  645 | Train Loss:  0.002030760447184245 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  646 | Train Loss:  0.0022851361831029257 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  647 | Train Loss:  0.002795949379603068 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  648 | Train Loss:  0.0022112393379211427 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  649 | Train Loss:  0.002139467199643453 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  650 | Train Loss:  0.001964970827102661 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  651 | Train Loss:  0.002208751837412516 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  652 | Train Loss:  0.0026958539088567097 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  653 | Train Loss:  0.0021414448817571002 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  654 | Train Loss:  0.0020576196908950804 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  655 | Train Loss:  0.0019050109386444091 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  656 | Train Loss:  0.0021347335974375406 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  657 | Train Loss:  0.0026113754510879517 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  658 | Train Loss:  0.0020714477698008217 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  659 | Train Loss:  0.001975636680920919 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  660 | Train Loss:  0.0018492176135381062 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  661 | Train Loss:  0.0020581986506779987 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  662 | Train Loss:  0.0025230832894643147 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  663 | Train Loss:  0.0020026155312856037 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  664 | Train Loss:  0.0018876065810521443 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  665 | Train Loss:  0.0017918550968170166 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  666 | Train Loss:  0.0019833368062973024 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  667 | Train Loss:  0.002428562839825948 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  668 | Train Loss:  0.0019371384382247925 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  669 | Train Loss:  0.0018029282490412393 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  670 | Train Loss:  0.0017335585753122966 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  671 | Train Loss:  0.0019124909241994223 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  672 | Train Loss:  0.0023358454306920367 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  673 | Train Loss:  0.0018745150168736776 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  674 | Train Loss:  0.0017238336801528931 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  675 | Train Loss:  0.0016763530174891154 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  676 | Train Loss:  0.001845881740252177 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  677 | Train Loss:  0.002250814437866211 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  678 | Train Loss:  0.0018138722578684488 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  679 | Train Loss:  0.0016514194011688233 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  680 | Train Loss:  0.001622437040011088 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  681 | Train Loss:  0.0017807223399480183 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  682 | Train Loss:  0.0021703894933064777 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  683 | Train Loss:  0.0017544203996658326 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  684 | Train Loss:  0.0015800957878430685 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  685 | Train Loss:  0.0015700950225194295 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  686 | Train Loss:  0.0017166223128636678 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  687 | Train Loss:  0.0020895147323608397 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  688 | Train Loss:  0.0016969205935796101 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  689 | Train Loss:  0.001509957214196523 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  690 | Train Loss:  0.001519249677658081 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  691 | Train Loss:  0.0016534800330797832 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  692 | Train Loss:  0.0020081303517023724 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  693 | Train Loss:  0.0016412833333015442 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  694 | Train Loss:  0.0014405753215154013 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  695 | Train Loss:  0.001468191146850586 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  696 | Train Loss:  0.0015930706262588501 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  697 | Train Loss:  0.0019273817539215087 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  698 | Train Loss:  0.0015881009896596273 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  699 | Train Loss:  0.0013750593860944113 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  700 | Train Loss:  0.001417423188686371 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  701 | Train Loss:  0.0015371265014012655 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  702 | Train Loss:  0.001851017673810323 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  703 | Train Loss:  0.001537764271100362 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  704 | Train Loss:  0.0013167961438496907 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  705 | Train Loss:  0.0013690202434857685 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  706 | Train Loss:  0.0014839606483777364 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  707 | Train Loss:  0.0017819863557815552 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  708 | Train Loss:  0.0014887501796086629 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  709 | Train Loss:  0.0012627699971199035 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  710 | Train Loss:  0.0013242411613464357 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  711 | Train Loss:  0.001431166430314382 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  712 | Train Loss:  0.0017154093583424887 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  713 | Train Loss:  0.001440479060014089 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  714 | Train Loss:  0.0012083148956298828 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  715 | Train Loss:  0.001282052497069041 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  716 | Train Loss:  0.0013780367374420165 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  717 | Train Loss:  0.0016463331381479898 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  718 | Train Loss:  0.0013936885197957357 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  719 | Train Loss:  0.0011526763439178467 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  720 | Train Loss:  0.001236863632996877 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  721 | Train Loss:  0.0013293845454851786 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  722 | Train Loss:  0.0015771203239758808 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  723 | Train Loss:  0.0013508368531862894 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  724 | Train Loss:  0.0011044559876124064 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  725 | Train Loss:  0.0011928955713907878 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  726 | Train Loss:  0.0012846521536509195 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  727 | Train Loss:  0.0015161852041880289 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  728 | Train Loss:  0.0013099677364031474 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  729 | Train Loss:  0.001063351333141327 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  730 | Train Loss:  0.0011526946226755779 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  731 | Train Loss:  0.0012411553661028545 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  732 | Train Loss:  0.0014635659257570903 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  733 | Train Loss:  0.0012687412897745768 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  734 | Train Loss:  0.0010233214497566223 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  735 | Train Loss:  0.0011157667636871337 | Train Accuracy:  1.0 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  736 | Train Loss:  0.0011971211433410645 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  737 | Train Loss:  0.0014100179076194763 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  738 | Train Loss:  0.0012279927730560302 | Train Accuracy:  1.0 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  739 | Train Loss:  0.0009795522689819336 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  740 | Train Loss:  0.0010779443383216857 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  741 | Train Loss:  0.0011550704638163248 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  742 | Train Loss:  0.0013535310824712118 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  743 | Train Loss:  0.0011898600061734518 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  744 | Train Loss:  0.0009379635254542033 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  745 | Train Loss:  0.001039870282014211 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  746 | Train Loss:  0.0011163198947906495 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  747 | Train Loss:  0.001301045517126719 | Train Accuracy:  1.0 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  748 | Train Loss:  0.0011535655458768208 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n",
            "Iteration:  749 | Train Loss:  0.0009004329641660054 | Train Accuracy:  1.0 | Validation Accuracy:  0.56\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 1.0\n",
            "Final Validation Accuracy: 0.56\n",
            "Maximum Training Accuracy: 1.0\n",
            "Maximum Validation Accuracy: 0.6266666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qeSbOlMLgNm4",
        "outputId": "2ab685c3-4805-4f1e-db46-3252ee1951a2"
      },
      "source": [
        "model = ANN_TS_3L()\n",
        "train(model, train_dataset, val_dataset, batch_size = 50, num_epochs=100, learning_rate = 0.005, momen = 0.7, use_adam = True, save_weights=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.013924005031585694 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1 | Train Loss:  0.013850003480911255 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2 | Train Loss:  0.013864932060241699 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3 | Train Loss:  0.013865151405334473 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  4 | Train Loss:  0.013854248523712158 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  5 | Train Loss:  0.013937231302261353 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  6 | Train Loss:  0.013844608068466187 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  7 | Train Loss:  0.013868027925491333 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  8 | Train Loss:  0.013852353096008302 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  9 | Train Loss:  0.01386380910873413 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  10 | Train Loss:  0.013864194154739379 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  11 | Train Loss:  0.01385438084602356 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  12 | Train Loss:  0.013934073448181152 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  13 | Train Loss:  0.01380223035812378 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  14 | Train Loss:  0.013874747753143311 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  15 | Train Loss:  0.013843202590942382 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  16 | Train Loss:  0.013865181207656861 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  17 | Train Loss:  0.0138655424118042 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  18 | Train Loss:  0.01385221004486084 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  19 | Train Loss:  0.013952744007110596 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  20 | Train Loss:  0.013778277635574342 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  21 | Train Loss:  0.013879069089889527 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  22 | Train Loss:  0.013838565349578858 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  23 | Train Loss:  0.013866196870803833 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  24 | Train Loss:  0.013866459131240844 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  25 | Train Loss:  0.013851224184036256 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  26 | Train Loss:  0.013962292671203613 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  27 | Train Loss:  0.013767968416213989 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  28 | Train Loss:  0.013880914449691773 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  29 | Train Loss:  0.013836867809295654 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  30 | Train Loss:  0.013866586685180664 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  31 | Train Loss:  0.013866753578186035 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  32 | Train Loss:  0.013850979804992676 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  33 | Train Loss:  0.013964000940322876 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  34 | Train Loss:  0.01376618504524231 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  35 | Train Loss:  0.013881077766418457 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  36 | Train Loss:  0.013836818933486938 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  37 | Train Loss:  0.013866535425186156 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  38 | Train Loss:  0.013866648674011231 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  39 | Train Loss:  0.013851104974746705 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  40 | Train Loss:  0.013961704969406128 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  41 | Train Loss:  0.013768391609191894 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  42 | Train Loss:  0.013880486488342286 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  43 | Train Loss:  0.013837447166442871 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  44 | Train Loss:  0.013866316080093383 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  45 | Train Loss:  0.013866413831710816 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  46 | Train Loss:  0.01385134220123291 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  47 | Train Loss:  0.01395843505859375 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  48 | Train Loss:  0.013771454095840454 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  49 | Train Loss:  0.013879791498184205 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  50 | Train Loss:  0.01383813500404358 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  51 | Train Loss:  0.013866112232208253 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  52 | Train Loss:  0.013866195678710938 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  53 | Train Loss:  0.013851535320281983 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  54 | Train Loss:  0.013955880403518677 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  55 | Train Loss:  0.01377374529838562 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  56 | Train Loss:  0.01387929081916809 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  57 | Train Loss:  0.013838582038879395 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  58 | Train Loss:  0.013865976333618165 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  59 | Train Loss:  0.013866063356399536 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  60 | Train Loss:  0.013851627111434936 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  61 | Train Loss:  0.01395450472831726 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  62 | Train Loss:  0.013774867057800294 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  63 | Train Loss:  0.01387903928756714 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  64 | Train Loss:  0.013838752508163452 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  65 | Train Loss:  0.013865919113159179 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  66 | Train Loss:  0.013865997791290283 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  67 | Train Loss:  0.01385162353515625 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  68 | Train Loss:  0.013954144716262818 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  69 | Train Loss:  0.013775001764297485 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  70 | Train Loss:  0.013878980875015259 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  71 | Train Loss:  0.01383870244026184 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  72 | Train Loss:  0.013865911960601806 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  73 | Train Loss:  0.013865976333618165 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  74 | Train Loss:  0.013851546049118042 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  75 | Train Loss:  0.013954321146011353 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  76 | Train Loss:  0.013774691820144654 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  77 | Train Loss:  0.01387898564338684 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  78 | Train Loss:  0.013838576078414917 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  79 | Train Loss:  0.013865914344787598 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  80 | Train Loss:  0.013865952491760253 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  81 | Train Loss:  0.013851449489593506 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  82 | Train Loss:  0.013954581022262573 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  83 | Train Loss:  0.013774337768554688 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  84 | Train Loss:  0.013878973722457886 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  85 | Train Loss:  0.013838423490524292 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  86 | Train Loss:  0.013865910768508911 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  87 | Train Loss:  0.013865917921066284 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  88 | Train Loss:  0.013851321935653686 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  89 | Train Loss:  0.01395481824874878 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  90 | Train Loss:  0.013774058818817138 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  91 | Train Loss:  0.013878910541534424 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  92 | Train Loss:  0.013838281631469726 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  93 | Train Loss:  0.013865889310836791 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  94 | Train Loss:  0.013865853548049928 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  95 | Train Loss:  0.013851172924041748 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  96 | Train Loss:  0.013954880237579346 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  97 | Train Loss:  0.013773977756500244 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  98 | Train Loss:  0.01387877345085144 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  99 | Train Loss:  0.013838140964508057 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  100 | Train Loss:  0.01386584758758545 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  101 | Train Loss:  0.0138657546043396 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  102 | Train Loss:  0.013850979804992676 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  103 | Train Loss:  0.013954805135726929 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  104 | Train Loss:  0.013774094581604003 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  105 | Train Loss:  0.013878533840179444 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  106 | Train Loss:  0.013838019371032715 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  107 | Train Loss:  0.01386576533317566 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  108 | Train Loss:  0.01386559009552002 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  109 | Train Loss:  0.013850734233856202 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  110 | Train Loss:  0.01395449161529541 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  111 | Train Loss:  0.013774467706680298 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  112 | Train Loss:  0.013878167867660522 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  113 | Train Loss:  0.013837851285934448 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  114 | Train Loss:  0.013865654468536376 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  115 | Train Loss:  0.01386536717414856 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  116 | Train Loss:  0.013850365877151488 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  117 | Train Loss:  0.013954204320907593 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  118 | Train Loss:  0.013774920701980591 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  119 | Train Loss:  0.013877639770507813 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  120 | Train Loss:  0.01383762240409851 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  121 | Train Loss:  0.013865485191345214 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  122 | Train Loss:  0.013865020275115967 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  123 | Train Loss:  0.013849840164184571 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  124 | Train Loss:  0.013953540325164795 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  125 | Train Loss:  0.013775874376296997 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  126 | Train Loss:  0.013876807689666749 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  127 | Train Loss:  0.013837265968322753 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  128 | Train Loss:  0.013865230083465576 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  129 | Train Loss:  0.013864502906799317 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  130 | Train Loss:  0.013848984241485595 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  131 | Train Loss:  0.013953080177307129 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  132 | Train Loss:  0.01377679467201233 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  133 | Train Loss:  0.013875601291656494 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  134 | Train Loss:  0.013836560249328613 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  135 | Train Loss:  0.01386483907699585 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  136 | Train Loss:  0.013863681554794312 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  137 | Train Loss:  0.013847535848617554 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  138 | Train Loss:  0.013952832221984863 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  139 | Train Loss:  0.013777962923049926 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  140 | Train Loss:  0.013873655796051026 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  141 | Train Loss:  0.013835227489471436 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  142 | Train Loss:  0.013864185810089111 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  143 | Train Loss:  0.013862252235412598 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  144 | Train Loss:  0.013844923973083496 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  145 | Train Loss:  0.013953137397766113 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  146 | Train Loss:  0.013779515027999878 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  147 | Train Loss:  0.013870161771774293 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  148 | Train Loss:  0.013832687139511109 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  149 | Train Loss:  0.013862948417663574 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  150 | Train Loss:  0.013859628438949586 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  151 | Train Loss:  0.013840038776397705 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  152 | Train Loss:  0.013952059745788574 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  153 | Train Loss:  0.013784987926483154 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  154 | Train Loss:  0.013862925767898559 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  155 | Train Loss:  0.013827698230743408 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  156 | Train Loss:  0.013860406875610352 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  157 | Train Loss:  0.013854326009750366 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  158 | Train Loss:  0.013829723596572877 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  159 | Train Loss:  0.013953708410263062 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  160 | Train Loss:  0.013792119026184081 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  161 | Train Loss:  0.01384791374206543 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  162 | Train Loss:  0.013817017078399657 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  163 | Train Loss:  0.013854373693466187 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  164 | Train Loss:  0.01384191870689392 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  165 | Train Loss:  0.01380693793296814 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  166 | Train Loss:  0.013948943614959717 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  167 | Train Loss:  0.013820565938949585 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  168 | Train Loss:  0.01381179690361023 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  169 | Train Loss:  0.0137880539894104 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  170 | Train Loss:  0.013841233253479003 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  171 | Train Loss:  0.01382269024848938 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  172 | Train Loss:  0.013750910758972168 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  173 | Train Loss:  0.013915330171585083 | Train Accuracy:  0.5 | Validation Accuracy:  0.52\n",
            "Iteration:  174 | Train Loss:  0.013934385776519776 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  175 | Train Loss:  0.013726263046264649 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  176 | Train Loss:  0.013731300830841064 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  177 | Train Loss:  0.013811829090118409 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  178 | Train Loss:  0.013811945915222168 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  179 | Train Loss:  0.01364516258239746 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  180 | Train Loss:  0.013788933753967286 | Train Accuracy:  0.4942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  181 | Train Loss:  0.014244635105133057 | Train Accuracy:  0.49714285714285716 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  182 | Train Loss:  0.0136257004737854 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  183 | Train Loss:  0.013688310384750366 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  184 | Train Loss:  0.013753571510314942 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  185 | Train Loss:  0.013815535306930542 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  186 | Train Loss:  0.013610502481460571 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  187 | Train Loss:  0.013850554227828979 | Train Accuracy:  0.49714285714285716 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  188 | Train Loss:  0.01421790599822998 | Train Accuracy:  0.49714285714285716 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  189 | Train Loss:  0.013513243198394776 | Train Accuracy:  0.5 | Validation Accuracy:  0.52\n",
            "Iteration:  190 | Train Loss:  0.013715982437133789 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  191 | Train Loss:  0.01369609236717224 | Train Accuracy:  0.6 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  192 | Train Loss:  0.013591197729110717 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  193 | Train Loss:  0.01340403437614441 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  194 | Train Loss:  0.014205409288406372 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  195 | Train Loss:  0.013493876457214355 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  196 | Train Loss:  0.013322927951812745 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  197 | Train Loss:  0.013348158597946167 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  198 | Train Loss:  0.013562737703323365 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  199 | Train Loss:  0.013371014595031738 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  200 | Train Loss:  0.01301956295967102 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  201 | Train Loss:  0.013630975484848023 | Train Accuracy:  0.54 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  202 | Train Loss:  0.01410138726234436 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  203 | Train Loss:  0.012754920721054077 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  204 | Train Loss:  0.012627049684524536 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  205 | Train Loss:  0.013557229042053223 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  206 | Train Loss:  0.012942336797714234 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  207 | Train Loss:  0.012798831462860108 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  208 | Train Loss:  0.012475041151046752 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  209 | Train Loss:  0.013854818344116211 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  210 | Train Loss:  0.013042137622833253 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  211 | Train Loss:  0.012256678342819214 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  212 | Train Loss:  0.012789986133575439 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  213 | Train Loss:  0.013020873069763184 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  214 | Train Loss:  0.012080858945846557 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  215 | Train Loss:  0.01385868787765503 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  216 | Train Loss:  0.011953831911087036 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  217 | Train Loss:  0.01138766884803772 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  218 | Train Loss:  0.011128426790237426 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  219 | Train Loss:  0.012391910552978516 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  220 | Train Loss:  0.01154935359954834 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  221 | Train Loss:  0.010950688123703003 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  222 | Train Loss:  0.01181573748588562 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  223 | Train Loss:  0.01358462929725647 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  224 | Train Loss:  0.011461220979690552 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  225 | Train Loss:  0.010381647348403931 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  226 | Train Loss:  0.011742048263549805 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  227 | Train Loss:  0.01194101095199585 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  228 | Train Loss:  0.009910855889320374 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  229 | Train Loss:  0.014294952154159546 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  230 | Train Loss:  0.012664809226989746 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  231 | Train Loss:  0.009697567820549011 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  232 | Train Loss:  0.009361541867256164 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  233 | Train Loss:  0.012653981447219848 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  234 | Train Loss:  0.010150175094604492 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  235 | Train Loss:  0.011487345695495605 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  236 | Train Loss:  0.010133850574493408 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  237 | Train Loss:  0.010265985727310181 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  238 | Train Loss:  0.01065340757369995 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  239 | Train Loss:  0.008913437128067017 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  240 | Train Loss:  0.010671247243881226 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  241 | Train Loss:  0.009775779843330383 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  242 | Train Loss:  0.008846973180770873 | Train Accuracy:  0.76 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  243 | Train Loss:  0.010798469781875611 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  244 | Train Loss:  0.013251335620880126 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  245 | Train Loss:  0.008758752346038819 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  246 | Train Loss:  0.008845327496528626 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  247 | Train Loss:  0.010609529018402099 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  248 | Train Loss:  0.010480760335922242 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  249 | Train Loss:  0.009285013675689697 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  250 | Train Loss:  0.012256150245666503 | Train Accuracy:  0.82 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  251 | Train Loss:  0.009949842691421509 | Train Accuracy:  0.82 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  252 | Train Loss:  0.00806235134601593 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  253 | Train Loss:  0.00796370267868042 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  254 | Train Loss:  0.011170345544815063 | Train Accuracy:  0.82 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  255 | Train Loss:  0.00853983759880066 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  256 | Train Loss:  0.010082072019577027 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  257 | Train Loss:  0.008397834300994873 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  258 | Train Loss:  0.009087254405021667 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  259 | Train Loss:  0.008855966329574584 | Train Accuracy:  0.84 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  260 | Train Loss:  0.007783549427986145 | Train Accuracy:  0.84 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  261 | Train Loss:  0.009086039066314697 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  262 | Train Loss:  0.008062423467636108 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  263 | Train Loss:  0.007482550144195557 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  264 | Train Loss:  0.00865227460861206 | Train Accuracy:  0.78 | Validation Accuracy:  0.56\n",
            "Iteration:  265 | Train Loss:  0.011112582683563233 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  266 | Train Loss:  0.00775745689868927 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  267 | Train Loss:  0.007040373086929321 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  268 | Train Loss:  0.00870107889175415 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  269 | Train Loss:  0.00864178717136383 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  270 | Train Loss:  0.0069723200798034665 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  271 | Train Loss:  0.010691096782684326 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  272 | Train Loss:  0.01139947772026062 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  273 | Train Loss:  0.006458194851875305 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  274 | Train Loss:  0.006850665807723999 | Train Accuracy:  0.8 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  275 | Train Loss:  0.009626471996307373 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  276 | Train Loss:  0.0083309006690979 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  277 | Train Loss:  0.008289902210235596 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  278 | Train Loss:  0.010125898122787476 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  279 | Train Loss:  0.008063716292381286 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  280 | Train Loss:  0.0061007851362228395 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  281 | Train Loss:  0.006584941744804383 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  282 | Train Loss:  0.010148545503616333 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  283 | Train Loss:  0.006593868732452392 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.6\n",
            "Iteration:  284 | Train Loss:  0.009818388223648071 | Train Accuracy:  0.88 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  285 | Train Loss:  0.006393459439277649 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  286 | Train Loss:  0.007835671901702881 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  287 | Train Loss:  0.006929872035980225 | Train Accuracy:  0.84 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  288 | Train Loss:  0.008144493103027345 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  289 | Train Loss:  0.007286145687103272 | Train Accuracy:  0.88 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  290 | Train Loss:  0.006752414703369141 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  291 | Train Loss:  0.006048092842102051 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.6\n",
            "Iteration:  292 | Train Loss:  0.006055962443351746 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  293 | Train Loss:  0.007190808653831482 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  294 | Train Loss:  0.007195611596107483 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  295 | Train Loss:  0.00598558783531189 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  296 | Train Loss:  0.006713570356369019 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  297 | Train Loss:  0.005684465169906616 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  298 | Train Loss:  0.005313156247138977 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  299 | Train Loss:  0.0058808445930480955 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  300 | Train Loss:  0.007159011363983154 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  301 | Train Loss:  0.0055075687170028685 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  302 | Train Loss:  0.005400719046592712 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  303 | Train Loss:  0.006674238443374634 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  304 | Train Loss:  0.005298914909362793 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  305 | Train Loss:  0.005346855521202088 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  306 | Train Loss:  0.006278476119041443 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  307 | Train Loss:  0.006817063093185425 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  308 | Train Loss:  0.004559924304485321 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  309 | Train Loss:  0.0049190235137939456 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  310 | Train Loss:  0.006809834837913514 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  311 | Train Loss:  0.005176326036453247 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  312 | Train Loss:  0.00495053380727768 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  313 | Train Loss:  0.006881247758865356 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  314 | Train Loss:  0.00702149748802185 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  315 | Train Loss:  0.003995127975940704 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  316 | Train Loss:  0.004318162798881531 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  317 | Train Loss:  0.005948505997657776 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  318 | Train Loss:  0.005240666270256042 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  319 | Train Loss:  0.003969810903072357 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  320 | Train Loss:  0.006417596936225891 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  321 | Train Loss:  0.007014517188072205 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  322 | Train Loss:  0.003666428029537201 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  323 | Train Loss:  0.0039509785175323485 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  324 | Train Loss:  0.004916411340236664 | Train Accuracy:  0.82 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  325 | Train Loss:  0.004575715363025665 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.6\n",
            "Iteration:  326 | Train Loss:  0.0034638938307762148 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  327 | Train Loss:  0.005335543155670166 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  328 | Train Loss:  0.005659230351448059 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  329 | Train Loss:  0.00304551362991333 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  330 | Train Loss:  0.003604883849620819 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  331 | Train Loss:  0.004980355799198151 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  332 | Train Loss:  0.004066374599933625 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  333 | Train Loss:  0.003603551387786865 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  334 | Train Loss:  0.00546825110912323 | Train Accuracy:  0.94 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  335 | Train Loss:  0.004851156175136566 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  336 | Train Loss:  0.002630720138549805 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  337 | Train Loss:  0.0032370907068252565 | Train Accuracy:  0.88 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  338 | Train Loss:  0.005215370655059814 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  339 | Train Loss:  0.003983672857284546 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  340 | Train Loss:  0.00375671923160553 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  341 | Train Loss:  0.0058111906051635746 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  342 | Train Loss:  0.0042490923404693605 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  343 | Train Loss:  0.0026820239424705503 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  344 | Train Loss:  0.00292776882648468 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  345 | Train Loss:  0.005570889115333557 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  346 | Train Loss:  0.003416305482387543 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  347 | Train Loss:  0.00517849326133728 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  348 | Train Loss:  0.006027636528015137 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  349 | Train Loss:  0.0035456517338752747 | Train Accuracy:  0.88 | Validation Accuracy:  0.56\n",
            "Iteration:  350 | Train Loss:  0.0041156020760536195 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  351 | Train Loss:  0.002706506550312042 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  352 | Train Loss:  0.009579238295555115 | Train Accuracy:  0.9 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  353 | Train Loss:  0.00237865149974823 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  354 | Train Loss:  0.013804959058761597 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  355 | Train Loss:  0.0046491226553916935 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  356 | Train Loss:  0.010700591802597047 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  357 | Train Loss:  0.001991073042154312 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  358 | Train Loss:  0.016694265604019164 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  359 | Train Loss:  0.008084723949432373 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  360 | Train Loss:  0.0200085711479187 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  361 | Train Loss:  0.0063611739873886105 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  362 | Train Loss:  0.024278366565704347 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  363 | Train Loss:  0.0039001861214637756 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  364 | Train Loss:  0.020100040435791014 | Train Accuracy:  0.66 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  365 | Train Loss:  0.011233526468276977 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.6\n",
            "Iteration:  366 | Train Loss:  0.0034504780173301697 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  367 | Train Loss:  0.007622112035751343 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  368 | Train Loss:  0.0033423241972923277 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  369 | Train Loss:  0.0028893038630485534 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  370 | Train Loss:  0.006602116227149964 | Train Accuracy:  0.84 | Validation Accuracy:  0.48\n",
            "Iteration:  371 | Train Loss:  0.004948869943618774 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  372 | Train Loss:  0.003894192576408386 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  373 | Train Loss:  0.005342872142791748 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  374 | Train Loss:  0.003269527554512024 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  375 | Train Loss:  0.002993403971195221 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  376 | Train Loss:  0.003746274709701538 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  377 | Train Loss:  0.00427753895521164 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  378 | Train Loss:  0.0029197511076927184 | Train Accuracy:  0.9 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  379 | Train Loss:  0.002816603183746338 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  380 | Train Loss:  0.0029314219951629638 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  381 | Train Loss:  0.002607319951057434 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  382 | Train Loss:  0.0031931018829345703 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  383 | Train Loss:  0.0069268780946731565 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  384 | Train Loss:  0.00350144624710083 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  385 | Train Loss:  0.006949857473373413 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  386 | Train Loss:  0.0036517280340194703 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  387 | Train Loss:  0.002461603730916977 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  388 | Train Loss:  0.002840249538421631 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  389 | Train Loss:  0.0033761852979660033 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.6\n",
            "Iteration:  390 | Train Loss:  0.0036912882328033448 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  391 | Train Loss:  0.0040355086326599125 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  392 | Train Loss:  0.005776890516281128 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  393 | Train Loss:  0.002274615168571472 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  394 | Train Loss:  0.0027949243783950807 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  395 | Train Loss:  0.002316962480545044 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  396 | Train Loss:  0.002143671214580536 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.6\n",
            "Iteration:  397 | Train Loss:  0.003008467853069305 | Train Accuracy:  0.96 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  398 | Train Loss:  0.003260355293750763 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  399 | Train Loss:  0.003505069613456726 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  400 | Train Loss:  0.002087656557559967 | Train Accuracy:  0.98 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  401 | Train Loss:  0.002183348834514618 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  402 | Train Loss:  0.0019637086987495424 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  403 | Train Loss:  0.0022147513926029207 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  404 | Train Loss:  0.003913338780403137 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  405 | Train Loss:  0.0029465603828430177 | Train Accuracy:  0.84 | Validation Accuracy:  0.48\n",
            "Iteration:  406 | Train Loss:  0.004227928519248962 | Train Accuracy:  0.9 | Validation Accuracy:  0.48\n",
            "Iteration:  407 | Train Loss:  0.002285422384738922 | Train Accuracy:  0.98 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  408 | Train Loss:  0.0020294027030467988 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  409 | Train Loss:  0.001945682168006897 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  410 | Train Loss:  0.002496370822191238 | Train Accuracy:  0.94 | Validation Accuracy:  0.6\n",
            "Iteration:  411 | Train Loss:  0.003224572241306305 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  412 | Train Loss:  0.002999924123287201 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  413 | Train Loss:  0.004208602607250213 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  414 | Train Loss:  0.0018308141827583313 | Train Accuracy:  0.98 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  415 | Train Loss:  0.002044825553894043 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  416 | Train Loss:  0.001755356788635254 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  417 | Train Loss:  0.0019438865780830384 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  418 | Train Loss:  0.0026529258489608764 | Train Accuracy:  0.96 | Validation Accuracy:  0.52\n",
            "Iteration:  419 | Train Loss:  0.0026024168729782103 | Train Accuracy:  0.86 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  420 | Train Loss:  0.0031345584988594056 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  421 | Train Loss:  0.0016935938596725464 | Train Accuracy:  0.98 | Validation Accuracy:  0.6\n",
            "Iteration:  422 | Train Loss:  0.001778116226196289 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  423 | Train Loss:  0.0015190319716930389 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  424 | Train Loss:  0.002033897787332535 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  425 | Train Loss:  0.0029053652286529542 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  426 | Train Loss:  0.002399592250585556 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  427 | Train Loss:  0.0034279090166091917 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  428 | Train Loss:  0.0016473308205604553 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.6\n",
            "Iteration:  429 | Train Loss:  0.0016788816452026367 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  430 | Train Loss:  0.0014681878685951233 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  431 | Train Loss:  0.0019628520309925078 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  432 | Train Loss:  0.002364099472761154 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  433 | Train Loss:  0.0022452667355537413 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  434 | Train Loss:  0.002902156710624695 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  435 | Train Loss:  0.001454833447933197 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  436 | Train Loss:  0.001533869206905365 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  437 | Train Loss:  0.0012878192961215972 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  438 | Train Loss:  0.0018849104642868042 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  439 | Train Loss:  0.0023177747428417207 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  440 | Train Loss:  0.00200104758143425 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  441 | Train Loss:  0.002779727876186371 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  442 | Train Loss:  0.001432187408208847 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  443 | Train Loss:  0.00140487939119339 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  444 | Train Loss:  0.0012141727656126023 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  445 | Train Loss:  0.001956924796104431 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  446 | Train Loss:  0.0020595857501029967 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  447 | Train Loss:  0.0018682697415351869 | Train Accuracy:  0.84 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  448 | Train Loss:  0.0025794219970703123 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  449 | Train Loss:  0.001321055293083191 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  450 | Train Loss:  0.0012965448200702666 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  451 | Train Loss:  0.0011064891517162322 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  452 | Train Loss:  0.0019236379861831666 | Train Accuracy:  0.94 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  453 | Train Loss:  0.0019133377075195312 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  454 | Train Loss:  0.0016717523336410522 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  455 | Train Loss:  0.002425447702407837 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  456 | Train Loss:  0.001309685856103897 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  457 | Train Loss:  0.0011941862106323242 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  458 | Train Loss:  0.0010388711094856263 | Train Accuracy:  0.86 | Validation Accuracy:  0.56\n",
            "Iteration:  459 | Train Loss:  0.0020270012319087982 | Train Accuracy:  0.94 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  460 | Train Loss:  0.0017359776794910432 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  461 | Train Loss:  0.0015477424860000611 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  462 | Train Loss:  0.002326703816652298 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  463 | Train Loss:  0.0012549227476119995 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  464 | Train Loss:  0.001109621524810791 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  465 | Train Loss:  0.0009678949415683747 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  466 | Train Loss:  0.002051486819982529 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  467 | Train Loss:  0.0016018350422382355 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  468 | Train Loss:  0.001392970383167267 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  469 | Train Loss:  0.0022265224158763888 | Train Accuracy:  0.9 | Validation Accuracy:  0.48\n",
            "Iteration:  470 | Train Loss:  0.001266644150018692 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  471 | Train Loss:  0.001035485863685608 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  472 | Train Loss:  0.0009241925925016403 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  473 | Train Loss:  0.0021738761663436888 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  474 | Train Loss:  0.0014559076726436615 | Train Accuracy:  0.94 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  475 | Train Loss:  0.0012881909310817718 | Train Accuracy:  0.82 | Validation Accuracy:  0.48\n",
            "Iteration:  476 | Train Loss:  0.0021571895480155946 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  477 | Train Loss:  0.0012460901588201524 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  478 | Train Loss:  0.0009722533822059631 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  479 | Train Loss:  0.0008766477555036545 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  480 | Train Loss:  0.0022407642006874087 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  481 | Train Loss:  0.0013576191663742065 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  482 | Train Loss:  0.0011713702976703644 | Train Accuracy:  0.82 | Validation Accuracy:  0.48\n",
            "Iteration:  483 | Train Loss:  0.002119992822408676 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  484 | Train Loss:  0.0012720896303653718 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  485 | Train Loss:  0.0009186333417892456 | Train Accuracy:  0.92 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  486 | Train Loss:  0.0008518276363611221 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  487 | Train Loss:  0.0023453570902347565 | Train Accuracy:  0.94 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  488 | Train Loss:  0.0012486481666564941 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  489 | Train Loss:  0.0010804298520088196 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  490 | Train Loss:  0.002073996216058731 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  491 | Train Loss:  0.0012922820448875428 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  492 | Train Loss:  0.0008748327195644378 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  493 | Train Loss:  0.0008253288269042968 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  494 | Train Loss:  0.0024541376531124117 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  495 | Train Loss:  0.0011718036979436873 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  496 | Train Loss:  0.001001439020037651 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  497 | Train Loss:  0.0020578929781913755 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  498 | Train Loss:  0.0013167400658130645 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  499 | Train Loss:  0.000836576297879219 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  500 | Train Loss:  0.0008062131702899933 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  501 | Train Loss:  0.002543864548206329 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  502 | Train Loss:  0.0011106852442026138 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  503 | Train Loss:  0.0009285900741815567 | Train Accuracy:  0.8 | Validation Accuracy:  0.48\n",
            "Iteration:  504 | Train Loss:  0.0020463910698890688 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  505 | Train Loss:  0.0013585080206394195 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  506 | Train Loss:  0.0008067457377910614 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  507 | Train Loss:  0.0007957416772842407 | Train Accuracy:  0.74 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  508 | Train Loss:  0.002654343843460083 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  509 | Train Loss:  0.0010564916580915451 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  510 | Train Loss:  0.0008713071048259735 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  511 | Train Loss:  0.0020422948896884918 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  512 | Train Loss:  0.0013963907957077026 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  513 | Train Loss:  0.0007844487577676773 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  514 | Train Loss:  0.0007842110097408295 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  515 | Train Loss:  0.0027687495946884157 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  516 | Train Loss:  0.0010242941230535507 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  517 | Train Loss:  0.0008235190063714982 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  518 | Train Loss:  0.0020602971315383913 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  519 | Train Loss:  0.001430659145116806 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  520 | Train Loss:  0.0007679303735494613 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  521 | Train Loss:  0.0007708065211772918 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  522 | Train Loss:  0.0028789535164833067 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  523 | Train Loss:  0.0010147234052419662 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  524 | Train Loss:  0.0007826662808656693 | Train Accuracy:  0.78 | Validation Accuracy:  0.48\n",
            "Iteration:  525 | Train Loss:  0.0021037866175174715 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  526 | Train Loss:  0.0014591753482818604 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  527 | Train Loss:  0.0007555580884218215 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  528 | Train Loss:  0.0007548382878303527 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  529 | Train Loss:  0.0029781848192214967 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  530 | Train Loss:  0.0010324525833129883 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  531 | Train Loss:  0.0007486310601234436 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  532 | Train Loss:  0.002184813618659973 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  533 | Train Loss:  0.0014694245159626008 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  534 | Train Loss:  0.0007447297871112824 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  535 | Train Loss:  0.000731135681271553 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  536 | Train Loss:  0.003051043152809143 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  537 | Train Loss:  0.0010973355174064637 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  538 | Train Loss:  0.0007198597490787506 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  539 | Train Loss:  0.0023422865569591523 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  540 | Train Loss:  0.0014283367991447448 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  541 | Train Loss:  0.0007315737009048462 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  542 | Train Loss:  0.0006877746433019638 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  543 | Train Loss:  0.0030674543976783753 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  544 | Train Loss:  0.0012657664716243743 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  545 | Train Loss:  0.000707661360502243 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  546 | Train Loss:  0.002681340277194977 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  547 | Train Loss:  0.0012163576483726502 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  548 | Train Loss:  0.00071181520819664 | Train Accuracy:  0.88 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  549 | Train Loss:  0.0005803235620260239 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  550 | Train Loss:  0.0028994116187095642 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  551 | Train Loss:  0.0018664020299911498 | Train Accuracy:  0.92 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  552 | Train Loss:  0.0008371675759553909 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  553 | Train Loss:  0.003871677815914154 | Train Accuracy:  0.86 | Validation Accuracy:  0.48\n",
            "Iteration:  554 | Train Loss:  0.00045099347829818725 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  555 | Train Loss:  0.0006324084103107452 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  556 | Train Loss:  0.00037230372428894044 | Train Accuracy:  0.74 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  557 | Train Loss:  0.0011563603579998016 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  558 | Train Loss:  0.0077195227146148685 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  559 | Train Loss:  0.005590678453445435 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  560 | Train Loss:  0.004262802600860596 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  561 | Train Loss:  0.00018473017960786818 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  562 | Train Loss:  0.0030805382132530214 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  563 | Train Loss:  0.0007163933664560318 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  564 | Train Loss:  0.00039935361593961715 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  565 | Train Loss:  0.001613108217716217 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  566 | Train Loss:  0.006562440395355224 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  567 | Train Loss:  0.0064865189790725706 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  568 | Train Loss:  0.010755382776260376 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  569 | Train Loss:  0.003989934623241424 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  570 | Train Loss:  0.014833582639694214 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  571 | Train Loss:  0.00464758962392807 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  572 | Train Loss:  0.017150681018829345 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  573 | Train Loss:  0.017490284442901613 | Train Accuracy:  0.96 | Validation Accuracy:  0.56\n",
            "Iteration:  574 | Train Loss:  0.0006388039886951447 | Train Accuracy:  0.78 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  575 | Train Loss:  0.0028320753574371336 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  576 | Train Loss:  0.027694742679595947 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  577 | Train Loss:  0.0005071111768484115 | Train Accuracy:  0.54 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  578 | Train Loss:  0.03510260581970215 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  579 | Train Loss:  0.005198534727096558 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  580 | Train Loss:  0.006738599538803101 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  581 | Train Loss:  0.018592774868011475 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  582 | Train Loss:  0.00029420463368296624 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  583 | Train Loss:  0.0034678974747657776 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  584 | Train Loss:  0.0024648331105709075 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  585 | Train Loss:  0.0007474075257778167 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  586 | Train Loss:  0.0010916128009557725 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  587 | Train Loss:  0.002131892144680023 | Train Accuracy:  0.88 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  588 | Train Loss:  0.00014828646555542946 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  589 | Train Loss:  0.006679717898368836 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  590 | Train Loss:  0.016282835006713868 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  591 | Train Loss:  0.0014299976825714112 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  592 | Train Loss:  0.016154969930648803 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  593 | Train Loss:  0.023628792762756347 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  594 | Train Loss:  0.0009700880199670791 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  595 | Train Loss:  0.009719899892807006 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  596 | Train Loss:  0.022506873607635498 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  597 | Train Loss:  0.019956659078598022 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  598 | Train Loss:  0.0015057122707366943 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  599 | Train Loss:  0.02076582908630371 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  600 | Train Loss:  0.033631396293640134 | Train Accuracy:  0.82 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  601 | Train Loss:  0.0163785719871521 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  602 | Train Loss:  0.006928785443305969 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  603 | Train Loss:  0.033699846267700194 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  604 | Train Loss:  0.04416303634643555 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  605 | Train Loss:  0.0454573917388916 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  606 | Train Loss:  0.03324568510055542 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  607 | Train Loss:  0.02375957727432251 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  608 | Train Loss:  0.010937806367874146 | Train Accuracy:  0.52 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  609 | Train Loss:  0.020704224109649658 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  610 | Train Loss:  0.0243656325340271 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  611 | Train Loss:  0.009728538990020751 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  612 | Train Loss:  0.00953563392162323 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  613 | Train Loss:  0.011837610006332398 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  614 | Train Loss:  0.011397466659545899 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  615 | Train Loss:  0.007105963230133057 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  616 | Train Loss:  0.00755852222442627 | Train Accuracy:  0.74 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  617 | Train Loss:  0.009803717732429504 | Train Accuracy:  0.92 | Validation Accuracy:  0.56\n",
            "Iteration:  618 | Train Loss:  0.007324258685111999 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  619 | Train Loss:  0.007831302881240844 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  620 | Train Loss:  0.007191807627677917 | Train Accuracy:  0.94 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  621 | Train Loss:  0.0066598266363143924 | Train Accuracy:  0.94 | Validation Accuracy:  0.6\n",
            "Iteration:  622 | Train Loss:  0.007743694186210633 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  623 | Train Loss:  0.006147527098655701 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  624 | Train Loss:  0.006493126153945923 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  625 | Train Loss:  0.006872223019599915 | Train Accuracy:  0.88 | Validation Accuracy:  0.48\n",
            "Iteration:  626 | Train Loss:  0.00917218267917633 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  627 | Train Loss:  0.0067608064413070676 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  628 | Train Loss:  0.0056310659646987915 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  629 | Train Loss:  0.010375800132751465 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  630 | Train Loss:  0.007088187336921692 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  631 | Train Loss:  0.006287875175476074 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  632 | Train Loss:  0.007496060132980347 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  633 | Train Loss:  0.011103612184524537 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  634 | Train Loss:  0.008262656331062317 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  635 | Train Loss:  0.005918540358543396 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  636 | Train Loss:  0.009921858906745911 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  637 | Train Loss:  0.00782336175441742 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  638 | Train Loss:  0.007338605523109436 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  639 | Train Loss:  0.00652477502822876 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  640 | Train Loss:  0.01028852105140686 | Train Accuracy:  0.84 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  641 | Train Loss:  0.00826720952987671 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  642 | Train Loss:  0.0061480790376663205 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  643 | Train Loss:  0.008582485318183898 | Train Accuracy:  0.82 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  644 | Train Loss:  0.007081506252288819 | Train Accuracy:  0.92 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  645 | Train Loss:  0.00730954647064209 | Train Accuracy:  0.96 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  646 | Train Loss:  0.006077383160591126 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  647 | Train Loss:  0.009243474006652833 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  648 | Train Loss:  0.00731019139289856 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  649 | Train Loss:  0.00551201343536377 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  650 | Train Loss:  0.008551709651947022 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  651 | Train Loss:  0.0064440065622329715 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  652 | Train Loss:  0.0064607739448547365 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  653 | Train Loss:  0.006053325533866882 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  654 | Train Loss:  0.00930513858795166 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  655 | Train Loss:  0.0067246264219284054 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  656 | Train Loss:  0.00488178014755249 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  657 | Train Loss:  0.009362204670906068 | Train Accuracy:  0.86 | Validation Accuracy:  0.56\n",
            "Iteration:  658 | Train Loss:  0.006329508423805237 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  659 | Train Loss:  0.005839924812316894 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  660 | Train Loss:  0.006305859088897705 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  661 | Train Loss:  0.010029137134552002 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  662 | Train Loss:  0.006602884531021118 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  663 | Train Loss:  0.004486939311027527 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  664 | Train Loss:  0.010389039516448975 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  665 | Train Loss:  0.006546129584312439 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  666 | Train Loss:  0.005563396215438843 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  667 | Train Loss:  0.006530650854110718 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  668 | Train Loss:  0.010797308683395386 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  669 | Train Loss:  0.006794506907463074 | Train Accuracy:  0.98 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  670 | Train Loss:  0.0042474067211151125 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  671 | Train Loss:  0.010906469821929932 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  672 | Train Loss:  0.006789816021919251 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  673 | Train Loss:  0.005562912225723266 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  674 | Train Loss:  0.006407511234283447 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  675 | Train Loss:  0.011075552701950073 | Train Accuracy:  0.86 | Validation Accuracy:  0.48\n",
            "Iteration:  676 | Train Loss:  0.0069563138484954835 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  677 | Train Loss:  0.004090349674224853 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  678 | Train Loss:  0.01083950161933899 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  679 | Train Loss:  0.006853469014167786 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  680 | Train Loss:  0.005670740008354187 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  681 | Train Loss:  0.006044031381607056 | Train Accuracy:  0.74 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  682 | Train Loss:  0.010881444215774536 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  683 | Train Loss:  0.00705035150051117 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  684 | Train Loss:  0.004009247720241547 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  685 | Train Loss:  0.010258749723434449 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  686 | Train Loss:  0.006695963144302368 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  687 | Train Loss:  0.0058233124017715455 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  688 | Train Loss:  0.005561352372169494 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  689 | Train Loss:  0.010320917367935181 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  690 | Train Loss:  0.006995880007743835 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  691 | Train Loss:  0.003961363136768341 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  692 | Train Loss:  0.009493647813796998 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  693 | Train Loss:  0.0063892102241516115 | Train Accuracy:  0.94 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  694 | Train Loss:  0.005942488312721253 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  695 | Train Loss:  0.005112922787666321 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  696 | Train Loss:  0.009644420742988586 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  697 | Train Loss:  0.006858624219894409 | Train Accuracy:  0.98 | Validation Accuracy:  0.6\n",
            "Iteration:  698 | Train Loss:  0.003920729458332062 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  699 | Train Loss:  0.008727942705154418 | Train Accuracy:  0.82 | Validation Accuracy:  0.5733333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.82\n",
            "Final Validation Accuracy: 0.5733333333333334\n",
            "Maximum Training Accuracy: 0.9914285714285714\n",
            "Maximum Validation Accuracy: 0.6133333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxXoo9boWHvw"
      },
      "source": [
        "##### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C0U9f11WKQ0"
      },
      "source": [
        "train_dataset = createTensorDataset(X2_train, y2_train)\n",
        "val_dataset = createTensorDataset(X2_val, y2_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gtY_mDIBWWnS",
        "outputId": "c056e72a-4d32-4201-cc25-557cd91cc228"
      },
      "source": [
        "model = ANN_TS2_2L()\n",
        "train(model, train_dataset, val_dataset, batch_size = 50, num_epochs=150, learning_rate = 0.01, momen = 0.7, use_adam = True, save_weights=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.014112745523452758 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1 | Train Loss:  0.013828034400939942 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2 | Train Loss:  0.01386417269706726 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3 | Train Loss:  0.013863334655761719 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  4 | Train Loss:  0.013864535093307494 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  5 | Train Loss:  0.013804484605789185 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  6 | Train Loss:  0.013847728967666626 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  7 | Train Loss:  0.01416388750076294 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  8 | Train Loss:  0.013799625635147094 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  9 | Train Loss:  0.013908164501190185 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  10 | Train Loss:  0.01375450611114502 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  11 | Train Loss:  0.013803530931472779 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  12 | Train Loss:  0.01380379319190979 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  13 | Train Loss:  0.013850370645523071 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  14 | Train Loss:  0.013710604906082153 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  15 | Train Loss:  0.014053013324737549 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  16 | Train Loss:  0.013896785974502564 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  17 | Train Loss:  0.013889518976211547 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  18 | Train Loss:  0.013704609870910645 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  19 | Train Loss:  0.013741657733917237 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  20 | Train Loss:  0.013846974372863769 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  21 | Train Loss:  0.01404832124710083 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  22 | Train Loss:  0.013810262680053711 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  23 | Train Loss:  0.01388045310974121 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  24 | Train Loss:  0.013784412145614624 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  25 | Train Loss:  0.013816049098968506 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  26 | Train Loss:  0.013815830945968628 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  27 | Train Loss:  0.013846864700317383 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  28 | Train Loss:  0.013747031688690186 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  29 | Train Loss:  0.013995088338851928 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  30 | Train Loss:  0.01388351559638977 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  31 | Train Loss:  0.013881374597549439 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  32 | Train Loss:  0.013716663122177125 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  33 | Train Loss:  0.013744535446166993 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  34 | Train Loss:  0.013846826553344727 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  35 | Train Loss:  0.014056822061538696 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  36 | Train Loss:  0.013807318210601806 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  37 | Train Loss:  0.013885340690612792 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  38 | Train Loss:  0.013773175477981568 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  39 | Train Loss:  0.013809529542922973 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  40 | Train Loss:  0.013809086084365844 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  41 | Train Loss:  0.01384739637374878 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  42 | Train Loss:  0.013727072477340698 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  43 | Train Loss:  0.014023449420928955 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  44 | Train Loss:  0.013891106843948365 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  45 | Train Loss:  0.013887481689453125 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  46 | Train Loss:  0.013697617053985596 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  47 | Train Loss:  0.013732565641403198 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  48 | Train Loss:  0.013847210407257081 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  49 | Train Loss:  0.014069900512695313 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  50 | Train Loss:  0.013805655241012573 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  51 | Train Loss:  0.013885865211486817 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  52 | Train Loss:  0.013772398233413696 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  53 | Train Loss:  0.013809313774108887 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  54 | Train Loss:  0.013809350728988647 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  55 | Train Loss:  0.01384688138961792 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  56 | Train Loss:  0.01373193621635437 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  57 | Train Loss:  0.014013363122940064 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  58 | Train Loss:  0.013887815475463867 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  59 | Train Loss:  0.013883932828903198 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  60 | Train Loss:  0.013706355094909669 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  61 | Train Loss:  0.013738576173782348 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  62 | Train Loss:  0.013846091032028197 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  63 | Train Loss:  0.014059251546859742 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  64 | Train Loss:  0.013806248903274537 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  65 | Train Loss:  0.013883390426635743 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  66 | Train Loss:  0.013773776292800903 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  67 | Train Loss:  0.013809034824371338 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  68 | Train Loss:  0.013808751106262207 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  69 | Train Loss:  0.013846485614776612 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  70 | Train Loss:  0.013730164766311646 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  71 | Train Loss:  0.014016554355621338 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  72 | Train Loss:  0.013888792991638184 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  73 | Train Loss:  0.01388418436050415 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  74 | Train Loss:  0.013702007532119751 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  75 | Train Loss:  0.013734714984893799 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  76 | Train Loss:  0.013845443725585938 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  77 | Train Loss:  0.014066872596740722 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  78 | Train Loss:  0.013804248571395873 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  79 | Train Loss:  0.013883252143859864 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  80 | Train Loss:  0.013771172761917114 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  81 | Train Loss:  0.013806840181350708 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  82 | Train Loss:  0.01380671739578247 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  83 | Train Loss:  0.013845921754837036 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  84 | Train Loss:  0.013727428913116456 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  85 | Train Loss:  0.014019240140914917 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  86 | Train Loss:  0.013889052867889405 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  87 | Train Loss:  0.013882920742034913 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  88 | Train Loss:  0.013701577186584473 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  89 | Train Loss:  0.013734045028686524 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  90 | Train Loss:  0.013843928575515746 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  91 | Train Loss:  0.014066946506500245 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  92 | Train Loss:  0.013802657127380371 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  93 | Train Loss:  0.013880902528762817 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  94 | Train Loss:  0.013770292997360229 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  95 | Train Loss:  0.013805068731307983 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  96 | Train Loss:  0.0138045072555542 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  97 | Train Loss:  0.013844784498214722 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  98 | Train Loss:  0.013725427389144897 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  99 | Train Loss:  0.014020904302597045 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  100 | Train Loss:  0.013889007568359375 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  101 | Train Loss:  0.0138807475566864 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  102 | Train Loss:  0.0137003493309021 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  103 | Train Loss:  0.013731908798217774 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  104 | Train Loss:  0.01384161353111267 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  105 | Train Loss:  0.014071488380432129 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  106 | Train Loss:  0.013799360990524291 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  107 | Train Loss:  0.013878340721130372 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  108 | Train Loss:  0.013766753673553466 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  109 | Train Loss:  0.013801331520080567 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  110 | Train Loss:  0.013799774646759033 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  111 | Train Loss:  0.013843111991882324 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  112 | Train Loss:  0.013718218803405761 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  113 | Train Loss:  0.014029759168624877 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  114 | Train Loss:  0.013890550136566163 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  115 | Train Loss:  0.013878403902053834 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  116 | Train Loss:  0.01369572639465332 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  117 | Train Loss:  0.01372734546661377 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  118 | Train Loss:  0.013837802410125732 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  119 | Train Loss:  0.014075634479522705 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  120 | Train Loss:  0.013794819116592407 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  121 | Train Loss:  0.013873423337936402 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  122 | Train Loss:  0.013763892650604247 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  123 | Train Loss:  0.013797323703765869 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  124 | Train Loss:  0.013793106079101563 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  125 | Train Loss:  0.013839999437332154 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  126 | Train Loss:  0.013711968660354614 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  127 | Train Loss:  0.014035234451293946 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  128 | Train Loss:  0.013890738487243653 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  129 | Train Loss:  0.013873263597488403 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  130 | Train Loss:  0.013691811561584473 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  131 | Train Loss:  0.013720909357070923 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  132 | Train Loss:  0.013831794261932373 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  133 | Train Loss:  0.014084243774414062 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  134 | Train Loss:  0.013786861896514893 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  135 | Train Loss:  0.013867186307907104 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  136 | Train Loss:  0.013756167888641358 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  137 | Train Loss:  0.013789361715316773 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  138 | Train Loss:  0.013779083490371704 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  139 | Train Loss:  0.013835254907608032 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  140 | Train Loss:  0.013693094253540039 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  141 | Train Loss:  0.014059025049209594 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  142 | Train Loss:  0.013895260095596313 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  143 | Train Loss:  0.013867074251174926 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  144 | Train Loss:  0.013683298826217652 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  145 | Train Loss:  0.013711034059524537 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  146 | Train Loss:  0.013820611238479615 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  147 | Train Loss:  0.014090074300765991 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  148 | Train Loss:  0.013774366378784179 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  149 | Train Loss:  0.01385395646095276 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  150 | Train Loss:  0.013747259378433227 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  151 | Train Loss:  0.013777782917022705 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  152 | Train Loss:  0.01375741720199585 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  153 | Train Loss:  0.013826653957366944 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  154 | Train Loss:  0.013672120571136474 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  155 | Train Loss:  0.014076645374298096 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  156 | Train Loss:  0.013894088268280029 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  157 | Train Loss:  0.013845692873001098 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  158 | Train Loss:  0.013699575662612914 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  159 | Train Loss:  0.013714832067489625 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  160 | Train Loss:  0.01380361795425415 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  161 | Train Loss:  0.014091261625289918 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  162 | Train Loss:  0.013752872943878175 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  163 | Train Loss:  0.013829848766326903 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  164 | Train Loss:  0.013724970817565917 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  165 | Train Loss:  0.013747172355651855 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  166 | Train Loss:  0.01371614933013916 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  167 | Train Loss:  0.013813585042953491 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  168 | Train Loss:  0.013612600564956666 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  169 | Train Loss:  0.014168846607208251 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  170 | Train Loss:  0.013912471532821656 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  171 | Train Loss:  0.013820769786834717 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  172 | Train Loss:  0.013699458837509155 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  173 | Train Loss:  0.013710087537765503 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  174 | Train Loss:  0.01377496361732483 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  175 | Train Loss:  0.014074242115020752 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  176 | Train Loss:  0.013728301525115966 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  177 | Train Loss:  0.013790233135223389 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  178 | Train Loss:  0.013702009916305541 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  179 | Train Loss:  0.013715673685073853 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  180 | Train Loss:  0.0136706805229187 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  181 | Train Loss:  0.013789265155792237 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  182 | Train Loss:  0.013594967126846314 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  183 | Train Loss:  0.01410422682762146 | Train Accuracy:  0.53 | Validation Accuracy:  0.52\n",
            "Iteration:  184 | Train Loss:  0.013857971429824829 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  185 | Train Loss:  0.013746147155761718 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  186 | Train Loss:  0.013816752433776856 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.44666666666666666\n",
            "Iteration:  187 | Train Loss:  0.01373928427696228 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  188 | Train Loss:  0.013720462322235108 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  189 | Train Loss:  0.01418809175491333 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  190 | Train Loss:  0.013675822019577026 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  191 | Train Loss:  0.01374376654624939 | Train Accuracy:  0.5642857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  192 | Train Loss:  0.013607771396636962 | Train Accuracy:  0.5671428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  193 | Train Loss:  0.013632389307022095 | Train Accuracy:  0.5528571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  194 | Train Loss:  0.013568159341812134 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  195 | Train Loss:  0.013749831914901733 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  196 | Train Loss:  0.013505252599716187 | Train Accuracy:  0.53 | Validation Accuracy:  0.52\n",
            "Iteration:  197 | Train Loss:  0.014192451238632203 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  198 | Train Loss:  0.013827472925186157 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.4066666666666667\n",
            "Iteration:  199 | Train Loss:  0.013659826517105102 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  200 | Train Loss:  0.013967618942260743 | Train Accuracy:  0.53 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  201 | Train Loss:  0.013812112808227538 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  202 | Train Loss:  0.013674389123916626 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  203 | Train Loss:  0.014197272062301636 | Train Accuracy:  0.53 | Validation Accuracy:  0.52\n",
            "Iteration:  204 | Train Loss:  0.013642585277557373 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  205 | Train Loss:  0.013717219829559327 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  206 | Train Loss:  0.013498001098632813 | Train Accuracy:  0.5671428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  207 | Train Loss:  0.013539843559265137 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  208 | Train Loss:  0.013443899154663087 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  209 | Train Loss:  0.013703181743621826 | Train Accuracy:  0.5528571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  210 | Train Loss:  0.013440945148468018 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  211 | Train Loss:  0.014098761081695556 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  212 | Train Loss:  0.013760986328125 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  213 | Train Loss:  0.013616505861282348 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  214 | Train Loss:  0.013936885595321656 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  215 | Train Loss:  0.013658665418624878 | Train Accuracy:  0.5471428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  216 | Train Loss:  0.01359053611755371 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  217 | Train Loss:  0.014513216018676757 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  218 | Train Loss:  0.013613146543502808 | Train Accuracy:  0.5528571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  219 | Train Loss:  0.01359214425086975 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  220 | Train Loss:  0.013496878147125245 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.43333333333333335\n",
            "Iteration:  221 | Train Loss:  0.013525876998901367 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  222 | Train Loss:  0.013359860181808472 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  223 | Train Loss:  0.01365655779838562 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  224 | Train Loss:  0.01334213137626648 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  225 | Train Loss:  0.014360636472702026 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  226 | Train Loss:  0.013816308975219727 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  227 | Train Loss:  0.0134936785697937 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  228 | Train Loss:  0.014011561870574951 | Train Accuracy:  0.53 | Validation Accuracy:  0.5\n",
            "Iteration:  229 | Train Loss:  0.013821241855621337 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  230 | Train Loss:  0.013538509607315063 | Train Accuracy:  0.5442857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  231 | Train Loss:  0.014037790298461915 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  232 | Train Loss:  0.013529305458068847 | Train Accuracy:  0.5528571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  233 | Train Loss:  0.013536578416824341 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  234 | Train Loss:  0.01330087423324585 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  235 | Train Loss:  0.013375422954559325 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  236 | Train Loss:  0.013226444721221925 | Train Accuracy:  0.61 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  237 | Train Loss:  0.013603817224502563 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.44666666666666666\n",
            "Iteration:  238 | Train Loss:  0.013323632478713989 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  239 | Train Loss:  0.013946300745010376 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  240 | Train Loss:  0.013631787300109863 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  241 | Train Loss:  0.013406274318695068 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  242 | Train Loss:  0.013917523622512817 | Train Accuracy:  0.6185714285714285 | Validation Accuracy:  0.44666666666666666\n",
            "Iteration:  243 | Train Loss:  0.013406202793121338 | Train Accuracy:  0.5528571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  244 | Train Loss:  0.0134413743019104 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  245 | Train Loss:  0.014769585132598876 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  246 | Train Loss:  0.013466155529022217 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  247 | Train Loss:  0.013294392824172973 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  248 | Train Loss:  0.013643215894699096 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  249 | Train Loss:  0.013434900045394898 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  250 | Train Loss:  0.013009083271026612 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  251 | Train Loss:  0.01356596827507019 | Train Accuracy:  0.5471428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  252 | Train Loss:  0.013173511028289795 | Train Accuracy:  0.54 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  253 | Train Loss:  0.014678471088409424 | Train Accuracy:  0.6 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  254 | Train Loss:  0.013652429580688477 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  255 | Train Loss:  0.013325288295745849 | Train Accuracy:  0.5071428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  256 | Train Loss:  0.014451566934585571 | Train Accuracy:  0.5185714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  257 | Train Loss:  0.01406771421432495 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.44\n",
            "Iteration:  258 | Train Loss:  0.013424853086471558 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  259 | Train Loss:  0.013951762914657592 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  260 | Train Loss:  0.013498427867889405 | Train Accuracy:  0.55 | Validation Accuracy:  0.5\n",
            "Iteration:  261 | Train Loss:  0.013448313474655152 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  262 | Train Loss:  0.013013792037963868 | Train Accuracy:  0.6185714285714285 | Validation Accuracy:  0.46\n",
            "Iteration:  263 | Train Loss:  0.013189195394515992 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  264 | Train Loss:  0.012953271865844726 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.46\n",
            "Iteration:  265 | Train Loss:  0.013512864112854003 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  266 | Train Loss:  0.013266123533248901 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  267 | Train Loss:  0.013674874305725098 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  268 | Train Loss:  0.013490008115768433 | Train Accuracy:  0.62 | Validation Accuracy:  0.43333333333333335\n",
            "Iteration:  269 | Train Loss:  0.013186091184616089 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  270 | Train Loss:  0.013519139289855956 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  271 | Train Loss:  0.013198056221008302 | Train Accuracy:  0.5757142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  272 | Train Loss:  0.013235629796981811 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  273 | Train Loss:  0.014332340955734253 | Train Accuracy:  0.5842857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  274 | Train Loss:  0.013298165798187257 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  275 | Train Loss:  0.013066825866699218 | Train Accuracy:  0.5642857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  276 | Train Loss:  0.013354744911193848 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  277 | Train Loss:  0.01318270206451416 | Train Accuracy:  0.64 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  278 | Train Loss:  0.012668365240097046 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  279 | Train Loss:  0.013472229242324829 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  280 | Train Loss:  0.01301422119140625 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  281 | Train Loss:  0.014323736429214478 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  282 | Train Loss:  0.01333225131034851 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  283 | Train Loss:  0.013333433866500854 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  284 | Train Loss:  0.014569563865661621 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  285 | Train Loss:  0.013590909242630005 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  286 | Train Loss:  0.01305904507637024 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  287 | Train Loss:  0.015046653747558593 | Train Accuracy:  0.55 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  288 | Train Loss:  0.013653726577758788 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  289 | Train Loss:  0.012983857393264771 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  290 | Train Loss:  0.013074029684066773 | Train Accuracy:  0.5614285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  291 | Train Loss:  0.013295024633407593 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  292 | Train Loss:  0.01298142671585083 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  293 | Train Loss:  0.01334795355796814 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  294 | Train Loss:  0.012920188903808593 | Train Accuracy:  0.55 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  295 | Train Loss:  0.014584280252456665 | Train Accuracy:  0.5842857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  296 | Train Loss:  0.013642266988754273 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  297 | Train Loss:  0.012945748567581176 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  298 | Train Loss:  0.013762900829315186 | Train Accuracy:  0.5642857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  299 | Train Loss:  0.013520115613937378 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.44666666666666666\n",
            "Iteration:  300 | Train Loss:  0.013179107904434204 | Train Accuracy:  0.62 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  301 | Train Loss:  0.013483185768127442 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  302 | Train Loss:  0.013192631006240844 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  303 | Train Loss:  0.012983196973800659 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.46\n",
            "Iteration:  304 | Train Loss:  0.012713656425476075 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.43333333333333335\n",
            "Iteration:  305 | Train Loss:  0.012922096252441406 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  306 | Train Loss:  0.01251224398612976 | Train Accuracy:  0.65 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  307 | Train Loss:  0.013293055295944213 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  308 | Train Loss:  0.012948830127716065 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.43333333333333335\n",
            "Iteration:  309 | Train Loss:  0.013517566919326783 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  310 | Train Loss:  0.013150587081909179 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  311 | Train Loss:  0.012828980684280395 | Train Accuracy:  0.5842857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  312 | Train Loss:  0.013482290506362914 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  313 | Train Loss:  0.01290123701095581 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  314 | Train Loss:  0.012979840040206908 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  315 | Train Loss:  0.014480979442596435 | Train Accuracy:  0.5985714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  316 | Train Loss:  0.013096019029617309 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  317 | Train Loss:  0.01263615608215332 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  318 | Train Loss:  0.013316196203231812 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  319 | Train Loss:  0.012935365438461304 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.46\n",
            "Iteration:  320 | Train Loss:  0.012192329168319702 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  321 | Train Loss:  0.013295227289199829 | Train Accuracy:  0.5785714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  322 | Train Loss:  0.012845500707626342 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  323 | Train Loss:  0.014105411767959595 | Train Accuracy:  0.65 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  324 | Train Loss:  0.012923001050949097 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  325 | Train Loss:  0.01322981834411621 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  326 | Train Loss:  0.014794338941574097 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  327 | Train Loss:  0.013346339464187623 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  328 | Train Loss:  0.012755894660949707 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  329 | Train Loss:  0.015167393684387208 | Train Accuracy:  0.56 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  330 | Train Loss:  0.013537214994430542 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  331 | Train Loss:  0.01243935465812683 | Train Accuracy:  0.6 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  332 | Train Loss:  0.01304685115814209 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  333 | Train Loss:  0.01312685251235962 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  334 | Train Loss:  0.01257153034210205 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.46\n",
            "Iteration:  335 | Train Loss:  0.013053534030914306 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  336 | Train Loss:  0.012777440547943116 | Train Accuracy:  0.5585714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  337 | Train Loss:  0.014909019470214844 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  338 | Train Loss:  0.013281228542327881 | Train Accuracy:  0.63 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  339 | Train Loss:  0.012602812051773072 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  340 | Train Loss:  0.014397069215774536 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  341 | Train Loss:  0.013931077718734742 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  342 | Train Loss:  0.012994961738586426 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  343 | Train Loss:  0.013320479393005371 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  344 | Train Loss:  0.013202545642852783 | Train Accuracy:  0.57 | Validation Accuracy:  0.5\n",
            "Iteration:  345 | Train Loss:  0.012818920612335204 | Train Accuracy:  0.63 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  346 | Train Loss:  0.012434104681015015 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.46\n",
            "Iteration:  347 | Train Loss:  0.012669844627380371 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  348 | Train Loss:  0.01227105140686035 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  349 | Train Loss:  0.013151873350143433 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  350 | Train Loss:  0.012856968641281129 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.46\n",
            "Iteration:  351 | Train Loss:  0.013212283849716186 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  352 | Train Loss:  0.012853326797485352 | Train Accuracy:  0.67 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  353 | Train Loss:  0.012454663515090942 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  354 | Train Loss:  0.01306873321533203 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  355 | Train Loss:  0.012653536796569824 | Train Accuracy:  0.63 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  356 | Train Loss:  0.012658349275588988 | Train Accuracy:  0.5842857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  357 | Train Loss:  0.013723609447479248 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  358 | Train Loss:  0.01281848430633545 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  359 | Train Loss:  0.0121886146068573 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  360 | Train Loss:  0.012748749256134033 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  361 | Train Loss:  0.012669113874435424 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  362 | Train Loss:  0.011914838552474976 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  363 | Train Loss:  0.012912571430206299 | Train Accuracy:  0.6128571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  364 | Train Loss:  0.012584301233291626 | Train Accuracy:  0.6214285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  365 | Train Loss:  0.013870333433151244 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  366 | Train Loss:  0.012545760869979859 | Train Accuracy:  0.5671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  367 | Train Loss:  0.012771952152252197 | Train Accuracy:  0.5471428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  368 | Train Loss:  0.014492747783660888 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  369 | Train Loss:  0.012960638999938965 | Train Accuracy:  0.62 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  370 | Train Loss:  0.012537721395492554 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  371 | Train Loss:  0.015023630857467652 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  372 | Train Loss:  0.013121827840805053 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  373 | Train Loss:  0.011902861595153809 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  374 | Train Loss:  0.013321555852890014 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  375 | Train Loss:  0.012746741771697998 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  376 | Train Loss:  0.011795437335968018 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  377 | Train Loss:  0.012837458848953247 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  378 | Train Loss:  0.012740362882614136 | Train Accuracy:  0.5985714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  379 | Train Loss:  0.014276976585388184 | Train Accuracy:  0.6814285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  380 | Train Loss:  0.012414778470993043 | Train Accuracy:  0.5585714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  381 | Train Loss:  0.012810037136077881 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  382 | Train Loss:  0.015004000663757323 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  383 | Train Loss:  0.013685847520828248 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  384 | Train Loss:  0.012362033128738403 | Train Accuracy:  0.5671428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  385 | Train Loss:  0.014355683326721191 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  386 | Train Loss:  0.01356179714202881 | Train Accuracy:  0.62 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  387 | Train Loss:  0.012107024192810059 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  388 | Train Loss:  0.012292219400405884 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  389 | Train Loss:  0.012740203142166139 | Train Accuracy:  0.5957142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  390 | Train Loss:  0.012604185342788697 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  391 | Train Loss:  0.012842552661895752 | Train Accuracy:  0.65 | Validation Accuracy:  0.48\n",
            "Iteration:  392 | Train Loss:  0.012375271320343018 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  393 | Train Loss:  0.014322384595870971 | Train Accuracy:  0.6214285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  394 | Train Loss:  0.01306122899055481 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  395 | Train Loss:  0.01204796314239502 | Train Accuracy:  0.61 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  396 | Train Loss:  0.013682535886764526 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  397 | Train Loss:  0.013288761377334595 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  398 | Train Loss:  0.012490278482437134 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  399 | Train Loss:  0.01291717529296875 | Train Accuracy:  0.6014285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  400 | Train Loss:  0.012795790433883666 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  401 | Train Loss:  0.0120389723777771 | Train Accuracy:  0.67 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  402 | Train Loss:  0.012051405906677247 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  403 | Train Loss:  0.012296661138534545 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  404 | Train Loss:  0.01185822367668152 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  405 | Train Loss:  0.012690153121948242 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.44\n",
            "Iteration:  406 | Train Loss:  0.012330660820007324 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  407 | Train Loss:  0.013257380723953247 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.46\n",
            "Iteration:  408 | Train Loss:  0.012436164617538452 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  409 | Train Loss:  0.011907066106796265 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  410 | Train Loss:  0.013351298570632934 | Train Accuracy:  0.69 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  411 | Train Loss:  0.01251650333404541 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  412 | Train Loss:  0.012189948558807373 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  413 | Train Loss:  0.013456244468688965 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  414 | Train Loss:  0.012568846940994263 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.44\n",
            "Iteration:  415 | Train Loss:  0.011459078788757324 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  416 | Train Loss:  0.012444939613342285 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.46\n",
            "Iteration:  417 | Train Loss:  0.012258564233779906 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  418 | Train Loss:  0.011427242755889893 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  419 | Train Loss:  0.012433037757873536 | Train Accuracy:  0.6328571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  420 | Train Loss:  0.012317471504211426 | Train Accuracy:  0.65 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  421 | Train Loss:  0.013376030921936035 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  422 | Train Loss:  0.011956287622451782 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  423 | Train Loss:  0.012589578628540038 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  424 | Train Loss:  0.01446559190750122 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  425 | Train Loss:  0.012427964210510255 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  426 | Train Loss:  0.01239256739616394 | Train Accuracy:  0.56 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  427 | Train Loss:  0.015045093297958374 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  428 | Train Loss:  0.012581316232681274 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  429 | Train Loss:  0.011327195167541503 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  430 | Train Loss:  0.013661624193191528 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  431 | Train Loss:  0.012369370460510254 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  432 | Train Loss:  0.011230447292327882 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  433 | Train Loss:  0.012673795223236084 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  434 | Train Loss:  0.01271033763885498 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  435 | Train Loss:  0.013445457220077514 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  436 | Train Loss:  0.011827232837677002 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  437 | Train Loss:  0.013072389364242553 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  438 | Train Loss:  0.015140750408172608 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  439 | Train Loss:  0.012839261293411255 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  440 | Train Loss:  0.0121482253074646 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  441 | Train Loss:  0.015258526802062989 | Train Accuracy:  0.5757142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  442 | Train Loss:  0.01331356644630432 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  443 | Train Loss:  0.0112783682346344 | Train Accuracy:  0.6271428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  444 | Train Loss:  0.01276425838470459 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  445 | Train Loss:  0.012897218465805054 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  446 | Train Loss:  0.012184547185897827 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  447 | Train Loss:  0.012211157083511353 | Train Accuracy:  0.62 | Validation Accuracy:  0.5\n",
            "Iteration:  448 | Train Loss:  0.012348307371139526 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  449 | Train Loss:  0.014817821979522704 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  450 | Train Loss:  0.012630459070205689 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  451 | Train Loss:  0.011612899303436279 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  452 | Train Loss:  0.014387272596359253 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  453 | Train Loss:  0.013976035118103027 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  454 | Train Loss:  0.012357269525527953 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  455 | Train Loss:  0.012378886938095093 | Train Accuracy:  0.5957142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  456 | Train Loss:  0.012784125804901124 | Train Accuracy:  0.5957142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  457 | Train Loss:  0.012160999774932861 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  458 | Train Loss:  0.011872336864471436 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.46\n",
            "Iteration:  459 | Train Loss:  0.01197134017944336 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  460 | Train Loss:  0.011701275110244751 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  461 | Train Loss:  0.01259616732597351 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  462 | Train Loss:  0.012354624271392823 | Train Accuracy:  0.7 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  463 | Train Loss:  0.01256941795349121 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  464 | Train Loss:  0.012099289894104004 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.44666666666666666\n",
            "Iteration:  465 | Train Loss:  0.011557812690734864 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  466 | Train Loss:  0.012641769647598267 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  467 | Train Loss:  0.012130775451660157 | Train Accuracy:  0.69 | Validation Accuracy:  0.44666666666666666\n",
            "Iteration:  468 | Train Loss:  0.01187228798866272 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  469 | Train Loss:  0.012318406105041504 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  470 | Train Loss:  0.012044409513473511 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  471 | Train Loss:  0.01107183814048767 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  472 | Train Loss:  0.011907583475112915 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  473 | Train Loss:  0.011832450628280639 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  474 | Train Loss:  0.011217635869979859 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  475 | Train Loss:  0.011941349506378174 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  476 | Train Loss:  0.011917692422866822 | Train Accuracy:  0.67 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  477 | Train Loss:  0.012886204719543458 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  478 | Train Loss:  0.011576883792877198 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  479 | Train Loss:  0.011672887802124023 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  480 | Train Loss:  0.013799487352371216 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  481 | Train Loss:  0.012097564935684204 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  482 | Train Loss:  0.011812738180160522 | Train Accuracy:  0.5871428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  483 | Train Loss:  0.013796077966690063 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  484 | Train Loss:  0.01211337685585022 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  485 | Train Loss:  0.010658363103866577 | Train Accuracy:  0.6128571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  486 | Train Loss:  0.013049986362457276 | Train Accuracy:  0.6757142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  487 | Train Loss:  0.011834791898727416 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.44666666666666666\n",
            "Iteration:  488 | Train Loss:  0.010819164514541625 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  489 | Train Loss:  0.012117334604263306 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  490 | Train Loss:  0.012251280546188355 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  491 | Train Loss:  0.012613579034805297 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  492 | Train Loss:  0.01137905478477478 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  493 | Train Loss:  0.012830231189727783 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  494 | Train Loss:  0.014346183538436889 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  495 | Train Loss:  0.011673128604888916 | Train Accuracy:  0.6 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  496 | Train Loss:  0.012476919889450074 | Train Accuracy:  0.57 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  497 | Train Loss:  0.014779762029647828 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  498 | Train Loss:  0.011823511123657227 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  499 | Train Loss:  0.010931605100631714 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  500 | Train Loss:  0.014060059785842896 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  501 | Train Loss:  0.011747170686721802 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  502 | Train Loss:  0.010766986608505249 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  503 | Train Loss:  0.012491053342819214 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  504 | Train Loss:  0.012477051019668579 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  505 | Train Loss:  0.012473331689834595 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  506 | Train Loss:  0.011330883502960205 | Train Accuracy:  0.55 | Validation Accuracy:  0.48\n",
            "Iteration:  507 | Train Loss:  0.01306593656539917 | Train Accuracy:  0.57 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  508 | Train Loss:  0.014952208995819092 | Train Accuracy:  0.71 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  509 | Train Loss:  0.012070748805999756 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  510 | Train Loss:  0.011958593130111694 | Train Accuracy:  0.5585714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  511 | Train Loss:  0.014978610277175904 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  512 | Train Loss:  0.012624439001083374 | Train Accuracy:  0.73 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  513 | Train Loss:  0.010521836280822754 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  514 | Train Loss:  0.013202199935913086 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  515 | Train Loss:  0.01270537257194519 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  516 | Train Loss:  0.011339839696884155 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  517 | Train Loss:  0.011573829650878907 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  518 | Train Loss:  0.012529910802841186 | Train Accuracy:  0.5985714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  519 | Train Loss:  0.014674944877624512 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.46\n",
            "Iteration:  520 | Train Loss:  0.011570426225662232 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  521 | Train Loss:  0.011649973392486572 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  522 | Train Loss:  0.015377448797225952 | Train Accuracy:  0.5728571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  523 | Train Loss:  0.014432072639465332 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  524 | Train Loss:  0.011702004671096802 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  525 | Train Loss:  0.012526216506958008 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  526 | Train Loss:  0.0132857084274292 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  527 | Train Loss:  0.012245273590087891 | Train Accuracy:  0.69 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  528 | Train Loss:  0.011518001556396484 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  529 | Train Loss:  0.011560043096542358 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  530 | Train Loss:  0.011903516054153442 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  531 | Train Loss:  0.012480396032333373 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  532 | Train Loss:  0.011919381618499756 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  533 | Train Loss:  0.012566322088241577 | Train Accuracy:  0.66 | Validation Accuracy:  0.52\n",
            "Iteration:  534 | Train Loss:  0.012198272943496704 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.46\n",
            "Iteration:  535 | Train Loss:  0.011304088830947877 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  536 | Train Loss:  0.012371702194213867 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  537 | Train Loss:  0.012048226594924927 | Train Accuracy:  0.74 | Validation Accuracy:  0.5\n",
            "Iteration:  538 | Train Loss:  0.011529728174209594 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.46\n",
            "Iteration:  539 | Train Loss:  0.011345409154891968 | Train Accuracy:  0.7 | Validation Accuracy:  0.52\n",
            "Iteration:  540 | Train Loss:  0.011548922061920167 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  541 | Train Loss:  0.010710654258728027 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  542 | Train Loss:  0.01144660234451294 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  543 | Train Loss:  0.011335433721542358 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  544 | Train Loss:  0.010844744443893432 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  545 | Train Loss:  0.011470590829849242 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  546 | Train Loss:  0.011600569486618043 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.46\n",
            "Iteration:  547 | Train Loss:  0.011990151405334472 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  548 | Train Loss:  0.011159611940383911 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  549 | Train Loss:  0.01090621829032898 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  550 | Train Loss:  0.012932063341140746 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  551 | Train Loss:  0.01165839672088623 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  552 | Train Loss:  0.011164140701293946 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  553 | Train Loss:  0.01226448655128479 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  554 | Train Loss:  0.011567319631576539 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  555 | Train Loss:  0.010073710680007935 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  556 | Train Loss:  0.01200998067855835 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  557 | Train Loss:  0.011220966577529906 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  558 | Train Loss:  0.010516219139099121 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  559 | Train Loss:  0.011119370460510253 | Train Accuracy:  0.6757142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  560 | Train Loss:  0.01166593074798584 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  561 | Train Loss:  0.012389687299728393 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  562 | Train Loss:  0.010675450563430786 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  563 | Train Loss:  0.0118779718875885 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  564 | Train Loss:  0.014104413986206054 | Train Accuracy:  0.73 | Validation Accuracy:  0.5\n",
            "Iteration:  565 | Train Loss:  0.011507806777954101 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  566 | Train Loss:  0.011406363248825073 | Train Accuracy:  0.59 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  567 | Train Loss:  0.013742336034774781 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  568 | Train Loss:  0.011424214839935302 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  569 | Train Loss:  0.009924317002296448 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  570 | Train Loss:  0.013462748527526856 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  571 | Train Loss:  0.011022672653198243 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  572 | Train Loss:  0.010215038061141967 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  573 | Train Loss:  0.01162968397140503 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  574 | Train Loss:  0.011851487159729003 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  575 | Train Loss:  0.011495556831359863 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.46\n",
            "Iteration:  576 | Train Loss:  0.010841289758682251 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  577 | Train Loss:  0.01257340908050537 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  578 | Train Loss:  0.013650904893875122 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  579 | Train Loss:  0.011005042791366578 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  580 | Train Loss:  0.012170863151550294 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  581 | Train Loss:  0.013482204675674438 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  582 | Train Loss:  0.010845351219177245 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  583 | Train Loss:  0.010453275442123412 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  584 | Train Loss:  0.013765524625778198 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  585 | Train Loss:  0.010721747875213622 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  586 | Train Loss:  0.010350959300994873 | Train Accuracy:  0.64 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  587 | Train Loss:  0.011793113946914673 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  588 | Train Loss:  0.011667841672897339 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  589 | Train Loss:  0.011190110445022583 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  590 | Train Loss:  0.010821242332458497 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  591 | Train Loss:  0.012446449995040893 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  592 | Train Loss:  0.013530240058898926 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  593 | Train Loss:  0.010953007936477662 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  594 | Train Loss:  0.012012910842895509 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  595 | Train Loss:  0.013396333456039428 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.46\n",
            "Iteration:  596 | Train Loss:  0.010803155899047852 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  597 | Train Loss:  0.010160787105560303 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  598 | Train Loss:  0.01381104588508606 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  599 | Train Loss:  0.0107991623878479 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.46\n",
            "Iteration:  600 | Train Loss:  0.010126538276672363 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  601 | Train Loss:  0.011548609733581542 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  602 | Train Loss:  0.011823515892028808 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  603 | Train Loss:  0.011494382619857788 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  604 | Train Loss:  0.010464794635772705 | Train Accuracy:  0.5757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  605 | Train Loss:  0.01258249044418335 | Train Accuracy:  0.5985714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  606 | Train Loss:  0.014249409437179566 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  607 | Train Loss:  0.011209883689880372 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  608 | Train Loss:  0.011372113227844238 | Train Accuracy:  0.58 | Validation Accuracy:  0.5\n",
            "Iteration:  609 | Train Loss:  0.01381811261177063 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  610 | Train Loss:  0.011376892328262328 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  611 | Train Loss:  0.009542647004127502 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  612 | Train Loss:  0.013637112379074097 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  613 | Train Loss:  0.011427041292190552 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  614 | Train Loss:  0.010095082521438599 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  615 | Train Loss:  0.011015652418136597 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  616 | Train Loss:  0.012200307846069337 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  617 | Train Loss:  0.012770416736602784 | Train Accuracy:  0.73 | Validation Accuracy:  0.54\n",
            "Iteration:  618 | Train Loss:  0.010136464834213257 | Train Accuracy:  0.5785714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  619 | Train Loss:  0.012450594902038575 | Train Accuracy:  0.57 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  620 | Train Loss:  0.015413190126419068 | Train Accuracy:  0.68 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  621 | Train Loss:  0.012458075284957886 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  622 | Train Loss:  0.010645745992660523 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  623 | Train Loss:  0.014344269037246704 | Train Accuracy:  0.5842857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  624 | Train Loss:  0.012958260774612427 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  625 | Train Loss:  0.00980827808380127 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  626 | Train Loss:  0.012542873620986938 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  627 | Train Loss:  0.012132477760314942 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  628 | Train Loss:  0.011143758296966552 | Train Accuracy:  0.77 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  629 | Train Loss:  0.010407406091690063 | Train Accuracy:  0.65 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  630 | Train Loss:  0.0117499041557312 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  631 | Train Loss:  0.014548957347869873 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  632 | Train Loss:  0.011163424253463745 | Train Accuracy:  0.68 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  633 | Train Loss:  0.010755199193954467 | Train Accuracy:  0.5728571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  634 | Train Loss:  0.015221861600875854 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  635 | Train Loss:  0.014788250923156738 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  636 | Train Loss:  0.011061497926712037 | Train Accuracy:  0.65 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  637 | Train Loss:  0.01157434105873108 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  638 | Train Loss:  0.01315218448638916 | Train Accuracy:  0.59 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  639 | Train Loss:  0.012078410387039185 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  640 | Train Loss:  0.010959397554397583 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  641 | Train Loss:  0.010703227519989013 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  642 | Train Loss:  0.011761922836303711 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  643 | Train Loss:  0.012081246376037597 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  644 | Train Loss:  0.011253876686096191 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  645 | Train Loss:  0.01223535180091858 | Train Accuracy:  0.67 | Validation Accuracy:  0.52\n",
            "Iteration:  646 | Train Loss:  0.012183340787887574 | Train Accuracy:  0.74 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  647 | Train Loss:  0.010827997922897339 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  648 | Train Loss:  0.012120157480239868 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  649 | Train Loss:  0.012090460062026978 | Train Accuracy:  0.73 | Validation Accuracy:  0.52\n",
            "Iteration:  650 | Train Loss:  0.011195224523544312 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  651 | Train Loss:  0.010348923206329345 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  652 | Train Loss:  0.010791182518005371 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  653 | Train Loss:  0.01032301902770996 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  654 | Train Loss:  0.010935490131378173 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  655 | Train Loss:  0.010429514646530151 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.54\n",
            "Iteration:  656 | Train Loss:  0.010224246978759765 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  657 | Train Loss:  0.010728018283843994 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  658 | Train Loss:  0.011156729459762572 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  659 | Train Loss:  0.011070401668548583 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  660 | Train Loss:  0.01053065538406372 | Train Accuracy:  0.77 | Validation Accuracy:  0.54\n",
            "Iteration:  661 | Train Loss:  0.010190373659133911 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  662 | Train Loss:  0.012234265804290772 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  663 | Train Loss:  0.011231794357299804 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  664 | Train Loss:  0.010275485515594483 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  665 | Train Loss:  0.010779190063476562 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  666 | Train Loss:  0.0107515549659729 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  667 | Train Loss:  0.009455618858337402 | Train Accuracy:  0.77 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  668 | Train Loss:  0.011062521934509278 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  669 | Train Loss:  0.010151902437210083 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  670 | Train Loss:  0.010054949522018432 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  671 | Train Loss:  0.010047707557678223 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  672 | Train Loss:  0.01079736590385437 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  673 | Train Loss:  0.011831129789352418 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  674 | Train Loss:  0.010064831972122192 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.46\n",
            "Iteration:  675 | Train Loss:  0.010503050088882446 | Train Accuracy:  0.63 | Validation Accuracy:  0.5\n",
            "Iteration:  676 | Train Loss:  0.013849384784698486 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  677 | Train Loss:  0.011784144639968873 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  678 | Train Loss:  0.009989550113677978 | Train Accuracy:  0.62 | Validation Accuracy:  0.5\n",
            "Iteration:  679 | Train Loss:  0.012423559427261352 | Train Accuracy:  0.65 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  680 | Train Loss:  0.011470390558242798 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  681 | Train Loss:  0.008895488977432251 | Train Accuracy:  0.69 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  682 | Train Loss:  0.01248877763748169 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  683 | Train Loss:  0.010527043342590333 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  684 | Train Loss:  0.009652037024497986 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  685 | Train Loss:  0.010094314813613892 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  686 | Train Loss:  0.011485425233840942 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  687 | Train Loss:  0.011715327501296996 | Train Accuracy:  0.73 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  688 | Train Loss:  0.009618427753448486 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  689 | Train Loss:  0.012084815502166748 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  690 | Train Loss:  0.014435571432113648 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  691 | Train Loss:  0.010964947938919067 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  692 | Train Loss:  0.010534671545028686 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  693 | Train Loss:  0.013399325609207154 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  694 | Train Loss:  0.010833572149276733 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5666666666666667\n",
            "Iteration:  695 | Train Loss:  0.008717910647392272 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  696 | Train Loss:  0.01369537353515625 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  697 | Train Loss:  0.010278255939483642 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  698 | Train Loss:  0.009430416226387024 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  699 | Train Loss:  0.010593352317810058 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  700 | Train Loss:  0.011609748601913453 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  701 | Train Loss:  0.011104735136032105 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  702 | Train Loss:  0.009674600958824157 | Train Accuracy:  0.5871428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  703 | Train Loss:  0.012379295825958252 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  704 | Train Loss:  0.01430283784866333 | Train Accuracy:  0.77 | Validation Accuracy:  0.56\n",
            "Iteration:  705 | Train Loss:  0.010754711627960205 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  706 | Train Loss:  0.010615001916885376 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  707 | Train Loss:  0.01331750512123108 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  708 | Train Loss:  0.010733108520507812 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  709 | Train Loss:  0.008660225868225098 | Train Accuracy:  0.65 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  710 | Train Loss:  0.01365960121154785 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  711 | Train Loss:  0.010400198698043824 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  712 | Train Loss:  0.009407927989959717 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  713 | Train Loss:  0.010274585485458374 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  714 | Train Loss:  0.011671833992004395 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  715 | Train Loss:  0.011602648496627808 | Train Accuracy:  0.73 | Validation Accuracy:  0.52\n",
            "Iteration:  716 | Train Loss:  0.009407724738121032 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  717 | Train Loss:  0.01230218529701233 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  718 | Train Loss:  0.014898699522018433 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  719 | Train Loss:  0.011381878852844238 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  720 | Train Loss:  0.01014022707939148 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  721 | Train Loss:  0.013774023056030274 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  722 | Train Loss:  0.011730666160583497 | Train Accuracy:  0.7928571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  723 | Train Loss:  0.008610908985137939 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  724 | Train Loss:  0.013265341520309448 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  725 | Train Loss:  0.011069684028625489 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  726 | Train Loss:  0.009829956889152527 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  727 | Train Loss:  0.009649532437324524 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  728 | Train Loss:  0.01173109769821167 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  729 | Train Loss:  0.013198304176330566 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  730 | Train Loss:  0.009502474069595337 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  731 | Train Loss:  0.01150666832923889 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  732 | Train Loss:  0.01568368434906006 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  733 | Train Loss:  0.013298286199569702 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  734 | Train Loss:  0.009603099822998047 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  735 | Train Loss:  0.013087888956069946 | Train Accuracy:  0.5785714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  736 | Train Loss:  0.013448501825332642 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  737 | Train Loss:  0.010121725797653199 | Train Accuracy:  0.76 | Validation Accuracy:  0.56\n",
            "Iteration:  738 | Train Loss:  0.011158052682876587 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  739 | Train Loss:  0.011041586399078368 | Train Accuracy:  0.64 | Validation Accuracy:  0.5\n",
            "Iteration:  740 | Train Loss:  0.011607604026794434 | Train Accuracy:  0.76 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  741 | Train Loss:  0.009992262125015259 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  742 | Train Loss:  0.010631738901138306 | Train Accuracy:  0.63 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  743 | Train Loss:  0.014382377862930298 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  744 | Train Loss:  0.011787127256393432 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  745 | Train Loss:  0.009751408100128174 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  746 | Train Loss:  0.01412940263748169 | Train Accuracy:  0.5842857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  747 | Train Loss:  0.015083142518997193 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  748 | Train Loss:  0.011317133903503418 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  749 | Train Loss:  0.009959388971328736 | Train Accuracy:  0.6014285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  750 | Train Loss:  0.01209347128868103 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  751 | Train Loss:  0.012382954359054565 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  752 | Train Loss:  0.010778002738952637 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  753 | Train Loss:  0.009423702955245972 | Train Accuracy:  0.67 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  754 | Train Loss:  0.010998407602310181 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  755 | Train Loss:  0.012222297191619873 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  756 | Train Loss:  0.011389846801757813 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  757 | Train Loss:  0.010915762186050415 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  758 | Train Loss:  0.011552448272705079 | Train Accuracy:  0.73 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  759 | Train Loss:  0.01084464430809021 | Train Accuracy:  0.81 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  760 | Train Loss:  0.011269710063934325 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  761 | Train Loss:  0.01109114646911621 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  762 | Train Loss:  0.010371959209442139 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  763 | Train Loss:  0.00962903082370758 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  764 | Train Loss:  0.009795398712158203 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  765 | Train Loss:  0.009243926405906678 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  766 | Train Loss:  0.0104263973236084 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  767 | Train Loss:  0.009585960507392884 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  768 | Train Loss:  0.00949237883090973 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  769 | Train Loss:  0.009809064269065857 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  770 | Train Loss:  0.01065115213394165 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  771 | Train Loss:  0.010242115259170532 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  772 | Train Loss:  0.009746559262275696 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  773 | Train Loss:  0.009638071656227112 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  774 | Train Loss:  0.011824148893356323 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  775 | Train Loss:  0.010705921649932861 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  776 | Train Loss:  0.009463248252868652 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  777 | Train Loss:  0.009911779761314393 | Train Accuracy:  0.7 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  778 | Train Loss:  0.009956685900688171 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  779 | Train Loss:  0.008808260560035705 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  780 | Train Loss:  0.010441635847091674 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  781 | Train Loss:  0.00900059461593628 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5666666666666667\n",
            "Iteration:  782 | Train Loss:  0.009450279474258423 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  783 | Train Loss:  0.009250746369361877 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  784 | Train Loss:  0.010141289234161377 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  785 | Train Loss:  0.011138988733291626 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  786 | Train Loss:  0.009557481408119201 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  787 | Train Loss:  0.00966773271560669 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  788 | Train Loss:  0.013282829523086548 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  789 | Train Loss:  0.01157140851020813 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  790 | Train Loss:  0.009095640778541565 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  791 | Train Loss:  0.011212114095687866 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  792 | Train Loss:  0.011002631187438964 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  793 | Train Loss:  0.008415873050689698 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  794 | Train Loss:  0.011488378047943115 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  795 | Train Loss:  0.009418785572052002 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  796 | Train Loss:  0.009286441206932068 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  797 | Train Loss:  0.008818199634552002 | Train Accuracy:  0.7 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  798 | Train Loss:  0.0107128643989563 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  799 | Train Loss:  0.011638449430465698 | Train Accuracy:  0.8 | Validation Accuracy:  0.54\n",
            "Iteration:  800 | Train Loss:  0.008840079307556153 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  801 | Train Loss:  0.011072399616241456 | Train Accuracy:  0.6214285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  802 | Train Loss:  0.014246690273284911 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  803 | Train Loss:  0.011028571128845215 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  804 | Train Loss:  0.00931134819984436 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  805 | Train Loss:  0.01272284984588623 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  806 | Train Loss:  0.010810407400131226 | Train Accuracy:  0.81 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  807 | Train Loss:  0.0077826327085495 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  808 | Train Loss:  0.013218151330947876 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  809 | Train Loss:  0.00951622486114502 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  810 | Train Loss:  0.00881347119808197 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  811 | Train Loss:  0.009247416853904724 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  812 | Train Loss:  0.011048400402069091 | Train Accuracy:  0.76 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  813 | Train Loss:  0.010799576044082642 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  814 | Train Loss:  0.008722947835922241 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  815 | Train Loss:  0.01172643780708313 | Train Accuracy:  0.6328571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  816 | Train Loss:  0.01399772047996521 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  817 | Train Loss:  0.01037068009376526 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  818 | Train Loss:  0.00961222529411316 | Train Accuracy:  0.62 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  819 | Train Loss:  0.012453827857971191 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  820 | Train Loss:  0.01010408878326416 | Train Accuracy:  0.82 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  821 | Train Loss:  0.007726265788078308 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  822 | Train Loss:  0.01312993884086609 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  823 | Train Loss:  0.009031260013580322 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  824 | Train Loss:  0.008693126440048217 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  825 | Train Loss:  0.009171323180198669 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  826 | Train Loss:  0.010727425813674927 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  827 | Train Loss:  0.010398143529891967 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  828 | Train Loss:  0.008616085648536682 | Train Accuracy:  0.62 | Validation Accuracy:  0.48\n",
            "Iteration:  829 | Train Loss:  0.011369146108627319 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  830 | Train Loss:  0.013566102981567383 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  831 | Train Loss:  0.010203742980957031 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  832 | Train Loss:  0.009408452510833741 | Train Accuracy:  0.63 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  833 | Train Loss:  0.011912331581115723 | Train Accuracy:  0.69 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  834 | Train Loss:  0.009842758774757385 | Train Accuracy:  0.8214285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  835 | Train Loss:  0.007623121738433838 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  836 | Train Loss:  0.012837599515914917 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  837 | Train Loss:  0.008798342943191529 | Train Accuracy:  0.82 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  838 | Train Loss:  0.008609172105789185 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  839 | Train Loss:  0.008917348384857178 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  840 | Train Loss:  0.010510451793670654 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  841 | Train Loss:  0.010295283794403077 | Train Accuracy:  0.75 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  842 | Train Loss:  0.008456614017486572 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  843 | Train Loss:  0.011173226833343507 | Train Accuracy:  0.65 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  844 | Train Loss:  0.013512645959854125 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  845 | Train Loss:  0.01022525668144226 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  846 | Train Loss:  0.009254189133644104 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  847 | Train Loss:  0.011875721216201783 | Train Accuracy:  0.69 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  848 | Train Loss:  0.009819523096084595 | Train Accuracy:  0.8214285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  849 | Train Loss:  0.007509746551513672 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  850 | Train Loss:  0.012816421985626221 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  851 | Train Loss:  0.008688177466392517 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  852 | Train Loss:  0.008500251173973083 | Train Accuracy:  0.74 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  853 | Train Loss:  0.008775385022163391 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  854 | Train Loss:  0.010417670011520386 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  855 | Train Loss:  0.010145978927612305 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  856 | Train Loss:  0.008324097990989685 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  857 | Train Loss:  0.011193579435348511 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  858 | Train Loss:  0.013322825431823731 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  859 | Train Loss:  0.010032871961593628 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  860 | Train Loss:  0.00921895444393158 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  861 | Train Loss:  0.011628870964050292 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  862 | Train Loss:  0.00947092354297638 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  863 | Train Loss:  0.00741309642791748 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  864 | Train Loss:  0.012757964134216308 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  865 | Train Loss:  0.008363331556320191 | Train Accuracy:  0.8214285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  866 | Train Loss:  0.008369159698486329 | Train Accuracy:  0.74 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  867 | Train Loss:  0.008645412921905517 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  868 | Train Loss:  0.01017938256263733 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  869 | Train Loss:  0.009803659319877624 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  870 | Train Loss:  0.008203043937683105 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  871 | Train Loss:  0.010945454835891724 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  872 | Train Loss:  0.013022407293319702 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  873 | Train Loss:  0.009887314438819884 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  874 | Train Loss:  0.009099311828613281 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  875 | Train Loss:  0.0112907874584198 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  876 | Train Loss:  0.009160152673721313 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  877 | Train Loss:  0.007311515212059021 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  878 | Train Loss:  0.012553366422653199 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  879 | Train Loss:  0.008022375702857971 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  880 | Train Loss:  0.008247445821762085 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  881 | Train Loss:  0.008438356518745423 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  882 | Train Loss:  0.009873220324516296 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  883 | Train Loss:  0.009438026547431946 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  884 | Train Loss:  0.008058841824531555 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  885 | Train Loss:  0.010575537681579589 | Train Accuracy:  0.7 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  886 | Train Loss:  0.01245376467704773 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  887 | Train Loss:  0.00955137312412262 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  888 | Train Loss:  0.00916886270046234 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  889 | Train Loss:  0.010481362342834472 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  890 | Train Loss:  0.008470605611801147 | Train Accuracy:  0.8214285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  891 | Train Loss:  0.007271720767021179 | Train Accuracy:  0.72 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  892 | Train Loss:  0.011922756433486939 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  893 | Train Loss:  0.0075192713737487794 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  894 | Train Loss:  0.008166141510009765 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  895 | Train Loss:  0.007974165081977845 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  896 | Train Loss:  0.009291805028915405 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  897 | Train Loss:  0.00895567238330841 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  898 | Train Loss:  0.007804920077323914 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  899 | Train Loss:  0.00972923457622528 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  900 | Train Loss:  0.011740130186080933 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  901 | Train Loss:  0.00943045437335968 | Train Accuracy:  0.73 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  902 | Train Loss:  0.008625576496124268 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  903 | Train Loss:  0.009518650770187377 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  904 | Train Loss:  0.008123276233673095 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  905 | Train Loss:  0.0069954580068588255 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  906 | Train Loss:  0.011029396057128906 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.54\n",
            "Iteration:  907 | Train Loss:  0.007279363870620728 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  908 | Train Loss:  0.007934528589248657 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  909 | Train Loss:  0.007436427474021912 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  910 | Train Loss:  0.008985299468040466 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  911 | Train Loss:  0.00877265453338623 | Train Accuracy:  0.79 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  912 | Train Loss:  0.007552089691162109 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  913 | Train Loss:  0.00933483362197876 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  914 | Train Loss:  0.011535869836807251 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  915 | Train Loss:  0.009300739765167236 | Train Accuracy:  0.75 | Validation Accuracy:  0.5\n",
            "Iteration:  916 | Train Loss:  0.008317813277244568 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  917 | Train Loss:  0.009128254055976868 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  918 | Train Loss:  0.007828401923179627 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  919 | Train Loss:  0.006753681302070618 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  920 | Train Loss:  0.0106413733959198 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  921 | Train Loss:  0.007128969430923462 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  922 | Train Loss:  0.007688181400299072 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  923 | Train Loss:  0.0070865309238433835 | Train Accuracy:  0.83 | Validation Accuracy:  0.5\n",
            "Iteration:  924 | Train Loss:  0.008792452812194824 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  925 | Train Loss:  0.00861332654953003 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  926 | Train Loss:  0.007360825538635254 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  927 | Train Loss:  0.00914703071117401 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  928 | Train Loss:  0.011416029930114747 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  929 | Train Loss:  0.009154863953590393 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  930 | Train Loss:  0.008133674860000611 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  931 | Train Loss:  0.008760074377059937 | Train Accuracy:  0.82 | Validation Accuracy:  0.5\n",
            "Iteration:  932 | Train Loss:  0.007567847967147827 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  933 | Train Loss:  0.006524100303649903 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  934 | Train Loss:  0.010180938243865966 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  935 | Train Loss:  0.0071182000637054444 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  936 | Train Loss:  0.00739644706249237 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  937 | Train Loss:  0.006906282305717468 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  938 | Train Loss:  0.008639461398124694 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  939 | Train Loss:  0.008710979223251343 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  940 | Train Loss:  0.007222203016281128 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  941 | Train Loss:  0.009337841868400573 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  942 | Train Loss:  0.011541160345077515 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  943 | Train Loss:  0.0090275239944458 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  944 | Train Loss:  0.008237934708595275 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  945 | Train Loss:  0.008399903178215026 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  946 | Train Loss:  0.0074728173017501835 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  947 | Train Loss:  0.006305887103080749 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  948 | Train Loss:  0.009558698534965515 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  949 | Train Loss:  0.007325916886329651 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  950 | Train Loss:  0.007095239162445068 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  951 | Train Loss:  0.007001656889915466 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  952 | Train Loss:  0.00842215359210968 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  953 | Train Loss:  0.009260444641113282 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  954 | Train Loss:  0.007021501660346985 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  955 | Train Loss:  0.010113401412963867 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  956 | Train Loss:  0.011625252962112427 | Train Accuracy:  0.8214285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  957 | Train Loss:  0.009134984612464904 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  958 | Train Loss:  0.008396158814430238 | Train Accuracy:  0.8 | Validation Accuracy:  0.5\n",
            "Iteration:  959 | Train Loss:  0.007891449928283691 | Train Accuracy:  0.85 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  960 | Train Loss:  0.007767493724822998 | Train Accuracy:  0.85 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  961 | Train Loss:  0.006052916646003723 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  962 | Train Loss:  0.008958407044410706 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  963 | Train Loss:  0.00743326723575592 | Train Accuracy:  0.85 | Validation Accuracy:  0.52\n",
            "Iteration:  964 | Train Loss:  0.006976481080055236 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  965 | Train Loss:  0.00724170446395874 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  966 | Train Loss:  0.008150712847709655 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  967 | Train Loss:  0.010055358409881593 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.54\n",
            "Iteration:  968 | Train Loss:  0.0068007433414459225 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  969 | Train Loss:  0.010990281105041504 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  970 | Train Loss:  0.01216226577758789 | Train Accuracy:  0.81 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  971 | Train Loss:  0.009273749589920045 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  972 | Train Loss:  0.009227346181869506 | Train Accuracy:  0.7985714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  973 | Train Loss:  0.007814196944236755 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  974 | Train Loss:  0.008006837368011475 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  975 | Train Loss:  0.0059808164834976195 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  976 | Train Loss:  0.00873896360397339 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  977 | Train Loss:  0.007910501956939698 | Train Accuracy:  0.85 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  978 | Train Loss:  0.006813932657241822 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5666666666666667\n",
            "Iteration:  979 | Train Loss:  0.00754332423210144 | Train Accuracy:  0.84 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  980 | Train Loss:  0.00797862708568573 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  981 | Train Loss:  0.010413362979888915 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  982 | Train Loss:  0.0069389349222183224 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  983 | Train Loss:  0.010962674617767334 | Train Accuracy:  0.6814285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  984 | Train Loss:  0.012883784770965577 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  985 | Train Loss:  0.008845381140708923 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  986 | Train Loss:  0.009564333558082581 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  987 | Train Loss:  0.008553614616394043 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  988 | Train Loss:  0.007548008561134339 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  989 | Train Loss:  0.006325117349624634 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  990 | Train Loss:  0.009013453722000122 | Train Accuracy:  0.78 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  991 | Train Loss:  0.008571393489837646 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  992 | Train Loss:  0.006728159189224243 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5666666666666667\n",
            "Iteration:  993 | Train Loss:  0.007493026852607727 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  994 | Train Loss:  0.008307135105133057 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  995 | Train Loss:  0.009620807766914367 | Train Accuracy:  0.84 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  996 | Train Loss:  0.007561243176460266 | Train Accuracy:  0.69 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  997 | Train Loss:  0.009497354030609131 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  998 | Train Loss:  0.012852522134780884 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  999 | Train Loss:  0.00890596330165863 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1000 | Train Loss:  0.009143096208572388 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1001 | Train Loss:  0.00941322922706604 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1002 | Train Loss:  0.007034482359886169 | Train Accuracy:  0.79 | Validation Accuracy:  0.5666666666666667\n",
            "Iteration:  1003 | Train Loss:  0.006533759832382202 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1004 | Train Loss:  0.00963490605354309 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1005 | Train Loss:  0.008179128170013428 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1006 | Train Loss:  0.006947458386421203 | Train Accuracy:  0.83 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1007 | Train Loss:  0.006851174235343933 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  1008 | Train Loss:  0.008627939820289612 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1009 | Train Loss:  0.00845316231250763 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1010 | Train Loss:  0.0077151978015899654 | Train Accuracy:  0.74 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1011 | Train Loss:  0.008248198628425598 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1012 | Train Loss:  0.012510865926742554 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1013 | Train Loss:  0.00921286404132843 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1014 | Train Loss:  0.008455137610435487 | Train Accuracy:  0.67 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1015 | Train Loss:  0.01004580855369568 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1016 | Train Loss:  0.006744815111160278 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  1017 | Train Loss:  0.0065611302852630615 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  1018 | Train Loss:  0.01060377836227417 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1019 | Train Loss:  0.007373698353767395 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1020 | Train Loss:  0.007485584020614624 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1021 | Train Loss:  0.006173498034477234 | Train Accuracy:  0.82 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  1022 | Train Loss:  0.008791291117668153 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1023 | Train Loss:  0.007546345591545105 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1024 | Train Loss:  0.0075027960538864135 | Train Accuracy:  0.81 | Validation Accuracy:  0.56\n",
            "Iteration:  1025 | Train Loss:  0.007374264001846313 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1026 | Train Loss:  0.011599522829055787 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5666666666666667\n",
            "Iteration:  1027 | Train Loss:  0.009595585465431213 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1028 | Train Loss:  0.007507616281509399 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1029 | Train Loss:  0.009925618171691894 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1030 | Train Loss:  0.006682647466659546 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5666666666666667\n",
            "Iteration:  1031 | Train Loss:  0.006211034655570984 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1032 | Train Loss:  0.011319546699523926 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1033 | Train Loss:  0.006552935838699341 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1034 | Train Loss:  0.007684351205825806 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1035 | Train Loss:  0.005948445796966553 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  1036 | Train Loss:  0.008603790998458863 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1037 | Train Loss:  0.007352728247642517 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1038 | Train Loss:  0.007007415294647217 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1039 | Train Loss:  0.007188947200775147 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1040 | Train Loss:  0.010879011154174804 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  1041 | Train Loss:  0.009625415802001953 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1042 | Train Loss:  0.006994820237159729 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1043 | Train Loss:  0.009249567985534668 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1044 | Train Loss:  0.006612042188644409 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5666666666666667\n",
            "Iteration:  1045 | Train Loss:  0.005808844566345215 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1046 | Train Loss:  0.011109213829040527 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1047 | Train Loss:  0.00599249541759491 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1048 | Train Loss:  0.00735066294670105 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1049 | Train Loss:  0.005834020376205444 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  1050 | Train Loss:  0.008273712396621703 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1051 | Train Loss:  0.007175209522247314 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1052 | Train Loss:  0.006609565615653992 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5666666666666667\n",
            "Iteration:  1053 | Train Loss:  0.00705370306968689 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1054 | Train Loss:  0.010481202602386474 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  1055 | Train Loss:  0.009046202898025513 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1056 | Train Loss:  0.006579431295394897 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1057 | Train Loss:  0.008569820523262025 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  1058 | Train Loss:  0.006424804925918579 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1059 | Train Loss:  0.0054692083597183225 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1060 | Train Loss:  0.010444712638854981 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1061 | Train Loss:  0.005623562932014465 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1062 | Train Loss:  0.006867153644561768 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1063 | Train Loss:  0.005668532848358154 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1064 | Train Loss:  0.007887069582939148 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  1065 | Train Loss:  0.006983644962310791 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1066 | Train Loss:  0.0063545465469360355 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  1067 | Train Loss:  0.007012622356414795 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  1068 | Train Loss:  0.010198428630828857 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1069 | Train Loss:  0.008647668361663818 | Train Accuracy:  0.81 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1070 | Train Loss:  0.006449029445648193 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1071 | Train Loss:  0.007878664135932922 | Train Accuracy:  0.83 | Validation Accuracy:  0.48\n",
            "Iteration:  1072 | Train Loss:  0.00619778573513031 | Train Accuracy:  0.8671428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  1073 | Train Loss:  0.00522797167301178 | Train Accuracy:  0.8 | Validation Accuracy:  0.56\n",
            "Iteration:  1074 | Train Loss:  0.009437127113342285 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1075 | Train Loss:  0.005385833382606506 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  1076 | Train Loss:  0.006375951170921326 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1077 | Train Loss:  0.0054280698299407956 | Train Accuracy:  0.87 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1078 | Train Loss:  0.0075735169649124145 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1079 | Train Loss:  0.006838468909263611 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1080 | Train Loss:  0.0060817205905914305 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1081 | Train Loss:  0.007158726453781128 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  1082 | Train Loss:  0.010002894401550293 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1083 | Train Loss:  0.008026777505874634 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1084 | Train Loss:  0.006144020557403564 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1085 | Train Loss:  0.007041851878166199 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1086 | Train Loss:  0.005950227975845337 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1087 | Train Loss:  0.005040728449821472 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1088 | Train Loss:  0.008423583507537842 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1089 | Train Loss:  0.004995105266571045 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1090 | Train Loss:  0.005894153714179993 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1091 | Train Loss:  0.005272033214569091 | Train Accuracy:  0.86 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1092 | Train Loss:  0.007169597148895264 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1093 | Train Loss:  0.006739630103111267 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1094 | Train Loss:  0.0058348214626312254 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1095 | Train Loss:  0.00734108567237854 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1096 | Train Loss:  0.009491065144538879 | Train Accuracy:  0.85 | Validation Accuracy:  0.5\n",
            "Iteration:  1097 | Train Loss:  0.007924869060516357 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1098 | Train Loss:  0.005718482732772827 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1099 | Train Loss:  0.0067484438419342044 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1100 | Train Loss:  0.005821985006332397 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1101 | Train Loss:  0.005206872820854187 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1102 | Train Loss:  0.008193678259849548 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1103 | Train Loss:  0.004842628836631775 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1104 | Train Loss:  0.00576906144618988 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1105 | Train Loss:  0.005306825041770935 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1106 | Train Loss:  0.006886040568351745 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1107 | Train Loss:  0.006513562202453613 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1108 | Train Loss:  0.005687388777732849 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1109 | Train Loss:  0.007014966011047364 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1110 | Train Loss:  0.009184133410453797 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  1111 | Train Loss:  0.007669769525527954 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1112 | Train Loss:  0.005473322868347168 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1113 | Train Loss:  0.0066235923767089845 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1114 | Train Loss:  0.0057101017236709595 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1115 | Train Loss:  0.005058009028434753 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1116 | Train Loss:  0.00829232633113861 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1117 | Train Loss:  0.004627948105335236 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1118 | Train Loss:  0.005726873278617859 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1119 | Train Loss:  0.005039083361625671 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1120 | Train Loss:  0.006713306903839112 | Train Accuracy:  0.88 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1121 | Train Loss:  0.00640340268611908 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1122 | Train Loss:  0.0055887365341186525 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  1123 | Train Loss:  0.007039723992347717 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  1124 | Train Loss:  0.009005013108253478 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1125 | Train Loss:  0.007618256211280823 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1126 | Train Loss:  0.0054821217060089114 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1127 | Train Loss:  0.006545662879943848 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1128 | Train Loss:  0.005535452365875244 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1129 | Train Loss:  0.005246890783309937 | Train Accuracy:  0.83 | Validation Accuracy:  0.54\n",
            "Iteration:  1130 | Train Loss:  0.007872812151908874 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1131 | Train Loss:  0.004638676047325135 | Train Accuracy:  0.86 | Validation Accuracy:  0.5\n",
            "Iteration:  1132 | Train Loss:  0.005561725497245789 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1133 | Train Loss:  0.005112119913101196 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1134 | Train Loss:  0.0064576339721679685 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1135 | Train Loss:  0.006256954073905945 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1136 | Train Loss:  0.005455542206764221 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  1137 | Train Loss:  0.006705809235572815 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1138 | Train Loss:  0.008825740218162537 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  1139 | Train Loss:  0.007359092235565186 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  1140 | Train Loss:  0.005280787944793701 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1141 | Train Loss:  0.006509532928466797 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1142 | Train Loss:  0.005374470949172974 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  1143 | Train Loss:  0.005025789737701416 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1144 | Train Loss:  0.007784130573272705 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1145 | Train Loss:  0.004356564283370972 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1146 | Train Loss:  0.005476308465003968 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1147 | Train Loss:  0.004653436243534088 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1148 | Train Loss:  0.006344839334487915 | Train Accuracy:  0.8842857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1149 | Train Loss:  0.006191114783287048 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1150 | Train Loss:  0.0053329461812973026 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1151 | Train Loss:  0.007073606848716735 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1152 | Train Loss:  0.008446140885353089 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1153 | Train Loss:  0.00740338921546936 | Train Accuracy:  0.8671428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1154 | Train Loss:  0.005161668062210083 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1155 | Train Loss:  0.00664472758769989 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1156 | Train Loss:  0.005462037920951843 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1157 | Train Loss:  0.005177241563796997 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  1158 | Train Loss:  0.0080162513256073 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1159 | Train Loss:  0.004390594363212585 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1160 | Train Loss:  0.005614252090454102 | Train Accuracy:  0.85 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1161 | Train Loss:  0.004629540145397186 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1162 | Train Loss:  0.006340619921684265 | Train Accuracy:  0.89 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1163 | Train Loss:  0.005992703437805176 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1164 | Train Loss:  0.005368675589561462 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1165 | Train Loss:  0.006740453839302063 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1166 | Train Loss:  0.00846112847328186 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1167 | Train Loss:  0.007221009731292725 | Train Accuracy:  0.87 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1168 | Train Loss:  0.00507857084274292 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1169 | Train Loss:  0.006681486368179322 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1170 | Train Loss:  0.005197290778160096 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1171 | Train Loss:  0.005553058385848999 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  1172 | Train Loss:  0.0074380582571029665 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1173 | Train Loss:  0.004589526057243347 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  1174 | Train Loss:  0.005433136224746704 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1175 | Train Loss:  0.004725545942783356 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  1176 | Train Loss:  0.006114050149917603 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1177 | Train Loss:  0.005845035314559936 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1178 | Train Loss:  0.005345951914787293 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1179 | Train Loss:  0.006294560432434082 | Train Accuracy:  0.82 | Validation Accuracy:  0.56\n",
            "Iteration:  1180 | Train Loss:  0.008560725450515748 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1181 | Train Loss:  0.006851142048835754 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1182 | Train Loss:  0.0050877809524536135 | Train Accuracy:  0.89 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1183 | Train Loss:  0.006529813408851623 | Train Accuracy:  0.85 | Validation Accuracy:  0.52\n",
            "Iteration:  1184 | Train Loss:  0.004988144040107727 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1185 | Train Loss:  0.005525271892547607 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1186 | Train Loss:  0.006899285316467285 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  1187 | Train Loss:  0.0048589488863945 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1188 | Train Loss:  0.005007880330085754 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1189 | Train Loss:  0.004978576600551605 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1190 | Train Loss:  0.005823347568511963 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1191 | Train Loss:  0.005792847275733948 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1192 | Train Loss:  0.0053585761785507205 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  1193 | Train Loss:  0.006026982665061951 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  1194 | Train Loss:  0.008497064709663391 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1195 | Train Loss:  0.006583659648895263 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1196 | Train Loss:  0.0050738811492919925 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1197 | Train Loss:  0.006522485613822937 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  1198 | Train Loss:  0.00483366459608078 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1199 | Train Loss:  0.005662458539009094 | Train Accuracy:  0.85 | Validation Accuracy:  0.54\n",
            "Iteration:  1200 | Train Loss:  0.006386291384696961 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1201 | Train Loss:  0.005105742812156677 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1202 | Train Loss:  0.0047562322020530704 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1203 | Train Loss:  0.00511398196220398 | Train Accuracy:  0.9 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1204 | Train Loss:  0.005515891313552857 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1205 | Train Loss:  0.005801640748977661 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1206 | Train Loss:  0.005133863687515259 | Train Accuracy:  0.8214285714285714 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1207 | Train Loss:  0.0058631616830825805 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  1208 | Train Loss:  0.00813717246055603 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1209 | Train Loss:  0.006219536066055298 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1210 | Train Loss:  0.005657814741134644 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1211 | Train Loss:  0.006048282384872436 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1212 | Train Loss:  0.004990007877349854 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1213 | Train Loss:  0.0054635626077651975 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1214 | Train Loss:  0.005712602138519287 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1215 | Train Loss:  0.005441617369651795 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1216 | Train Loss:  0.004437550306320191 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1217 | Train Loss:  0.005821494460105896 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  1218 | Train Loss:  0.005421278476715088 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1219 | Train Loss:  0.006401320695877075 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1220 | Train Loss:  0.004892094433307648 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1221 | Train Loss:  0.005778926014900207 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1222 | Train Loss:  0.008171380758285522 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1223 | Train Loss:  0.006234875321388245 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1224 | Train Loss:  0.006886212229728699 | Train Accuracy:  0.88 | Validation Accuracy:  0.52\n",
            "Iteration:  1225 | Train Loss:  0.005741457939147949 | Train Accuracy:  0.9 | Validation Accuracy:  0.52\n",
            "Iteration:  1226 | Train Loss:  0.0057790642976760865 | Train Accuracy:  0.83 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1227 | Train Loss:  0.004753000736236572 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1228 | Train Loss:  0.005757405757904053 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  1229 | Train Loss:  0.005416151285171509 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1230 | Train Loss:  0.004931047558784485 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1231 | Train Loss:  0.006599556803703308 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1232 | Train Loss:  0.006033321619033813 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1233 | Train Loss:  0.007466499209403992 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.54\n",
            "Iteration:  1234 | Train Loss:  0.004781404137611389 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  1235 | Train Loss:  0.006480684876441956 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1236 | Train Loss:  0.007777753472328186 | Train Accuracy:  0.86 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1237 | Train Loss:  0.00751270592212677 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1238 | Train Loss:  0.007992213368415832 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1239 | Train Loss:  0.006263198256492615 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1240 | Train Loss:  0.0073353111743927005 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1241 | Train Loss:  0.003610806167125702 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1242 | Train Loss:  0.007280766367912293 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1243 | Train Loss:  0.003503538966178894 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1244 | Train Loss:  0.007924370765686035 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1245 | Train Loss:  0.003965898752212525 | Train Accuracy:  0.74 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1246 | Train Loss:  0.010666924715042114 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1247 | Train Loss:  0.006358764767646789 | Train Accuracy:  0.7 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1248 | Train Loss:  0.008127852082252503 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1249 | Train Loss:  0.005523640513420105 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1250 | Train Loss:  0.009049594402313232 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1251 | Train Loss:  0.0060018813610076905 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1252 | Train Loss:  0.004507451951503753 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1253 | Train Loss:  0.005437977313995361 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1254 | Train Loss:  0.005867328643798828 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1255 | Train Loss:  0.003581911325454712 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1256 | Train Loss:  0.0064378690719604495 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1257 | Train Loss:  0.0036071336269378664 | Train Accuracy:  0.9 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1258 | Train Loss:  0.004216192364692688 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1259 | Train Loss:  0.0034404343366622927 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1260 | Train Loss:  0.005571420192718506 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1261 | Train Loss:  0.006144148707389832 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1262 | Train Loss:  0.005991640090942382 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1263 | Train Loss:  0.00783772110939026 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1264 | Train Loss:  0.008369815349578858 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1265 | Train Loss:  0.007146304845809937 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1266 | Train Loss:  0.005905006527900696 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  1267 | Train Loss:  0.006895647644996643 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  1268 | Train Loss:  0.007400608658790588 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  1269 | Train Loss:  0.004607308208942413 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  1270 | Train Loss:  0.007665015459060669 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1271 | Train Loss:  0.0037034636735916136 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1272 | Train Loss:  0.004777332246303559 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1273 | Train Loss:  0.0033379006385803223 | Train Accuracy:  0.9042857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  1274 | Train Loss:  0.004897914230823517 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1275 | Train Loss:  0.005314173698425293 | Train Accuracy:  0.8214285714285714 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1276 | Train Loss:  0.0045319655537605285 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1277 | Train Loss:  0.006080677509307861 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1278 | Train Loss:  0.006717846393585205 | Train Accuracy:  0.8671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1279 | Train Loss:  0.006181038618087768 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1280 | Train Loss:  0.004406368136405945 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1281 | Train Loss:  0.006769564151763916 | Train Accuracy:  0.87 | Validation Accuracy:  0.52\n",
            "Iteration:  1282 | Train Loss:  0.004446900188922882 | Train Accuracy:  0.81 | Validation Accuracy:  0.48\n",
            "Iteration:  1283 | Train Loss:  0.005642472505569458 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1284 | Train Loss:  0.005298324823379517 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1285 | Train Loss:  0.005582684278488159 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1286 | Train Loss:  0.004051689803600311 | Train Accuracy:  0.79 | Validation Accuracy:  0.48\n",
            "Iteration:  1287 | Train Loss:  0.005095768570899963 | Train Accuracy:  0.86 | Validation Accuracy:  0.5\n",
            "Iteration:  1288 | Train Loss:  0.005594756007194519 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1289 | Train Loss:  0.0059201431274414065 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1290 | Train Loss:  0.005036939382553101 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1291 | Train Loss:  0.005154403448104858 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  1292 | Train Loss:  0.006773530840873719 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1293 | Train Loss:  0.005339176058769226 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1294 | Train Loss:  0.004134198725223541 | Train Accuracy:  0.89 | Validation Accuracy:  0.54\n",
            "Iteration:  1295 | Train Loss:  0.005324096083641052 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1296 | Train Loss:  0.004192914962768555 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1297 | Train Loss:  0.003476631045341492 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1298 | Train Loss:  0.005026154518127442 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1299 | Train Loss:  0.003997253775596618 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1300 | Train Loss:  0.0038589629530906677 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1301 | Train Loss:  0.003738557696342468 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  1302 | Train Loss:  0.005780012011528015 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  1303 | Train Loss:  0.005162563920021057 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1304 | Train Loss:  0.005332217812538147 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1305 | Train Loss:  0.004824109971523285 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1306 | Train Loss:  0.006878975033760071 | Train Accuracy:  0.9 | Validation Accuracy:  0.5\n",
            "Iteration:  1307 | Train Loss:  0.005164876580238342 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1308 | Train Loss:  0.0039588001370429995 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  1309 | Train Loss:  0.005131692290306091 | Train Accuracy:  0.8671428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1310 | Train Loss:  0.004179116487503052 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1311 | Train Loss:  0.0035099291801452635 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1312 | Train Loss:  0.004900243878364563 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1313 | Train Loss:  0.0037837669253349302 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1314 | Train Loss:  0.0035606101155281067 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1315 | Train Loss:  0.0032045489549636843 | Train Accuracy:  0.87 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1316 | Train Loss:  0.0050472128391265865 | Train Accuracy:  0.88 | Validation Accuracy:  0.52\n",
            "Iteration:  1317 | Train Loss:  0.004736948013305664 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1318 | Train Loss:  0.004909595549106598 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1319 | Train Loss:  0.0048319709300994875 | Train Accuracy:  0.91 | Validation Accuracy:  0.5\n",
            "Iteration:  1320 | Train Loss:  0.006631856560707092 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1321 | Train Loss:  0.004747251868247986 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  1322 | Train Loss:  0.0036374178528785707 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1323 | Train Loss:  0.005249259471893311 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1324 | Train Loss:  0.004124698340892792 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1325 | Train Loss:  0.003314610421657562 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1326 | Train Loss:  0.00487011194229126 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1327 | Train Loss:  0.003519688546657562 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1328 | Train Loss:  0.0033304351568222046 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1329 | Train Loss:  0.002798861265182495 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1330 | Train Loss:  0.004556732475757599 | Train Accuracy:  0.9 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1331 | Train Loss:  0.004471777379512787 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1332 | Train Loss:  0.004938439130783081 | Train Accuracy:  0.82 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1333 | Train Loss:  0.004858515858650207 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1334 | Train Loss:  0.006547119617462158 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1335 | Train Loss:  0.0046349743008613584 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1336 | Train Loss:  0.003652297854423523 | Train Accuracy:  0.91 | Validation Accuracy:  0.5\n",
            "Iteration:  1337 | Train Loss:  0.0052329558134078975 | Train Accuracy:  0.83 | Validation Accuracy:  0.5\n",
            "Iteration:  1338 | Train Loss:  0.004567855596542358 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1339 | Train Loss:  0.002954171895980835 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1340 | Train Loss:  0.005093300342559814 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1341 | Train Loss:  0.0028998956084251406 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1342 | Train Loss:  0.003338399827480316 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1343 | Train Loss:  0.002507040202617645 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1344 | Train Loss:  0.0042562663555145265 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1345 | Train Loss:  0.004616972208023071 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1346 | Train Loss:  0.00495406299829483 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1347 | Train Loss:  0.005527255535125733 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1348 | Train Loss:  0.006739371418952942 | Train Accuracy:  0.9042857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1349 | Train Loss:  0.004675195813179016 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1350 | Train Loss:  0.004162805676460266 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1351 | Train Loss:  0.005339915156364441 | Train Accuracy:  0.77 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1352 | Train Loss:  0.006096432209014893 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1353 | Train Loss:  0.0026244303584098817 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1354 | Train Loss:  0.005798429250717163 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1355 | Train Loss:  0.002693837285041809 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1356 | Train Loss:  0.003509824275970459 | Train Accuracy:  0.92 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1357 | Train Loss:  0.002905939221382141 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1358 | Train Loss:  0.004078917801380157 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1359 | Train Loss:  0.0053854650259017945 | Train Accuracy:  0.74 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1360 | Train Loss:  0.005524123907089233 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1361 | Train Loss:  0.007936028242111206 | Train Accuracy:  0.89 | Validation Accuracy:  0.52\n",
            "Iteration:  1362 | Train Loss:  0.007958616614341735 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1363 | Train Loss:  0.005695394873619079 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1364 | Train Loss:  0.006373167634010315 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1365 | Train Loss:  0.0060355645418167115 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1366 | Train Loss:  0.010361999273300171 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1367 | Train Loss:  0.0026181820034980774 | Train Accuracy:  0.75 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1368 | Train Loss:  0.008924283385276795 | Train Accuracy:  0.92 | Validation Accuracy:  0.52\n",
            "Iteration:  1369 | Train Loss:  0.003130341172218323 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1370 | Train Loss:  0.005215821266174317 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1371 | Train Loss:  0.003586861789226532 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1372 | Train Loss:  0.0038587096333503722 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  1373 | Train Loss:  0.007360855340957642 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1374 | Train Loss:  0.004502236843109131 | Train Accuracy:  0.69 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1375 | Train Loss:  0.009598848223686219 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1376 | Train Loss:  0.005793812870979309 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1377 | Train Loss:  0.009955055117607116 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1378 | Train Loss:  0.0037615028023719787 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1379 | Train Loss:  0.01236475706100464 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1380 | Train Loss:  0.0037478217482566833 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1381 | Train Loss:  0.014566279649734497 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1382 | Train Loss:  0.004751178622245789 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1383 | Train Loss:  0.012552309036254882 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1384 | Train Loss:  0.005315042734146118 | Train Accuracy:  0.6328571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1385 | Train Loss:  0.011961554288864135 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1386 | Train Loss:  0.009599745273590088 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1387 | Train Loss:  0.008540554642677308 | Train Accuracy:  0.6814285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1388 | Train Loss:  0.0076055264472961424 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1389 | Train Loss:  0.005555588006973267 | Train Accuracy:  0.87 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1390 | Train Loss:  0.007398654818534851 | Train Accuracy:  0.88 | Validation Accuracy:  0.5\n",
            "Iteration:  1391 | Train Loss:  0.006006518006324768 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1392 | Train Loss:  0.005316275358200073 | Train Accuracy:  0.88 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1393 | Train Loss:  0.006976937055587769 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1394 | Train Loss:  0.005142365097999573 | Train Accuracy:  0.77 | Validation Accuracy:  0.48\n",
            "Iteration:  1395 | Train Loss:  0.006323016285896301 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1396 | Train Loss:  0.005772568583488465 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  1397 | Train Loss:  0.005382379293441772 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  1398 | Train Loss:  0.007422515749931335 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1399 | Train Loss:  0.004489707946777344 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1400 | Train Loss:  0.011143462657928467 | Train Accuracy:  0.91 | Validation Accuracy:  0.52\n",
            "Iteration:  1401 | Train Loss:  0.005295482277870178 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1402 | Train Loss:  0.008280609250068665 | Train Accuracy:  0.69 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1403 | Train Loss:  0.008783095479011536 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1404 | Train Loss:  0.006898801922798157 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1405 | Train Loss:  0.009866370558738709 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1406 | Train Loss:  0.005931999683380127 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1407 | Train Loss:  0.009274033904075623 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1408 | Train Loss:  0.007269954681396485 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1409 | Train Loss:  0.007772527933120728 | Train Accuracy:  0.77 | Validation Accuracy:  0.46\n",
            "Iteration:  1410 | Train Loss:  0.009273359775543213 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1411 | Train Loss:  0.004815635979175567 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1412 | Train Loss:  0.012699401378631592 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1413 | Train Loss:  0.00403594046831131 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1414 | Train Loss:  0.015417399406433106 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  1415 | Train Loss:  0.011923365592956543 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1416 | Train Loss:  0.00889718472957611 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1417 | Train Loss:  0.020332024097442628 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1418 | Train Loss:  0.013245741128921509 | Train Accuracy:  0.61 | Validation Accuracy:  0.52\n",
            "Iteration:  1419 | Train Loss:  0.01201507329940796 | Train Accuracy:  0.5585714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1420 | Train Loss:  0.02318905830383301 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  1421 | Train Loss:  0.00768382728099823 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1422 | Train Loss:  0.014073376655578613 | Train Accuracy:  0.6271428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1423 | Train Loss:  0.013578424453735352 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1424 | Train Loss:  0.0061734944581985475 | Train Accuracy:  0.6128571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1425 | Train Loss:  0.015171504020690918 | Train Accuracy:  0.7 | Validation Accuracy:  0.48\n",
            "Iteration:  1426 | Train Loss:  0.009187151193618775 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1427 | Train Loss:  0.007032163143157959 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1428 | Train Loss:  0.009586641192436218 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1429 | Train Loss:  0.006261872053146362 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1430 | Train Loss:  0.009078211188316344 | Train Accuracy:  0.91 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1431 | Train Loss:  0.006865703463554382 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1432 | Train Loss:  0.010930125713348388 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1433 | Train Loss:  0.010720782279968262 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  1434 | Train Loss:  0.006535274386405945 | Train Accuracy:  0.64 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1435 | Train Loss:  0.011290833950042725 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1436 | Train Loss:  0.006651440262794494 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1437 | Train Loss:  0.005501002669334411 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1438 | Train Loss:  0.009342759847640991 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1439 | Train Loss:  0.00501065194606781 | Train Accuracy:  0.8671428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1440 | Train Loss:  0.0059853696823120115 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1441 | Train Loss:  0.005652665495872498 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1442 | Train Loss:  0.005779876112937927 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1443 | Train Loss:  0.006087535619735717 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1444 | Train Loss:  0.005649495124816895 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1445 | Train Loss:  0.006987372636795044 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1446 | Train Loss:  0.008891051411628723 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1447 | Train Loss:  0.006260488629341126 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1448 | Train Loss:  0.007910455465316773 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  1449 | Train Loss:  0.00721731960773468 | Train Accuracy:  0.91 | Validation Accuracy:  0.5\n",
            "Iteration:  1450 | Train Loss:  0.006096258163452149 | Train Accuracy:  0.83 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1451 | Train Loss:  0.005770374536514283 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1452 | Train Loss:  0.006423738598823547 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1453 | Train Loss:  0.006028372645378113 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1454 | Train Loss:  0.005546862483024597 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1455 | Train Loss:  0.004928426742553711 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1456 | Train Loss:  0.005738449096679687 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  1457 | Train Loss:  0.0063099700212478635 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  1458 | Train Loss:  0.005772876143455505 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1459 | Train Loss:  0.006209909319877625 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1460 | Train Loss:  0.010347801446914672 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1461 | Train Loss:  0.006398817896842957 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1462 | Train Loss:  0.007778914570808411 | Train Accuracy:  0.7 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1463 | Train Loss:  0.009003846645355225 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1464 | Train Loss:  0.005186011791229248 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1465 | Train Loss:  0.0055650418996810915 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1466 | Train Loss:  0.006820630431175232 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1467 | Train Loss:  0.005170140266418457 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1468 | Train Loss:  0.005016734004020691 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1469 | Train Loss:  0.004242337048053741 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1470 | Train Loss:  0.0052291578054428104 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1471 | Train Loss:  0.005519177317619323 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1472 | Train Loss:  0.0053684192895889285 | Train Accuracy:  0.79 | Validation Accuracy:  0.52\n",
            "Iteration:  1473 | Train Loss:  0.005599461197853088 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1474 | Train Loss:  0.009154573678970337 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1475 | Train Loss:  0.006072459220886231 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1476 | Train Loss:  0.008411728143692017 | Train Accuracy:  0.74 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1477 | Train Loss:  0.00783286452293396 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1478 | Train Loss:  0.005483280420303344 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1479 | Train Loss:  0.0051997840404510495 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1480 | Train Loss:  0.005399903655052185 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1481 | Train Loss:  0.005020955801010132 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1482 | Train Loss:  0.004453652501106262 | Train Accuracy:  0.92 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1483 | Train Loss:  0.004051810801029205 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1484 | Train Loss:  0.0047246432304382325 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1485 | Train Loss:  0.005765916109085083 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1486 | Train Loss:  0.005022408366203308 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  1487 | Train Loss:  0.006038411259651184 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1488 | Train Loss:  0.009316055178642273 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1489 | Train Loss:  0.005376642346382141 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1490 | Train Loss:  0.008969563841819763 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  1491 | Train Loss:  0.007007476091384888 | Train Accuracy:  0.9042857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1492 | Train Loss:  0.005820119380950927 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1493 | Train Loss:  0.004842468202114105 | Train Accuracy:  0.92 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1494 | Train Loss:  0.0047129586338996885 | Train Accuracy:  0.9042857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1495 | Train Loss:  0.005014423131942749 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1496 | Train Loss:  0.003884783983230591 | Train Accuracy:  0.92 | Validation Accuracy:  0.5\n",
            "Iteration:  1497 | Train Loss:  0.0041688838601112365 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1498 | Train Loss:  0.004674427509307862 | Train Accuracy:  0.9042857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1499 | Train Loss:  0.006411803960800171 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1500 | Train Loss:  0.00484903872013092 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1501 | Train Loss:  0.006718856692314148 | Train Accuracy:  0.75 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1502 | Train Loss:  0.009890414476394653 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1503 | Train Loss:  0.005323370099067688 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  1504 | Train Loss:  0.009300237894058228 | Train Accuracy:  0.79 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  1505 | Train Loss:  0.006532578468322754 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1506 | Train Loss:  0.00602463960647583 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1507 | Train Loss:  0.0046447646617889405 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1508 | Train Loss:  0.004578868746757507 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1509 | Train Loss:  0.005183706879615784 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1510 | Train Loss:  0.0036651134490966798 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1511 | Train Loss:  0.004233905673027038 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1512 | Train Loss:  0.004467743933200836 | Train Accuracy:  0.9 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1513 | Train Loss:  0.006635319590568543 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1514 | Train Loss:  0.004846878051757812 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1515 | Train Loss:  0.006921756863594055 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  1516 | Train Loss:  0.010190744400024414 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1517 | Train Loss:  0.005215020179748535 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1518 | Train Loss:  0.009465212225914002 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1519 | Train Loss:  0.007057830095291138 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1520 | Train Loss:  0.00585505485534668 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1521 | Train Loss:  0.004885377585887909 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1522 | Train Loss:  0.004635780751705169 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1523 | Train Loss:  0.005304518342018128 | Train Accuracy:  0.91 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1524 | Train Loss:  0.0037856388092041018 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1525 | Train Loss:  0.00392420768737793 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1526 | Train Loss:  0.004625832438468933 | Train Accuracy:  0.91 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1527 | Train Loss:  0.005760709047317505 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1528 | Train Loss:  0.004986684024333954 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1529 | Train Loss:  0.005968165397644043 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  1530 | Train Loss:  0.009771428108215331 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1531 | Train Loss:  0.005215888619422912 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1532 | Train Loss:  0.008848849534988403 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  1533 | Train Loss:  0.008020832538604736 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1534 | Train Loss:  0.005092507004737854 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1535 | Train Loss:  0.005248484611511231 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  1536 | Train Loss:  0.0050111418962478635 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1537 | Train Loss:  0.005010073184967041 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1538 | Train Loss:  0.0040140548348426815 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1539 | Train Loss:  0.003472893238067627 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1540 | Train Loss:  0.004754912555217743 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1541 | Train Loss:  0.005022265911102295 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1542 | Train Loss:  0.005070626735687256 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1543 | Train Loss:  0.00526052713394165 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1544 | Train Loss:  0.00938641607761383 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1545 | Train Loss:  0.005445606708526611 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1546 | Train Loss:  0.008086705803871155 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1547 | Train Loss:  0.009041396379470825 | Train Accuracy:  0.93 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1548 | Train Loss:  0.004436588287353516 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1549 | Train Loss:  0.0054003697633743285 | Train Accuracy:  0.85 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1550 | Train Loss:  0.0057949495315551755 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1551 | Train Loss:  0.004752919375896454 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1552 | Train Loss:  0.004571579396724701 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1553 | Train Loss:  0.0031742757558822633 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1554 | Train Loss:  0.004945448338985443 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1555 | Train Loss:  0.004394923448562622 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1556 | Train Loss:  0.0050503617525100705 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1557 | Train Loss:  0.004710665047168732 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1558 | Train Loss:  0.008731431365013122 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1559 | Train Loss:  0.005956116318702698 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1560 | Train Loss:  0.0073007744550704955 | Train Accuracy:  0.68 | Validation Accuracy:  0.52\n",
            "Iteration:  1561 | Train Loss:  0.00953319251537323 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1562 | Train Loss:  0.003994278609752655 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1563 | Train Loss:  0.005309842824935913 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1564 | Train Loss:  0.006663213968276977 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1565 | Train Loss:  0.004204436242580414 | Train Accuracy:  0.82 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1566 | Train Loss:  0.00511155903339386 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1567 | Train Loss:  0.003116059899330139 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1568 | Train Loss:  0.004918436408042908 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1569 | Train Loss:  0.004154689908027649 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1570 | Train Loss:  0.00478715032339096 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1571 | Train Loss:  0.004481296837329864 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1572 | Train Loss:  0.0077346664667129516 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1573 | Train Loss:  0.006225873827934265 | Train Accuracy:  0.76 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1574 | Train Loss:  0.006087759137153625 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1575 | Train Loss:  0.009139373898506165 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1576 | Train Loss:  0.0037863308191299436 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1577 | Train Loss:  0.004673963189125061 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1578 | Train Loss:  0.007380715012550354 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1579 | Train Loss:  0.003598962128162384 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1580 | Train Loss:  0.005352375507354737 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1581 | Train Loss:  0.003344329595565796 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1582 | Train Loss:  0.004613317549228668 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1583 | Train Loss:  0.004114955961704254 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1584 | Train Loss:  0.004435416162014007 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1585 | Train Loss:  0.004387663900852204 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1586 | Train Loss:  0.0068673622608184815 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1587 | Train Loss:  0.005989357233047486 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  1588 | Train Loss:  0.0052277761697769164 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1589 | Train Loss:  0.0077781927585601806 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1590 | Train Loss:  0.003767033815383911 | Train Accuracy:  0.85 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1591 | Train Loss:  0.003793326914310455 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1592 | Train Loss:  0.0070384305715560916 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1593 | Train Loss:  0.003199225962162018 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1594 | Train Loss:  0.004764069020748139 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1595 | Train Loss:  0.0035288119316101074 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1596 | Train Loss:  0.0041738063097000126 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1597 | Train Loss:  0.003991149067878723 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1598 | Train Loss:  0.004196301400661469 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1599 | Train Loss:  0.004247545599937439 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  1600 | Train Loss:  0.00629480242729187 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1601 | Train Loss:  0.005211262106895447 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1602 | Train Loss:  0.004599406719207764 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1603 | Train Loss:  0.006272923350334168 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1604 | Train Loss:  0.003692731857299805 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1605 | Train Loss:  0.0030064654350280763 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1606 | Train Loss:  0.006075523495674133 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1607 | Train Loss:  0.003041662573814392 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1608 | Train Loss:  0.003952231109142303 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1609 | Train Loss:  0.00340010941028595 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1610 | Train Loss:  0.0039264106750488284 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1611 | Train Loss:  0.0037391433119773865 | Train Accuracy:  0.86 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1612 | Train Loss:  0.004131960570812225 | Train Accuracy:  0.84 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1613 | Train Loss:  0.004247208833694458 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1614 | Train Loss:  0.005969918966293335 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1615 | Train Loss:  0.004515087604522705 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1616 | Train Loss:  0.004235850274562835 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1617 | Train Loss:  0.0049802067875862124 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1618 | Train Loss:  0.0035005024075508116 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1619 | Train Loss:  0.0025267100334167483 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1620 | Train Loss:  0.004825529456138611 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1621 | Train Loss:  0.0030722272396087645 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1622 | Train Loss:  0.003157958984375 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1623 | Train Loss:  0.0031083741784095763 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1624 | Train Loss:  0.00397426187992096 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1625 | Train Loss:  0.0035859391093254088 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1626 | Train Loss:  0.004235394299030304 | Train Accuracy:  0.7985714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  1627 | Train Loss:  0.004628222286701202 | Train Accuracy:  0.9 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1628 | Train Loss:  0.005567166805267334 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1629 | Train Loss:  0.004184829294681549 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1630 | Train Loss:  0.003842712640762329 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1631 | Train Loss:  0.004076379835605621 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1632 | Train Loss:  0.0033627593517303466 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1633 | Train Loss:  0.0023506587743759156 | Train Accuracy:  0.91 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1634 | Train Loss:  0.004007680416107178 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1635 | Train Loss:  0.0032612010836601257 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1636 | Train Loss:  0.002914627194404602 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1637 | Train Loss:  0.0029325944185256956 | Train Accuracy:  0.8842857142857142 | Validation Accuracy:  0.54\n",
            "Iteration:  1638 | Train Loss:  0.004601280987262726 | Train Accuracy:  0.93 | Validation Accuracy:  0.5\n",
            "Iteration:  1639 | Train Loss:  0.0034626540541648865 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1640 | Train Loss:  0.004706731140613556 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1641 | Train Loss:  0.0053811299800872806 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1642 | Train Loss:  0.005259746313095092 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  1643 | Train Loss:  0.00452627032995224 | Train Accuracy:  0.89 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1644 | Train Loss:  0.003468635082244873 | Train Accuracy:  0.92 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1645 | Train Loss:  0.0038816848397254943 | Train Accuracy:  0.92 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1646 | Train Loss:  0.0032899585366249085 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1647 | Train Loss:  0.0028072860836982727 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1648 | Train Loss:  0.003700379133224487 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1649 | Train Loss:  0.0038202381134033203 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1650 | Train Loss:  0.0032861500978469847 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1651 | Train Loss:  0.0029418408870697022 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1652 | Train Loss:  0.005951626896858215 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1653 | Train Loss:  0.003373202383518219 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1654 | Train Loss:  0.0056104081869125366 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1655 | Train Loss:  0.006311982870101929 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1656 | Train Loss:  0.005208742618560791 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1657 | Train Loss:  0.0053029567003250126 | Train Accuracy:  0.91 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1658 | Train Loss:  0.0031902849674224853 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1659 | Train Loss:  0.0045440769195556644 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1660 | Train Loss:  0.0032222366333007815 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1661 | Train Loss:  0.003731017708778381 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1662 | Train Loss:  0.003713200092315674 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1663 | Train Loss:  0.004453727602958679 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1664 | Train Loss:  0.0041485270857810974 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1665 | Train Loss:  0.002864919900894165 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1666 | Train Loss:  0.007630403637886047 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1667 | Train Loss:  0.0034372875094413756 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1668 | Train Loss:  0.006529107689857483 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1669 | Train Loss:  0.00935598909854889 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1670 | Train Loss:  0.005039287805557251 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  1671 | Train Loss:  0.007381491065025329 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1672 | Train Loss:  0.003484550416469574 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1673 | Train Loss:  0.005574150681495666 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1674 | Train Loss:  0.0037179887294769287 | Train Accuracy:  0.86 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1675 | Train Loss:  0.004389228522777558 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1676 | Train Loss:  0.0045653656125068665 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1677 | Train Loss:  0.003745640218257904 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1678 | Train Loss:  0.0060802680253982545 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1679 | Train Loss:  0.0022135551273822786 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1680 | Train Loss:  0.009232382774353027 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1681 | Train Loss:  0.004973431825637817 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1682 | Train Loss:  0.006855049133300781 | Train Accuracy:  0.6014285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1683 | Train Loss:  0.01511040210723877 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  1684 | Train Loss:  0.005508855581283569 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1685 | Train Loss:  0.009016413688659668 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  1686 | Train Loss:  0.00754240095615387 | Train Accuracy:  0.94 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1687 | Train Loss:  0.004279787540435791 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1688 | Train Loss:  0.007192311882972717 | Train Accuracy:  0.93 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1689 | Train Loss:  0.002227306365966797 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1690 | Train Loss:  0.005746701955795288 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1691 | Train Loss:  0.002880875766277313 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1692 | Train Loss:  0.004881595969200134 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1693 | Train Loss:  0.0042596268653869625 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1694 | Train Loss:  0.004987067878246308 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  1695 | Train Loss:  0.011790159940719604 | Train Accuracy:  0.81 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1696 | Train Loss:  0.004077600836753845 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1697 | Train Loss:  0.016581348180770873 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1698 | Train Loss:  0.011907811164855958 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1699 | Train Loss:  0.005982558727264404 | Train Accuracy:  0.6014285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1700 | Train Loss:  0.01593355894088745 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1701 | Train Loss:  0.004762212634086609 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1702 | Train Loss:  0.009688309431076049 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1703 | Train Loss:  0.00525767982006073 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1704 | Train Loss:  0.003529861569404602 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1705 | Train Loss:  0.006864861845970154 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1706 | Train Loss:  0.003121780753135681 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1707 | Train Loss:  0.006130401492118836 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1708 | Train Loss:  0.00370217502117157 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1709 | Train Loss:  0.007996447086334228 | Train Accuracy:  0.93 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1710 | Train Loss:  0.006341421008110046 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  1711 | Train Loss:  0.006387452483177185 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1712 | Train Loss:  0.014427555799484253 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1713 | Train Loss:  0.005597111582756042 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1714 | Train Loss:  0.013783056735992432 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1715 | Train Loss:  0.019760735034942627 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1716 | Train Loss:  0.003993211984634399 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1717 | Train Loss:  0.012146768569946289 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1718 | Train Loss:  0.01141510009765625 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1719 | Train Loss:  0.005658410787582398 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1720 | Train Loss:  0.011140737533569336 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1721 | Train Loss:  0.0029445874691009523 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1722 | Train Loss:  0.005652725100517273 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1723 | Train Loss:  0.005154101848602295 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1724 | Train Loss:  0.004165658950805664 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1725 | Train Loss:  0.004932126104831696 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1726 | Train Loss:  0.005437803268432617 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1727 | Train Loss:  0.009587199687957763 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1728 | Train Loss:  0.003906969726085663 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1729 | Train Loss:  0.010159643888473511 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1730 | Train Loss:  0.006808342933654785 | Train Accuracy:  0.88 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1731 | Train Loss:  0.0029258528351783753 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  1732 | Train Loss:  0.013695982694625854 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1733 | Train Loss:  0.00418580561876297 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  1734 | Train Loss:  0.004654301404953003 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1735 | Train Loss:  0.007335653901100159 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1736 | Train Loss:  0.003742804825305939 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1737 | Train Loss:  0.0038462844491004944 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1738 | Train Loss:  0.0048215663433074955 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1739 | Train Loss:  0.00493500679731369 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  1740 | Train Loss:  0.005359029173851013 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1741 | Train Loss:  0.003834723234176636 | Train Accuracy:  0.8 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1742 | Train Loss:  0.004568844139575958 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1743 | Train Loss:  0.005538642406463623 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1744 | Train Loss:  0.0035152077674865724 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1745 | Train Loss:  0.0023600982129573823 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1746 | Train Loss:  0.0064429306983947755 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1747 | Train Loss:  0.00301420122385025 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1748 | Train Loss:  0.0030729448795318603 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  1749 | Train Loss:  0.0032537376880645754 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  1750 | Train Loss:  0.0036863651871681213 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1751 | Train Loss:  0.003538833558559418 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1752 | Train Loss:  0.003876279890537262 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1753 | Train Loss:  0.005712831616401673 | Train Accuracy:  0.79 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1754 | Train Loss:  0.006790825724601745 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1755 | Train Loss:  0.00390442430973053 | Train Accuracy:  0.74 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1756 | Train Loss:  0.005958836078643798 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1757 | Train Loss:  0.007712197899818421 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1758 | Train Loss:  0.003307199776172638 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1759 | Train Loss:  0.003203662037849426 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1760 | Train Loss:  0.008229835033416748 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1761 | Train Loss:  0.0028282809257507324 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1762 | Train Loss:  0.004019874334335327 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1763 | Train Loss:  0.003938053250312806 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1764 | Train Loss:  0.003342715799808502 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1765 | Train Loss:  0.0032244053483009337 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1766 | Train Loss:  0.003943881988525391 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1767 | Train Loss:  0.0048702841997146605 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1768 | Train Loss:  0.0058747994899749755 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1769 | Train Loss:  0.003856668174266815 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1770 | Train Loss:  0.004863990545272827 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1771 | Train Loss:  0.006848888993263244 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1772 | Train Loss:  0.0035086169838905333 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  1773 | Train Loss:  0.002579526901245117 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1774 | Train Loss:  0.007653982639312744 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  1775 | Train Loss:  0.0031107422709465028 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1776 | Train Loss:  0.003337829113006592 | Train Accuracy:  0.81 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1777 | Train Loss:  0.0037569853663444517 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1778 | Train Loss:  0.00370168149471283 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1779 | Train Loss:  0.003182559311389923 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1780 | Train Loss:  0.00405459851026535 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  1781 | Train Loss:  0.005787622928619385 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1782 | Train Loss:  0.005975517034530639 | Train Accuracy:  0.94 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1783 | Train Loss:  0.00358097106218338 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1784 | Train Loss:  0.0053473967313766475 | Train Accuracy:  0.73 | Validation Accuracy:  0.5\n",
            "Iteration:  1785 | Train Loss:  0.006619868278503418 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1786 | Train Loss:  0.0032246959209442138 | Train Accuracy:  0.89 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1787 | Train Loss:  0.002580386400222778 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1788 | Train Loss:  0.006839032173156738 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1789 | Train Loss:  0.00297970175743103 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1790 | Train Loss:  0.0031074398756027223 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1791 | Train Loss:  0.003287961184978485 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1792 | Train Loss:  0.0036448052525520323 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1793 | Train Loss:  0.003178987801074982 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1794 | Train Loss:  0.003938297927379608 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1795 | Train Loss:  0.006002439260482788 | Train Accuracy:  0.81 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1796 | Train Loss:  0.006187103986740113 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1797 | Train Loss:  0.003516870141029358 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1798 | Train Loss:  0.005606359839439392 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1799 | Train Loss:  0.006941401958465576 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1800 | Train Loss:  0.0031526854634284975 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1801 | Train Loss:  0.0026600226759910584 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1802 | Train Loss:  0.006935514211654663 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1803 | Train Loss:  0.0029043883085250856 | Train Accuracy:  0.9 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1804 | Train Loss:  0.003175458610057831 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1805 | Train Loss:  0.003265703320503235 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1806 | Train Loss:  0.0035423746705055235 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1807 | Train Loss:  0.0031161099672317506 | Train Accuracy:  0.82 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1808 | Train Loss:  0.00391006052494049 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1809 | Train Loss:  0.005954336524009705 | Train Accuracy:  0.81 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1810 | Train Loss:  0.006046946048736572 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1811 | Train Loss:  0.003468472957611084 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1812 | Train Loss:  0.005423208475112915 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1813 | Train Loss:  0.006896722912788391 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1814 | Train Loss:  0.0031498107314109802 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1815 | Train Loss:  0.002565180659294128 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1816 | Train Loss:  0.0069376111030578615 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1817 | Train Loss:  0.002958425283432007 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1818 | Train Loss:  0.0030694589018821715 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1819 | Train Loss:  0.0032787674665451048 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1820 | Train Loss:  0.0035882464051246645 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1821 | Train Loss:  0.003045667111873627 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1822 | Train Loss:  0.003945508301258087 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1823 | Train Loss:  0.006170541644096374 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1824 | Train Loss:  0.005937145352363587 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1825 | Train Loss:  0.003382491171360016 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1826 | Train Loss:  0.0054133528470993045 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1827 | Train Loss:  0.006632879376411438 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1828 | Train Loss:  0.00309223473072052 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1829 | Train Loss:  0.0024228888750076295 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1830 | Train Loss:  0.0066094291210174565 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1831 | Train Loss:  0.0030152079463005065 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1832 | Train Loss:  0.0028839582204818726 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1833 | Train Loss:  0.003142138123512268 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1834 | Train Loss:  0.003697200417518616 | Train Accuracy:  0.94 | Validation Accuracy:  0.5\n",
            "Iteration:  1835 | Train Loss:  0.0030751320719718932 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1836 | Train Loss:  0.003956671953201294 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1837 | Train Loss:  0.006534115076065063 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1838 | Train Loss:  0.005940335988998413 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1839 | Train Loss:  0.003307117223739624 | Train Accuracy:  0.75 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1840 | Train Loss:  0.005579730272293091 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1841 | Train Loss:  0.006583209037780762 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1842 | Train Loss:  0.003029702603816986 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1843 | Train Loss:  0.0023873206973075867 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1844 | Train Loss:  0.006498481035232544 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1845 | Train Loss:  0.002974931001663208 | Train Accuracy:  0.91 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1846 | Train Loss:  0.0028113219141960143 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1847 | Train Loss:  0.003048258423805237 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1848 | Train Loss:  0.0036700764298439026 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1849 | Train Loss:  0.003066215217113495 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1850 | Train Loss:  0.003913604021072388 | Train Accuracy:  0.72 | Validation Accuracy:  0.52\n",
            "Iteration:  1851 | Train Loss:  0.006638920307159424 | Train Accuracy:  0.7985714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1852 | Train Loss:  0.006025012135505676 | Train Accuracy:  0.94 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1853 | Train Loss:  0.0032668617367744446 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1854 | Train Loss:  0.005702393651008606 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1855 | Train Loss:  0.0065503746271133425 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1856 | Train Loss:  0.002954295575618744 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1857 | Train Loss:  0.002368863523006439 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1858 | Train Loss:  0.006355131864547729 | Train Accuracy:  0.88 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1859 | Train Loss:  0.002967967092990875 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1860 | Train Loss:  0.002725561559200287 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1861 | Train Loss:  0.002953613996505737 | Train Accuracy:  0.85 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1862 | Train Loss:  0.003645155727863312 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1863 | Train Loss:  0.0029933398962020876 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1864 | Train Loss:  0.0038707107305526733 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  1865 | Train Loss:  0.006672419905662537 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.54\n",
            "Iteration:  1866 | Train Loss:  0.006057878136634827 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1867 | Train Loss:  0.003226342499256134 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1868 | Train Loss:  0.00578030526638031 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1869 | Train Loss:  0.006865127682685852 | Train Accuracy:  0.9 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1870 | Train Loss:  0.0029398852586746214 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1871 | Train Loss:  0.002400730103254318 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1872 | Train Loss:  0.006665911674499512 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1873 | Train Loss:  0.0029921627044677736 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1874 | Train Loss:  0.002772960364818573 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1875 | Train Loss:  0.00307207316160202 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1876 | Train Loss:  0.0036111631989479065 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1877 | Train Loss:  0.002914144992828369 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1878 | Train Loss:  0.0038960495591163634 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1879 | Train Loss:  0.006539344787597656 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1880 | Train Loss:  0.005875055193901062 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1881 | Train Loss:  0.0031961947679519653 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1882 | Train Loss:  0.005560685992240906 | Train Accuracy:  0.7 | Validation Accuracy:  0.5\n",
            "Iteration:  1883 | Train Loss:  0.0069764131307601925 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1884 | Train Loss:  0.00298514723777771 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1885 | Train Loss:  0.0023523329198360445 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1886 | Train Loss:  0.006955586075782776 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1887 | Train Loss:  0.003073088824748993 | Train Accuracy:  0.91 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1888 | Train Loss:  0.002761205434799194 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1889 | Train Loss:  0.0031389787793159483 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1890 | Train Loss:  0.0036693039536476136 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1891 | Train Loss:  0.0029002392292022706 | Train Accuracy:  0.81 | Validation Accuracy:  0.54\n",
            "Iteration:  1892 | Train Loss:  0.0038872551918029785 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  1893 | Train Loss:  0.006845735311508179 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.54\n",
            "Iteration:  1894 | Train Loss:  0.005969174504280091 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1895 | Train Loss:  0.0031722763180732725 | Train Accuracy:  0.73 | Validation Accuracy:  0.52\n",
            "Iteration:  1896 | Train Loss:  0.005875605344772339 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1897 | Train Loss:  0.006877397298812866 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1898 | Train Loss:  0.002903846800327301 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1899 | Train Loss:  0.0023224659264087675 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1900 | Train Loss:  0.006660876274108887 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1901 | Train Loss:  0.003157484531402588 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1902 | Train Loss:  0.0025980883836746217 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1903 | Train Loss:  0.0031012699007987978 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1904 | Train Loss:  0.0038207980990409853 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1905 | Train Loss:  0.002893962562084198 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1906 | Train Loss:  0.0039291056990623475 | Train Accuracy:  0.7 | Validation Accuracy:  0.52\n",
            "Iteration:  1907 | Train Loss:  0.007022500038146973 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  1908 | Train Loss:  0.006002189517021179 | Train Accuracy:  0.94 | Validation Accuracy:  0.5\n",
            "Iteration:  1909 | Train Loss:  0.0031085127592086793 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  1910 | Train Loss:  0.0057936906814575195 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1911 | Train Loss:  0.006976008415222168 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1912 | Train Loss:  0.0029210251569747924 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1913 | Train Loss:  0.002274504452943802 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1914 | Train Loss:  0.006863182783126831 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1915 | Train Loss:  0.003310989439487457 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1916 | Train Loss:  0.0025279852747917175 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1917 | Train Loss:  0.0031692087650299072 | Train Accuracy:  0.82 | Validation Accuracy:  0.52\n",
            "Iteration:  1918 | Train Loss:  0.003993640542030334 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1919 | Train Loss:  0.002869642972946167 | Train Accuracy:  0.8 | Validation Accuracy:  0.54\n",
            "Iteration:  1920 | Train Loss:  0.003988457024097443 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1921 | Train Loss:  0.007368237972259522 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  1922 | Train Loss:  0.006009526252746582 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1923 | Train Loss:  0.003072260618209839 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1924 | Train Loss:  0.006005251407623291 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1925 | Train Loss:  0.007020957469940185 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1926 | Train Loss:  0.0028994202613830565 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1927 | Train Loss:  0.002246234565973282 | Train Accuracy:  0.77 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1928 | Train Loss:  0.006920374035835266 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1929 | Train Loss:  0.003401152789592743 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1930 | Train Loss:  0.0024569907784461973 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1931 | Train Loss:  0.0031602728366851808 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1932 | Train Loss:  0.004180363118648529 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1933 | Train Loss:  0.0029133376479148865 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  1934 | Train Loss:  0.003977981805801392 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1935 | Train Loss:  0.007708553075790405 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1936 | Train Loss:  0.006220722198486328 | Train Accuracy:  0.94 | Validation Accuracy:  0.5\n",
            "Iteration:  1937 | Train Loss:  0.0030646601319313047 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1938 | Train Loss:  0.006309900879859925 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1939 | Train Loss:  0.007409493327140808 | Train Accuracy:  0.89 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1940 | Train Loss:  0.002885846495628357 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1941 | Train Loss:  0.00231900155544281 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1942 | Train Loss:  0.007120063900947571 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1943 | Train Loss:  0.003491002023220062 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1944 | Train Loss:  0.002436784356832504 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1945 | Train Loss:  0.00326203316450119 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1946 | Train Loss:  0.0042314758896827695 | Train Accuracy:  0.93 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1947 | Train Loss:  0.0028664687275886534 | Train Accuracy:  0.8 | Validation Accuracy:  0.54\n",
            "Iteration:  1948 | Train Loss:  0.004008040726184845 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1949 | Train Loss:  0.007791630029678345 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1950 | Train Loss:  0.006207954883575439 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1951 | Train Loss:  0.0030632483959197997 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1952 | Train Loss:  0.006308128237724304 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1953 | Train Loss:  0.007765048146247864 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1954 | Train Loss:  0.0029409271478652954 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1955 | Train Loss:  0.0023709671199321747 | Train Accuracy:  0.75 | Validation Accuracy:  0.52\n",
            "Iteration:  1956 | Train Loss:  0.007617976665496826 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1957 | Train Loss:  0.0036081719398498536 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1958 | Train Loss:  0.0024913100898265837 | Train Accuracy:  0.79 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1959 | Train Loss:  0.0033898207545280455 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1960 | Train Loss:  0.004421465694904327 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1961 | Train Loss:  0.002934049367904663 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  1962 | Train Loss:  0.003988624811172486 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1963 | Train Loss:  0.008218891620635986 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1964 | Train Loss:  0.0066769134998321536 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1965 | Train Loss:  0.0030901196599006655 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1966 | Train Loss:  0.006853517889976501 | Train Accuracy:  0.67 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1967 | Train Loss:  0.00851111650466919 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  1968 | Train Loss:  0.002883739173412323 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1969 | Train Loss:  0.00257938951253891 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1970 | Train Loss:  0.008086071014404297 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1971 | Train Loss:  0.0036089375615119936 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1972 | Train Loss:  0.0025412848591804503 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1973 | Train Loss:  0.0035903140902519225 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1974 | Train Loss:  0.004333525002002716 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1975 | Train Loss:  0.002867404222488403 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1976 | Train Loss:  0.003987034857273102 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1977 | Train Loss:  0.00799394965171814 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1978 | Train Loss:  0.006662501692771911 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1979 | Train Loss:  0.003219926357269287 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1980 | Train Loss:  0.00685926616191864 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1981 | Train Loss:  0.009574193358421326 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1982 | Train Loss:  0.0031033092737197876 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1983 | Train Loss:  0.002761125862598419 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1984 | Train Loss:  0.009495762586593627 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1985 | Train Loss:  0.003883807361125946 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1986 | Train Loss:  0.0027177008986473085 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1987 | Train Loss:  0.004123899042606354 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1988 | Train Loss:  0.004628302454948425 | Train Accuracy:  0.93 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1989 | Train Loss:  0.0028492480516433714 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  1990 | Train Loss:  0.004088453352451325 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1991 | Train Loss:  0.008435453176498414 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1992 | Train Loss:  0.0070464956760406495 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1993 | Train Loss:  0.0032792985439300537 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1994 | Train Loss:  0.007209755182266235 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1995 | Train Loss:  0.010007206201553345 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1996 | Train Loss:  0.0031807821989059447 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1997 | Train Loss:  0.0027516618371009826 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1998 | Train Loss:  0.00965512216091156 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1999 | Train Loss:  0.0044735163450241085 | Train Accuracy:  0.91 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2000 | Train Loss:  0.0024778690934181215 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2001 | Train Loss:  0.004513110816478729 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2002 | Train Loss:  0.005399699211120605 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  2003 | Train Loss:  0.0028291192650794984 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2004 | Train Loss:  0.004405269920825958 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2005 | Train Loss:  0.009385547637939452 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2006 | Train Loss:  0.007108991742134094 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2007 | Train Loss:  0.0032218682765960695 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  2008 | Train Loss:  0.007349520325660706 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  2009 | Train Loss:  0.010571516752243042 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2010 | Train Loss:  0.003595248758792877 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2011 | Train Loss:  0.002673853039741516 | Train Accuracy:  0.71 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2012 | Train Loss:  0.010715540647506714 | Train Accuracy:  0.81 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2013 | Train Loss:  0.0054150927066802974 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2014 | Train Loss:  0.002304638624191284 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2015 | Train Loss:  0.004966440200805664 | Train Accuracy:  0.74 | Validation Accuracy:  0.52\n",
            "Iteration:  2016 | Train Loss:  0.006909132599830627 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2017 | Train Loss:  0.003185723125934601 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2018 | Train Loss:  0.004699144661426544 | Train Accuracy:  0.61 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2019 | Train Loss:  0.012668670415878295 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2020 | Train Loss:  0.010242801904678345 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2021 | Train Loss:  0.003281439244747162 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  2022 | Train Loss:  0.010637691020965576 | Train Accuracy:  0.6128571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2023 | Train Loss:  0.014282759428024292 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2024 | Train Loss:  0.003247712254524231 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2025 | Train Loss:  0.004009620249271393 | Train Accuracy:  0.6757142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2026 | Train Loss:  0.01236375331878662 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2027 | Train Loss:  0.005826008319854736 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2028 | Train Loss:  0.0024447612464427947 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2029 | Train Loss:  0.005441535115242004 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2030 | Train Loss:  0.007634266018867492 | Train Accuracy:  0.92 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2031 | Train Loss:  0.0036022964119911192 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2032 | Train Loss:  0.004743379950523377 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2033 | Train Loss:  0.013960353136062621 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2034 | Train Loss:  0.012895535230636596 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2035 | Train Loss:  0.003904092013835907 | Train Accuracy:  0.63 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2036 | Train Loss:  0.011710660457611084 | Train Accuracy:  0.5871428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  2037 | Train Loss:  0.020172977447509767 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2038 | Train Loss:  0.004483021199703217 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  2039 | Train Loss:  0.004943322837352753 | Train Accuracy:  0.6185714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2040 | Train Loss:  0.018124629259109497 | Train Accuracy:  0.74 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2041 | Train Loss:  0.00927564024925232 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2042 | Train Loss:  0.0024737949669361116 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2043 | Train Loss:  0.007941015362739563 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2044 | Train Loss:  0.011673868894577026 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2045 | Train Loss:  0.004960523843765259 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2046 | Train Loss:  0.005397485494613647 | Train Accuracy:  0.5757142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2047 | Train Loss:  0.017735726833343506 | Train Accuracy:  0.5871428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  2048 | Train Loss:  0.02258491039276123 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2049 | Train Loss:  0.011214196681976318 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2050 | Train Loss:  0.010686712265014648 | Train Accuracy:  0.5528571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2051 | Train Loss:  0.036791014671325686 | Train Accuracy:  0.6014285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2052 | Train Loss:  0.02441746711730957 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2053 | Train Loss:  0.002209659218788147 | Train Accuracy:  0.58 | Validation Accuracy:  0.5\n",
            "Iteration:  2054 | Train Loss:  0.023473539352416993 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2055 | Train Loss:  0.028937814235687257 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2056 | Train Loss:  0.020029773712158205 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  2057 | Train Loss:  0.004133726954460144 | Train Accuracy:  0.5557142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2058 | Train Loss:  0.02095848321914673 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2059 | Train Loss:  0.04560237407684326 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2060 | Train Loss:  0.02209919214248657 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2061 | Train Loss:  0.006647827625274658 | Train Accuracy:  0.5028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2062 | Train Loss:  0.0331261682510376 | Train Accuracy:  0.4957142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2063 | Train Loss:  0.0396509861946106 | Train Accuracy:  0.49714285714285716 | Validation Accuracy:  0.5\n",
            "Iteration:  2064 | Train Loss:  0.03181362390518189 | Train Accuracy:  0.55 | Validation Accuracy:  0.5\n",
            "Iteration:  2065 | Train Loss:  0.0162955904006958 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2066 | Train Loss:  0.007548670172691345 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2067 | Train Loss:  0.01696298360824585 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2068 | Train Loss:  0.02237286329269409 | Train Accuracy:  0.5471428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  2069 | Train Loss:  0.020752460956573487 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2070 | Train Loss:  0.010224761962890625 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  2071 | Train Loss:  0.009828706383705138 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2072 | Train Loss:  0.01520167350769043 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2073 | Train Loss:  0.012293072938919068 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2074 | Train Loss:  0.008164787292480468 | Train Accuracy:  0.8842857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2075 | Train Loss:  0.007813909649848938 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2076 | Train Loss:  0.008615382313728333 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2077 | Train Loss:  0.00799800932407379 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2078 | Train Loss:  0.007231743335723877 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  2079 | Train Loss:  0.006231997013092041 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2080 | Train Loss:  0.007127980589866638 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2081 | Train Loss:  0.00587128221988678 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2082 | Train Loss:  0.005961386561393738 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2083 | Train Loss:  0.006357685923576355 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2084 | Train Loss:  0.007678735852241516 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2085 | Train Loss:  0.006700613498687744 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2086 | Train Loss:  0.005705130696296692 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2087 | Train Loss:  0.010116711854934693 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  2088 | Train Loss:  0.009734105467796326 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  2089 | Train Loss:  0.007001248002052307 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2090 | Train Loss:  0.011002730131149292 | Train Accuracy:  0.6214285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2091 | Train Loss:  0.016153508424758913 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2092 | Train Loss:  0.008953367471694946 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2093 | Train Loss:  0.005915274024009705 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2094 | Train Loss:  0.012104294300079345 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2095 | Train Loss:  0.013411473035812378 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2096 | Train Loss:  0.008563827276229858 | Train Accuracy:  0.87 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2097 | Train Loss:  0.006237632036209107 | Train Accuracy:  0.67 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2098 | Train Loss:  0.012184351682662964 | Train Accuracy:  0.6328571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2099 | Train Loss:  0.014594045877456665 | Train Accuracy:  0.82 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2100 | Train Loss:  0.007867094278335571 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2101 | Train Loss:  0.008392211794853211 | Train Accuracy:  0.68 | Validation Accuracy:  0.5\n",
            "Iteration:  2102 | Train Loss:  0.014211277961730957 | Train Accuracy:  0.79 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2103 | Train Loss:  0.011880621910095215 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2104 | Train Loss:  0.007542237043380738 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2105 | Train Loss:  0.012493350505828858 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  2106 | Train Loss:  0.011214818954467774 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2107 | Train Loss:  0.007467859387397766 | Train Accuracy:  0.86 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2108 | Train Loss:  0.006776024103164673 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2109 | Train Loss:  0.009640092253684998 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2110 | Train Loss:  0.00998960316181183 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2111 | Train Loss:  0.007996288537979125 | Train Accuracy:  0.8842857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  2112 | Train Loss:  0.007033073306083679 | Train Accuracy:  0.75 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2113 | Train Loss:  0.010334272384643555 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  2114 | Train Loss:  0.00864368438720703 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2115 | Train Loss:  0.006441962718963623 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2116 | Train Loss:  0.008841075897216798 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2117 | Train Loss:  0.009421834349632263 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2118 | Train Loss:  0.007497934103012085 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2119 | Train Loss:  0.008614676594734192 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  2120 | Train Loss:  0.0076386725902557375 | Train Accuracy:  0.92 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2121 | Train Loss:  0.006218092441558838 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2122 | Train Loss:  0.006714463829994201 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2123 | Train Loss:  0.007659972906112671 | Train Accuracy:  0.79 | Validation Accuracy:  0.5\n",
            "Iteration:  2124 | Train Loss:  0.00736204206943512 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2125 | Train Loss:  0.00639355480670929 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2126 | Train Loss:  0.007275893688201905 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2127 | Train Loss:  0.009011119604110718 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2128 | Train Loss:  0.006752672791481018 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2129 | Train Loss:  0.006803020238876343 | Train Accuracy:  0.87 | Validation Accuracy:  0.52\n",
            "Iteration:  2130 | Train Loss:  0.009216152429580689 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2131 | Train Loss:  0.008487113118171692 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2132 | Train Loss:  0.00749981939792633 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2133 | Train Loss:  0.010238523483276368 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2134 | Train Loss:  0.00788108229637146 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2135 | Train Loss:  0.0059489023685455325 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2136 | Train Loss:  0.007289518713951111 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2137 | Train Loss:  0.008807348012924194 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  2138 | Train Loss:  0.007618901729583741 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2139 | Train Loss:  0.006056257486343384 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2140 | Train Loss:  0.007809824347496033 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2141 | Train Loss:  0.010040029287338256 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  2142 | Train Loss:  0.0069841712713241575 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2143 | Train Loss:  0.0067468094825744625 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2144 | Train Loss:  0.009771385192871095 | Train Accuracy:  0.9 | Validation Accuracy:  0.52\n",
            "Iteration:  2145 | Train Loss:  0.00901032567024231 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2146 | Train Loss:  0.0071929353475570675 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2147 | Train Loss:  0.010079300403594971 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2148 | Train Loss:  0.008078296780586242 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2149 | Train Loss:  0.006091398000717163 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2150 | Train Loss:  0.006827442049980164 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2151 | Train Loss:  0.008610060214996338 | Train Accuracy:  0.75 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2152 | Train Loss:  0.007725982069969177 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2153 | Train Loss:  0.006122044920921325 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2154 | Train Loss:  0.0073554497957229615 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2155 | Train Loss:  0.009673853516578674 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2156 | Train Loss:  0.006965261697769165 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2157 | Train Loss:  0.0064768165349960325 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2158 | Train Loss:  0.00925354242324829 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2159 | Train Loss:  0.008711841702461243 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  2160 | Train Loss:  0.007119805216789245 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2161 | Train Loss:  0.009787372350692748 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2162 | Train Loss:  0.007631528377532959 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2163 | Train Loss:  0.005930074453353882 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2164 | Train Loss:  0.006765648722648621 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2165 | Train Loss:  0.008440579175949097 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2166 | Train Loss:  0.007362782955169678 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2167 | Train Loss:  0.005849460363388062 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2168 | Train Loss:  0.007344799637794494 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2169 | Train Loss:  0.009582810997962952 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2170 | Train Loss:  0.006714490652084351 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2171 | Train Loss:  0.0064444899559021 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2172 | Train Loss:  0.009220201969146729 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2173 | Train Loss:  0.008543096780776978 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2174 | Train Loss:  0.007025146484375 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2175 | Train Loss:  0.009959675073623657 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2176 | Train Loss:  0.007508153319358826 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2177 | Train Loss:  0.005847309231758118 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2178 | Train Loss:  0.006711755990982056 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2179 | Train Loss:  0.00858981192111969 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2180 | Train Loss:  0.007232846021652222 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2181 | Train Loss:  0.005602514147758484 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2182 | Train Loss:  0.007300347089767456 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2183 | Train Loss:  0.009760891199111938 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2184 | Train Loss:  0.006355056166648864 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2185 | Train Loss:  0.0060739278793334964 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2186 | Train Loss:  0.009420928359031678 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2187 | Train Loss:  0.00825659155845642 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2188 | Train Loss:  0.006638799905776978 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2189 | Train Loss:  0.01059659719467163 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  2190 | Train Loss:  0.007807719707489014 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2191 | Train Loss:  0.0054772084951400755 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2192 | Train Loss:  0.006268042922019958 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2193 | Train Loss:  0.00918485164642334 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  2194 | Train Loss:  0.007712565660476685 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2195 | Train Loss:  0.00530022144317627 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2196 | Train Loss:  0.007661727666854859 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2197 | Train Loss:  0.010693154335021972 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2198 | Train Loss:  0.006262155175209045 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2199 | Train Loss:  0.005963364243507385 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2200 | Train Loss:  0.010425679683685303 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2201 | Train Loss:  0.008117365837097167 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2202 | Train Loss:  0.006617723703384399 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2203 | Train Loss:  0.011762198209762573 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2204 | Train Loss:  0.008186603784561158 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2205 | Train Loss:  0.004999808967113495 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2206 | Train Loss:  0.006740865111351013 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2207 | Train Loss:  0.009878919124603272 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2208 | Train Loss:  0.007495090365409851 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2209 | Train Loss:  0.004947914481163025 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2210 | Train Loss:  0.008360134959220887 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  2211 | Train Loss:  0.01144242763519287 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  2212 | Train Loss:  0.006710248589515686 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2213 | Train Loss:  0.0062167060375213625 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  2214 | Train Loss:  0.010224964618682861 | Train Accuracy:  0.87 | Validation Accuracy:  0.5\n",
            "Iteration:  2215 | Train Loss:  0.008943469524383544 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2216 | Train Loss:  0.00635252058506012 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2217 | Train Loss:  0.009876689314842224 | Train Accuracy:  0.7985714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2218 | Train Loss:  0.008120177388191223 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2219 | Train Loss:  0.006215867400169372 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  2220 | Train Loss:  0.005618005394935608 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2221 | Train Loss:  0.008209424614906312 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2222 | Train Loss:  0.007964453697204589 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2223 | Train Loss:  0.0060756725072860715 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2224 | Train Loss:  0.0063152223825454715 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2225 | Train Loss:  0.009596092104911804 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2226 | Train Loss:  0.006835048794746399 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2227 | Train Loss:  0.005290733575820923 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2228 | Train Loss:  0.008634499311447143 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2229 | Train Loss:  0.007696630954742431 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2230 | Train Loss:  0.006366478204727173 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2231 | Train Loss:  0.009089961051940917 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2232 | Train Loss:  0.0070213860273361205 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2233 | Train Loss:  0.00489289790391922 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2234 | Train Loss:  0.006078271269798279 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2235 | Train Loss:  0.008070737719535828 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2236 | Train Loss:  0.0065274500846862794 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2237 | Train Loss:  0.004823704659938813 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2238 | Train Loss:  0.007463610768318176 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2239 | Train Loss:  0.009240325093269348 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2240 | Train Loss:  0.005459960699081421 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2241 | Train Loss:  0.006355102658271789 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2242 | Train Loss:  0.009824893474578857 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2243 | Train Loss:  0.006723484992980957 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2244 | Train Loss:  0.0067244553565979 | Train Accuracy:  0.74 | Validation Accuracy:  0.5\n",
            "Iteration:  2245 | Train Loss:  0.011586005687713624 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2246 | Train Loss:  0.007404888868331909 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2247 | Train Loss:  0.004584920108318329 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2248 | Train Loss:  0.0073035812377929684 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2249 | Train Loss:  0.009354205131530761 | Train Accuracy:  0.7928571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2250 | Train Loss:  0.006589992642402649 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2251 | Train Loss:  0.004544743597507477 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2252 | Train Loss:  0.008215568661689758 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2253 | Train Loss:  0.010352864265441894 | Train Accuracy:  0.89 | Validation Accuracy:  0.5\n",
            "Iteration:  2254 | Train Loss:  0.005731531381607056 | Train Accuracy:  0.91 | Validation Accuracy:  0.52\n",
            "Iteration:  2255 | Train Loss:  0.006364085674285889 | Train Accuracy:  0.8214285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2256 | Train Loss:  0.010550336837768555 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2257 | Train Loss:  0.007363744378089905 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2258 | Train Loss:  0.006317392587661743 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2259 | Train Loss:  0.011405242681503296 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2260 | Train Loss:  0.00799809694290161 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2261 | Train Loss:  0.004959828555583954 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  2262 | Train Loss:  0.0063745051622390745 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  2263 | Train Loss:  0.009140527844429015 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2264 | Train Loss:  0.007267229557037354 | Train Accuracy:  0.93 | Validation Accuracy:  0.52\n",
            "Iteration:  2265 | Train Loss:  0.004854909479618073 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  2266 | Train Loss:  0.007159938216209412 | Train Accuracy:  0.74 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2267 | Train Loss:  0.010215442180633545 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2268 | Train Loss:  0.006491404771804809 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2269 | Train Loss:  0.005513155460357666 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2270 | Train Loss:  0.009580197930335998 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2271 | Train Loss:  0.0076175123453140255 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2272 | Train Loss:  0.006100915074348449 | Train Accuracy:  0.78 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2273 | Train Loss:  0.009455683827400207 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2274 | Train Loss:  0.007468417286872864 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2275 | Train Loss:  0.005202099084854126 | Train Accuracy:  0.83 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2276 | Train Loss:  0.005534887909889221 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2277 | Train Loss:  0.007964347004890442 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2278 | Train Loss:  0.007080830335617065 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2279 | Train Loss:  0.00510524570941925 | Train Accuracy:  0.8671428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2280 | Train Loss:  0.006339364051818848 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2281 | Train Loss:  0.009271520376205444 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2282 | Train Loss:  0.006539625525474549 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2283 | Train Loss:  0.0052147024869918825 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2284 | Train Loss:  0.008663432598114014 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2285 | Train Loss:  0.007197920083999634 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2286 | Train Loss:  0.006050711870193482 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2287 | Train Loss:  0.008504723906517029 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2288 | Train Loss:  0.006944779753684998 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  2289 | Train Loss:  0.005132814049720764 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2290 | Train Loss:  0.00527107298374176 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2291 | Train Loss:  0.007275260686874389 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  2292 | Train Loss:  0.006647085547447204 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2293 | Train Loss:  0.005007886290550232 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2294 | Train Loss:  0.0060070836544036865 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2295 | Train Loss:  0.008595995306968689 | Train Accuracy:  0.86 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2296 | Train Loss:  0.0062772136926651 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2297 | Train Loss:  0.005146158337593079 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2298 | Train Loss:  0.008194321393966674 | Train Accuracy:  0.91 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2299 | Train Loss:  0.006789908409118652 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2300 | Train Loss:  0.005978361368179321 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2301 | Train Loss:  0.008114213347434998 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  2302 | Train Loss:  0.006547009944915772 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2303 | Train Loss:  0.0049821209907531736 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2304 | Train Loss:  0.005195478200912476 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2305 | Train Loss:  0.0069577634334564206 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  2306 | Train Loss:  0.0063132643699646 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2307 | Train Loss:  0.004800000786781311 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2308 | Train Loss:  0.005921518802642823 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2309 | Train Loss:  0.008253371715545655 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2310 | Train Loss:  0.006005822420120239 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2311 | Train Loss:  0.00513184666633606 | Train Accuracy:  0.88 | Validation Accuracy:  0.52\n",
            "Iteration:  2312 | Train Loss:  0.008064716458320617 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2313 | Train Loss:  0.006516239643096924 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2314 | Train Loss:  0.005928924083709717 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2315 | Train Loss:  0.008109075427055358 | Train Accuracy:  0.87 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2316 | Train Loss:  0.006344221234321594 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2317 | Train Loss:  0.004817234873771667 | Train Accuracy:  0.84 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2318 | Train Loss:  0.005236269235610962 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2319 | Train Loss:  0.006894877552986145 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  2320 | Train Loss:  0.006086368560791016 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2321 | Train Loss:  0.00455940842628479 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2322 | Train Loss:  0.006004799604415894 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2323 | Train Loss:  0.00808793306350708 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2324 | Train Loss:  0.005732420682907104 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2325 | Train Loss:  0.005196933150291443 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2326 | Train Loss:  0.008117765784263611 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2327 | Train Loss:  0.006173173785209656 | Train Accuracy:  0.92 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2328 | Train Loss:  0.005947463512420655 | Train Accuracy:  0.81 | Validation Accuracy:  0.54\n",
            "Iteration:  2329 | Train Loss:  0.00832358717918396 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2330 | Train Loss:  0.0061455339193344114 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2331 | Train Loss:  0.004621897041797638 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2332 | Train Loss:  0.005394169688224792 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2333 | Train Loss:  0.006897575259208679 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2334 | Train Loss:  0.005765533447265625 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  2335 | Train Loss:  0.004275360405445099 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  2336 | Train Loss:  0.006188513040542603 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2337 | Train Loss:  0.008042494058609009 | Train Accuracy:  0.9 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2338 | Train Loss:  0.005460805296897888 | Train Accuracy:  0.94 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2339 | Train Loss:  0.005316566228866577 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2340 | Train Loss:  0.008258411288261413 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2341 | Train Loss:  0.005950529575347901 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2342 | Train Loss:  0.005924579501152038 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2343 | Train Loss:  0.008739414215087891 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2344 | Train Loss:  0.006124882698059082 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2345 | Train Loss:  0.004449053704738617 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2346 | Train Loss:  0.0055805319547653194 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2347 | Train Loss:  0.007032164931297302 | Train Accuracy:  0.82 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2348 | Train Loss:  0.005633034706115723 | Train Accuracy:  0.94 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2349 | Train Loss:  0.004107179939746857 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2350 | Train Loss:  0.0063042551279068 | Train Accuracy:  0.78 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2351 | Train Loss:  0.008177783489227295 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2352 | Train Loss:  0.0054095077514648435 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2353 | Train Loss:  0.005331588983535767 | Train Accuracy:  0.87 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2354 | Train Loss:  0.008346014618873597 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2355 | Train Loss:  0.00584592878818512 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  2356 | Train Loss:  0.005885688662528992 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2357 | Train Loss:  0.008783723711967468 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2358 | Train Loss:  0.006060307025909424 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2359 | Train Loss:  0.004374550282955169 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2360 | Train Loss:  0.005568188428878784 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2361 | Train Loss:  0.006994133591651916 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2362 | Train Loss:  0.005567898154258728 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2363 | Train Loss:  0.0040213847160339355 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2364 | Train Loss:  0.006268552541732788 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2365 | Train Loss:  0.008218697905540466 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  2366 | Train Loss:  0.005399239063262939 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  2367 | Train Loss:  0.005277419090270996 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2368 | Train Loss:  0.008431884050369263 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2369 | Train Loss:  0.005902242064476013 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2370 | Train Loss:  0.005790033936500549 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2371 | Train Loss:  0.00865199327468872 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2372 | Train Loss:  0.0060596466064453125 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2373 | Train Loss:  0.00437316507101059 | Train Accuracy:  0.82 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2374 | Train Loss:  0.005404540300369263 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2375 | Train Loss:  0.00686764657497406 | Train Accuracy:  0.82 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2376 | Train Loss:  0.005564779639244079 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2377 | Train Loss:  0.003980596661567688 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2378 | Train Loss:  0.006118924617767334 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2379 | Train Loss:  0.00811541736125946 | Train Accuracy:  0.9 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2380 | Train Loss:  0.005393670797348022 | Train Accuracy:  0.94 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2381 | Train Loss:  0.005159654021263123 | Train Accuracy:  0.87 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2382 | Train Loss:  0.008333633542060853 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2383 | Train Loss:  0.0057772380113601685 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  2384 | Train Loss:  0.005754884481430054 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2385 | Train Loss:  0.008307214379310607 | Train Accuracy:  0.88 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2386 | Train Loss:  0.005868964195251465 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2387 | Train Loss:  0.0043265831470489504 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2388 | Train Loss:  0.005232581496238708 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2389 | Train Loss:  0.006606065630912781 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2390 | Train Loss:  0.005433973073959351 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2391 | Train Loss:  0.003929008543491363 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  2392 | Train Loss:  0.005903866291046143 | Train Accuracy:  0.79 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2393 | Train Loss:  0.007898332476615906 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2394 | Train Loss:  0.005353794693946839 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2395 | Train Loss:  0.005029356479644776 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2396 | Train Loss:  0.008112523555755615 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2397 | Train Loss:  0.005656225681304932 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.46\n",
            "Iteration:  2398 | Train Loss:  0.005669527053833008 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2399 | Train Loss:  0.008186885714530944 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2400 | Train Loss:  0.005777031183242798 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2401 | Train Loss:  0.0042572212219238285 | Train Accuracy:  0.83 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2402 | Train Loss:  0.0051516669988632205 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2403 | Train Loss:  0.006498723030090332 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2404 | Train Loss:  0.005350625514984131 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2405 | Train Loss:  0.0038643455505371093 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2406 | Train Loss:  0.005812064409255981 | Train Accuracy:  0.79 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2407 | Train Loss:  0.007828202247619629 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2408 | Train Loss:  0.005326312184333801 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2409 | Train Loss:  0.004962430596351624 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2410 | Train Loss:  0.008042370676994324 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2411 | Train Loss:  0.005556113719940185 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  2412 | Train Loss:  0.005608352422714233 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2413 | Train Loss:  0.008048908710479736 | Train Accuracy:  0.8842857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  2414 | Train Loss:  0.005700356960296631 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2415 | Train Loss:  0.004229519963264466 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2416 | Train Loss:  0.005003321766853332 | Train Accuracy:  0.73 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2417 | Train Loss:  0.006342875957489014 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2418 | Train Loss:  0.005311667323112488 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2419 | Train Loss:  0.0038339993357658386 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2420 | Train Loss:  0.005639970302581787 | Train Accuracy:  0.7928571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2421 | Train Loss:  0.0076900869607925415 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2422 | Train Loss:  0.0053235703706741334 | Train Accuracy:  0.94 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2423 | Train Loss:  0.004836380779743195 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2424 | Train Loss:  0.007972809076309205 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2425 | Train Loss:  0.005504838228225708 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  2426 | Train Loss:  0.005549728870391846 | Train Accuracy:  0.8214285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  2427 | Train Loss:  0.007690135836601258 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2428 | Train Loss:  0.0055716317892074586 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2429 | Train Loss:  0.004173067510128021 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2430 | Train Loss:  0.0049190753698349 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2431 | Train Loss:  0.006162511110305786 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2432 | Train Loss:  0.005227907299995422 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2433 | Train Loss:  0.0037604525685310366 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2434 | Train Loss:  0.005536183714866638 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2435 | Train Loss:  0.007562217712402344 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2436 | Train Loss:  0.005286604762077331 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2437 | Train Loss:  0.004759137630462647 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2438 | Train Loss:  0.007808179259300232 | Train Accuracy:  0.93 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2439 | Train Loss:  0.005290930271148682 | Train Accuracy:  0.93 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2440 | Train Loss:  0.005522432923316956 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2441 | Train Loss:  0.0076289671659469606 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2442 | Train Loss:  0.005444539785385132 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2443 | Train Loss:  0.004098618030548095 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2444 | Train Loss:  0.004781451523303986 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  2445 | Train Loss:  0.00597561001777649 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2446 | Train Loss:  0.005059601068496704 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2447 | Train Loss:  0.0036982184648513793 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2448 | Train Loss:  0.005365550518035889 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2449 | Train Loss:  0.00735684335231781 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2450 | Train Loss:  0.005190217494964599 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  2451 | Train Loss:  0.004689330160617828 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2452 | Train Loss:  0.007786714434623718 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2453 | Train Loss:  0.005353719592094421 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  2454 | Train Loss:  0.005426219701766968 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.54\n",
            "Iteration:  2455 | Train Loss:  0.007467806339263916 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2456 | Train Loss:  0.005416778326034546 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2457 | Train Loss:  0.0040792286396026615 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2458 | Train Loss:  0.00470055490732193 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2459 | Train Loss:  0.005913723111152649 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2460 | Train Loss:  0.005082949995994568 | Train Accuracy:  0.94 | Validation Accuracy:  0.5\n",
            "Iteration:  2461 | Train Loss:  0.0036492130160331727 | Train Accuracy:  0.88 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2462 | Train Loss:  0.005314042568206787 | Train Accuracy:  0.7985714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2463 | Train Loss:  0.007310426831245422 | Train Accuracy:  0.9 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2464 | Train Loss:  0.005211666226387024 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2465 | Train Loss:  0.004601184725761414 | Train Accuracy:  0.88 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2466 | Train Loss:  0.007630225419998169 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2467 | Train Loss:  0.005081010460853577 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2468 | Train Loss:  0.005420057773590088 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2469 | Train Loss:  0.007325711846351624 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2470 | Train Loss:  0.005279393792152405 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2471 | Train Loss:  0.0040003108978271485 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2472 | Train Loss:  0.0045777025818824766 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2473 | Train Loss:  0.005740379691123962 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2474 | Train Loss:  0.004942343533039093 | Train Accuracy:  0.94 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2475 | Train Loss:  0.0036080092191696166 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  2476 | Train Loss:  0.005109787583351135 | Train Accuracy:  0.8 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2477 | Train Loss:  0.007106876969337463 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2478 | Train Loss:  0.0051400291919708255 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2479 | Train Loss:  0.00451105922460556 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2480 | Train Loss:  0.007519422173500061 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2481 | Train Loss:  0.0051171380281448365 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2482 | Train Loss:  0.005331357717514038 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2483 | Train Loss:  0.007108083963394165 | Train Accuracy:  0.9 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2484 | Train Loss:  0.0052103596925735475 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2485 | Train Loss:  0.003975658118724823 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2486 | Train Loss:  0.00447991281747818 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2487 | Train Loss:  0.00561597228050232 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2488 | Train Loss:  0.004923383295536041 | Train Accuracy:  0.94 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2489 | Train Loss:  0.0035572946071624756 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2490 | Train Loss:  0.005039607882499695 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2491 | Train Loss:  0.007027338147163391 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2492 | Train Loss:  0.005152438282966614 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2493 | Train Loss:  0.004434982240200043 | Train Accuracy:  0.8842857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2494 | Train Loss:  0.007443811893463135 | Train Accuracy:  0.93 | Validation Accuracy:  0.5\n",
            "Iteration:  2495 | Train Loss:  0.004911211431026459 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2496 | Train Loss:  0.005320177674293518 | Train Accuracy:  0.83 | Validation Accuracy:  0.54\n",
            "Iteration:  2497 | Train Loss:  0.00695506751537323 | Train Accuracy:  0.9 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2498 | Train Loss:  0.0051016658544540405 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2499 | Train Loss:  0.003910853266716003 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2500 | Train Loss:  0.004391624927520752 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2501 | Train Loss:  0.005439727902412415 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2502 | Train Loss:  0.004802552759647369 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2503 | Train Loss:  0.0035050541162490846 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2504 | Train Loss:  0.004914203584194183 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2505 | Train Loss:  0.00687914490699768 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2506 | Train Loss:  0.0050845670700073245 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2507 | Train Loss:  0.004358173012733459 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  2508 | Train Loss:  0.007375836372375488 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2509 | Train Loss:  0.004903097450733185 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2510 | Train Loss:  0.005237659215927124 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2511 | Train Loss:  0.006742695569992066 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  2512 | Train Loss:  0.005044209957122803 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2513 | Train Loss:  0.003870652914047241 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2514 | Train Loss:  0.004295380413532257 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2515 | Train Loss:  0.0053035861253738405 | Train Accuracy:  0.83 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2516 | Train Loss:  0.004718420803546905 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2517 | Train Loss:  0.0034329494833946228 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  2518 | Train Loss:  0.004811395406723023 | Train Accuracy:  0.8071428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2519 | Train Loss:  0.006685442328453064 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2520 | Train Loss:  0.0050321388244628906 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2521 | Train Loss:  0.004287072718143463 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2522 | Train Loss:  0.007233063578605652 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  2523 | Train Loss:  0.004694548547267914 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2524 | Train Loss:  0.005224156379699707 | Train Accuracy:  0.84 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2525 | Train Loss:  0.006576786041259766 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  2526 | Train Loss:  0.00490115076303482 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2527 | Train Loss:  0.0037845149636268616 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2528 | Train Loss:  0.004220756590366363 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2529 | Train Loss:  0.0051503157615661625 | Train Accuracy:  0.83 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2530 | Train Loss:  0.004578530788421631 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2531 | Train Loss:  0.003360302746295929 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2532 | Train Loss:  0.0046969825029373165 | Train Accuracy:  0.81 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2533 | Train Loss:  0.0065457034111022945 | Train Accuracy:  0.9 | Validation Accuracy:  0.48\n",
            "Iteration:  2534 | Train Loss:  0.004943693578243255 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2535 | Train Loss:  0.004230071604251861 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2536 | Train Loss:  0.007166056036949158 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  2537 | Train Loss:  0.004625770449638367 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2538 | Train Loss:  0.005147455334663391 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2539 | Train Loss:  0.006455824375152588 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2540 | Train Loss:  0.0048526814579963684 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2541 | Train Loss:  0.0037562370300292967 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  2542 | Train Loss:  0.004092818796634674 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2543 | Train Loss:  0.005028221607208252 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2544 | Train Loss:  0.00456882894039154 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2545 | Train Loss:  0.0033486294746398926 | Train Accuracy:  0.9 | Validation Accuracy:  0.48\n",
            "Iteration:  2546 | Train Loss:  0.004551323354244232 | Train Accuracy:  0.81 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2547 | Train Loss:  0.006468243598937988 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  2548 | Train Loss:  0.004982942938804627 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2549 | Train Loss:  0.004129731655120849 | Train Accuracy:  0.89 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2550 | Train Loss:  0.00711834728717804 | Train Accuracy:  0.93 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2551 | Train Loss:  0.004591877460479736 | Train Accuracy:  0.94 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2552 | Train Loss:  0.005111004710197448 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2553 | Train Loss:  0.00634686529636383 | Train Accuracy:  0.91 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2554 | Train Loss:  0.004816350936889649 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2555 | Train Loss:  0.003739517331123352 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2556 | Train Loss:  0.003995395004749298 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2557 | Train Loss:  0.00498102068901062 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2558 | Train Loss:  0.004589648842811584 | Train Accuracy:  0.94 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2559 | Train Loss:  0.00334701269865036 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2560 | Train Loss:  0.00446214497089386 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2561 | Train Loss:  0.0064735329151153565 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  2562 | Train Loss:  0.005019627213478088 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2563 | Train Loss:  0.0040445753931999204 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2564 | Train Loss:  0.007088372707366944 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  2565 | Train Loss:  0.004588328897953033 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2566 | Train Loss:  0.005050011277198792 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2567 | Train Loss:  0.006162130832672119 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2568 | Train Loss:  0.004757401347160339 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2569 | Train Loss:  0.003701743185520172 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2570 | Train Loss:  0.003911529183387757 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2571 | Train Loss:  0.004874799251556396 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2572 | Train Loss:  0.0045448380708694456 | Train Accuracy:  0.94 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2573 | Train Loss:  0.0032975274324417115 | Train Accuracy:  0.9042857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  2574 | Train Loss:  0.00436143159866333 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2575 | Train Loss:  0.006324357390403748 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2576 | Train Loss:  0.0050080007314682005 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2577 | Train Loss:  0.003973540961742401 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2578 | Train Loss:  0.006987572312355041 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2579 | Train Loss:  0.00437480092048645 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2580 | Train Loss:  0.005015612244606018 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2581 | Train Loss:  0.006010373830795288 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2582 | Train Loss:  0.004643170237541199 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2583 | Train Loss:  0.003645331859588623 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2584 | Train Loss:  0.00380126029253006 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2585 | Train Loss:  0.004721833467483521 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2586 | Train Loss:  0.004478393793106079 | Train Accuracy:  0.94 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2587 | Train Loss:  0.0033149203658103944 | Train Accuracy:  0.91 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2588 | Train Loss:  0.004161026477813721 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2589 | Train Loss:  0.006260404586791992 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2590 | Train Loss:  0.005054236650466919 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2591 | Train Loss:  0.0038806647062301636 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2592 | Train Loss:  0.0068782025575637815 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2593 | Train Loss:  0.004532132744789124 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2594 | Train Loss:  0.004930572807788849 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2595 | Train Loss:  0.005803576707839966 | Train Accuracy:  0.91 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2596 | Train Loss:  0.004691110253334046 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2597 | Train Loss:  0.003715322017669678 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2598 | Train Loss:  0.0036172598600387575 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2599 | Train Loss:  0.00461961030960083 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2600 | Train Loss:  0.004576493501663208 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2601 | Train Loss:  0.0033691298961639406 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2602 | Train Loss:  0.004034497141838074 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2603 | Train Loss:  0.0062381309270858765 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2604 | Train Loss:  0.005195655822753906 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2605 | Train Loss:  0.003760667145252228 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2606 | Train Loss:  0.006927382946014404 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2607 | Train Loss:  0.004455476105213165 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  2608 | Train Loss:  0.004882688820362091 | Train Accuracy:  0.85 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2609 | Train Loss:  0.005715527534484863 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2610 | Train Loss:  0.004654678106307983 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2611 | Train Loss:  0.00371468722820282 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2612 | Train Loss:  0.0035260885953903197 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2613 | Train Loss:  0.004610776603221893 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2614 | Train Loss:  0.00464752733707428 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2615 | Train Loss:  0.0034142455458641054 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  2616 | Train Loss:  0.003921484649181366 | Train Accuracy:  0.8 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2617 | Train Loss:  0.006306107044219971 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2618 | Train Loss:  0.005321548581123352 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2619 | Train Loss:  0.003686983585357666 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2620 | Train Loss:  0.006833903789520264 | Train Accuracy:  0.92 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2621 | Train Loss:  0.004633312225341797 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.46\n",
            "Iteration:  2622 | Train Loss:  0.004796127080917359 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2623 | Train Loss:  0.005434578061103821 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  2624 | Train Loss:  0.004727189540863037 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2625 | Train Loss:  0.0038518759608268736 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2626 | Train Loss:  0.003330011069774628 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2627 | Train Loss:  0.004534059166908264 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2628 | Train Loss:  0.004863017201423645 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2629 | Train Loss:  0.0035983526706695555 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2630 | Train Loss:  0.003756941258907318 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2631 | Train Loss:  0.006378374695777893 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  2632 | Train Loss:  0.005607784390449524 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2633 | Train Loss:  0.0035644304752349854 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2634 | Train Loss:  0.006897279620170593 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2635 | Train Loss:  0.004640847444534302 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2636 | Train Loss:  0.004752904772758484 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2637 | Train Loss:  0.005293589830398559 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  2638 | Train Loss:  0.004745146930217743 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  2639 | Train Loss:  0.00395549088716507 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2640 | Train Loss:  0.0032134997844696046 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2641 | Train Loss:  0.004501399993896485 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2642 | Train Loss:  0.004991212785243988 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  2643 | Train Loss:  0.0037587165832519533 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2644 | Train Loss:  0.003597269952297211 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2645 | Train Loss:  0.006480896472930908 | Train Accuracy:  0.85 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2646 | Train Loss:  0.00585372269153595 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2647 | Train Loss:  0.003507901132106781 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2648 | Train Loss:  0.006779026985168457 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2649 | Train Loss:  0.004943611919879913 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2650 | Train Loss:  0.0047163012623786926 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2651 | Train Loss:  0.004924461245536804 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  2652 | Train Loss:  0.004836601316928864 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2653 | Train Loss:  0.004259821772575378 | Train Accuracy:  0.89 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2654 | Train Loss:  0.003023688495159149 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2655 | Train Loss:  0.00448325127363205 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2656 | Train Loss:  0.005429916381835938 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2657 | Train Loss:  0.0041383284330368045 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  2658 | Train Loss:  0.00344358891248703 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2659 | Train Loss:  0.006720428466796875 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2660 | Train Loss:  0.0064066660404205325 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2661 | Train Loss:  0.0034122973680496215 | Train Accuracy:  0.8842857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2662 | Train Loss:  0.006945142149925232 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2663 | Train Loss:  0.005091153979301453 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2664 | Train Loss:  0.004721481204032898 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2665 | Train Loss:  0.0047831711173057555 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2666 | Train Loss:  0.004951325953006744 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  2667 | Train Loss:  0.004543076455593109 | Train Accuracy:  0.9042857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2668 | Train Loss:  0.0029332491755485533 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2669 | Train Loss:  0.0044460582733154294 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2670 | Train Loss:  0.0057453131675720215 | Train Accuracy:  0.8842857142857142 | Validation Accuracy:  0.5\n",
            "Iteration:  2671 | Train Loss:  0.00456649512052536 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2672 | Train Loss:  0.0032762107253074646 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  2673 | Train Loss:  0.007007099390029907 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2674 | Train Loss:  0.00696114182472229 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  2675 | Train Loss:  0.003419276773929596 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2676 | Train Loss:  0.006759531497955322 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2677 | Train Loss:  0.005606022477149963 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2678 | Train Loss:  0.00476044625043869 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2679 | Train Loss:  0.00443187415599823 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2680 | Train Loss:  0.005151679515838623 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2681 | Train Loss:  0.005211266875267029 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2682 | Train Loss:  0.002845889925956726 | Train Accuracy:  0.76 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2683 | Train Loss:  0.004355851113796234 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2684 | Train Loss:  0.006433908939361572 | Train Accuracy:  0.86 | Validation Accuracy:  0.5\n",
            "Iteration:  2685 | Train Loss:  0.005492168664932251 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2686 | Train Loss:  0.0030652546882629396 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2687 | Train Loss:  0.007402044534683227 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2688 | Train Loss:  0.008080135583877563 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  2689 | Train Loss:  0.0034579989314079285 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2690 | Train Loss:  0.006750128269195557 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2691 | Train Loss:  0.006179680824279785 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2692 | Train Loss:  0.004987254440784454 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2693 | Train Loss:  0.004095223546028137 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2694 | Train Loss:  0.005430171489715576 | Train Accuracy:  0.92 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2695 | Train Loss:  0.006189636588096618 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2696 | Train Loss:  0.0028816503286361694 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2697 | Train Loss:  0.004301637709140778 | Train Accuracy:  0.68 | Validation Accuracy:  0.52\n",
            "Iteration:  2698 | Train Loss:  0.00710300087928772 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2699 | Train Loss:  0.0065497148036956785 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.46\n",
            "Iteration:  2700 | Train Loss:  0.002873106896877289 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2701 | Train Loss:  0.0075994783639907835 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2702 | Train Loss:  0.009191747903823853 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2703 | Train Loss:  0.0037730732560157776 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  2704 | Train Loss:  0.006241745352745056 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2705 | Train Loss:  0.007041508555412293 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2706 | Train Loss:  0.005564691424369812 | Train Accuracy:  0.93 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2707 | Train Loss:  0.0034677359461784364 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2708 | Train Loss:  0.005595962405204773 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2709 | Train Loss:  0.007839179039001465 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2710 | Train Loss:  0.003459453582763672 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2711 | Train Loss:  0.003623960614204407 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2712 | Train Loss:  0.00805074155330658 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2713 | Train Loss:  0.009218886494636536 | Train Accuracy:  0.96 | Validation Accuracy:  0.5\n",
            "Iteration:  2714 | Train Loss:  0.0027868905663490295 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2715 | Train Loss:  0.007478604316711426 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2716 | Train Loss:  0.01138717532157898 | Train Accuracy:  0.8671428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  2717 | Train Loss:  0.005181542038917542 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2718 | Train Loss:  0.005160089731216431 | Train Accuracy:  0.8242857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2719 | Train Loss:  0.007921322584152221 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2720 | Train Loss:  0.007457059621810913 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2721 | Train Loss:  0.0028723251819610597 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2722 | Train Loss:  0.005100840330123901 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2723 | Train Loss:  0.010186102390289307 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2724 | Train Loss:  0.005839284658432007 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2725 | Train Loss:  0.0024767832458019255 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2726 | Train Loss:  0.007940278649330139 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2727 | Train Loss:  0.013350920677185059 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2728 | Train Loss:  0.003937353789806366 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2729 | Train Loss:  0.005299761295318604 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2730 | Train Loss:  0.012850552797317505 | Train Accuracy:  0.76 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2731 | Train Loss:  0.008541845083236695 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2732 | Train Loss:  0.003683863580226898 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2733 | Train Loss:  0.007144615650177002 | Train Accuracy:  0.8128571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2734 | Train Loss:  0.010015857219696046 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2735 | Train Loss:  0.004048057496547699 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2736 | Train Loss:  0.0037442153692245485 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2737 | Train Loss:  0.010445879697799683 | Train Accuracy:  0.86 | Validation Accuracy:  0.52\n",
            "Iteration:  2738 | Train Loss:  0.009440850019454956 | Train Accuracy:  0.94 | Validation Accuracy:  0.5\n",
            "Iteration:  2739 | Train Loss:  0.00172805055975914 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2740 | Train Loss:  0.005432525873184204 | Train Accuracy:  0.65 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2741 | Train Loss:  0.01473552107810974 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2742 | Train Loss:  0.007677187323570252 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.46\n",
            "Iteration:  2743 | Train Loss:  0.002746277153491974 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2744 | Train Loss:  0.010219379663467407 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  2745 | Train Loss:  0.011516941785812378 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  2746 | Train Loss:  0.004470966458320617 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2747 | Train Loss:  0.0035728999972343446 | Train Accuracy:  0.81 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2748 | Train Loss:  0.009677870869636536 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2749 | Train Loss:  0.007345499396324158 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2750 | Train Loss:  0.0035148003697395326 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2751 | Train Loss:  0.007436583638191223 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2752 | Train Loss:  0.009145801067352294 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  2753 | Train Loss:  0.0025553131103515626 | Train Accuracy:  0.87 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2754 | Train Loss:  0.0028507447242736815 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2755 | Train Loss:  0.009982044100761414 | Train Accuracy:  0.81 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2756 | Train Loss:  0.007879284620285034 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2757 | Train Loss:  0.0023451939225196837 | Train Accuracy:  0.8271428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2758 | Train Loss:  0.005864953398704529 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2759 | Train Loss:  0.009177882671356202 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2760 | Train Loss:  0.005427644252777099 | Train Accuracy:  0.96 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2761 | Train Loss:  0.0023553431034088134 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2762 | Train Loss:  0.006879937648773193 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  2763 | Train Loss:  0.006819508075714111 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2764 | Train Loss:  0.003821847438812256 | Train Accuracy:  0.95 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  2765 | Train Loss:  0.004237767457962036 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2766 | Train Loss:  0.0062423723936080935 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.46\n",
            "Iteration:  2767 | Train Loss:  0.002526707351207733 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2768 | Train Loss:  0.0026730048656463624 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  2769 | Train Loss:  0.005516456365585327 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  2770 | Train Loss:  0.0059886366128921505 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2771 | Train Loss:  0.0026009345054626466 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2772 | Train Loss:  0.003704764544963837 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2773 | Train Loss:  0.005641551613807678 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2774 | Train Loss:  0.0050888872146606446 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  2775 | Train Loss:  0.002518179416656494 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2776 | Train Loss:  0.004990099668502807 | Train Accuracy:  0.9 | Validation Accuracy:  0.52\n",
            "Iteration:  2777 | Train Loss:  0.004837013185024262 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  2778 | Train Loss:  0.0041964098811149595 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2779 | Train Loss:  0.0032485827803611757 | Train Accuracy:  0.96 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2780 | Train Loss:  0.0037579602003097535 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2781 | Train Loss:  0.0021389465034008025 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2782 | Train Loss:  0.0026015952229499818 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2783 | Train Loss:  0.003417890965938568 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2784 | Train Loss:  0.003980574905872345 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2785 | Train Loss:  0.002351861596107483 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2786 | Train Loss:  0.003405059576034546 | Train Accuracy:  0.9 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2787 | Train Loss:  0.003925341069698334 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2788 | Train Loss:  0.004011005461215973 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  2789 | Train Loss:  0.0025220081210136414 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2790 | Train Loss:  0.004837203919887543 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2791 | Train Loss:  0.0034851732850074767 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2792 | Train Loss:  0.003427288830280304 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2793 | Train Loss:  0.003082277178764343 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2794 | Train Loss:  0.002845011055469513 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2795 | Train Loss:  0.0016683252155780793 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  2796 | Train Loss:  0.00243738055229187 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2797 | Train Loss:  0.002903131544589996 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2798 | Train Loss:  0.0031608054041862487 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2799 | Train Loss:  0.001982402056455612 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  2800 | Train Loss:  0.0032358673214912415 | Train Accuracy:  0.92 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2801 | Train Loss:  0.003364309370517731 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  2802 | Train Loss:  0.0034546002745628355 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  2803 | Train Loss:  0.002397888004779816 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  2804 | Train Loss:  0.004747076332569123 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2805 | Train Loss:  0.002990063726902008 | Train Accuracy:  0.95 | Validation Accuracy:  0.52\n",
            "Iteration:  2806 | Train Loss:  0.003093218505382538 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2807 | Train Loss:  0.0029810506105422976 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2808 | Train Loss:  0.002629265487194061 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2809 | Train Loss:  0.0015386644005775452 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2810 | Train Loss:  0.0022718949615955354 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2811 | Train Loss:  0.0027373704314231874 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  2812 | Train Loss:  0.0028438162803649902 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  2813 | Train Loss:  0.0017812435328960418 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2814 | Train Loss:  0.0031598713994026185 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2815 | Train Loss:  0.003152753710746765 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  2816 | Train Loss:  0.0031685149669647217 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2817 | Train Loss:  0.0021560588479042054 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2818 | Train Loss:  0.004574705958366394 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2819 | Train Loss:  0.002761944532394409 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2820 | Train Loss:  0.002840472459793091 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2821 | Train Loss:  0.0028883492946624755 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2822 | Train Loss:  0.0025213077664375306 | Train Accuracy:  0.95 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2823 | Train Loss:  0.0014650915563106538 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2824 | Train Loss:  0.0021722862124443055 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2825 | Train Loss:  0.0028493207693099975 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2826 | Train Loss:  0.002661808729171753 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2827 | Train Loss:  0.0016672398149967195 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  2828 | Train Loss:  0.0033074581623077394 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2829 | Train Loss:  0.0031035691499710083 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  2830 | Train Loss:  0.0030089402198791504 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2831 | Train Loss:  0.0020864032208919524 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2832 | Train Loss:  0.004543494880199433 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2833 | Train Loss:  0.0026296871900558473 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2834 | Train Loss:  0.002619490623474121 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2835 | Train Loss:  0.0028864941000938415 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2836 | Train Loss:  0.0024727998673915864 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2837 | Train Loss:  0.001394881010055542 | Train Accuracy:  0.92 | Validation Accuracy:  0.52\n",
            "Iteration:  2838 | Train Loss:  0.0021851402521133423 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2839 | Train Loss:  0.0030170732736587522 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2840 | Train Loss:  0.002563730180263519 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2841 | Train Loss:  0.0016332755982875825 | Train Accuracy:  0.93 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2842 | Train Loss:  0.0034249603748321535 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2843 | Train Loss:  0.0030630674958229067 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2844 | Train Loss:  0.002928024232387543 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2845 | Train Loss:  0.0020266728103160857 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2846 | Train Loss:  0.00444868803024292 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2847 | Train Loss:  0.002527887523174286 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2848 | Train Loss:  0.0025611495971679687 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2849 | Train Loss:  0.002896084487438202 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2850 | Train Loss:  0.002436694502830505 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2851 | Train Loss:  0.0013784480094909668 | Train Accuracy:  0.9157142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2852 | Train Loss:  0.0022123879194259643 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2853 | Train Loss:  0.003168085813522339 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2854 | Train Loss:  0.0024424919486045835 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  2855 | Train Loss:  0.001623709797859192 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2856 | Train Loss:  0.003628050684928894 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2857 | Train Loss:  0.003034408092498779 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  2858 | Train Loss:  0.002850252091884613 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2859 | Train Loss:  0.0020388077199459077 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2860 | Train Loss:  0.004453900456428528 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2861 | Train Loss:  0.0024322448670864106 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2862 | Train Loss:  0.002471150755882263 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2863 | Train Loss:  0.0029687023162841795 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2864 | Train Loss:  0.0023889276385307312 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2865 | Train Loss:  0.0013477906584739685 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2866 | Train Loss:  0.002312265783548355 | Train Accuracy:  0.8928571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2867 | Train Loss:  0.003363214433193207 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2868 | Train Loss:  0.002336039990186691 | Train Accuracy:  0.96 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2869 | Train Loss:  0.0016740390658378601 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2870 | Train Loss:  0.003845854103565216 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2871 | Train Loss:  0.0030091127753257754 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2872 | Train Loss:  0.002804643213748932 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2873 | Train Loss:  0.002082440257072449 | Train Accuracy:  0.97 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2874 | Train Loss:  0.004454499781131744 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2875 | Train Loss:  0.0023510304093360902 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2876 | Train Loss:  0.002446160465478897 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2877 | Train Loss:  0.0030554994940757752 | Train Accuracy:  0.97 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2878 | Train Loss:  0.002349451631307602 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  2879 | Train Loss:  0.0013557116687297822 | Train Accuracy:  0.8842857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2880 | Train Loss:  0.002415185123682022 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2881 | Train Loss:  0.0034983059763908386 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2882 | Train Loss:  0.002227813750505447 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  2883 | Train Loss:  0.0017454372346401214 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2884 | Train Loss:  0.004065569341182709 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2885 | Train Loss:  0.0029564234614372254 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2886 | Train Loss:  0.0027790164947509768 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2887 | Train Loss:  0.002150156944990158 | Train Accuracy:  0.97 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2888 | Train Loss:  0.0044643738865852356 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2889 | Train Loss:  0.0022868897020816804 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2890 | Train Loss:  0.002442208081483841 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2891 | Train Loss:  0.00313836008310318 | Train Accuracy:  0.97 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2892 | Train Loss:  0.002296832203865051 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2893 | Train Loss:  0.0013630399107933044 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2894 | Train Loss:  0.002515801191329956 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2895 | Train Loss:  0.003595767319202423 | Train Accuracy:  0.97 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2896 | Train Loss:  0.0021308641135692596 | Train Accuracy:  0.95 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2897 | Train Loss:  0.001823529452085495 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2898 | Train Loss:  0.004214756488800049 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2899 | Train Loss:  0.0028890427947044373 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2900 | Train Loss:  0.002762366533279419 | Train Accuracy:  0.97 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2901 | Train Loss:  0.002174181491136551 | Train Accuracy:  0.97 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2902 | Train Loss:  0.004395254552364349 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2903 | Train Loss:  0.0022256675362586974 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2904 | Train Loss:  0.0024370568990707397 | Train Accuracy:  0.97 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2905 | Train Loss:  0.0031249821186065674 | Train Accuracy:  0.97 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2906 | Train Loss:  0.00222159743309021 | Train Accuracy:  0.92 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2907 | Train Loss:  0.0013611634075641633 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  2908 | Train Loss:  0.002530495524406433 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2909 | Train Loss:  0.003566773533821106 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2910 | Train Loss:  0.0020505133271217345 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2911 | Train Loss:  0.0018485584855079651 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2912 | Train Loss:  0.004223705232143402 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2913 | Train Loss:  0.0028022041916847228 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2914 | Train Loss:  0.0027350348234176634 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2915 | Train Loss:  0.002170008718967438 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2916 | Train Loss:  0.004379940032958984 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2917 | Train Loss:  0.002169966548681259 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2918 | Train Loss:  0.0024005115032196046 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2919 | Train Loss:  0.003122778534889221 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2920 | Train Loss:  0.0021641315519809723 | Train Accuracy:  0.92 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2921 | Train Loss:  0.0013371656835079193 | Train Accuracy:  0.87 | Validation Accuracy:  0.5\n",
            "Iteration:  2922 | Train Loss:  0.0025316202640533448 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2923 | Train Loss:  0.0035546311736106874 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2924 | Train Loss:  0.0019817952811717987 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2925 | Train Loss:  0.0018533653020858765 | Train Accuracy:  0.88 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2926 | Train Loss:  0.004238692820072174 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2927 | Train Loss:  0.0027347755432128905 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2928 | Train Loss:  0.002712888419628143 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2929 | Train Loss:  0.0021196046471595766 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2930 | Train Loss:  0.004323824048042297 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2931 | Train Loss:  0.0021286918222904205 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2932 | Train Loss:  0.0023825961351394654 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2933 | Train Loss:  0.003069095015525818 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2934 | Train Loss:  0.0021269166469573973 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2935 | Train Loss:  0.0013093703985214233 | Train Accuracy:  0.87 | Validation Accuracy:  0.5\n",
            "Iteration:  2936 | Train Loss:  0.0024810652434825897 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2937 | Train Loss:  0.003543423116207123 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2938 | Train Loss:  0.001941535919904709 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2939 | Train Loss:  0.0018200214207172395 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2940 | Train Loss:  0.004214014708995819 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  2941 | Train Loss:  0.0027087971568107603 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2942 | Train Loss:  0.0026505795121192933 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2943 | Train Loss:  0.0021269094944000246 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2944 | Train Loss:  0.004318122565746307 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2945 | Train Loss:  0.0020735305547714233 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2946 | Train Loss:  0.002321410775184631 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2947 | Train Loss:  0.003046065866947174 | Train Accuracy:  0.97 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2948 | Train Loss:  0.002066618800163269 | Train Accuracy:  0.92 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2949 | Train Loss:  0.0012511061131954193 | Train Accuracy:  0.87 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2950 | Train Loss:  0.002439926564693451 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2951 | Train Loss:  0.0035191014409065246 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2952 | Train Loss:  0.0018713228404521943 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2953 | Train Loss:  0.0017909200489521027 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2954 | Train Loss:  0.004243123233318329 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2955 | Train Loss:  0.0026253846287727354 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2956 | Train Loss:  0.0026276829838752748 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2957 | Train Loss:  0.0020184868574142454 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2958 | Train Loss:  0.0042864525318145755 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2959 | Train Loss:  0.0020364826917648317 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2960 | Train Loss:  0.0022945219278335573 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2961 | Train Loss:  0.002993368208408356 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  2962 | Train Loss:  0.002048927694559097 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2963 | Train Loss:  0.001215273067355156 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  2964 | Train Loss:  0.0023995065689086915 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2965 | Train Loss:  0.0034913608431816102 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2966 | Train Loss:  0.001845642626285553 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2967 | Train Loss:  0.0017535436153411866 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2968 | Train Loss:  0.004137501120567322 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2969 | Train Loss:  0.002611670196056366 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2970 | Train Loss:  0.0025589674711227416 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2971 | Train Loss:  0.0020300011336803437 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2972 | Train Loss:  0.004251936674118042 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2973 | Train Loss:  0.0019865241646766663 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  2974 | Train Loss:  0.002243698090314865 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2975 | Train Loss:  0.0029619228839874267 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  2976 | Train Loss:  0.0020182445645332337 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2977 | Train Loss:  0.0011618593335151672 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2978 | Train Loss:  0.0023556117713451384 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2979 | Train Loss:  0.003506830334663391 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2980 | Train Loss:  0.001789611577987671 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2981 | Train Loss:  0.0017159929871559143 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2982 | Train Loss:  0.004175778329372406 | Train Accuracy:  0.9271428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2983 | Train Loss:  0.00254795640707016 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2984 | Train Loss:  0.0025208428502082824 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2985 | Train Loss:  0.001934167742729187 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2986 | Train Loss:  0.004212243556976318 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2987 | Train Loss:  0.0019439378380775453 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  2988 | Train Loss:  0.0022022876143455504 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2989 | Train Loss:  0.0028709563612937927 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  2990 | Train Loss:  0.0019600076973438265 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  2991 | Train Loss:  0.0011239945143461227 | Train Accuracy:  0.87 | Validation Accuracy:  0.5\n",
            "Iteration:  2992 | Train Loss:  0.0022733470797538756 | Train Accuracy:  0.88 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2993 | Train Loss:  0.0034123614430427553 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2994 | Train Loss:  0.0017549386620521546 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2995 | Train Loss:  0.001649867445230484 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2996 | Train Loss:  0.004067353010177612 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2997 | Train Loss:  0.002512402832508087 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2998 | Train Loss:  0.0024576570093631745 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  2999 | Train Loss:  0.0018853014707565308 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  3000 | Train Loss:  0.004220710694789886 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  3001 | Train Loss:  0.0019137518107891084 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3002 | Train Loss:  0.0021673484146595002 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3003 | Train Loss:  0.0029142576456069945 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3004 | Train Loss:  0.0020005279779434205 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3005 | Train Loss:  0.001080189198255539 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  3006 | Train Loss:  0.002281952351331711 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  3007 | Train Loss:  0.0035652005672454834 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3008 | Train Loss:  0.0017290374636650086 | Train Accuracy:  0.94 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3009 | Train Loss:  0.001645393818616867 | Train Accuracy:  0.87 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3010 | Train Loss:  0.004158602952957153 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3011 | Train Loss:  0.002497171610593796 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3012 | Train Loss:  0.0024197638034820558 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3013 | Train Loss:  0.0018913508951663971 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3014 | Train Loss:  0.0041994693875312804 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  3015 | Train Loss:  0.001864418387413025 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  3016 | Train Loss:  0.002139340341091156 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3017 | Train Loss:  0.002874476611614227 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3018 | Train Loss:  0.001933898776769638 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  3019 | Train Loss:  0.0010588966310024262 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3020 | Train Loss:  0.0022565241158008574 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3021 | Train Loss:  0.003457716703414917 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3022 | Train Loss:  0.0016746050119400024 | Train Accuracy:  0.94 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3023 | Train Loss:  0.001614731252193451 | Train Accuracy:  0.87 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3024 | Train Loss:  0.004085786938667298 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  3025 | Train Loss:  0.0024350962042808534 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3026 | Train Loss:  0.002377786785364151 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  3027 | Train Loss:  0.0018451681733131409 | Train Accuracy:  0.97 | Validation Accuracy:  0.48\n",
            "Iteration:  3028 | Train Loss:  0.004185709655284881 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  3029 | Train Loss:  0.0018317919969558715 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3030 | Train Loss:  0.002110581248998642 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3031 | Train Loss:  0.002856572866439819 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3032 | Train Loss:  0.0019150997698307037 | Train Accuracy:  0.9257142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3033 | Train Loss:  0.0010209383070468902 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3034 | Train Loss:  0.0022252070903778075 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  3035 | Train Loss:  0.003452368974685669 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3036 | Train Loss:  0.0016327103972434997 | Train Accuracy:  0.94 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3037 | Train Loss:  0.001572137176990509 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  3038 | Train Loss:  0.004063651263713837 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  3039 | Train Loss:  0.002400016635656357 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3040 | Train Loss:  0.002338191270828247 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3041 | Train Loss:  0.0017789211869239808 | Train Accuracy:  0.97 | Validation Accuracy:  0.48\n",
            "Iteration:  3042 | Train Loss:  0.00414098471403122 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  3043 | Train Loss:  0.001799885332584381 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3044 | Train Loss:  0.0020639152824878694 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3045 | Train Loss:  0.0027796301245689393 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  3046 | Train Loss:  0.001907738447189331 | Train Accuracy:  0.93 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3047 | Train Loss:  0.0009736453741788864 | Train Accuracy:  0.87 | Validation Accuracy:  0.5\n",
            "Iteration:  3048 | Train Loss:  0.002128557711839676 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  3049 | Train Loss:  0.0034283387660980227 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3050 | Train Loss:  0.0016333450376987456 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3051 | Train Loss:  0.0014851826429367065 | Train Accuracy:  0.8642857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  3052 | Train Loss:  0.004017190933227539 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3053 | Train Loss:  0.002418549358844757 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3054 | Train Loss:  0.00227096289396286 | Train Accuracy:  0.97 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3055 | Train Loss:  0.0017693383991718291 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3056 | Train Loss:  0.0041878363490104676 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3057 | Train Loss:  0.0017760440707206727 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3058 | Train Loss:  0.0020374429225921632 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  3059 | Train Loss:  0.0028613346815109255 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3060 | Train Loss:  0.0019012172520160675 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3061 | Train Loss:  0.0009509604424238205 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3062 | Train Loss:  0.002166990339756012 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  3063 | Train Loss:  0.0035007911920547485 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3064 | Train Loss:  0.001564231961965561 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3065 | Train Loss:  0.0015160469710826874 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  3066 | Train Loss:  0.004104490578174591 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  3067 | Train Loss:  0.0023392704129219055 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3068 | Train Loss:  0.002251489460468292 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  3069 | Train Loss:  0.0016917121410369874 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  3070 | Train Loss:  0.004106490612030029 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3071 | Train Loss:  0.0017346668243408204 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3072 | Train Loss:  0.0019837337732315063 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3073 | Train Loss:  0.0026869946718215943 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3074 | Train Loss:  0.0018644307553768158 | Train Accuracy:  0.93 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3075 | Train Loss:  0.0008982933312654495 | Train Accuracy:  0.87 | Validation Accuracy:  0.5\n",
            "Iteration:  3076 | Train Loss:  0.0020133297145366667 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  3077 | Train Loss:  0.003385983407497406 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  3078 | Train Loss:  0.0015822148323059082 | Train Accuracy:  0.95 | Validation Accuracy:  0.5\n",
            "Iteration:  3079 | Train Loss:  0.0013647174835205078 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3080 | Train Loss:  0.003957707881927491 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3081 | Train Loss:  0.0023975256085395813 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3082 | Train Loss:  0.002174921631813049 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  3083 | Train Loss:  0.0016598239541053771 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3084 | Train Loss:  0.004189935624599457 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3085 | Train Loss:  0.0017377398908138275 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3086 | Train Loss:  0.001967378258705139 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3087 | Train Loss:  0.002829720377922058 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3088 | Train Loss:  0.0019215193390846252 | Train Accuracy:  0.93 | Validation Accuracy:  0.52\n",
            "Iteration:  3089 | Train Loss:  0.0008936899900436401 | Train Accuracy:  0.8671428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  3090 | Train Loss:  0.002106998562812805 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  3091 | Train Loss:  0.0035932299494743345 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  3092 | Train Loss:  0.0015473109483718872 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3093 | Train Loss:  0.0014297689497470855 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  3094 | Train Loss:  0.004133160710334777 | Train Accuracy:  0.9185714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3095 | Train Loss:  0.00235574945807457 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3096 | Train Loss:  0.0021648649871349335 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3097 | Train Loss:  0.0016760070621967315 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3098 | Train Loss:  0.0041186797618865964 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3099 | Train Loss:  0.001686859279870987 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3100 | Train Loss:  0.0019342491030693053 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3101 | Train Loss:  0.0026874259114265443 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3102 | Train Loss:  0.0018450544774532317 | Train Accuracy:  0.93 | Validation Accuracy:  0.52\n",
            "Iteration:  3103 | Train Loss:  0.0008584786206483841 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3104 | Train Loss:  0.001976271420717239 | Train Accuracy:  0.8671428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3105 | Train Loss:  0.003354216516017914 | Train Accuracy:  0.97 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3106 | Train Loss:  0.001518140882253647 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  3107 | Train Loss:  0.0013364432752132416 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3108 | Train Loss:  0.003930323123931885 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3109 | Train Loss:  0.002311011254787445 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3110 | Train Loss:  0.0021055608987808226 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  3111 | Train Loss:  0.0015721803903579713 | Train Accuracy:  0.96 | Validation Accuracy:  0.5\n",
            "Iteration:  3112 | Train Loss:  0.004114799201488495 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3113 | Train Loss:  0.0016809703409671783 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3114 | Train Loss:  0.00186274915933609 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3115 | Train Loss:  0.0026378545165061953 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3116 | Train Loss:  0.0018967422842979431 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3117 | Train Loss:  0.000802859142422676 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3118 | Train Loss:  0.0018875284492969513 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3119 | Train Loss:  0.0034634247422218323 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3120 | Train Loss:  0.0015672069787979125 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3121 | Train Loss:  0.0012493108958005906 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3122 | Train Loss:  0.003968062698841095 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3123 | Train Loss:  0.002380100041627884 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3124 | Train Loss:  0.002059252709150314 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3125 | Train Loss:  0.0016005583107471465 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3126 | Train Loss:  0.004221374392509461 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  3127 | Train Loss:  0.0016656427085399628 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3128 | Train Loss:  0.001851269155740738 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3129 | Train Loss:  0.0027650216221809386 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3130 | Train Loss:  0.0019344693422317504 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3131 | Train Loss:  0.000782575011253357 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3132 | Train Loss:  0.0019675345718860628 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3133 | Train Loss:  0.0035483309626579283 | Train Accuracy:  0.96 | Validation Accuracy:  0.5\n",
            "Iteration:  3134 | Train Loss:  0.001535799652338028 | Train Accuracy:  0.95 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3135 | Train Loss:  0.0012731006741523742 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3136 | Train Loss:  0.003966709077358246 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  3137 | Train Loss:  0.0023648813366889954 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3138 | Train Loss:  0.0020543548464775087 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3139 | Train Loss:  0.0016149622201919555 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  3140 | Train Loss:  0.004195624589920044 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3141 | Train Loss:  0.0016403263807296753 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3142 | Train Loss:  0.0018318103253841401 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3143 | Train Loss:  0.002744216024875641 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3144 | Train Loss:  0.001872445046901703 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3145 | Train Loss:  0.0007787399739027024 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3146 | Train Loss:  0.0019073337316513062 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3147 | Train Loss:  0.003419188559055328 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3148 | Train Loss:  0.0014733266830444336 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3149 | Train Loss:  0.0012356120347976685 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3150 | Train Loss:  0.003944320380687713 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  3151 | Train Loss:  0.0022797125577926638 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  3152 | Train Loss:  0.001993124783039093 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3153 | Train Loss:  0.0015017037093639374 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3154 | Train Loss:  0.004165635704994202 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3155 | Train Loss:  0.0016408023238182069 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3156 | Train Loss:  0.0017699001729488374 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3157 | Train Loss:  0.0026598986983299255 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3158 | Train Loss:  0.001917518675327301 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3159 | Train Loss:  0.0007323635369539261 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3160 | Train Loss:  0.0018022850155830384 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3161 | Train Loss:  0.0035303869843482973 | Train Accuracy:  0.96 | Validation Accuracy:  0.5\n",
            "Iteration:  3162 | Train Loss:  0.0015549658238887788 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3163 | Train Loss:  0.001138688251376152 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3164 | Train Loss:  0.003978400528430939 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3165 | Train Loss:  0.0024142664670944213 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3166 | Train Loss:  0.0019554269313812257 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3167 | Train Loss:  0.0015895287692546845 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3168 | Train Loss:  0.004327556490898133 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3169 | Train Loss:  0.001623847186565399 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  3170 | Train Loss:  0.0017622444033622742 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3171 | Train Loss:  0.0028443890810012818 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  3172 | Train Loss:  0.0019420376420021057 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  3173 | Train Loss:  0.0007251372933387756 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  3174 | Train Loss:  0.0019333177804946899 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  3175 | Train Loss:  0.0036054354906082152 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  3176 | Train Loss:  0.0014550912380218506 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3177 | Train Loss:  0.0012021150439977645 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  3178 | Train Loss:  0.003973257839679718 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3179 | Train Loss:  0.0022984080016613005 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3180 | Train Loss:  0.0019311679899692536 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  3181 | Train Loss:  0.0014960774779319763 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3182 | Train Loss:  0.004208122193813324 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3183 | Train Loss:  0.0015945085883140564 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3184 | Train Loss:  0.0017413383722305299 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3185 | Train Loss:  0.002687433958053589 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  3186 | Train Loss:  0.0019518756866455079 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3187 | Train Loss:  0.0006927121430635452 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3188 | Train Loss:  0.001812494695186615 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3189 | Train Loss:  0.003557288348674774 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3190 | Train Loss:  0.0015342609584331512 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3191 | Train Loss:  0.0010964038223028182 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3192 | Train Loss:  0.003861879110336304 | Train Accuracy:  0.88 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3193 | Train Loss:  0.0024261674284934997 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3194 | Train Loss:  0.0019047190248966217 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3195 | Train Loss:  0.001505635976791382 | Train Accuracy:  0.94 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3196 | Train Loss:  0.004326851963996887 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3197 | Train Loss:  0.0016308462619781495 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  3198 | Train Loss:  0.0016955247521400452 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3199 | Train Loss:  0.002807464301586151 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  3200 | Train Loss:  0.002001924514770508 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3201 | Train Loss:  0.000671917125582695 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3202 | Train Loss:  0.0018121537566184998 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3203 | Train Loss:  0.0036916786432266233 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3204 | Train Loss:  0.0014915952086448669 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3205 | Train Loss:  0.0011206860840320587 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3206 | Train Loss:  0.0040381869673728945 | Train Accuracy:  0.8785714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3207 | Train Loss:  0.002355334609746933 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3208 | Train Loss:  0.0018703345954418182 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  3209 | Train Loss:  0.0014718174934387207 | Train Accuracy:  0.94 | Validation Accuracy:  0.52\n",
            "Iteration:  3210 | Train Loss:  0.0043238186836242675 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3211 | Train Loss:  0.0016074100136756898 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  3212 | Train Loss:  0.0016748067736625672 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3213 | Train Loss:  0.0027805039286613463 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3214 | Train Loss:  0.002051423043012619 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3215 | Train Loss:  0.0006568858027458191 | Train Accuracy:  0.87 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3216 | Train Loss:  0.0018040227890014648 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3217 | Train Loss:  0.0036094015836715698 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  3218 | Train Loss:  0.001541159600019455 | Train Accuracy:  0.96 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3219 | Train Loss:  0.0010591935366392135 | Train Accuracy:  0.8357142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3220 | Train Loss:  0.0038247695565223694 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  3221 | Train Loss:  0.002455768585205078 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3222 | Train Loss:  0.001863979399204254 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3223 | Train Loss:  0.0014952537417411804 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3224 | Train Loss:  0.004416323900222778 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3225 | Train Loss:  0.0016389070451259613 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3226 | Train Loss:  0.0016384825110435485 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3227 | Train Loss:  0.0028726300597190857 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  3228 | Train Loss:  0.0020873160660266877 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3229 | Train Loss:  0.0006362555921077728 | Train Accuracy:  0.87 | Validation Accuracy:  0.5\n",
            "Iteration:  3230 | Train Loss:  0.0017955362796783446 | Train Accuracy:  0.8185714285714286 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3231 | Train Loss:  0.003751859366893768 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3232 | Train Loss:  0.0014582115411758423 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3233 | Train Loss:  0.0010832717269659042 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3234 | Train Loss:  0.004046355783939362 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  3235 | Train Loss:  0.002355198860168457 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3236 | Train Loss:  0.0018022936582565308 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  3237 | Train Loss:  0.0013997969031333923 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  3238 | Train Loss:  0.004343714118003845 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3239 | Train Loss:  0.001595344990491867 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3240 | Train Loss:  0.0016204364597797393 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3241 | Train Loss:  0.0027697074413299562 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3242 | Train Loss:  0.002088560461997986 | Train Accuracy:  0.95 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3243 | Train Loss:  0.0006138563528656959 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3244 | Train Loss:  0.001707085072994232 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3245 | Train Loss:  0.0038025280833244323 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  3246 | Train Loss:  0.0015705806016921998 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3247 | Train Loss:  0.000996766835451126 | Train Accuracy:  0.83 | Validation Accuracy:  0.54\n",
            "Iteration:  3248 | Train Loss:  0.003901187777519226 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3249 | Train Loss:  0.002520844340324402 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3250 | Train Loss:  0.0018070191144943237 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  3251 | Train Loss:  0.0014211855828762054 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3252 | Train Loss:  0.0045597904920578 | Train Accuracy:  0.96 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3253 | Train Loss:  0.0017112460732460022 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3254 | Train Loss:  0.0015921565890312196 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3255 | Train Loss:  0.002962581515312195 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3256 | Train Loss:  0.0022019270062446595 | Train Accuracy:  0.95 | Validation Accuracy:  0.52\n",
            "Iteration:  3257 | Train Loss:  0.0006093370541930199 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  3258 | Train Loss:  0.0017857152223587037 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3259 | Train Loss:  0.0039658302068710325 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  3260 | Train Loss:  0.0015029054880142212 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3261 | Train Loss:  0.0010430260002613067 | Train Accuracy:  0.8157142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  3262 | Train Loss:  0.004070253074169159 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3263 | Train Loss:  0.0024390117824077606 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  3264 | Train Loss:  0.0017774519324302673 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3265 | Train Loss:  0.0014225441217422486 | Train Accuracy:  0.93 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3266 | Train Loss:  0.0044253748655319215 | Train Accuracy:  0.96 | Validation Accuracy:  0.52\n",
            "Iteration:  3267 | Train Loss:  0.0016378343105316162 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3268 | Train Loss:  0.0015454213321208954 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3269 | Train Loss:  0.002739374041557312 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3270 | Train Loss:  0.002229970395565033 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3271 | Train Loss:  0.0005847847461700439 | Train Accuracy:  0.8757142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3272 | Train Loss:  0.0016021320223808288 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3273 | Train Loss:  0.003817107677459717 | Train Accuracy:  0.94 | Validation Accuracy:  0.52\n",
            "Iteration:  3274 | Train Loss:  0.0016871717572212218 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3275 | Train Loss:  0.0008879119902849197 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3276 | Train Loss:  0.0039005282521247862 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3277 | Train Loss:  0.0027213871479034426 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  3278 | Train Loss:  0.001785760372877121 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3279 | Train Loss:  0.0014191983640193938 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3280 | Train Loss:  0.004762406051158905 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3281 | Train Loss:  0.0017289425432682037 | Train Accuracy:  0.9771428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3282 | Train Loss:  0.0015357942879199982 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3283 | Train Loss:  0.003080693483352661 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3284 | Train Loss:  0.002270564138889313 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3285 | Train Loss:  0.0005826614797115326 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3286 | Train Loss:  0.00178125262260437 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3287 | Train Loss:  0.003937181234359741 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  3288 | Train Loss:  0.0015056642889976501 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3289 | Train Loss:  0.0009747663140296936 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3290 | Train Loss:  0.003965257406234741 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  3291 | Train Loss:  0.002513954043388367 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  3292 | Train Loss:  0.0017441743612289428 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  3293 | Train Loss:  0.0013432557880878448 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3294 | Train Loss:  0.004634839296340942 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3295 | Train Loss:  0.001754445880651474 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3296 | Train Loss:  0.0015139435231685638 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3297 | Train Loss:  0.002849043607711792 | Train Accuracy:  0.97 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3298 | Train Loss:  0.0024259527027606963 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  3299 | Train Loss:  0.000564010851085186 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3300 | Train Loss:  0.0015651640295982362 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3301 | Train Loss:  0.0040571090579032895 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3302 | Train Loss:  0.001790289431810379 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3303 | Train Loss:  0.0008514001220464707 | Train Accuracy:  0.8014285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3304 | Train Loss:  0.003965795040130615 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3305 | Train Loss:  0.0028480774164199828 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3306 | Train Loss:  0.0017650099098682403 | Train Accuracy:  0.95 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3307 | Train Loss:  0.0014018933475017548 | Train Accuracy:  0.91 | Validation Accuracy:  0.52\n",
            "Iteration:  3308 | Train Loss:  0.004878815710544587 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  3309 | Train Loss:  0.0018142086267471313 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3310 | Train Loss:  0.0014704547822475434 | Train Accuracy:  0.94 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3311 | Train Loss:  0.0030039286613464354 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  3312 | Train Loss:  0.002416016459465027 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  3313 | Train Loss:  0.0005531140416860581 | Train Accuracy:  0.87 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3314 | Train Loss:  0.001594887375831604 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  3315 | Train Loss:  0.0040126946568489075 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3316 | Train Loss:  0.0017005349695682526 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  3317 | Train Loss:  0.0008542165905237197 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3318 | Train Loss:  0.004004130661487579 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3319 | Train Loss:  0.002793240249156952 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  3320 | Train Loss:  0.0017167602479457855 | Train Accuracy:  0.95 | Validation Accuracy:  0.52\n",
            "Iteration:  3321 | Train Loss:  0.0013751038908958436 | Train Accuracy:  0.9042857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  3322 | Train Loss:  0.004992797374725342 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  3323 | Train Loss:  0.00178196519613266 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3324 | Train Loss:  0.0014648868143558502 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  3325 | Train Loss:  0.0030585914850234986 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3326 | Train Loss:  0.002613060176372528 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  3327 | Train Loss:  0.0005674948170781136 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3328 | Train Loss:  0.0017639820277690888 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  3329 | Train Loss:  0.004042320549488067 | Train Accuracy:  0.93 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3330 | Train Loss:  0.0020411694049835205 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3331 | Train Loss:  0.0007515821605920791 | Train Accuracy:  0.8042857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3332 | Train Loss:  0.003747186362743378 | Train Accuracy:  0.81 | Validation Accuracy:  0.54\n",
            "Iteration:  3333 | Train Loss:  0.003195070922374725 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3334 | Train Loss:  0.0018382076919078827 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3335 | Train Loss:  0.0013354125618934632 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3336 | Train Loss:  0.005316262245178223 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3337 | Train Loss:  0.0020039927959442138 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3338 | Train Loss:  0.0016097135841846466 | Train Accuracy:  0.9214285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  3339 | Train Loss:  0.003796425759792328 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  3340 | Train Loss:  0.0020679859817028046 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3341 | Train Loss:  0.0006042272597551345 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3342 | Train Loss:  0.0018068651854991913 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  3343 | Train Loss:  0.003779045045375824 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3344 | Train Loss:  0.0014643940329551698 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  3345 | Train Loss:  0.0008421388268470765 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  3346 | Train Loss:  0.003821636140346527 | Train Accuracy:  0.8328571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3347 | Train Loss:  0.00258968323469162 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3348 | Train Loss:  0.001716834306716919 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3349 | Train Loss:  0.0011640309542417526 | Train Accuracy:  0.91 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3350 | Train Loss:  0.0048108908534049985 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3351 | Train Loss:  0.0020631092786788942 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3352 | Train Loss:  0.0013279774785041809 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  3353 | Train Loss:  0.002710757553577423 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3354 | Train Loss:  0.0031442487239837645 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  3355 | Train Loss:  0.0005652928724884987 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  3356 | Train Loss:  0.0015491926670074463 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3357 | Train Loss:  0.004431767165660858 | Train Accuracy:  0.9071428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3358 | Train Loss:  0.0026263427734375 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3359 | Train Loss:  0.0006700118631124497 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3360 | Train Loss:  0.00382732093334198 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3361 | Train Loss:  0.00375875324010849 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3362 | Train Loss:  0.0018424849212169648 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3363 | Train Loss:  0.0014546522498130798 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3364 | Train Loss:  0.0057596474885940555 | Train Accuracy:  0.94 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3365 | Train Loss:  0.0020314060151576997 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3366 | Train Loss:  0.0015660181641578674 | Train Accuracy:  0.9 | Validation Accuracy:  0.52\n",
            "Iteration:  3367 | Train Loss:  0.004049035012722016 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  3368 | Train Loss:  0.0020882619917392733 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3369 | Train Loss:  0.0005959327146410942 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3370 | Train Loss:  0.001811317056417465 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  3371 | Train Loss:  0.0037956562638282775 | Train Accuracy:  0.9385714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3372 | Train Loss:  0.0014857108891010284 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3373 | Train Loss:  0.000777655616402626 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  3374 | Train Loss:  0.003623130023479462 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3375 | Train Loss:  0.0027122652530670167 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3376 | Train Loss:  0.0018601545691490173 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3377 | Train Loss:  0.0010925593972206115 | Train Accuracy:  0.8985714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  3378 | Train Loss:  0.005086341500282287 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3379 | Train Loss:  0.0023460102081298826 | Train Accuracy:  0.9757142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3380 | Train Loss:  0.001279250681400299 | Train Accuracy:  0.9328571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3381 | Train Loss:  0.002855171263217926 | Train Accuracy:  0.9414285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3382 | Train Loss:  0.003564698100090027 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3383 | Train Loss:  0.0005695471912622452 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  3384 | Train Loss:  0.001631326675415039 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3385 | Train Loss:  0.004803443551063538 | Train Accuracy:  0.91 | Validation Accuracy:  0.52\n",
            "Iteration:  3386 | Train Loss:  0.0025015410780906675 | Train Accuracy:  0.97 | Validation Accuracy:  0.48\n",
            "Iteration:  3387 | Train Loss:  0.0006973066926002502 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  3388 | Train Loss:  0.0039376398921012875 | Train Accuracy:  0.77 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3389 | Train Loss:  0.003590472936630249 | Train Accuracy:  0.9585714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3390 | Train Loss:  0.0018734918534755707 | Train Accuracy:  0.9442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3391 | Train Loss:  0.0012692654132843019 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3392 | Train Loss:  0.005658301711082459 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3393 | Train Loss:  0.0023054543137550356 | Train Accuracy:  0.97 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3394 | Train Loss:  0.0014718598127365112 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3395 | Train Loss:  0.003866966962814331 | Train Accuracy:  0.95 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3396 | Train Loss:  0.002692342698574066 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3397 | Train Loss:  0.0005460033938288689 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3398 | Train Loss:  0.0016281358897686006 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3399 | Train Loss:  0.004272404015064239 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  3400 | Train Loss:  0.0017801207304000855 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3401 | Train Loss:  0.0007171517610549926 | Train Accuracy:  0.7957142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3402 | Train Loss:  0.0035894384980201723 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3403 | Train Loss:  0.003141317069530487 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3404 | Train Loss:  0.002043580263853073 | Train Accuracy:  0.9528571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3405 | Train Loss:  0.001071595847606659 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3406 | Train Loss:  0.00526155412197113 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3407 | Train Loss:  0.002778451442718506 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3408 | Train Loss:  0.0013235396146774293 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  3409 | Train Loss:  0.0030992478132247925 | Train Accuracy:  0.9242857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  3410 | Train Loss:  0.004197316467761994 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3411 | Train Loss:  0.0005554714798927307 | Train Accuracy:  0.8528571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3412 | Train Loss:  0.0016225461661815643 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3413 | Train Loss:  0.005488615036010742 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3414 | Train Loss:  0.0021878397464752198 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  3415 | Train Loss:  0.0007919133454561233 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  3416 | Train Loss:  0.0041402122378349305 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  3417 | Train Loss:  0.0034850090742111206 | Train Accuracy:  0.9571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3418 | Train Loss:  0.0019245243072509766 | Train Accuracy:  0.9471428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3419 | Train Loss:  0.0013114504516124725 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3420 | Train Loss:  0.005518384575843811 | Train Accuracy:  0.9142857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3421 | Train Loss:  0.002583841383457184 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3422 | Train Loss:  0.0014425899088382722 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  3423 | Train Loss:  0.0031588706374168396 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3424 | Train Loss:  0.003707258701324463 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3425 | Train Loss:  0.00057364322245121 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3426 | Train Loss:  0.0013581769168376924 | Train Accuracy:  0.75 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3427 | Train Loss:  0.005022390484809875 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  3428 | Train Loss:  0.0024852077662944794 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3429 | Train Loss:  0.0006615513563156128 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3430 | Train Loss:  0.00433812528848648 | Train Accuracy:  0.76 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3431 | Train Loss:  0.0036748385429382323 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3432 | Train Loss:  0.0018886567652225494 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3433 | Train Loss:  0.0011908204853534699 | Train Accuracy:  0.8614285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3434 | Train Loss:  0.005817198753356933 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3435 | Train Loss:  0.002604246437549591 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3436 | Train Loss:  0.0012482187151908874 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3437 | Train Loss:  0.003127970993518829 | Train Accuracy:  0.9128571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3438 | Train Loss:  0.004082416296005249 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3439 | Train Loss:  0.0006231230869889259 | Train Accuracy:  0.8728571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3440 | Train Loss:  0.0015101099014282226 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3441 | Train Loss:  0.005077368021011353 | Train Accuracy:  0.8814285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3442 | Train Loss:  0.0032510238885879515 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3443 | Train Loss:  0.0005624894052743912 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3444 | Train Loss:  0.0034851714968681335 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3445 | Train Loss:  0.0047544708847999575 | Train Accuracy:  0.9357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3446 | Train Loss:  0.0023899954557418824 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3447 | Train Loss:  0.0011146073043346405 | Train Accuracy:  0.83 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3448 | Train Loss:  0.006575794816017151 | Train Accuracy:  0.8957142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3449 | Train Loss:  0.0033707934617996215 | Train Accuracy:  0.97 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3450 | Train Loss:  0.0014917053282260894 | Train Accuracy:  0.8557142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3451 | Train Loss:  0.004925031960010528 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3452 | Train Loss:  0.003248957097530365 | Train Accuracy:  0.9557142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3453 | Train Loss:  0.0005874075368046761 | Train Accuracy:  0.8442857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3454 | Train Loss:  0.0016697809100151063 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3455 | Train Loss:  0.004694147109985352 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3456 | Train Loss:  0.0021141676604747774 | Train Accuracy:  0.9614285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3457 | Train Loss:  0.0006124873086810112 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3458 | Train Loss:  0.003456178605556488 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  3459 | Train Loss:  0.0037381675839424132 | Train Accuracy:  0.9228571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  3460 | Train Loss:  0.002591474950313568 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3461 | Train Loss:  0.0009510714560747146 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3462 | Train Loss:  0.005747706890106201 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3463 | Train Loss:  0.003985617756843567 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3464 | Train Loss:  0.0013408029079437255 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  3465 | Train Loss:  0.0030689412355422974 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  3466 | Train Loss:  0.006077956557273865 | Train Accuracy:  0.9714285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3467 | Train Loss:  0.0006722424179315567 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3468 | Train Loss:  0.0017416372895240784 | Train Accuracy:  0.7 | Validation Accuracy:  0.48\n",
            "Iteration:  3469 | Train Loss:  0.006708363890647888 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3470 | Train Loss:  0.0028525468707084655 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  3471 | Train Loss:  0.0007332520186901092 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  3472 | Train Loss:  0.004384908676147461 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  3473 | Train Loss:  0.004330420792102814 | Train Accuracy:  0.9371428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3474 | Train Loss:  0.002262285202741623 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3475 | Train Loss:  0.0012496587634086608 | Train Accuracy:  0.8385714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  3476 | Train Loss:  0.005881273746490478 | Train Accuracy:  0.8871428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3477 | Train Loss:  0.0035638430714607238 | Train Accuracy:  0.9671428571428572 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3478 | Train Loss:  0.0014743123948574065 | Train Accuracy:  0.9014285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3479 | Train Loss:  0.003129647970199585 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3480 | Train Loss:  0.005537059307098389 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  3481 | Train Loss:  0.000723121389746666 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  3482 | Train Loss:  0.0013239949941635132 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3483 | Train Loss:  0.0061242181062698365 | Train Accuracy:  0.8585714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3484 | Train Loss:  0.0034509384632110595 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3485 | Train Loss:  0.0005897539108991622 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  3486 | Train Loss:  0.0037462791800498964 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  3487 | Train Loss:  0.005316027402877808 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3488 | Train Loss:  0.002975681722164154 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3489 | Train Loss:  0.0010163749754428864 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3490 | Train Loss:  0.0067362385988235475 | Train Accuracy:  0.8471428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3491 | Train Loss:  0.0043410822749137875 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  3492 | Train Loss:  0.0014056670665740967 | Train Accuracy:  0.88 | Validation Accuracy:  0.54\n",
            "Iteration:  3493 | Train Loss:  0.0036853161454200745 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  3494 | Train Loss:  0.0059332305192947386 | Train Accuracy:  0.9728571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  3495 | Train Loss:  0.0007492288947105408 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3496 | Train Loss:  0.0013336215913295746 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  3497 | Train Loss:  0.006410336494445801 | Train Accuracy:  0.8414285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3498 | Train Loss:  0.0037450489401817323 | Train Accuracy:  0.9642857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  3499 | Train Loss:  0.000582372434437275 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.76\n",
            "Final Validation Accuracy: 0.52\n",
            "Maximum Training Accuracy: 0.9771428571428571\n",
            "Maximum Validation Accuracy: 0.5733333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6bR9mUTswMS"
      },
      "source": [
        "#### Time-Frequency Domain Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b16_1b6TRUa"
      },
      "source": [
        "##### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7-LoLdIs34p"
      },
      "source": [
        "train_dataset = createTensorDataset(X_train_wv, y_train_wv)\n",
        "val_dataset = createTensorDataset(X_val_wv, y_val_wv)\n",
        "\n",
        "#Downsample the height and width to make training easier\n",
        "train_dataset = downsampleTensorHW(train_dataset, 2)\n",
        "val_dataset = downsampleTensorHW(val_dataset, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tIokMkxolULF",
        "outputId": "651ed42f-f532-4347-8777-7a48f2698190"
      },
      "source": [
        "model = CNN_WV()\n",
        "train(model, train_dataset, val_dataset, batch_size = 20, num_epochs=15, learning_rate = 0.00025, momen = 0.4, use_adam = False, save_weights=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.0344363272190094 | Train Accuracy:  0.4828571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1 | Train Loss:  0.03526872396469116 | Train Accuracy:  0.4857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2 | Train Loss:  0.03467753529548645 | Train Accuracy:  0.4942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  3 | Train Loss:  0.035622885823249816 | Train Accuracy:  0.5028571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  4 | Train Loss:  0.0345097541809082 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  5 | Train Loss:  0.03390579223632813 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  6 | Train Loss:  0.034937348961830136 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  7 | Train Loss:  0.03477916717529297 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  8 | Train Loss:  0.03362263441085815 | Train Accuracy:  0.5 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  9 | Train Loss:  0.035621273517608645 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  10 | Train Loss:  0.03433466255664826 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  11 | Train Loss:  0.03556068539619446 | Train Accuracy:  0.56 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  12 | Train Loss:  0.034042105078697205 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  13 | Train Loss:  0.034402722120285036 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  14 | Train Loss:  0.03384956419467926 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  15 | Train Loss:  0.03518132269382477 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  16 | Train Loss:  0.03543078005313873 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  17 | Train Loss:  0.03511520028114319 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  18 | Train Loss:  0.0344515860080719 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  19 | Train Loss:  0.034818011522293094 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  20 | Train Loss:  0.03441956639289856 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  21 | Train Loss:  0.03524729311466217 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  22 | Train Loss:  0.033909177780151366 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  23 | Train Loss:  0.03348249793052673 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  24 | Train Loss:  0.03511476516723633 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  25 | Train Loss:  0.03449333310127258 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  26 | Train Loss:  0.033765488862991334 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  27 | Train Loss:  0.03490716814994812 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  28 | Train Loss:  0.03434332013130188 | Train Accuracy:  0.6 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  29 | Train Loss:  0.034841838479042056 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  30 | Train Loss:  0.03355701565742493 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  31 | Train Loss:  0.034620678424835204 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  32 | Train Loss:  0.03363692760467529 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  33 | Train Loss:  0.03488560318946839 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  34 | Train Loss:  0.034780532121658325 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  35 | Train Loss:  0.034934130311012265 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  36 | Train Loss:  0.034307864308357236 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  37 | Train Loss:  0.03453567624092102 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  38 | Train Loss:  0.03416983783245087 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  39 | Train Loss:  0.03487970530986786 | Train Accuracy:  0.62 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  40 | Train Loss:  0.033588549494743346 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  41 | Train Loss:  0.03317541480064392 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  42 | Train Loss:  0.03500811755657196 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  43 | Train Loss:  0.034310469031333925 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  44 | Train Loss:  0.03373755812644959 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  45 | Train Loss:  0.03455295562744141 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.6\n",
            "Iteration:  46 | Train Loss:  0.034113073348999025 | Train Accuracy:  0.64 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  47 | Train Loss:  0.03443373441696167 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  48 | Train Loss:  0.03331494927406311 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  49 | Train Loss:  0.03450320065021515 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  50 | Train Loss:  0.0334050178527832 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.6\n",
            "Iteration:  51 | Train Loss:  0.034591776132583615 | Train Accuracy:  0.64 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  52 | Train Loss:  0.034432914853096006 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  53 | Train Loss:  0.034672942757606504 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  54 | Train Loss:  0.034168434143066403 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  55 | Train Loss:  0.03429884910583496 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  56 | Train Loss:  0.033933711051940915 | Train Accuracy:  0.62 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  57 | Train Loss:  0.03454530537128449 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.64\n",
            "Iteration:  58 | Train Loss:  0.033344289660453795 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  59 | Train Loss:  0.03292518258094788 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  60 | Train Loss:  0.03478710055351257 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  61 | Train Loss:  0.03415694832801819 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  62 | Train Loss:  0.03361403346061707 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  63 | Train Loss:  0.03436390161514282 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  64 | Train Loss:  0.033790099620819095 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  65 | Train Loss:  0.03418295681476593 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.64\n",
            "Iteration:  66 | Train Loss:  0.03316120803356171 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  67 | Train Loss:  0.034316536784172055 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  68 | Train Loss:  0.03319196105003357 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  69 | Train Loss:  0.03430917263031006 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  70 | Train Loss:  0.03420486748218536 | Train Accuracy:  0.64 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  71 | Train Loss:  0.034362542629241946 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  72 | Train Loss:  0.034014204144477846 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  73 | Train Loss:  0.03401771783828735 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  74 | Train Loss:  0.03371434211730957 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  75 | Train Loss:  0.03425693809986115 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  76 | Train Loss:  0.03310892581939697 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.6\n",
            "Iteration:  77 | Train Loss:  0.032698386907577516 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  78 | Train Loss:  0.0345842182636261 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  79 | Train Loss:  0.03400298655033111 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.6\n",
            "Iteration:  80 | Train Loss:  0.033488374948501584 | Train Accuracy:  0.68 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  81 | Train Loss:  0.03416944444179535 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  82 | Train Loss:  0.03352706730365753 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  83 | Train Loss:  0.03393210768699646 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.64\n",
            "Iteration:  84 | Train Loss:  0.03301268219947815 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  85 | Train Loss:  0.034106120467185974 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  86 | Train Loss:  0.032989495992660524 | Train Accuracy:  0.66 | Validation Accuracy:  0.6\n",
            "Iteration:  87 | Train Loss:  0.03403860926628113 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  88 | Train Loss:  0.03396822810173035 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  89 | Train Loss:  0.034093576669692996 | Train Accuracy:  0.66 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  90 | Train Loss:  0.03384276032447815 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  91 | Train Loss:  0.03377125859260559 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  92 | Train Loss:  0.0335080623626709 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  93 | Train Loss:  0.033969318866729735 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.64\n",
            "Iteration:  94 | Train Loss:  0.03288956582546234 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  95 | Train Loss:  0.03247508406639099 | Train Accuracy:  0.66 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  96 | Train Loss:  0.03437914252281189 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  97 | Train Loss:  0.033857762813568115 | Train Accuracy:  0.68 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  98 | Train Loss:  0.03333363234996796 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  99 | Train Loss:  0.03400338292121887 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  100 | Train Loss:  0.033231419324874875 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  101 | Train Loss:  0.033697772026062014 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  102 | Train Loss:  0.03285366892814636 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  103 | Train Loss:  0.03392168581485748 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  104 | Train Loss:  0.032781746983528134 | Train Accuracy:  0.7 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  105 | Train Loss:  0.033779627084732054 | Train Accuracy:  0.7 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  106 | Train Loss:  0.03379747569561005 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  107 | Train Loss:  0.033803990483283995 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  108 | Train Loss:  0.0336943656206131 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.6\n",
            "Iteration:  109 | Train Loss:  0.033528557419776915 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.6\n",
            "Iteration:  110 | Train Loss:  0.03327881693840027 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.6\n",
            "Iteration:  111 | Train Loss:  0.03369772434234619 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  112 | Train Loss:  0.03264879584312439 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.6\n",
            "Iteration:  113 | Train Loss:  0.03223805725574493 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  114 | Train Loss:  0.03422413766384125 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  115 | Train Loss:  0.03373792469501495 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  116 | Train Loss:  0.03322439193725586 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  117 | Train Loss:  0.03379876613616943 | Train Accuracy:  0.7 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  118 | Train Loss:  0.03297402560710907 | Train Accuracy:  0.72 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  119 | Train Loss:  0.03347526490688324 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  120 | Train Loss:  0.032695522904396056 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  121 | Train Loss:  0.03370049595832825 | Train Accuracy:  0.7 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  122 | Train Loss:  0.03258225917816162 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  123 | Train Loss:  0.03355026841163635 | Train Accuracy:  0.72 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  124 | Train Loss:  0.03355815708637237 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  125 | Train Loss:  0.033508273959159854 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  126 | Train Loss:  0.033522605895996094 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.6\n",
            "Iteration:  127 | Train Loss:  0.033300721645355226 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  128 | Train Loss:  0.033046764135360715 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  129 | Train Loss:  0.033445915579795836 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  130 | Train Loss:  0.03246323466300964 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  131 | Train Loss:  0.032006242871284486 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  132 | Train Loss:  0.034001460671424864 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  133 | Train Loss:  0.03358942866325378 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  134 | Train Loss:  0.033083492517471315 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  135 | Train Loss:  0.03363434076309204 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  136 | Train Loss:  0.032738405466079715 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.6266666666666667\n",
            "Iteration:  137 | Train Loss:  0.033236318826675416 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  138 | Train Loss:  0.03253779411315918 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  139 | Train Loss:  0.033494284749031066 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  140 | Train Loss:  0.03239371180534363 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  141 | Train Loss:  0.033301007747650144 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  142 | Train Loss:  0.03332304358482361 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  143 | Train Loss:  0.03323696851730347 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  144 | Train Loss:  0.03337675929069519 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  145 | Train Loss:  0.03305933177471161 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  146 | Train Loss:  0.032824674248695375 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  147 | Train Loss:  0.03318820595741272 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.6\n",
            "Iteration:  148 | Train Loss:  0.0322591245174408 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  149 | Train Loss:  0.03178328573703766 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  150 | Train Loss:  0.03379352688789368 | Train Accuracy:  0.72 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  151 | Train Loss:  0.03344569504261017 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  152 | Train Loss:  0.0329530268907547 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.6\n",
            "Iteration:  153 | Train Loss:  0.03344970643520355 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.6\n",
            "Iteration:  154 | Train Loss:  0.032481136918067935 | Train Accuracy:  0.76 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  155 | Train Loss:  0.033015137910842894 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  156 | Train Loss:  0.03234914541244507 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  157 | Train Loss:  0.03335018455982208 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  158 | Train Loss:  0.03221073150634766 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  159 | Train Loss:  0.03304903209209442 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  160 | Train Loss:  0.033076658844947815 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  161 | Train Loss:  0.032972913980484006 | Train Accuracy:  0.72 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  162 | Train Loss:  0.033241158723831175 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  163 | Train Loss:  0.032822543382644655 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  164 | Train Loss:  0.03260424733161926 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  165 | Train Loss:  0.03295489549636841 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.6\n",
            "Iteration:  166 | Train Loss:  0.03205046355724335 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  167 | Train Loss:  0.03153777718544006 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  168 | Train Loss:  0.03361632227897644 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  169 | Train Loss:  0.033301559090614316 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  170 | Train Loss:  0.03282774388790131 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  171 | Train Loss:  0.03328642249107361 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  172 | Train Loss:  0.03224325478076935 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.6\n",
            "Iteration:  173 | Train Loss:  0.03280550539493561 | Train Accuracy:  0.76 | Validation Accuracy:  0.6\n",
            "Iteration:  174 | Train Loss:  0.032194823026657104 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  175 | Train Loss:  0.03315592110157013 | Train Accuracy:  0.76 | Validation Accuracy:  0.6\n",
            "Iteration:  176 | Train Loss:  0.032025200128555295 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  177 | Train Loss:  0.03281850814819336 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  178 | Train Loss:  0.03286997377872467 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  179 | Train Loss:  0.03270338177680969 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  180 | Train Loss:  0.03310917317867279 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  181 | Train Loss:  0.032589465379714966 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  182 | Train Loss:  0.032385116815567015 | Train Accuracy:  0.76 | Validation Accuracy:  0.56\n",
            "Iteration:  183 | Train Loss:  0.03270609378814697 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  184 | Train Loss:  0.03185875415802002 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  185 | Train Loss:  0.03131708204746246 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  186 | Train Loss:  0.033427664637565614 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  187 | Train Loss:  0.033147412538528445 | Train Accuracy:  0.78 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  188 | Train Loss:  0.03270358443260193 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  189 | Train Loss:  0.03307637572288513 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  190 | Train Loss:  0.03200288712978363 | Train Accuracy:  0.78 | Validation Accuracy:  0.6\n",
            "Iteration:  191 | Train Loss:  0.03258107602596283 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.6\n",
            "Iteration:  192 | Train Loss:  0.032035037875175476 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  193 | Train Loss:  0.03298937380313873 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  194 | Train Loss:  0.031846100091934205 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  195 | Train Loss:  0.03258811235427857 | Train Accuracy:  0.8 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  196 | Train Loss:  0.03268770277500153 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  197 | Train Loss:  0.03241835534572601 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  198 | Train Loss:  0.03299678564071655 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  199 | Train Loss:  0.0323618084192276 | Train Accuracy:  0.76 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  200 | Train Loss:  0.03214489221572876 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  201 | Train Loss:  0.03250130414962769 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  202 | Train Loss:  0.031646886467933656 | Train Accuracy:  0.76 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  203 | Train Loss:  0.031071946024894714 | Train Accuracy:  0.74 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  204 | Train Loss:  0.033216634392738344 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  205 | Train Loss:  0.033026525378227235 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  206 | Train Loss:  0.03254435956478119 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  207 | Train Loss:  0.03293383717536926 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.64\n",
            "Iteration:  208 | Train Loss:  0.03173607289791107 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  209 | Train Loss:  0.03239431083202362 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.6\n",
            "Iteration:  210 | Train Loss:  0.03188335597515106 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  211 | Train Loss:  0.03278031945228577 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  212 | Train Loss:  0.03168434798717499 | Train Accuracy:  0.8 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  213 | Train Loss:  0.03235836923122406 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  214 | Train Loss:  0.03253044486045838 | Train Accuracy:  0.76 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  215 | Train Loss:  0.03213127851486206 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  216 | Train Loss:  0.03287019729614258 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  217 | Train Loss:  0.03212202191352844 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  218 | Train Loss:  0.03190385699272156 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  219 | Train Loss:  0.032271581888198855 | Train Accuracy:  0.8 | Validation Accuracy:  0.56\n",
            "Iteration:  220 | Train Loss:  0.03145397007465363 | Train Accuracy:  0.78 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  221 | Train Loss:  0.03086470365524292 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.6133333333333333\n",
            "Iteration:  222 | Train Loss:  0.03301554322242737 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  223 | Train Loss:  0.03286478817462921 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  224 | Train Loss:  0.032390272617340087 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  225 | Train Loss:  0.0327321857213974 | Train Accuracy:  0.8 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  226 | Train Loss:  0.0315039336681366 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  227 | Train Loss:  0.03217896521091461 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  228 | Train Loss:  0.031727734208107 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.6\n",
            "Iteration:  229 | Train Loss:  0.03257504999637604 | Train Accuracy:  0.8 | Validation Accuracy:  0.56\n",
            "Iteration:  230 | Train Loss:  0.03150443732738495 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  231 | Train Loss:  0.03214097023010254 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  232 | Train Loss:  0.03235557377338409 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  233 | Train Loss:  0.03186020255088806 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  234 | Train Loss:  0.03272790908813476 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  235 | Train Loss:  0.031884396076202394 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  236 | Train Loss:  0.031675925850868224 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  237 | Train Loss:  0.0320415735244751 | Train Accuracy:  0.8 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  238 | Train Loss:  0.03126011490821838 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.6\n",
            "Iteration:  239 | Train Loss:  0.03062019348144531 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.6\n",
            "Iteration:  240 | Train Loss:  0.03281229138374329 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  241 | Train Loss:  0.03271464705467224 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  242 | Train Loss:  0.032248812913894656 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  243 | Train Loss:  0.032526654005050656 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  244 | Train Loss:  0.031245440244674683 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  245 | Train Loss:  0.031961303949356076 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  246 | Train Loss:  0.031536069512367246 | Train Accuracy:  0.76 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  247 | Train Loss:  0.032451510429382324 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  248 | Train Loss:  0.031328755617141726 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  249 | Train Loss:  0.03190707564353943 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  250 | Train Loss:  0.032149726152420045 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  251 | Train Loss:  0.03162407577037811 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  252 | Train Loss:  0.032598116993904115 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  253 | Train Loss:  0.03163959383964539 | Train Accuracy:  0.8 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  254 | Train Loss:  0.03146256804466248 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  255 | Train Loss:  0.031806057691574095 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  256 | Train Loss:  0.03106740415096283 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  257 | Train Loss:  0.030409741401672363 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.6\n",
            "Iteration:  258 | Train Loss:  0.03260231614112854 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  259 | Train Loss:  0.032556730508804324 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  260 | Train Loss:  0.03208241164684296 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  261 | Train Loss:  0.03235553205013275 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  262 | Train Loss:  0.03099108040332794 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  263 | Train Loss:  0.03173081278800964 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  264 | Train Loss:  0.031349393725395205 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  265 | Train Loss:  0.032271969318389895 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  266 | Train Loss:  0.031159716844558715 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  267 | Train Loss:  0.03167577981948853 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  268 | Train Loss:  0.031959453225135805 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  269 | Train Loss:  0.03136081397533417 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5866666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.8057142857142857\n",
            "Final Validation Accuracy: 0.5866666666666667\n",
            "Maximum Training Accuracy: 0.8457142857142858\n",
            "Maximum Validation Accuracy: 0.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7MyAyepHncNE",
        "outputId": "cd48cc29-0a97-4a31-bff4-da01ebd62ecd"
      },
      "source": [
        "model = CNN_WV()\n",
        "train(model, train_dataset, val_dataset, batch_size = 20, num_epochs=15, learning_rate = 0.0003, momen = 0.4, use_adam = False, save_weights=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.03468606173992157 | Train Accuracy:  0.4942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1 | Train Loss:  0.03460254967212677 | Train Accuracy:  0.4942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2 | Train Loss:  0.034476035833358766 | Train Accuracy:  0.5028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3 | Train Loss:  0.03520435094833374 | Train Accuracy:  0.5028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  4 | Train Loss:  0.03423711657524109 | Train Accuracy:  0.5028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  5 | Train Loss:  0.03477444648742676 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  6 | Train Loss:  0.0345884770154953 | Train Accuracy:  0.5057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  7 | Train Loss:  0.03470664620399475 | Train Accuracy:  0.5057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  8 | Train Loss:  0.03506752550601959 | Train Accuracy:  0.5057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  9 | Train Loss:  0.03418151438236237 | Train Accuracy:  0.5028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  10 | Train Loss:  0.034509068727493285 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  11 | Train Loss:  0.0353096753358841 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  12 | Train Loss:  0.03433580994606018 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  13 | Train Loss:  0.035717743635177615 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  14 | Train Loss:  0.03494772613048554 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  15 | Train Loss:  0.03404841721057892 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  16 | Train Loss:  0.03428349494934082 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  17 | Train Loss:  0.03368962109088898 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  18 | Train Loss:  0.034676355123519895 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  19 | Train Loss:  0.03448610305786133 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  20 | Train Loss:  0.03445633053779602 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  21 | Train Loss:  0.03506761491298675 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  22 | Train Loss:  0.03413126468658447 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  23 | Train Loss:  0.0346809059381485 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  24 | Train Loss:  0.034564542770385745 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  25 | Train Loss:  0.03462448716163635 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  26 | Train Loss:  0.03505335450172424 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  27 | Train Loss:  0.034010502696037295 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  28 | Train Loss:  0.03451652228832245 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  29 | Train Loss:  0.03507894575595856 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  30 | Train Loss:  0.034216827154159545 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  31 | Train Loss:  0.035694637894630434 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  32 | Train Loss:  0.03484092354774475 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  33 | Train Loss:  0.033971387147903445 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  34 | Train Loss:  0.0341057151556015 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  35 | Train Loss:  0.0336267352104187 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  36 | Train Loss:  0.03464432656764984 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  37 | Train Loss:  0.03437067866325379 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  38 | Train Loss:  0.03441598415374756 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  39 | Train Loss:  0.034941858053207396 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  40 | Train Loss:  0.03403764367103577 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  41 | Train Loss:  0.03461023867130279 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  42 | Train Loss:  0.03451432585716248 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  43 | Train Loss:  0.03455124497413635 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  44 | Train Loss:  0.03498864769935608 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  45 | Train Loss:  0.03390732407569885 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  46 | Train Loss:  0.03448468148708343 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  47 | Train Loss:  0.034914106130599976 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  48 | Train Loss:  0.0341339647769928 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  49 | Train Loss:  0.03564444184303284 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  50 | Train Loss:  0.034744182229042055 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  51 | Train Loss:  0.03389312624931336 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  52 | Train Loss:  0.03398234248161316 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  53 | Train Loss:  0.03355511724948883 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  54 | Train Loss:  0.03461064696311951 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  55 | Train Loss:  0.03427098393440246 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  56 | Train Loss:  0.03436698019504547 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  57 | Train Loss:  0.034828943014144895 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  58 | Train Loss:  0.03395220637321472 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  59 | Train Loss:  0.03454872071743011 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  60 | Train Loss:  0.034455642104148865 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  61 | Train Loss:  0.03449060320854187 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  62 | Train Loss:  0.034920293092727664 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  63 | Train Loss:  0.033820897340774536 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  64 | Train Loss:  0.03444066941738129 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  65 | Train Loss:  0.03477530777454376 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  66 | Train Loss:  0.03406751751899719 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  67 | Train Loss:  0.035583320260047915 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  68 | Train Loss:  0.03465433120727539 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  69 | Train Loss:  0.03382104337215423 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  70 | Train Loss:  0.03389186859130859 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  71 | Train Loss:  0.03347218036651611 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  72 | Train Loss:  0.03457193374633789 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  73 | Train Loss:  0.034179466962814334 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  74 | Train Loss:  0.034312331676483156 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  75 | Train Loss:  0.03471871316432953 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  76 | Train Loss:  0.03387596607208252 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  77 | Train Loss:  0.03448805809020996 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  78 | Train Loss:  0.03439095616340637 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  79 | Train Loss:  0.034432679414749146 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  80 | Train Loss:  0.03485662639141083 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  81 | Train Loss:  0.03373759388923645 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  82 | Train Loss:  0.03438919186592102 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  83 | Train Loss:  0.034649410843849184 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  84 | Train Loss:  0.034001654386520384 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  85 | Train Loss:  0.03553160727024078 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  86 | Train Loss:  0.034572634100914004 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  87 | Train Loss:  0.03375146985054016 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  88 | Train Loss:  0.03379727005958557 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  89 | Train Loss:  0.03339570760726929 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  90 | Train Loss:  0.034534066915512085 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  91 | Train Loss:  0.03408574461936951 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  92 | Train Loss:  0.034255105257034305 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  93 | Train Loss:  0.03460990786552429 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  94 | Train Loss:  0.03380623757839203 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  95 | Train Loss:  0.034430915117263795 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  96 | Train Loss:  0.0343269407749176 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  97 | Train Loss:  0.03437698483467102 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  98 | Train Loss:  0.03479364812374115 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  99 | Train Loss:  0.03366114497184754 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  100 | Train Loss:  0.034332916140556335 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  101 | Train Loss:  0.03453051745891571 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  102 | Train Loss:  0.03393508791923523 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  103 | Train Loss:  0.035471987724304196 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  104 | Train Loss:  0.034485599398612975 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  105 | Train Loss:  0.033680886030197144 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  106 | Train Loss:  0.033712783455848695 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  107 | Train Loss:  0.03331705927848816 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  108 | Train Loss:  0.03449736535549164 | Train Accuracy:  0.58 | Validation Accuracy:  0.48\n",
            "Iteration:  109 | Train Loss:  0.033999717235565184 | Train Accuracy:  0.58 | Validation Accuracy:  0.48\n",
            "Iteration:  110 | Train Loss:  0.03419749736785889 | Train Accuracy:  0.58 | Validation Accuracy:  0.48\n",
            "Iteration:  111 | Train Loss:  0.03450060486793518 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  112 | Train Loss:  0.033740824460983275 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  113 | Train Loss:  0.03437226414680481 | Train Accuracy:  0.58 | Validation Accuracy:  0.48\n",
            "Iteration:  114 | Train Loss:  0.034260088205337526 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  115 | Train Loss:  0.034324252605438234 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  116 | Train Loss:  0.03471871018409729 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  117 | Train Loss:  0.033604162931442264 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  118 | Train Loss:  0.034253448247909546 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  119 | Train Loss:  0.034447023272514345 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  120 | Train Loss:  0.03388969600200653 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  121 | Train Loss:  0.03539077639579773 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  122 | Train Loss:  0.03440277278423309 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  123 | Train Loss:  0.03360745012760162 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  124 | Train Loss:  0.03364906907081604 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  125 | Train Loss:  0.0332366555929184 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  126 | Train Loss:  0.034453803300857545 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  127 | Train Loss:  0.03391810953617096 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  128 | Train Loss:  0.03413406312465668 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  129 | Train Loss:  0.03438892960548401 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  130 | Train Loss:  0.03369441628456116 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  131 | Train Loss:  0.03432338833808899 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  132 | Train Loss:  0.034169751405715945 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  133 | Train Loss:  0.03427363336086273 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  134 | Train Loss:  0.034651821851730345 | Train Accuracy:  0.6 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  135 | Train Loss:  0.033543330430984494 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  136 | Train Loss:  0.03418206572532654 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  137 | Train Loss:  0.034343117475509645 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  138 | Train Loss:  0.03383931517601013 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  139 | Train Loss:  0.035310035943984984 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  140 | Train Loss:  0.034318336844444276 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  141 | Train Loss:  0.033545634150505065 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  142 | Train Loss:  0.03357885181903839 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  143 | Train Loss:  0.03314118981361389 | Train Accuracy:  0.6 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  144 | Train Loss:  0.034416377544403076 | Train Accuracy:  0.6 | Validation Accuracy:  0.48\n",
            "Iteration:  145 | Train Loss:  0.033840125799179076 | Train Accuracy:  0.6 | Validation Accuracy:  0.48\n",
            "Iteration:  146 | Train Loss:  0.03406612575054169 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  147 | Train Loss:  0.03427289426326752 | Train Accuracy:  0.6 | Validation Accuracy:  0.48\n",
            "Iteration:  148 | Train Loss:  0.03364820182323456 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  149 | Train Loss:  0.03428110480308533 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  150 | Train Loss:  0.034083437919616696 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  151 | Train Loss:  0.034223359823226926 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  152 | Train Loss:  0.03456755876541138 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  153 | Train Loss:  0.03349263072013855 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  154 | Train Loss:  0.034093844890594485 | Train Accuracy:  0.62 | Validation Accuracy:  0.48\n",
            "Iteration:  155 | Train Loss:  0.03426793813705444 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  156 | Train Loss:  0.033802494406700134 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  157 | Train Loss:  0.035208660364151004 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  158 | Train Loss:  0.034235239028930664 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  159 | Train Loss:  0.03348335921764374 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  160 | Train Loss:  0.03353514969348907 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  161 | Train Loss:  0.03302995264530182 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  162 | Train Loss:  0.034372645616531375 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  163 | Train Loss:  0.03375940322875977 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  164 | Train Loss:  0.03399316966533661 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  165 | Train Loss:  0.034164565801620486 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  166 | Train Loss:  0.03360660076141357 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  167 | Train Loss:  0.03423531055450439 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  168 | Train Loss:  0.0339980810880661 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  169 | Train Loss:  0.034171515703201295 | Train Accuracy:  0.62 | Validation Accuracy:  0.48\n",
            "Iteration:  170 | Train Loss:  0.03449118733406067 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  171 | Train Loss:  0.03343144953250885 | Train Accuracy:  0.62 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  172 | Train Loss:  0.034009295701980594 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  173 | Train Loss:  0.03419146239757538 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  174 | Train Loss:  0.03376772999763489 | Train Accuracy:  0.62 | Validation Accuracy:  0.48\n",
            "Iteration:  175 | Train Loss:  0.03510777056217194 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  176 | Train Loss:  0.03414921164512634 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  177 | Train Loss:  0.03341826796531677 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  178 | Train Loss:  0.03349877893924713 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  179 | Train Loss:  0.032921820878982544 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  180 | Train Loss:  0.0343298077583313 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  181 | Train Loss:  0.03368096053600311 | Train Accuracy:  0.62 | Validation Accuracy:  0.48\n",
            "Iteration:  182 | Train Loss:  0.03392069935798645 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  183 | Train Loss:  0.03406843245029449 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  184 | Train Loss:  0.03356326520442963 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  185 | Train Loss:  0.03419206142425537 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  186 | Train Loss:  0.03391081988811493 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  187 | Train Loss:  0.03412366807460785 | Train Accuracy:  0.64 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  188 | Train Loss:  0.03441886901855469 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  189 | Train Loss:  0.033374708890914914 | Train Accuracy:  0.64 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  190 | Train Loss:  0.03393596410751343 | Train Accuracy:  0.64 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  191 | Train Loss:  0.03410385251045227 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  192 | Train Loss:  0.03371421694755554 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  193 | Train Loss:  0.03503401875495911 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  194 | Train Loss:  0.03406733572483063 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  195 | Train Loss:  0.033357685804367064 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  196 | Train Loss:  0.03339712023735046 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  197 | Train Loss:  0.03283622562885284 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  198 | Train Loss:  0.03428942561149597 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  199 | Train Loss:  0.03360576927661896 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  200 | Train Loss:  0.03385115265846252 | Train Accuracy:  0.64 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  201 | Train Loss:  0.03398444652557373 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  202 | Train Loss:  0.03351203501224518 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  203 | Train Loss:  0.03414061665534973 | Train Accuracy:  0.64 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  204 | Train Loss:  0.03383329808712006 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  205 | Train Loss:  0.03407287299633026 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  206 | Train Loss:  0.034346333146095274 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  207 | Train Loss:  0.03332619369029999 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  208 | Train Loss:  0.03385831713676453 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  209 | Train Loss:  0.03402187824249268 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  210 | Train Loss:  0.03367168307304382 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  211 | Train Loss:  0.03494333624839783 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  212 | Train Loss:  0.03399302959442139 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  213 | Train Loss:  0.033295619487762454 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  214 | Train Loss:  0.03333455920219421 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  215 | Train Loss:  0.03274873197078705 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  216 | Train Loss:  0.03425690233707428 | Train Accuracy:  0.64 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  217 | Train Loss:  0.03352463245391846 | Train Accuracy:  0.64 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  218 | Train Loss:  0.03379702270030975 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  219 | Train Loss:  0.0338914692401886 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  220 | Train Loss:  0.03346269726753235 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  221 | Train Loss:  0.03407300114631653 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  222 | Train Loss:  0.03377107977867126 | Train Accuracy:  0.66 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  223 | Train Loss:  0.03402319550514221 | Train Accuracy:  0.66 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  224 | Train Loss:  0.0343015730381012 | Train Accuracy:  0.66 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  225 | Train Loss:  0.03326573371887207 | Train Accuracy:  0.66 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  226 | Train Loss:  0.033782166242599485 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  227 | Train Loss:  0.03394149541854859 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  228 | Train Loss:  0.03362394571304321 | Train Accuracy:  0.64 | Validation Accuracy:  0.48\n",
            "Iteration:  229 | Train Loss:  0.034861615300178526 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  230 | Train Loss:  0.03392117917537689 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  231 | Train Loss:  0.03323270380496979 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  232 | Train Loss:  0.0332638680934906 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  233 | Train Loss:  0.03267043232917786 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  234 | Train Loss:  0.034221047163009645 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  235 | Train Loss:  0.03344222009181976 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  236 | Train Loss:  0.033733388781547545 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  237 | Train Loss:  0.03379930555820465 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  238 | Train Loss:  0.03339985013008118 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  239 | Train Loss:  0.03402349352836609 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  240 | Train Loss:  0.03369341492652893 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  241 | Train Loss:  0.033966952562332155 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  242 | Train Loss:  0.034235960245132445 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  243 | Train Loss:  0.03320889174938202 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  244 | Train Loss:  0.03369858264923096 | Train Accuracy:  0.68 | Validation Accuracy:  0.48\n",
            "Iteration:  245 | Train Loss:  0.033858072757720944 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  246 | Train Loss:  0.033579897880554196 | Train Accuracy:  0.66 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  247 | Train Loss:  0.03478106260299683 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  248 | Train Loss:  0.03384716510772705 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  249 | Train Loss:  0.03317585587501526 | Train Accuracy:  0.68 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  250 | Train Loss:  0.03318159282207489 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  251 | Train Loss:  0.03259214460849762 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  252 | Train Loss:  0.03417964577674866 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  253 | Train Loss:  0.033364468812942506 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  254 | Train Loss:  0.033661818504333495 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.4666666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-fd9587f97985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_WV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_adam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-b26df35304af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, val_dataset, batch_size, num_epochs, learning_rate, momen, use_cuda, use_adam, save_weights)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0miters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# compute *average* loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute training accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mval_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# compute validation accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"| Train Loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"| Train Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"| Validation Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-2a2bbc9c2451>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(model, data_loader, train, use_cuda)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-f403dc54e718>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#flatten the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b93VlyYuTxPf"
      },
      "source": [
        "##### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn-3yqTTTzL6"
      },
      "source": [
        "train_dataset = createTensorDataset(X_train2_wv, y_train2_wv)\n",
        "val_dataset = createTensorDataset(X_val2_wv, y_val2_wv)\n",
        "\n",
        "#Downsample the height and width to make training easier\n",
        "train_dataset = downsampleTensorHW(train_dataset, 2)\n",
        "val_dataset = downsampleTensorHW(val_dataset, 2)\n",
        "\n",
        "print(\"Train Data Shape: \", train_dataset.tensors[0].shape)\n",
        "print(\"Train Labels Shape: \", train_dataset.tensors[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YU3KlwRU4pY"
      },
      "source": [
        "model = CNN2_WV()\n",
        "train(model, train_dataset, val_dataset, batch_size = 15, num_epochs=15, learning_rate = 0.0005, momen = 0.55, use_adam = True, save_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}