{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG_Classification_Model_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7qq8shK0KRqRhRg4TnWAp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhanwadia/EEGClassification/blob/Farhan/EEG_Classification_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNGbjcY_pmoW"
      },
      "source": [
        "# EEG Classification Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R2YgRFEXx6I"
      },
      "source": [
        "## 1. Clone the GitHub Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXv7k4iwXM4j",
        "outputId": "fa6d82e4-3c1a-470d-c877-74946188867b"
      },
      "source": [
        "!git clone https://github.com/farhanwadia/EEGClassification\r\n",
        "!cd EEGClassification && git checkout Farhan\r\n",
        "\r\n",
        "#Change the working directory to the EEGClassification folder \r\n",
        "%cd EEGClassification\r\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EEGClassification'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 10585 (delta 15), reused 2 (delta 0), pack-reused 10538\u001b[K\n",
            "Receiving objects: 100% (10585/10585), 3.97 GiB | 25.64 MiB/s, done.\n",
            "Resolving deltas: 100% (525/525), done.\n",
            "Checking out files: 100% (10476/10476), done.\n",
            "Checking out files: 100% (3968/3968), done.\n",
            "Branch 'Farhan' set up to track remote branch 'Farhan' from 'origin'.\n",
            "Switched to a new branch 'Farhan'\n",
            "/content/EEGClassification\n",
            "/content/EEGClassification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-nWvGasqRnV"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J1KleV0pxZ8"
      },
      "source": [
        "#!pip install mne\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "#import mne\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.animation as animation\r\n",
        "from sklearn import svm\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "import pickle\r\n",
        "\r\n",
        "import csv\r\n",
        "import json\r\n",
        "from datetime import datetime\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch.optim as optim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNa6GwZGrGil"
      },
      "source": [
        "## 2. Split data into training, validation, and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mub_0BwqqLoG"
      },
      "source": [
        "def loadCSV(filename):\r\n",
        "    # Takes in a string of the csv file name where the EEG data is (# of measurements by 4 channels)\r\n",
        "    # Returns the data as an np array, transposed, with all values /10**6\r\n",
        "    data = np.loadtxt(filename, delimiter=',')\r\n",
        "    data = data.T / 10**6\r\n",
        "    return data\r\n",
        "\r\n",
        "def jsonToNp(pathToJSON):\r\n",
        "    with open(pathToJSON, \"r\") as f:\r\n",
        "        data = np.array(json.load(f))\r\n",
        "    return data \r\n",
        "\r\n",
        "def getFiles(parentPath):\r\n",
        "    # Returns all files in the folder and its subfolders as a list\r\n",
        "    listOfFiles = list()\r\n",
        "    for (dirpath, dirnames, filenames) in os.walk(parentPath):\r\n",
        "        listOfFiles += [os.path.join(dirpath, file) for file in filenames]\r\n",
        "    return listOfFiles\r\n",
        "\r\n",
        "def createDataset(openFiles, closedFiles):\r\n",
        "    n = len(openFiles) + len(closedFiles)\r\n",
        "    w = loadCSV(openFiles[0]).shape[0]\r\n",
        "    h = loadCSV(openFiles[0]).shape[1]\r\n",
        "\r\n",
        "    X = np.zeros((n, w, h))\r\n",
        "    y = np.zeros((n))\r\n",
        "    filenames = []\r\n",
        "\r\n",
        "    # Put files into np arrays. \r\n",
        "    #Assumes all data has already been cut to correct lengths, with no inconsistincies in the numper of data points between files\r\n",
        "    i = 0\r\n",
        "    for lst in [openFiles, closedFiles]:\r\n",
        "        for file in lst:\r\n",
        "            data = loadCSV(file)\r\n",
        "            X[i] = data\r\n",
        "            if lst == openFiles:\r\n",
        "                y[i] = 1            #Label 1: Open\r\n",
        "            else:\r\n",
        "                y[i] = 0            #Label 0: Closed\r\n",
        "\r\n",
        "            name = file.split(r\"\\\\\")[-1].split(\".\")[0]\r\n",
        "            filenames.append(name)\r\n",
        "            i = i+1\r\n",
        "    return X, y, filenames\r\n",
        "\r\n",
        "def createDatasetFromJSON(openFiles, closedFiles):\r\n",
        "    n = len(openFiles) + len(closedFiles)\r\n",
        "    c = jsonToNp(openFiles[0]).shape[0]\r\n",
        "    h = jsonToNp(openFiles[0]).shape[1]\r\n",
        "    w = jsonToNp(openFiles[0]).shape[2]\r\n",
        "\r\n",
        "    X = np.zeros((n, c, h, w))\r\n",
        "    y = np.zeros((n))\r\n",
        "    filenames = []\r\n",
        "    \r\n",
        "    # Put files into np arrays.\r\n",
        "    i = 0\r\n",
        "    for lst in [openFiles, closedFiles]:\r\n",
        "        for file in lst:\r\n",
        "            data = jsonToNp(file)\r\n",
        "            X[i] = data\r\n",
        "            if lst == openFiles:\r\n",
        "                y[i] = 1            #Label 1: Open\r\n",
        "            else:\r\n",
        "                y[i] = 0            #Label 0: Closed\r\n",
        "\r\n",
        "            name = file.split(r\"\\\\\")[-1].split(\".\")[0]\r\n",
        "            filenames.append(name)\r\n",
        "            i = i+1\r\n",
        "    return X, y, filenames\r\n",
        "\r\n",
        "\r\n",
        "def shuffleDataset(X, y, filenames):\r\n",
        "    indices = np.arange(X.shape[0])\r\n",
        "    seed = 21 \r\n",
        "    np.random.seed(seed)\r\n",
        "    np.random.shuffle(indices)\r\n",
        "    X = X[indices]\r\n",
        "    y = y[indices]\r\n",
        "    filenames = np.array(filenames)\r\n",
        "    filenames = filenames[indices]\r\n",
        "    return X, y, filenames\r\n",
        "\r\n",
        "def splitDataset(X, y, filenames, percent_train):\r\n",
        "    n = X.shape[0]\r\n",
        "    X_train = X[:int(percent_train*n)]\r\n",
        "    X_val = X[int(percent_train*n):]\r\n",
        "    y_train = y[:int(percent_train*n)]\r\n",
        "    y_val = y[int(percent_train*n):]\r\n",
        "    filenames_train = filenames[:int(percent_train*n)]\r\n",
        "    filenames_val = filenames[int(percent_train*n):]\r\n",
        "    return X_train, y_train, filenames_train, X_val, y_val, filenames_val"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdgHI_1wU0dh"
      },
      "source": [
        "### Time Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZBg0Y3RUhW6"
      },
      "source": [
        "#### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBLWqP6bYKW2",
        "outputId": "fa39bacf-3f48-41c9-b37e-52bad05558e5"
      },
      "source": [
        "openPath = os.getcwd() + r\"//Nov 2020 Filtered Data//5s//OPEN//\"\r\n",
        "closedPath = os.getcwd() + r\"//Nov 2020 Filtered Data//5s//CLOSE//\"\r\n",
        "openPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//5s//OPEN//\"\r\n",
        "closedPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//5s//CLOSE//\"\r\n",
        "openFiles = getFiles(openPath) + getFiles(openPath2)\r\n",
        "closedFiles = getFiles(closedPath) + getFiles(closedPath2) \r\n",
        "\r\n",
        "X, y, filenames = createDataset(openFiles, closedFiles)\r\n",
        "X, y, filenames = shuffleDataset(X, y, filenames)\r\n",
        "X_train, y_train, filenames_train, X_other, y_other, filenames_other = splitDataset(X, y, filenames, percent_train=0.7)\r\n",
        "X_val, y_val, filenames_val, X_test, y_test, filenames_test = splitDataset(X_other, y_other, filenames_other, percent_train=0.5) \r\n",
        "\r\n",
        "print(\"X_train Shape: \", X_train.shape)\r\n",
        "print(\"y_train Shape: \", y_train.shape)\r\n",
        "print(\"X_val Shape: \", X_val.shape)\r\n",
        "print(\"y_val Shape: \", y_val.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape:  (350, 4, 1280)\n",
            "y_train Shape:  (350,)\n",
            "X_val Shape:  (75, 4, 1280)\n",
            "y_val Shape:  (75,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tUAxmirUmcC"
      },
      "source": [
        "#### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMUajSIm9BHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc25861-9649-46e7-e8d7-0aef93c12ea1"
      },
      "source": [
        "openPath = os.getcwd() + r\"//Nov 2020 Filtered Data//2x3_5s//OPEN//\"\r\n",
        "closedPath = os.getcwd() + r\"//Nov 2020 Filtered Data//2x3_5s//CLOSE//\"\r\n",
        "openPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//2x3_5s//OPEN//\"\r\n",
        "closedPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//2x3_5s//CLOSE//\"\r\n",
        "openFiles = getFiles(openPath) + getFiles(openPath2)\r\n",
        "closedFiles = getFiles(closedPath) + getFiles(closedPath2) \r\n",
        "\r\n",
        "X, y, filenames = createDataset(openFiles, closedFiles)\r\n",
        "X, y, filenames = shuffleDataset(X, y, filenames)\r\n",
        "X2_train, y2_train, filenames2_train, X_other, y_other, filenames_other = splitDataset(X, y, filenames, percent_train=0.7)\r\n",
        "X2_val, y2_val, filenames2_val, X2_test, y2_test, filenames2_test = splitDataset(X_other, y_other, filenames_other, percent_train=0.5) \r\n",
        "\r\n",
        "print(\"X2_train Shape: \", X2_train.shape)\r\n",
        "print(\"y2_train Shape: \", y2_train.shape)\r\n",
        "print(\"X2_val Shape: \", X2_val.shape)\r\n",
        "print(\"y2_val Shape: \", y2_val.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X2_train Shape:  (700, 4, 896)\n",
            "y2_train Shape:  (700,)\n",
            "X2_val Shape:  (150, 4, 896)\n",
            "y2_val Shape:  (150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr3XXCrvU8Po"
      },
      "source": [
        "### Frequency Domain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3i-vD1YQRd"
      },
      "source": [
        "Due to frequency domain models having the worst accuracies in the initial training on only the Nov 2020 data, they are not considered here for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxLuUoi-VBxI"
      },
      "source": [
        "### Time-Frequency (Wavelets Transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdNQyUkJSijY"
      },
      "source": [
        "#### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FpqhWuIX0g-",
        "outputId": "71bb9c98-59f9-42c0-cf7c-9e0d93f3f9d0"
      },
      "source": [
        "openPath = os.getcwd() + r\"//Nov 2020 Filtered Data//5s//Spectograms//OPEN//\"\r\n",
        "closedPath = os.getcwd() + r\"//Nov 2020 Filtered Data//5s//Spectograms//CLOSE//\"\r\n",
        "openPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//5s//Spectograms//OPEN//\"\r\n",
        "closedPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//5s//Spectograms//CLOSE//\"\r\n",
        "openFiles = getFiles(openPath) + getFiles(openPath2)\r\n",
        "closedFiles = getFiles(closedPath) + getFiles(closedPath2) \r\n",
        "\r\n",
        "X, y, filenames = createDatasetFromJSON(openFiles, closedFiles)\r\n",
        "X, y, filenames = shuffleDataset(X, y, filenames)\r\n",
        "X_train_wv, y_train_wv, filenames_train_wv, X_other, y_other, filenames_other = splitDataset(X, y, filenames, percent_train=0.7)\r\n",
        "X_val_wv, y_val_wv, filenames_val_wv, X_test_wv, y_test_wv, filenames_test_wv = splitDataset(X_other, y_other, filenames_other, percent_train=0.5) \r\n",
        "\r\n",
        "print(\"X_train_wv Shape: \", X_train_wv.shape)\r\n",
        "print(\"y_train_wv Shape: \", y_train_wv.shape)\r\n",
        "print(\"X_val_wv Shape: \", X_val_wv.shape)\r\n",
        "print(\"y_val_wv Shape: \", y_val_wv.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_wv Shape:  (350, 4, 60, 1280)\n",
            "y_train_wv Shape:  (350,)\n",
            "X_val_wv Shape:  (75, 4, 60, 1280)\n",
            "y_val_wv Shape:  (75,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1REZ0W2SlLv"
      },
      "source": [
        "#### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cyKm9DLYtZD",
        "outputId": "f2efd258-c678-4e2f-a0a1-bb663b9e1164"
      },
      "source": [
        "openPath = os.getcwd() + r\"//Nov 2020 Filtered Data//2x3_5s//Spectograms//OPEN//\"\r\n",
        "closedPath = os.getcwd() + r\"//Nov 2020 Filtered Data//2x3_5s//Spectograms//CLOSE//\"\r\n",
        "openPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//2x3_5s//Spectograms//OPEN//\"\r\n",
        "closedPath2 = os.getcwd() + r\"//Feb 2021 Filtered Data//2x3_5s//Spectograms//CLOSE//\"\r\n",
        "openFiles = getFiles(openPath) + getFiles(openPath2)\r\n",
        "closedFiles = getFiles(closedPath) + getFiles(closedPath2) \r\n",
        "\r\n",
        "X, y, filenames = createDatasetFromJSON(openFiles, closedFiles)\r\n",
        "X, y, filenames = shuffleDataset(X, y, filenames)\r\n",
        "X2_train_wv, y2_train_wv, filenames2_train_wv, X_other, y_other, filenames_other = splitDataset(X, y, filenames, percent_train=0.7)\r\n",
        "X2_val_wv, y2_val_wv, filenames2_val_wv, X2_test_wv, y2_test_wv, filenames2_test_wv = splitDataset(X_other, y_other, filenames_other, percent_train=0.5) \r\n",
        "\r\n",
        "print(\"X2_train_wv Shape: \", X2_train_wv.shape)\r\n",
        "print(\"y2_train_wv Shape: \", y2_train_wv.shape)\r\n",
        "print(\"X2_val_wv Shape: \", X2_val_wv.shape)\r\n",
        "print(\"y2_val_wv Shape: \", y2_val_wv.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X2_train_wv Shape:  (700, 4, 60, 896)\n",
            "y2_train_wv Shape:  (700,)\n",
            "X2_val_wv Shape:  (150, 4, 60, 896)\n",
            "y2_val_wv Shape:  (150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVxIqqkFxbpJ"
      },
      "source": [
        "## 3. Time Series Baseline Models\r\n",
        "As a baseline, try using a linear SVM and some non-linear SVMs with different amounts of regularization to try and classify the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hnV_fRfWgSx"
      },
      "source": [
        "def get_accuracy_svm(model, X, y):\r\n",
        "    predictions = model.predict(X)\r\n",
        "    num_correct = np.sum((predictions - y) == 0)\r\n",
        "    n = X.shape[0]\r\n",
        "    accuracy = num_correct/n\r\n",
        "    print(\"The number of correct predictions is: \", num_correct)\r\n",
        "    print(\"The number of files is: \", n)\r\n",
        "    print(\"The accuracy is: \", accuracy)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd26AnVtVE1b"
      },
      "source": [
        "### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZkEQAAPq6UV",
        "outputId": "90a35e04-82b7-46b9-dec7-3a7c9b555b37"
      },
      "source": [
        "# Stack channels and datapoints into one dimension for sklearn to work\r\n",
        "X_train_svm = X_train.reshape(X_train.shape[0], 4*(256*5))\r\n",
        "X_val_svm = X_val.reshape(X_val.shape[0], 4*(256*5))\r\n",
        "\r\n",
        "# Fit the models\r\n",
        "# Nonlinear model 1 has a higher regularization (1) than model 2 (1/10)\r\n",
        "# Higher regularization helps to increase variance and reduce overfitting   \r\n",
        "model_linear = svm.LinearSVC()\r\n",
        "model_linear.fit(X_train_svm, y_train)\r\n",
        "\r\n",
        "model_nonlinear_1 = svm.SVC(kernel='sigmoid', C=1)\r\n",
        "model_nonlinear_1.fit(X_train_svm, y_train)\r\n",
        "\r\n",
        "model_nonlinear_2 = svm.SVC(kernel='sigmoid', C=10)\r\n",
        "model_nonlinear_2.fit(X_train_svm, y_train)\r\n",
        "\r\n",
        "model_nonlinear_3 = svm.SVC(kernel='sigmoid', C=100)\r\n",
        "model_nonlinear_3.fit(X_train_svm, y_train)\r\n",
        "\r\n",
        "model_nonlinear_4 = svm.SVC(kernel='rbf', C=1)\r\n",
        "model_nonlinear_4.fit(X_train_svm, y_train)\r\n",
        "\r\n",
        "model_nonlinear_5 = svm.SVC(kernel='rbf', C=10)\r\n",
        "model_nonlinear_5.fit(X_train_svm, y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLNQLfcKyxDJ"
      },
      "source": [
        "#### Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "byQwGmwhyZVY",
        "outputId": "aae76cb9-ff2f-4698-dbfc-ecb661c2579d"
      },
      "source": [
        "# Linear model accuracies\r\n",
        "print(\"Linear Model \\n\")\r\n",
        "print(\"Training Accuracy\")\r\n",
        "get_accuracy_svm(model_linear, X_train_svm, y_train)\r\n",
        "print(\"\\nValidation Accuracy\")\r\n",
        "get_accuracy_svm(model_linear, X_val_svm, y_val)\r\n",
        "\r\n",
        "# Linear model coefficients\r\n",
        "coefs = model_linear.coef_[0]\r\n",
        "intercept = model_linear.intercept_\r\n",
        "#print(\"The coefficients of the hyperplane are: \", coefs)\r\n",
        "print(\"The shape of the coefficients vector is: \", coefs.shape)\r\n",
        "print(\"The intercept of the hyperplane is: \", intercept, \"\\n\")\r\n",
        "\r\n",
        "#Plot the coefficients of the linear SVM\r\n",
        "x = np.array(range(1, len(coefs)+1))\r\n",
        "plt.plot(x, coefs)\r\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Model \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  178\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.5085714285714286\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  37\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.49333333333333335\n",
            "The shape of the coefficients vector is:  (5120,)\n",
            "The intercept of the hyperplane is:  [-0.01712076] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE23_lhQy2zh"
      },
      "source": [
        "#### Non-Linear Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwJriIRUW8Ux",
        "outputId": "4f114130-6de8-43bb-b83a-13b32bc1c5df"
      },
      "source": [
        "#Non-Linear Model 1 Accuracies\r\n",
        "print(\"\\nNon-Linear Model 1 \\n\")\r\n",
        "print(\"Training Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_1, X_train_svm, y_train)\r\n",
        "print(\"\\nValidation Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_1, X_val_svm, y_val)\r\n",
        "\r\n",
        "#Non-Linear Model 2 Accuracies\r\n",
        "print(\"\\nNon-Linear Model 2 \\n\")\r\n",
        "print(\"Training Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_2, X_train_svm, y_train)\r\n",
        "print(\"\\nValidation Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_2, X_val_svm, y_val)\r\n",
        "\r\n",
        "#Non-Linear Model 3 Accuracies\r\n",
        "print(\"\\nNon-Linear Model 3 \\n\")\r\n",
        "print(\"Training Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_3, X_train_svm, y_train)\r\n",
        "print(\"\\nValidation Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_3, X_val_svm, y_val)\r\n",
        "\r\n",
        "#Non-Linear Model 4 Accuracies\r\n",
        "print(\"\\nNon-Linear Model 4 \\n\")\r\n",
        "print(\"Training Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_4, X_train_svm, y_train)\r\n",
        "print(\"\\nValidation Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_4, X_val_svm, y_val)\r\n",
        "\r\n",
        "#Non-Linear Model 5 Accuracies\r\n",
        "print(\"\\nNon-Linear Model 5 \\n\")\r\n",
        "print(\"Training Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_5, X_train_svm, y_train)\r\n",
        "print(\"\\nValidation Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_5, X_val_svm, y_val)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Non-Linear Model 1 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  247\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.7057142857142857\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  42\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.56\n",
            "\n",
            "Non-Linear Model 2 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  262\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.7485714285714286\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  48\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.64\n",
            "\n",
            "Non-Linear Model 3 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  266\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.76\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  38\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.5066666666666667\n",
            "\n",
            "Non-Linear Model 4 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  309\n",
            "The number of files is:  350\n",
            "The accuracy is:  0.8828571428571429\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  44\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.5866666666666667\n",
            "\n",
            "Non-Linear Model 5 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  350\n",
            "The number of files is:  350\n",
            "The accuracy is:  1.0\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  45\n",
            "The number of files is:  75\n",
            "The accuracy is:  0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2ilhY-6VIsE"
      },
      "source": [
        "### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7HHJoq7VX1E",
        "outputId": "e64f0532-8360-4410-d601-b99b441b41da"
      },
      "source": [
        "# Stack channels and datapoints into one dimension for sklearn to work\r\n",
        "X_train_svm = X2_train.reshape(X2_train.shape[0], 4*int(256*3.5))\r\n",
        "X_val_svm = X2_val.reshape(X2_val.shape[0], 4*int(256*3.5))\r\n",
        "\r\n",
        "# Fit the models\r\n",
        "# Nonlinear model 1 has a higher regularization (1) than model 2 (1/10)\r\n",
        "# Higher regularization helps to increase variance and reduce overfitting   \r\n",
        "model_linear = svm.LinearSVC()\r\n",
        "model_linear.fit(X_train_svm, y2_train)\r\n",
        "\r\n",
        "model_nonlinear_1 = svm.SVC(kernel='sigmoid')\r\n",
        "model_nonlinear_1.fit(X_train_svm, y2_train)\r\n",
        "\r\n",
        "model_nonlinear_2 = svm.SVC(kernel='sigmoid', C=10)\r\n",
        "model_nonlinear_2.fit(X_train_svm, y2_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='sigmoid',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSO3XLiAVX1F"
      },
      "source": [
        "#### Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "hbSTmKACVX1F",
        "outputId": "80d1ffc9-1d50-469b-8193-413d8a35984b"
      },
      "source": [
        "# Linear model accuracies\r\n",
        "print(\"Linear Model \\n\")\r\n",
        "print(\"Training Accuracy\")\r\n",
        "get_accuracy_svm(model_linear, X_train_svm, y2_train)\r\n",
        "print(\"\\nValidation Accuracy\")\r\n",
        "get_accuracy_svm(model_linear, X_val_svm, y2_val)\r\n",
        "\r\n",
        "# Linear model coefficients\r\n",
        "coefs = model_linear.coef_[0]\r\n",
        "intercept = model_linear.intercept_\r\n",
        "#print(\"The coefficients of the hyperplane are: \", coefs)\r\n",
        "print(\"The shape of the coefficients vector is: \", coefs.shape)\r\n",
        "print(\"The intercept of the hyperplane is: \", intercept, \"\\n\")\r\n",
        "\r\n",
        "#Plot the coefficients of the linear SVM\r\n",
        "x = np.array(range(1, len(coefs)+1))\r\n",
        "plt.plot(x, coefs)\r\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Model \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  367\n",
            "The number of files is:  700\n",
            "The accuracy is:  0.5242857142857142\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  77\n",
            "The number of files is:  150\n",
            "The accuracy is:  0.5133333333333333\n",
            "The shape of the coefficients vector is:  (3584,)\n",
            "The intercept of the hyperplane is:  [-0.04852089] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwvP6Y2rVX1G"
      },
      "source": [
        "#### Non-Linear Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vLgOBz0VX1G",
        "outputId": "82da3464-857f-445e-865f-78e5059c05ad"
      },
      "source": [
        "#Non-Linear Model 1 Accuracies\r\n",
        "print(\"\\nNon-Linear Model 1 \\n\")\r\n",
        "print(\"Training Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_1, X_train_svm, y2_train)\r\n",
        "print(\"\\nValidation Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_1, X_val_svm, y2_val)\r\n",
        "\r\n",
        "#Non-Linear Model 2 Accuracies\r\n",
        "print(\"\\nNon-Linear Model 2 \\n\")\r\n",
        "print(\"Training Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_2, X_train_svm, y2_train)\r\n",
        "print(\"\\nValidation Accuracy\")\r\n",
        "get_accuracy_svm(model_nonlinear_2, X_val_svm, y2_val)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Non-Linear Model 1 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  406\n",
            "The number of files is:  700\n",
            "The accuracy is:  0.58\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  70\n",
            "The number of files is:  150\n",
            "The accuracy is:  0.4666666666666667\n",
            "\n",
            "Non-Linear Model 2 \n",
            "\n",
            "Training Accuracy\n",
            "The number of correct predictions is:  437\n",
            "The number of files is:  700\n",
            "The accuracy is:  0.6242857142857143\n",
            "\n",
            "Validation Accuracy\n",
            "The number of correct predictions is:  77\n",
            "The number of files is:  150\n",
            "The accuracy is:  0.5133333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo6z_u30jzen"
      },
      "source": [
        "### Discussion\r\n",
        "The best model so far seems to be with 5s data using nonlinear model 2, which was a SVM using sigmoid kernel and regularization of 1/10. The validation accuracy for this model was 64%, which is the benchmark that any deep learning model should exceed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSyMaqQpnA7Y"
      },
      "source": [
        "# Saving model to file\r\n",
        "filename = 'svm_kernel-sigmoid_C-10_5s.sav'\r\n",
        "pickle.dump(model_nonlinear_2, open(filename, 'wb'))\r\n",
        " \r\n",
        "# some time later...\r\n",
        "# load the model\r\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\r\n",
        "result = loaded_model.score(X_test_svm, Y_test_svm)\r\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr-Ma-KmzUAB"
      },
      "source": [
        "## 4. Deep Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMKJ04BXx9SN"
      },
      "source": [
        "### Training Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Hcneb4pPdE"
      },
      "source": [
        "torch.manual_seed(21) # set the random seed\r\n",
        "\r\n",
        "def createTensorDataset(data, labels):\r\n",
        "    # Returns a tensor dataset object given np arrays of the data and labels\r\n",
        "    data_tensor = torch.tensor(data)\r\n",
        "    labels_tensor = torch.tensor(labels)\r\n",
        "    dataset = TensorDataset(data_tensor, labels_tensor)\r\n",
        "    return dataset\r\n",
        "\r\n",
        "def addDimensionForCNNModels(dataset):\r\n",
        "# Takes in a pytorch dataset with data of size [N, C, H]\r\n",
        "# Returns a pytorch dataset with data of size [N, 1, C, H]\r\n",
        "# This allows us to treat the multiple EEG channnels like a 2D image of 1 channel\r\n",
        "    data = dataset.tensors[0]\r\n",
        "    labels = dataset.tensors[1]\r\n",
        "    data = torch.unsqueeze(data, 1)\r\n",
        "    return TensorDataset(data, labels)\r\n",
        "\r\n",
        "def downsampleTensorHW(dataset, factor):\r\n",
        "    # Given a tensor dataset of data, labels, takes data of shape [N, C, H, W]\r\n",
        "    # Returns the dataset, but with data of shape [N, C, H/factor, W/factor]\r\n",
        "    data = dataset.tensors[0]\r\n",
        "    labels = dataset.tensors[1]\r\n",
        "    data_new = F.interpolate(data, size=(int(data.shape[-2] /factor), int(data.shape[-1] /factor)), mode='bicubic', align_corners=False)\r\n",
        "    return TensorDataset(data_new, labels)\r\n",
        "\r\n",
        "def get_accuracy(model, data_loader, train=False, use_cuda=True):\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    for file, labels in iter(data_loader):\r\n",
        "        file = file.float()\r\n",
        "        labels = labels.long()\r\n",
        "        if use_cuda and torch.cuda.is_available():\r\n",
        "            file = file.cuda()\r\n",
        "            labels = labels.cuda()\r\n",
        "        output = model(file)\r\n",
        "        pred = output.max(1, keepdim=True)[1]\r\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\r\n",
        "        total += file.shape[0]\r\n",
        "    return correct / total\r\n",
        "\r\n",
        "def plot_training_curve(iters, losses, train_acc, val_acc):\r\n",
        "    # plotting\r\n",
        "    plt.title(\"Training Curve\")\r\n",
        "    plt.plot(iters, losses, label=\"Train\")\r\n",
        "    plt.xlabel(\"Iterations\")\r\n",
        "    plt.ylabel(\"Loss\")\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "    plt.title(\"Training Curve\")\r\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\r\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\r\n",
        "    plt.xlabel(\"Iterations\")\r\n",
        "    plt.ylabel(\"Training Accuracy\")\r\n",
        "    plt.legend(loc='best')\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\r\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\r\n",
        "    print(\"Maximum Training Accuracy: {}\".format(max(train_acc)))\r\n",
        "    print(\"Maximum Validation Accuracy: {}\".format(max(val_acc)))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Q3lvRV2dbK"
      },
      "source": [
        "def train(model, train_dataset, val_dataset, batch_size=100, num_epochs=1, learning_rate=0.01, momen=0.9, use_cuda=True, use_adam=True, save_weights=True):\r\n",
        "    # Create folder to save the weights in\r\n",
        "    now = datetime.now()\r\n",
        "    folder_name = model.name + ' Weights ' + now.strftime(\"%Y-%m-%d %H-%M\")\r\n",
        "    save_path = os.getcwd() + \"//\" + folder_name + \"//\"\r\n",
        "    if save_weights and not os.path.exists(folder_name):\r\n",
        "        os.makedirs(folder_name)\r\n",
        "    \r\n",
        "    # Make dataloader objects to iterate over\r\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\r\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\r\n",
        "\r\n",
        "    #Define loss functions and optimizer\r\n",
        "    criterion = nn.CrossEntropyLoss()\r\n",
        "    if use_adam:\r\n",
        "        optimizer = optim.Adam(model.parameters(), lr = learning_rate)\r\n",
        "    else:\r\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momen)\r\n",
        "\r\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\r\n",
        "    # training\r\n",
        "    n = 0 # the number of iterations\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        for file, labels in iter(train_loader):\r\n",
        "            \r\n",
        "            file = file.float()\r\n",
        "            labels = labels.long()\r\n",
        "            if use_cuda and torch.cuda.is_available():\r\n",
        "                file = file.cuda()\r\n",
        "                labels = labels.cuda()\r\n",
        "            \r\n",
        "            out = model(file)             # forward pass\r\n",
        "            loss = criterion(out, labels) # compute the total loss\r\n",
        "            loss.backward()               # backward pass (compute parameter updates)\r\n",
        "            optimizer.step()              # make the updates for each parameter\r\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\r\n",
        "\r\n",
        "            # save the current training information\r\n",
        "            iters.append(n)\r\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\r\n",
        "            train_acc.append(get_accuracy(model, train_loader, train=True)) # compute training accuracy \r\n",
        "            val_acc.append(get_accuracy(model, val_loader, train=False))  # compute validation accuracy\r\n",
        "            print(\"Iteration: \", str(n), \"| Train Loss: \", losses[n], \"| Train Accuracy: \", train_acc[n], \"| Validation Accuracy: \", val_acc[n])\r\n",
        "            n += 1\r\n",
        "            model_path = \"model_{0}_bs{1}_lr{2}_epoch{3}_iteration{4}_val-acc{5}\".format(model.name, \r\n",
        "                                                                                         batch_size, \r\n",
        "                                                                                         str(learning_rate).replace('.', '-'), \r\n",
        "                                                                                         epoch, n, str(round(val_acc[-1]*100, 4)).replace('.', '-'))\r\n",
        "            if save_weights:\r\n",
        "                if val_acc[-1] == max(val_acc) and val_acc.count(val_acc[-1]) == 1:\r\n",
        "                    torch.save(model.state_dict(), save_path + model_path + \".pth\") #save weights at new maximum for validation accuracy\r\n",
        "    if save_weights:\r\n",
        "        torch.save(model.state_dict(), save_path + model_path + \".pth\") #Save the very last iteration\r\n",
        "        #Write the train loss and train/val accuracies to CSV file\r\n",
        "        epochs = np.arange(1, num_epochs + 1)\r\n",
        "        np.savetxt(save_path + \"{}_train_loss.csv\".format(model_path), losses)\r\n",
        "        np.savetxt(save_path + \"{}_train_acc.csv\".format(model_path), train_acc)\r\n",
        "        np.savetxt(save_path + \"{}_val_acc.csv\".format(model_path), val_acc) \r\n",
        "\r\n",
        "    # plotting\r\n",
        "    plot_training_curve(iters, losses, train_acc, val_acc)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZX-kvza2F4S"
      },
      "source": [
        "### Model Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvktHMTuxpKW"
      },
      "source": [
        "#### Time Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buKLe1VA14yL"
      },
      "source": [
        "class ANN_TS_2L(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(ANN_TS_2L, self).__init__()\r\n",
        "        self.name = \"ANN_TS_2L\"\r\n",
        "        self.layer1 = nn.Linear((256*5)*4, 200)\r\n",
        "        self.layer2 = nn.Linear(200, 50)\r\n",
        "        self.layer3 = nn.Linear(50, 2)\r\n",
        "    def forward(self, img):\r\n",
        "        flattened = img.view(-1, (256*5)*4)\r\n",
        "        activation1 = F.relu(self.layer1(flattened))\r\n",
        "        activation2 = F.relu(self.layer2(activation1))\r\n",
        "        output = self.layer3(activation2)\r\n",
        "        return output\r\n",
        "\r\n",
        "class ANN_TS2_2L(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(ANN_TS2_2L, self).__init__()\r\n",
        "        self.name = \"ANN_TS2_2L\"\r\n",
        "        self.layer1 = nn.Linear(int(256*3.5)*4, 200)\r\n",
        "        self.layer2 = nn.Linear(200, 50)\r\n",
        "        self.layer3 = nn.Linear(50, 2)\r\n",
        "    def forward(self, img):\r\n",
        "        flattened = img.view(-1, int(256*3.5)*4)\r\n",
        "        activation1 = F.relu(self.layer1(flattened))\r\n",
        "        activation2 = F.relu(self.layer2(activation1))\r\n",
        "        output = self.layer3(activation2)\r\n",
        "        return output\r\n",
        "\r\n",
        "class ANN_TS_3L(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(ANN_TS_3L, self).__init__()\r\n",
        "        self.name = \"ANN_TS_3L\"\r\n",
        "        self.layer1 = nn.Linear((256*5)*4, 500)\r\n",
        "        self.layer2 = nn.Linear(500, 200)\r\n",
        "        self.layer3 = nn.Linear(200, 50)\r\n",
        "        self.layer4 = nn.Linear(50, 2)\r\n",
        "    def forward(self, img):\r\n",
        "        flattened = img.view(-1, (256*5)*4)\r\n",
        "        activation1 = F.relu(self.layer1(flattened))\r\n",
        "        activation2 = F.relu(self.layer2(activation1))\r\n",
        "        activation3 = F.relu(self.layer3(activation2))\r\n",
        "        output = self.layer4(activation3)\r\n",
        "        return output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8rMoL8jj5N"
      },
      "source": [
        "#### Time-Frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCvrJQaYjn6D"
      },
      "source": [
        "class CNN_WV(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(CNN_WV, self).__init__()\r\n",
        "        self.name = \"CNN_WV\"\r\n",
        "        \r\n",
        "        self.conv1 = nn.Conv2d(4, 8, 4) #in_channels, out_channels (# of kernels to try), kernel_size. Size in is 4x30x640\r\n",
        "        self.pool = nn.MaxPool2d(2, 2) #kernel_size (for the pool), stride. Size in should be 8x26x636 \r\n",
        "        self.conv2 = nn.Conv2d(8, 16, 4) #size in should be 8x13x318\r\n",
        "        self.pool = nn.MaxPool2d(2, 2) # size in should be 16x9x314\r\n",
        "        \r\n",
        "        self.fc1 = nn.Linear(16*5*157, 2500) #size in should be 16x5x157\r\n",
        "        self.fc2 = nn.Linear(2500, 500)\r\n",
        "        self.fc3 = nn.Linear(500, 50)\r\n",
        "        self.fc4 = nn.Linear(50, 2)\r\n",
        " \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.pool(F.relu(self.conv1(x)))\r\n",
        "        x = self.pool(F.relu(self.conv2(x)))\r\n",
        "        x = x.view(x.size(0), -1) #flatten the input\r\n",
        "\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = F.relu(self.fc3(x)) \r\n",
        "        x = self.fc4(x)\r\n",
        "        x = x.squeeze(1)\r\n",
        "        return x\r\n",
        "\r\n",
        "class CNN2_WV(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(CNN2_WV, self).__init__()\r\n",
        "        self.name = \"CNN2_WV\"\r\n",
        "        \r\n",
        "        self.conv1 = nn.Conv2d(4, 8, 4) #in_channels, out_channels (# of kernels to try), kernel_size. Size in is 4x30x448\r\n",
        "        self.pool = nn.MaxPool2d(2, 2) #kernel_size (for the pool), stride. Size in should be 8x26x444 \r\n",
        "        self.conv2 = nn.Conv2d(8, 16, 4) #size in should be 8x13x222\r\n",
        "        self.pool = nn.MaxPool2d(2, 2) # size in should be 16x9x218\r\n",
        "        \r\n",
        "        self.fc1 = nn.Linear(16*5*109, 2000) #size in should be 16x5x109\r\n",
        "        self.fc2 = nn.Linear(2000, 500)\r\n",
        "        self.fc3 = nn.Linear(500, 50)\r\n",
        "        self.fc4 = nn.Linear(50, 2)\r\n",
        " \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.pool(F.relu(self.conv1(x)))\r\n",
        "        x = self.pool(F.relu(self.conv2(x)))\r\n",
        "        x = x.view(x.size(0), -1) #flatten the input\r\n",
        "\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = F.relu(self.fc3(x)) \r\n",
        "        x = self.fc4(x)\r\n",
        "        x = x.squeeze(1)\r\n",
        "        return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgACcb09yVQF"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAhDmTVnyZyc"
      },
      "source": [
        "#### Time Series Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNsh9odqWCFi"
      },
      "source": [
        "##### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt1pmqAy-auw"
      },
      "source": [
        "train_dataset = createTensorDataset(X_train, y_train)\r\n",
        "val_dataset = createTensorDataset(X_val, y_val)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PiTeHZ_alZvV",
        "outputId": "746212f4-548c-4897-cee0-dae079141b5b"
      },
      "source": [
        "model = ANN_TS_2L()\r\n",
        "train(model, train_dataset, val_dataset, batch_size = 50, num_epochs=150, learning_rate = 0.001, momen = 0.7, use_adam = True, save_weights=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.013875420093536378 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1 | Train Loss:  0.013849161863327027 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2 | Train Loss:  0.013863927125930786 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3 | Train Loss:  0.013863979578018189 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  4 | Train Loss:  0.013855831623077393 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  5 | Train Loss:  0.013916316032409668 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  6 | Train Loss:  0.01381292700767517 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  7 | Train Loss:  0.013871253728866577 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  8 | Train Loss:  0.013848507404327392 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  9 | Train Loss:  0.013863765001296997 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  10 | Train Loss:  0.013863880634307862 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  11 | Train Loss:  0.013855575323104859 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  12 | Train Loss:  0.013915951251983643 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  13 | Train Loss:  0.013807672262191772 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  14 | Train Loss:  0.013872145414352418 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  15 | Train Loss:  0.01384695291519165 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  16 | Train Loss:  0.013863837718963623 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  17 | Train Loss:  0.013864011764526367 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  18 | Train Loss:  0.01385488748550415 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  19 | Train Loss:  0.013920861482620239 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  20 | Train Loss:  0.01380121111869812 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  21 | Train Loss:  0.013873276710510253 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  22 | Train Loss:  0.013845245838165283 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  23 | Train Loss:  0.013863965272903442 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  24 | Train Loss:  0.013864188194274903 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  25 | Train Loss:  0.013854163885116576 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  26 | Train Loss:  0.013926256895065308 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  27 | Train Loss:  0.013795028924942016 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  28 | Train Loss:  0.013874379396438598 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  29 | Train Loss:  0.013843661546707154 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  30 | Train Loss:  0.01386409044265747 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  31 | Train Loss:  0.013864364624023438 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  32 | Train Loss:  0.013853507041931152 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  33 | Train Loss:  0.013931214809417725 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  34 | Train Loss:  0.013789610862731934 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  35 | Train Loss:  0.013875346183776855 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  36 | Train Loss:  0.013842294216156006 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  37 | Train Loss:  0.013864189386367798 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  38 | Train Loss:  0.013864511251449585 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  39 | Train Loss:  0.013852938413619995 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  40 | Train Loss:  0.013935432434082032 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  41 | Train Loss:  0.013785063028335572 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  42 | Train Loss:  0.0138761568069458 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  43 | Train Loss:  0.013841140270233154 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  44 | Train Loss:  0.013864238262176514 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  45 | Train Loss:  0.013864617347717285 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  46 | Train Loss:  0.013852446079254151 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  47 | Train Loss:  0.013938910961151123 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  48 | Train Loss:  0.013781319856643676 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  49 | Train Loss:  0.013876806497573852 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  50 | Train Loss:  0.013840183019638061 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  51 | Train Loss:  0.013864235877990723 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  52 | Train Loss:  0.013864675760269165 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  53 | Train Loss:  0.013852015733718873 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  54 | Train Loss:  0.013941699266433715 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  55 | Train Loss:  0.01377829074859619 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  56 | Train Loss:  0.013877302408218384 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  57 | Train Loss:  0.013839383125305176 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  58 | Train Loss:  0.013864175081253052 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  59 | Train Loss:  0.01386468768119812 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  60 | Train Loss:  0.013851633071899414 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  61 | Train Loss:  0.013943885564804076 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  62 | Train Loss:  0.013775870800018311 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  63 | Train Loss:  0.013877665996551514 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  64 | Train Loss:  0.013838711977005005 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  65 | Train Loss:  0.01386405348777771 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  66 | Train Loss:  0.013864647150039672 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  67 | Train Loss:  0.01385128140449524 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  68 | Train Loss:  0.013945536613464355 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  69 | Train Loss:  0.01377395510673523 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  70 | Train Loss:  0.013877912759780883 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  71 | Train Loss:  0.013838137388229371 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  72 | Train Loss:  0.013863873481750489 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  73 | Train Loss:  0.0138645601272583 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  74 | Train Loss:  0.013850941658020019 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  75 | Train Loss:  0.013946763277053832 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  76 | Train Loss:  0.013772437572479248 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  77 | Train Loss:  0.013878055810928346 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  78 | Train Loss:  0.01383763074874878 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  79 | Train Loss:  0.013863624334335327 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  80 | Train Loss:  0.013864418268203735 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  81 | Train Loss:  0.013850600719451904 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  82 | Train Loss:  0.013947651386260987 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  83 | Train Loss:  0.013771202564239502 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  84 | Train Loss:  0.013878114223480224 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  85 | Train Loss:  0.013837164640426636 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  86 | Train Loss:  0.013863308429718018 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  87 | Train Loss:  0.013864223957061767 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  88 | Train Loss:  0.013850245475769043 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  89 | Train Loss:  0.013948276042938232 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  90 | Train Loss:  0.013770172595977783 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  91 | Train Loss:  0.013878101110458374 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  92 | Train Loss:  0.013836706876754762 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  93 | Train Loss:  0.013862916231155396 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  94 | Train Loss:  0.013863983154296875 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  95 | Train Loss:  0.013849859237670898 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  96 | Train Loss:  0.01394875168800354 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  97 | Train Loss:  0.013769211769104004 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  98 | Train Loss:  0.013878036737442017 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  99 | Train Loss:  0.013836233615875245 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  100 | Train Loss:  0.013862447738647461 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  101 | Train Loss:  0.013863688707351685 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  102 | Train Loss:  0.01384942889213562 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  103 | Train Loss:  0.013949072360992432 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  104 | Train Loss:  0.013768332004547119 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  105 | Train Loss:  0.013877907991409302 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  106 | Train Loss:  0.01383573055267334 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  107 | Train Loss:  0.013861889839172364 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  108 | Train Loss:  0.013863322734832763 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  109 | Train Loss:  0.013848953247070313 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  110 | Train Loss:  0.013949230909347535 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  111 | Train Loss:  0.013767518997192384 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  112 | Train Loss:  0.013877716064453125 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  113 | Train Loss:  0.013835197687149048 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  114 | Train Loss:  0.013861225843429565 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  115 | Train Loss:  0.013862892389297485 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  116 | Train Loss:  0.013848402500152589 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  117 | Train Loss:  0.013949328660964965 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  118 | Train Loss:  0.01376664161682129 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  119 | Train Loss:  0.013877476453781129 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  120 | Train Loss:  0.013834594488143922 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  121 | Train Loss:  0.01386045217514038 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  122 | Train Loss:  0.013862382173538208 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  123 | Train Loss:  0.013847792148590088 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  124 | Train Loss:  0.013949263095855712 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  125 | Train Loss:  0.01376580834388733 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  126 | Train Loss:  0.013877160549163818 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  127 | Train Loss:  0.013833932876586914 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  128 | Train Loss:  0.013859550952911377 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  129 | Train Loss:  0.013861782550811767 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  130 | Train Loss:  0.013847087621688842 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  131 | Train Loss:  0.013949209451675415 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  132 | Train Loss:  0.013764784336090088 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  133 | Train Loss:  0.01387681245803833 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  134 | Train Loss:  0.013833150863647461 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  135 | Train Loss:  0.013858505487442017 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  136 | Train Loss:  0.013861093521118164 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  137 | Train Loss:  0.013846267461776734 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  138 | Train Loss:  0.013949147462844848 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  139 | Train Loss:  0.013763595819473267 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  140 | Train Loss:  0.013876404762268067 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  141 | Train Loss:  0.013832250833511353 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  142 | Train Loss:  0.01385729670524597 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  143 | Train Loss:  0.013860297203063966 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  144 | Train Loss:  0.013845324516296387 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  145 | Train Loss:  0.013949085474014283 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  146 | Train Loss:  0.01376219630241394 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  147 | Train Loss:  0.013875941038131714 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  148 | Train Loss:  0.013831210136413575 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  149 | Train Loss:  0.01385590672492981 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  150 | Train Loss:  0.013859367370605469 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  151 | Train Loss:  0.01384424090385437 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  152 | Train Loss:  0.013948924541473388 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  153 | Train Loss:  0.013760713338851928 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  154 | Train Loss:  0.013875372409820556 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  155 | Train Loss:  0.013830047845840455 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  156 | Train Loss:  0.013854286670684814 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  157 | Train Loss:  0.013858282566070556 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  158 | Train Loss:  0.013843013048171997 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  159 | Train Loss:  0.013948532342910767 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  160 | Train Loss:  0.013759196996688842 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  161 | Train Loss:  0.013874669075012207 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  162 | Train Loss:  0.013828749656677247 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  163 | Train Loss:  0.013852412700653077 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  164 | Train Loss:  0.013857018947601319 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  165 | Train Loss:  0.013841618299484253 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  166 | Train Loss:  0.01394809365272522 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  167 | Train Loss:  0.013757327795028687 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  168 | Train Loss:  0.013873887062072755 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  169 | Train Loss:  0.013827216625213624 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  170 | Train Loss:  0.013850255012512207 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  171 | Train Loss:  0.013855558633804322 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  172 | Train Loss:  0.013840010166168213 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  173 | Train Loss:  0.013947430849075317 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  174 | Train Loss:  0.013755432367324828 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  175 | Train Loss:  0.013872916698455811 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  176 | Train Loss:  0.013825527429580688 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  177 | Train Loss:  0.01384774923324585 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  178 | Train Loss:  0.013853850364685059 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  179 | Train Loss:  0.013838186264038085 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  180 | Train Loss:  0.013946447372436523 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  181 | Train Loss:  0.013753399848937989 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  182 | Train Loss:  0.013871761560440064 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  183 | Train Loss:  0.013823589086532593 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  184 | Train Loss:  0.01384485125541687 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  185 | Train Loss:  0.013851861953735351 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  186 | Train Loss:  0.013836077451705932 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  187 | Train Loss:  0.013945437669754028 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  188 | Train Loss:  0.013750839233398437 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  189 | Train Loss:  0.013870477676391602 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  190 | Train Loss:  0.013821289539337159 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  191 | Train Loss:  0.013841508626937867 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  192 | Train Loss:  0.013849575519561768 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  193 | Train Loss:  0.013833612203598022 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  194 | Train Loss:  0.01394437313079834 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  195 | Train Loss:  0.013747853040695191 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  196 | Train Loss:  0.013868957757949829 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  197 | Train Loss:  0.013818665742874145 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  198 | Train Loss:  0.013837627172470092 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  199 | Train Loss:  0.013846896886825562 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  200 | Train Loss:  0.01383082389831543 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  201 | Train Loss:  0.013942831754684448 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  202 | Train Loss:  0.013744604587554932 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  203 | Train Loss:  0.013867169618606567 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  204 | Train Loss:  0.013815600872039795 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  205 | Train Loss:  0.013833129405975341 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  206 | Train Loss:  0.013843798637390136 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  207 | Train Loss:  0.01382757067680359 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  208 | Train Loss:  0.013941459655761719 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  209 | Train Loss:  0.013740324974060058 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  210 | Train Loss:  0.013865182399749756 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  211 | Train Loss:  0.013811968564987183 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  212 | Train Loss:  0.013827917575836181 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  213 | Train Loss:  0.013840196132659912 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  214 | Train Loss:  0.013823821544647216 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  215 | Train Loss:  0.0139396870136261 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  216 | Train Loss:  0.013735687732696534 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  217 | Train Loss:  0.01386278510093689 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  218 | Train Loss:  0.013807835578918458 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  219 | Train Loss:  0.013821862936019898 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  220 | Train Loss:  0.013835973739624023 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  221 | Train Loss:  0.013819572925567626 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  222 | Train Loss:  0.013937312364578246 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  223 | Train Loss:  0.013730483055114746 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  224 | Train Loss:  0.013859957456588745 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  225 | Train Loss:  0.01380305528640747 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  226 | Train Loss:  0.013814892768859863 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  227 | Train Loss:  0.013831076622009277 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  228 | Train Loss:  0.013814717531204224 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  229 | Train Loss:  0.01393502950668335 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  230 | Train Loss:  0.013723796606063843 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  231 | Train Loss:  0.013856816291809081 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  232 | Train Loss:  0.013797343969345092 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  233 | Train Loss:  0.013806840181350708 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  234 | Train Loss:  0.013825417757034301 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  235 | Train Loss:  0.013809154033660889 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  236 | Train Loss:  0.01393239140510559 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  237 | Train Loss:  0.013716198205947876 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  238 | Train Loss:  0.013853061199188232 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  239 | Train Loss:  0.013790864944458008 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  240 | Train Loss:  0.013797523975372315 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  241 | Train Loss:  0.01381877899169922 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  242 | Train Loss:  0.013802828788757325 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  243 | Train Loss:  0.013928439617156983 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  244 | Train Loss:  0.013708263635635376 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  245 | Train Loss:  0.01384851336479187 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  246 | Train Loss:  0.013783502578735351 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  247 | Train Loss:  0.01378682255744934 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  248 | Train Loss:  0.013811084032058716 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  249 | Train Loss:  0.013795574903488159 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  250 | Train Loss:  0.013923968076705933 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  251 | Train Loss:  0.013698668479919433 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  252 | Train Loss:  0.013843398094177246 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  253 | Train Loss:  0.013774762153625488 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  254 | Train Loss:  0.013774603605270386 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  255 | Train Loss:  0.013802282810211182 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  256 | Train Loss:  0.013787200450897217 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  257 | Train Loss:  0.013919979333877563 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  258 | Train Loss:  0.01368653416633606 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  259 | Train Loss:  0.013837647438049317 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  260 | Train Loss:  0.013764551877975463 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  261 | Train Loss:  0.013760571479797363 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  262 | Train Loss:  0.013792142868041993 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  263 | Train Loss:  0.013777704238891601 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  264 | Train Loss:  0.013915446996688842 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  265 | Train Loss:  0.013672446012496947 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  266 | Train Loss:  0.013830976486206055 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  267 | Train Loss:  0.013752864599227905 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  268 | Train Loss:  0.013744462728500367 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  269 | Train Loss:  0.013780485391616821 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  270 | Train Loss:  0.01376711368560791 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  271 | Train Loss:  0.013909260034561157 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  272 | Train Loss:  0.013657306432723998 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  273 | Train Loss:  0.0138230562210083 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  274 | Train Loss:  0.013739660978317261 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  275 | Train Loss:  0.013726115226745605 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  276 | Train Loss:  0.013767116069793701 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  277 | Train Loss:  0.013755279779434203 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  278 | Train Loss:  0.01390236258506775 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  279 | Train Loss:  0.01363966941833496 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  280 | Train Loss:  0.013814070224761964 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  281 | Train Loss:  0.013724464178085326 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  282 | Train Loss:  0.013705353736877441 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  283 | Train Loss:  0.013751881122589111 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  284 | Train Loss:  0.013741822242736816 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  285 | Train Loss:  0.013895000219345094 | Train Accuracy:  0.58 | Validation Accuracy:  0.48\n",
            "Iteration:  286 | Train Loss:  0.013619062900543212 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  287 | Train Loss:  0.013803797960281371 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  288 | Train Loss:  0.013707282543182374 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  289 | Train Loss:  0.01368188500404358 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  290 | Train Loss:  0.013734546899795532 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  291 | Train Loss:  0.013726903200149536 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  292 | Train Loss:  0.013885090351104737 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  293 | Train Loss:  0.013597266674041748 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  294 | Train Loss:  0.013791601657867431 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  295 | Train Loss:  0.013688225746154786 | Train Accuracy:  0.58 | Validation Accuracy:  0.48\n",
            "Iteration:  296 | Train Loss:  0.013655494451522827 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  297 | Train Loss:  0.013714832067489625 | Train Accuracy:  0.5771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  298 | Train Loss:  0.013710347414016723 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  299 | Train Loss:  0.01387050747871399 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  300 | Train Loss:  0.013576191663742066 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  301 | Train Loss:  0.013776873350143432 | Train Accuracy:  0.6 | Validation Accuracy:  0.44\n",
            "Iteration:  302 | Train Loss:  0.013667525053024291 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  303 | Train Loss:  0.013625644445419312 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  304 | Train Loss:  0.013692396879196166 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  305 | Train Loss:  0.01369186520576477 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  306 | Train Loss:  0.013852800130844117 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  307 | Train Loss:  0.013553200960159302 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  308 | Train Loss:  0.013760238885879517 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  309 | Train Loss:  0.013643984794616698 | Train Accuracy:  0.6 | Validation Accuracy:  0.44\n",
            "Iteration:  310 | Train Loss:  0.013592326641082763 | Train Accuracy:  0.6 | Validation Accuracy:  0.44\n",
            "Iteration:  311 | Train Loss:  0.013667237758636475 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.44\n",
            "Iteration:  312 | Train Loss:  0.013670878410339355 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  313 | Train Loss:  0.013835068941116333 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.44\n",
            "Iteration:  314 | Train Loss:  0.013524856567382813 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  315 | Train Loss:  0.013741908073425292 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  316 | Train Loss:  0.013617228269577026 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  317 | Train Loss:  0.013555083274841308 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  318 | Train Loss:  0.013639141321182251 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  319 | Train Loss:  0.013647586107254028 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  320 | Train Loss:  0.013813886642456055 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  321 | Train Loss:  0.013494966030120849 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  322 | Train Loss:  0.013720674514770508 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  323 | Train Loss:  0.013588064908981323 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.44\n",
            "Iteration:  324 | Train Loss:  0.01351335048675537 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  325 | Train Loss:  0.01360773205757141 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  326 | Train Loss:  0.013621934652328492 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  327 | Train Loss:  0.013788695335388184 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  328 | Train Loss:  0.013462928533554077 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  329 | Train Loss:  0.013696873188018798 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  330 | Train Loss:  0.013555357456207276 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  331 | Train Loss:  0.013467086553573608 | Train Accuracy:  0.62 | Validation Accuracy:  0.44\n",
            "Iteration:  332 | Train Loss:  0.013573039770126343 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.44\n",
            "Iteration:  333 | Train Loss:  0.013593168258666992 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  334 | Train Loss:  0.01376441478729248 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.44\n",
            "Iteration:  335 | Train Loss:  0.013423651456832886 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  336 | Train Loss:  0.013670943975448609 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  337 | Train Loss:  0.013518965244293213 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  338 | Train Loss:  0.013415942192077637 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  339 | Train Loss:  0.013534953594207763 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  340 | Train Loss:  0.013561625480651856 | Train Accuracy:  0.62 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  341 | Train Loss:  0.013735949993133545 | Train Accuracy:  0.68 | Validation Accuracy:  0.44\n",
            "Iteration:  342 | Train Loss:  0.013382084369659424 | Train Accuracy:  0.66 | Validation Accuracy:  0.44\n",
            "Iteration:  343 | Train Loss:  0.013641881942749023 | Train Accuracy:  0.66 | Validation Accuracy:  0.44\n",
            "Iteration:  344 | Train Loss:  0.013479009866714478 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  345 | Train Loss:  0.0133599853515625 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  346 | Train Loss:  0.013493363857269286 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.44\n",
            "Iteration:  347 | Train Loss:  0.013526993989944457 | Train Accuracy:  0.62 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  348 | Train Loss:  0.013705562353134155 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.44\n",
            "Iteration:  349 | Train Loss:  0.013335928916931153 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.44\n",
            "Iteration:  350 | Train Loss:  0.013609843254089355 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.44\n",
            "Iteration:  351 | Train Loss:  0.013435685634613037 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  352 | Train Loss:  0.013298745155334473 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  353 | Train Loss:  0.013448008298873902 | Train Accuracy:  0.64 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  354 | Train Loss:  0.01348949909210205 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.44\n",
            "Iteration:  355 | Train Loss:  0.013670405149459839 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  356 | Train Loss:  0.013287222385406494 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.44\n",
            "Iteration:  357 | Train Loss:  0.013574427366256714 | Train Accuracy:  0.68 | Validation Accuracy:  0.44\n",
            "Iteration:  358 | Train Loss:  0.013388668298721313 | Train Accuracy:  0.66 | Validation Accuracy:  0.44\n",
            "Iteration:  359 | Train Loss:  0.013232227563858032 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  360 | Train Loss:  0.013398817777633666 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  361 | Train Loss:  0.013448922634124756 | Train Accuracy:  0.64 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  362 | Train Loss:  0.013631588220596314 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  363 | Train Loss:  0.013235011100769044 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.44\n",
            "Iteration:  364 | Train Loss:  0.013535729646682738 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.44\n",
            "Iteration:  365 | Train Loss:  0.013337990045547485 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.44\n",
            "Iteration:  366 | Train Loss:  0.013160368204116821 | Train Accuracy:  0.66 | Validation Accuracy:  0.44\n",
            "Iteration:  367 | Train Loss:  0.013345762491226196 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.44\n",
            "Iteration:  368 | Train Loss:  0.013405193090438843 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.44\n",
            "Iteration:  369 | Train Loss:  0.01359114408493042 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  370 | Train Loss:  0.013176571130752563 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  371 | Train Loss:  0.013493903875350953 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  372 | Train Loss:  0.013283584117889404 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.44\n",
            "Iteration:  373 | Train Loss:  0.01308290958404541 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.44\n",
            "Iteration:  374 | Train Loss:  0.01328872799873352 | Train Accuracy:  0.66 | Validation Accuracy:  0.44\n",
            "Iteration:  375 | Train Loss:  0.013358813524246217 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.44\n",
            "Iteration:  376 | Train Loss:  0.013541477918624877 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  377 | Train Loss:  0.013119513988494874 | Train Accuracy:  0.7 | Validation Accuracy:  0.48\n",
            "Iteration:  378 | Train Loss:  0.013448104858398438 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  379 | Train Loss:  0.01322556972503662 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  380 | Train Loss:  0.013000231981277467 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.44\n",
            "Iteration:  381 | Train Loss:  0.01322810173034668 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.44\n",
            "Iteration:  382 | Train Loss:  0.013309199810028077 | Train Accuracy:  0.66 | Validation Accuracy:  0.44\n",
            "Iteration:  383 | Train Loss:  0.013493903875350953 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  384 | Train Loss:  0.013052293062210084 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  385 | Train Loss:  0.01339970350265503 | Train Accuracy:  0.7 | Validation Accuracy:  0.48\n",
            "Iteration:  386 | Train Loss:  0.013163050413131714 | Train Accuracy:  0.7 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  387 | Train Loss:  0.0129128098487854 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  388 | Train Loss:  0.013164006471633911 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.44\n",
            "Iteration:  389 | Train Loss:  0.013256809711456298 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.44\n",
            "Iteration:  390 | Train Loss:  0.013441135883331299 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  391 | Train Loss:  0.012984260320663452 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  392 | Train Loss:  0.013347514867782594 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  393 | Train Loss:  0.013097755908966065 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  394 | Train Loss:  0.012819958925247192 | Train Accuracy:  0.7 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  395 | Train Loss:  0.01309664487838745 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  396 | Train Loss:  0.013202041387557983 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  397 | Train Loss:  0.013381836414337158 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  398 | Train Loss:  0.012914249897003174 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  399 | Train Loss:  0.013291743993759155 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  400 | Train Loss:  0.013029216527938843 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  401 | Train Loss:  0.012722539901733398 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  402 | Train Loss:  0.013026285171508788 | Train Accuracy:  0.7 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  403 | Train Loss:  0.013144832849502564 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  404 | Train Loss:  0.013317817449569702 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  405 | Train Loss:  0.012842917442321777 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  406 | Train Loss:  0.013232272863388062 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  407 | Train Loss:  0.012957795858383178 | Train Accuracy:  0.7 | Validation Accuracy:  0.48\n",
            "Iteration:  408 | Train Loss:  0.012620687484741211 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  409 | Train Loss:  0.012952984571456909 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  410 | Train Loss:  0.013085386753082275 | Train Accuracy:  0.7 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  411 | Train Loss:  0.013250739574432372 | Train Accuracy:  0.7 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  412 | Train Loss:  0.012767794132232667 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  413 | Train Loss:  0.01316948413848877 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  414 | Train Loss:  0.012883439064025878 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  415 | Train Loss:  0.012515022754669189 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  416 | Train Loss:  0.012876948118209839 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  417 | Train Loss:  0.013023909330368042 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  418 | Train Loss:  0.013180994987487793 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  419 | Train Loss:  0.012689496278762818 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  420 | Train Loss:  0.013103451728820801 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  421 | Train Loss:  0.012806483507156373 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  422 | Train Loss:  0.01240584373474121 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  423 | Train Loss:  0.01279848337173462 | Train Accuracy:  0.7 | Validation Accuracy:  0.48\n",
            "Iteration:  424 | Train Loss:  0.012960678339004517 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  425 | Train Loss:  0.013108311891555787 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  426 | Train Loss:  0.012608546018600463 | Train Accuracy:  0.72 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  427 | Train Loss:  0.01303427219390869 | Train Accuracy:  0.72 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  428 | Train Loss:  0.012727333307266235 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  429 | Train Loss:  0.0122935152053833 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  430 | Train Loss:  0.012717920541763305 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  431 | Train Loss:  0.012895913124084472 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  432 | Train Loss:  0.01303412914276123 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  433 | Train Loss:  0.012523586750030518 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  434 | Train Loss:  0.012962334156036377 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  435 | Train Loss:  0.012645984888076783 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  436 | Train Loss:  0.012178616523742676 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  437 | Train Loss:  0.012635550498962402 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  438 | Train Loss:  0.012829879522323609 | Train Accuracy:  0.7 | Validation Accuracy:  0.48\n",
            "Iteration:  439 | Train Loss:  0.012956702709197998 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  440 | Train Loss:  0.012437617778778077 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  441 | Train Loss:  0.012887606620788574 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  442 | Train Loss:  0.012563090324401855 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  443 | Train Loss:  0.012061091661453248 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  444 | Train Loss:  0.01255170464515686 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  445 | Train Loss:  0.012762866020202636 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  446 | Train Loss:  0.012874370813369751 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  447 | Train Loss:  0.012351553440093994 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  448 | Train Loss:  0.012810288667678834 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  449 | Train Loss:  0.012478805780410766 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  450 | Train Loss:  0.011941996812820434 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  451 | Train Loss:  0.012466588020324708 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  452 | Train Loss:  0.0126948881149292 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  453 | Train Loss:  0.012792654037475586 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  454 | Train Loss:  0.012261322736740111 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  455 | Train Loss:  0.01273074746131897 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  456 | Train Loss:  0.01239319086074829 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  457 | Train Loss:  0.011821784973144532 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  458 | Train Loss:  0.012380449771881104 | Train Accuracy:  0.72 | Validation Accuracy:  0.52\n",
            "Iteration:  459 | Train Loss:  0.012626193761825562 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  460 | Train Loss:  0.012709305286407471 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  461 | Train Loss:  0.01216976523399353 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  462 | Train Loss:  0.01264898419380188 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  463 | Train Loss:  0.01230677604675293 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  464 | Train Loss:  0.01170038342475891 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  465 | Train Loss:  0.01229348659515381 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  466 | Train Loss:  0.012556976079940796 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  467 | Train Loss:  0.012622401714324952 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  468 | Train Loss:  0.012078313827514649 | Train Accuracy:  0.72 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  469 | Train Loss:  0.012565181255340577 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  470 | Train Loss:  0.01221961498260498 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  471 | Train Loss:  0.011578726768493652 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  472 | Train Loss:  0.012205787897109986 | Train Accuracy:  0.72 | Validation Accuracy:  0.52\n",
            "Iteration:  473 | Train Loss:  0.012487293481826782 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  474 | Train Loss:  0.012535706758499146 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  475 | Train Loss:  0.011984610557556152 | Train Accuracy:  0.72 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  476 | Train Loss:  0.012479672431945801 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  477 | Train Loss:  0.012131588459014893 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  478 | Train Loss:  0.01145746111869812 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  479 | Train Loss:  0.012117486000061035 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  480 | Train Loss:  0.012417292594909668 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  481 | Train Loss:  0.012447843551635742 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  482 | Train Loss:  0.011890677213668823 | Train Accuracy:  0.72 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  483 | Train Loss:  0.012392449378967284 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  484 | Train Loss:  0.012044060230255126 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  485 | Train Loss:  0.011335437297821044 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  486 | Train Loss:  0.012028836011886597 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  487 | Train Loss:  0.012347064018249511 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  488 | Train Loss:  0.012358719110488891 | Train Accuracy:  0.74 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  489 | Train Loss:  0.011794331073760987 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  490 | Train Loss:  0.012303942441940307 | Train Accuracy:  0.74 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  491 | Train Loss:  0.011956071853637696 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  492 | Train Loss:  0.011214325428009033 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  493 | Train Loss:  0.011939795017242431 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  494 | Train Loss:  0.012276642322540283 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  495 | Train Loss:  0.012268400192260743 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  496 | Train Loss:  0.011698395013809204 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  497 | Train Loss:  0.012214288711547852 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  498 | Train Loss:  0.011867705583572388 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  499 | Train Loss:  0.011094838380813599 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  500 | Train Loss:  0.0118503737449646 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  501 | Train Loss:  0.012206143140792847 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  502 | Train Loss:  0.0121797513961792 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  503 | Train Loss:  0.011600461006164551 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  504 | Train Loss:  0.012123639583587647 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  505 | Train Loss:  0.011780239343643188 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  506 | Train Loss:  0.010975130796432496 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  507 | Train Loss:  0.011761001348495483 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  508 | Train Loss:  0.012135568857192993 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  509 | Train Loss:  0.012091896533966064 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  510 | Train Loss:  0.011496849060058593 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  511 | Train Loss:  0.012032198905944824 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  512 | Train Loss:  0.011691845655441284 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  513 | Train Loss:  0.010858092308044433 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  514 | Train Loss:  0.011671444177627563 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  515 | Train Loss:  0.012064884901046753 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  516 | Train Loss:  0.011998442411422729 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  517 | Train Loss:  0.011401557922363281 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  518 | Train Loss:  0.011940191984176635 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  519 | Train Loss:  0.011605372428894043 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  520 | Train Loss:  0.010741060972213745 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  521 | Train Loss:  0.011581860780715943 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  522 | Train Loss:  0.011994254589080811 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  523 | Train Loss:  0.011912455558776855 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  524 | Train Loss:  0.011295955181121826 | Train Accuracy:  0.76 | Validation Accuracy:  0.48\n",
            "Iteration:  525 | Train Loss:  0.01184768319129944 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  526 | Train Loss:  0.01151831865310669 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  527 | Train Loss:  0.010625962018966675 | Train Accuracy:  0.76 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  528 | Train Loss:  0.011492458581924438 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  529 | Train Loss:  0.011923439502716064 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  530 | Train Loss:  0.011820706129074097 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  531 | Train Loss:  0.011196151971817017 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  532 | Train Loss:  0.01175501823425293 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  533 | Train Loss:  0.011431735754013062 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  534 | Train Loss:  0.01051364779472351 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  535 | Train Loss:  0.011402710676193237 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  536 | Train Loss:  0.011852738857269287 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  537 | Train Loss:  0.011730500459671021 | Train Accuracy:  0.76 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  538 | Train Loss:  0.01109755277633667 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  539 | Train Loss:  0.011662964820861816 | Train Accuracy:  0.76 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  540 | Train Loss:  0.011346625089645386 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  541 | Train Loss:  0.010402090549468994 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  542 | Train Loss:  0.011313141584396362 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  543 | Train Loss:  0.01178223967552185 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  544 | Train Loss:  0.011646291017532348 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  545 | Train Loss:  0.010992332696914672 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  546 | Train Loss:  0.01157172441482544 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  547 | Train Loss:  0.011262201070785523 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  548 | Train Loss:  0.010291253328323363 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  549 | Train Loss:  0.011224102973937989 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  550 | Train Loss:  0.011711517572402954 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  551 | Train Loss:  0.011555423736572265 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  552 | Train Loss:  0.010892162322998047 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  553 | Train Loss:  0.011481872797012328 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  554 | Train Loss:  0.011179132461547852 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  555 | Train Loss:  0.01018114686012268 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  556 | Train Loss:  0.01113539457321167 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  557 | Train Loss:  0.011640747785568237 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  558 | Train Loss:  0.011464637517929078 | Train Accuracy:  0.78 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  559 | Train Loss:  0.010790166854858398 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  560 | Train Loss:  0.011392624378204345 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  561 | Train Loss:  0.01109605073928833 | Train Accuracy:  0.78 | Validation Accuracy:  0.48\n",
            "Iteration:  562 | Train Loss:  0.010074169635772704 | Train Accuracy:  0.78 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  563 | Train Loss:  0.01104658842086792 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  564 | Train Loss:  0.011570076942443847 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  565 | Train Loss:  0.011373724937438965 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  566 | Train Loss:  0.010691323280334473 | Train Accuracy:  0.78 | Validation Accuracy:  0.48\n",
            "Iteration:  567 | Train Loss:  0.011304240226745605 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  568 | Train Loss:  0.011014487743377686 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  569 | Train Loss:  0.00996837556362152 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  570 | Train Loss:  0.01095787763595581 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  571 | Train Loss:  0.01149970293045044 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  572 | Train Loss:  0.011288859844207765 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  573 | Train Loss:  0.010586555004119874 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  574 | Train Loss:  0.011215968132019043 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  575 | Train Loss:  0.01093358039855957 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  576 | Train Loss:  0.009863548278808594 | Train Accuracy:  0.78 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  577 | Train Loss:  0.010869983434677124 | Train Accuracy:  0.78 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  578 | Train Loss:  0.011429361104965209 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  579 | Train Loss:  0.011205252408981323 | Train Accuracy:  0.8 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  580 | Train Loss:  0.010479406118392945 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  581 | Train Loss:  0.011127786636352539 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  582 | Train Loss:  0.01085288166999817 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  583 | Train Loss:  0.009760917425155639 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  584 | Train Loss:  0.010782626867294311 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  585 | Train Loss:  0.01135891318321228 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  586 | Train Loss:  0.01111548662185669 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  587 | Train Loss:  0.010379934310913086 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  588 | Train Loss:  0.011040626764297486 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  589 | Train Loss:  0.010773469209671021 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  590 | Train Loss:  0.00966035783290863 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  591 | Train Loss:  0.010694884061813355 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  592 | Train Loss:  0.011288784742355347 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  593 | Train Loss:  0.011026557683944702 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  594 | Train Loss:  0.010282915830612183 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  595 | Train Loss:  0.010954475402832032 | Train Accuracy:  0.8 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  596 | Train Loss:  0.010695827007293702 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  597 | Train Loss:  0.009560168385505677 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.48\n",
            "Iteration:  598 | Train Loss:  0.010607194900512696 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  599 | Train Loss:  0.01121894121170044 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  600 | Train Loss:  0.010941929817199707 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  601 | Train Loss:  0.01018303155899048 | Train Accuracy:  0.82 | Validation Accuracy:  0.52\n",
            "Iteration:  602 | Train Loss:  0.010868754386901856 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  603 | Train Loss:  0.010619206428527832 | Train Accuracy:  0.78 | Validation Accuracy:  0.48\n",
            "Iteration:  604 | Train Loss:  0.00946065604686737 | Train Accuracy:  0.78 | Validation Accuracy:  0.48\n",
            "Iteration:  605 | Train Loss:  0.010519756078720093 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  606 | Train Loss:  0.01114902377128601 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  607 | Train Loss:  0.010856071710586548 | Train Accuracy:  0.82 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  608 | Train Loss:  0.010083919763565064 | Train Accuracy:  0.82 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  609 | Train Loss:  0.010783891677856445 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  610 | Train Loss:  0.010543956756591796 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  611 | Train Loss:  0.009361831545829773 | Train Accuracy:  0.78 | Validation Accuracy:  0.48\n",
            "Iteration:  612 | Train Loss:  0.010432485342025757 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  613 | Train Loss:  0.01107918381690979 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  614 | Train Loss:  0.010771667957305909 | Train Accuracy:  0.82 | Validation Accuracy:  0.52\n",
            "Iteration:  615 | Train Loss:  0.009984515309333801 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  616 | Train Loss:  0.010699588060379028 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  617 | Train Loss:  0.010469475984573364 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  618 | Train Loss:  0.0092642343044281 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.48\n",
            "Iteration:  619 | Train Loss:  0.010345416069030762 | Train Accuracy:  0.78 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  620 | Train Loss:  0.011009324789047242 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  621 | Train Loss:  0.01068698763847351 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  622 | Train Loss:  0.009886656403541565 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  623 | Train Loss:  0.010616021156311035 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  624 | Train Loss:  0.010395364761352539 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  625 | Train Loss:  0.00916902780532837 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  626 | Train Loss:  0.010258183479309083 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  627 | Train Loss:  0.01093967080116272 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  628 | Train Loss:  0.010603311061859131 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  629 | Train Loss:  0.009790826439857483 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  630 | Train Loss:  0.010533413887023925 | Train Accuracy:  0.82 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  631 | Train Loss:  0.010322422981262206 | Train Accuracy:  0.8 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  632 | Train Loss:  0.00907469093799591 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  633 | Train Loss:  0.010171116590499877 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  634 | Train Loss:  0.010870131254196167 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  635 | Train Loss:  0.010521140098571777 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  636 | Train Loss:  0.009694836139678954 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  637 | Train Loss:  0.010451290607452392 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  638 | Train Loss:  0.010250113010406493 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  639 | Train Loss:  0.008981674909591675 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  640 | Train Loss:  0.010084216594696044 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  641 | Train Loss:  0.010800626277923584 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  642 | Train Loss:  0.010438563823699952 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  643 | Train Loss:  0.009600273370742797 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  644 | Train Loss:  0.010369917154312134 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  645 | Train Loss:  0.010178499221801758 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  646 | Train Loss:  0.008890339136123658 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  647 | Train Loss:  0.009997276067733764 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  648 | Train Loss:  0.010731354951858521 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  649 | Train Loss:  0.010357098579406738 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  650 | Train Loss:  0.009506636261940003 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  651 | Train Loss:  0.010289379358291627 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  652 | Train Loss:  0.01010817289352417 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  653 | Train Loss:  0.008799431324005126 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  654 | Train Loss:  0.009910637140274048 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  655 | Train Loss:  0.010662196874618531 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  656 | Train Loss:  0.010276778936386108 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  657 | Train Loss:  0.009412587881088256 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  658 | Train Loss:  0.010209174156188964 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  659 | Train Loss:  0.010038368701934815 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  660 | Train Loss:  0.008709819912910461 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  661 | Train Loss:  0.009824202060699463 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  662 | Train Loss:  0.010593152046203614 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  663 | Train Loss:  0.01019646406173706 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  664 | Train Loss:  0.009319629073143005 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  665 | Train Loss:  0.010129595994949342 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  666 | Train Loss:  0.00996964693069458 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  667 | Train Loss:  0.008620645999908447 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  668 | Train Loss:  0.009738153219223023 | Train Accuracy:  0.8 | Validation Accuracy:  0.52\n",
            "Iteration:  669 | Train Loss:  0.010524193048477173 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  670 | Train Loss:  0.010116679668426514 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  671 | Train Loss:  0.009226750135421753 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  672 | Train Loss:  0.010050324201583862 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  673 | Train Loss:  0.009901195764541626 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  674 | Train Loss:  0.008533103466033936 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  675 | Train Loss:  0.009652248620986938 | Train Accuracy:  0.8 | Validation Accuracy:  0.52\n",
            "Iteration:  676 | Train Loss:  0.01045536994934082 | Train Accuracy:  0.8 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  677 | Train Loss:  0.010036150217056275 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  678 | Train Loss:  0.009136025309562684 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  679 | Train Loss:  0.009971908330917358 | Train Accuracy:  0.84 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  680 | Train Loss:  0.009833693504333496 | Train Accuracy:  0.82 | Validation Accuracy:  0.52\n",
            "Iteration:  681 | Train Loss:  0.008446434140205383 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  682 | Train Loss:  0.009566554427146911 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  683 | Train Loss:  0.01038681983947754 | Train Accuracy:  0.8 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  684 | Train Loss:  0.009957199692726135 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  685 | Train Loss:  0.009045355319976807 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  686 | Train Loss:  0.009893999695777892 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  687 | Train Loss:  0.009766906499862671 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  688 | Train Loss:  0.008360511660575866 | Train Accuracy:  0.82 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  689 | Train Loss:  0.009481241106986999 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  690 | Train Loss:  0.010318421125411988 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  691 | Train Loss:  0.0098785400390625 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  692 | Train Loss:  0.00895527720451355 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  693 | Train Loss:  0.009816523194313049 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  694 | Train Loss:  0.009700533151626587 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  695 | Train Loss:  0.0082757705450058 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  696 | Train Loss:  0.009396207332611085 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  697 | Train Loss:  0.010250285863876343 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  698 | Train Loss:  0.00980100154876709 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  699 | Train Loss:  0.008865596055984496 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  700 | Train Loss:  0.009739575386047363 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  701 | Train Loss:  0.009634780287742615 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  702 | Train Loss:  0.008191835880279542 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  703 | Train Loss:  0.009311558008193969 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  704 | Train Loss:  0.010182275772094726 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  705 | Train Loss:  0.009722903370857239 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  706 | Train Loss:  0.008777302503585816 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  707 | Train Loss:  0.009663225412368774 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  708 | Train Loss:  0.00956943154335022 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  709 | Train Loss:  0.0081091570854187 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  710 | Train Loss:  0.009227147102355957 | Train Accuracy:  0.82 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  711 | Train Loss:  0.010114635229110719 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  712 | Train Loss:  0.009646851420402527 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  713 | Train Loss:  0.008689013719558715 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  714 | Train Loss:  0.009587430357933045 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  715 | Train Loss:  0.009504823088645935 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  716 | Train Loss:  0.008026900291442872 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  717 | Train Loss:  0.009143254160881043 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  718 | Train Loss:  0.010047072172164917 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  719 | Train Loss:  0.00956990361213684 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  720 | Train Loss:  0.008602010607719422 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  721 | Train Loss:  0.0095121169090271 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  722 | Train Loss:  0.009440398216247559 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  723 | Train Loss:  0.007946027517318726 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  724 | Train Loss:  0.009059597849845885 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  725 | Train Loss:  0.009979785084724427 | Train Accuracy:  0.82 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  726 | Train Loss:  0.009493174552917481 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  727 | Train Loss:  0.008516398668289184 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  728 | Train Loss:  0.009437608122825623 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  729 | Train Loss:  0.009376637935638428 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  730 | Train Loss:  0.007865917682647706 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  731 | Train Loss:  0.008976286053657532 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  732 | Train Loss:  0.009912812113761903 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  733 | Train Loss:  0.009417662620544434 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  734 | Train Loss:  0.008431155681610108 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  735 | Train Loss:  0.009363635182380677 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  736 | Train Loss:  0.009313425421714783 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  737 | Train Loss:  0.0077864092588424685 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  738 | Train Loss:  0.008893468976020813 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  739 | Train Loss:  0.00984606146812439 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  740 | Train Loss:  0.009342620372772217 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  741 | Train Loss:  0.008346418142318726 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  742 | Train Loss:  0.009290086627006531 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  743 | Train Loss:  0.009250504970550537 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  744 | Train Loss:  0.0077077698707580565 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  745 | Train Loss:  0.008811085224151612 | Train Accuracy:  0.84 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  746 | Train Loss:  0.009779542684555054 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  747 | Train Loss:  0.00926766276359558 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  748 | Train Loss:  0.008262642025947571 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  749 | Train Loss:  0.00921710729598999 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  750 | Train Loss:  0.009187951683998108 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  751 | Train Loss:  0.007630002498626709 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  752 | Train Loss:  0.008729102611541749 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  753 | Train Loss:  0.00971329927444458 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  754 | Train Loss:  0.009193193316459656 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  755 | Train Loss:  0.008179674744606019 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  756 | Train Loss:  0.009144726395606994 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  757 | Train Loss:  0.009125842452049256 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  758 | Train Loss:  0.007552934288978577 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  759 | Train Loss:  0.008647570013999939 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  760 | Train Loss:  0.009647294878959656 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  761 | Train Loss:  0.009118753671646117 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  762 | Train Loss:  0.008097686171531678 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  763 | Train Loss:  0.009072922468185425 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  764 | Train Loss:  0.009064072370529174 | Train Accuracy:  0.84 | Validation Accuracy:  0.52\n",
            "Iteration:  765 | Train Loss:  0.007476694583892822 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  766 | Train Loss:  0.008566452860832215 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  767 | Train Loss:  0.009581570625305175 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  768 | Train Loss:  0.009044688940048218 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  769 | Train Loss:  0.008016553521156312 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  770 | Train Loss:  0.009001724720001221 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  771 | Train Loss:  0.009002720713615417 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  772 | Train Loss:  0.007401164174079895 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  773 | Train Loss:  0.008485777974128724 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  774 | Train Loss:  0.009516183733940125 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  775 | Train Loss:  0.00897194504737854 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  776 | Train Loss:  0.007935609221458435 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  777 | Train Loss:  0.008930999636650085 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  778 | Train Loss:  0.008941819667816162 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  779 | Train Loss:  0.007326028347015381 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  780 | Train Loss:  0.008405707478523254 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  781 | Train Loss:  0.009450984001159669 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  782 | Train Loss:  0.008899025917053223 | Train Accuracy:  0.86 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  783 | Train Loss:  0.007855374813079834 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  784 | Train Loss:  0.008860655426979065 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  785 | Train Loss:  0.00888101100921631 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  786 | Train Loss:  0.007251812219619751 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  787 | Train Loss:  0.008326077461242675 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  788 | Train Loss:  0.009386045336723327 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  789 | Train Loss:  0.008826109170913697 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  790 | Train Loss:  0.007776169776916504 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  791 | Train Loss:  0.008790937066078187 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  792 | Train Loss:  0.008820554614067078 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  793 | Train Loss:  0.007178314924240112 | Train Accuracy:  0.86 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  794 | Train Loss:  0.008246883153915405 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  795 | Train Loss:  0.009321417808532715 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  796 | Train Loss:  0.008754180669784546 | Train Accuracy:  0.86 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  797 | Train Loss:  0.007697391510009766 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  798 | Train Loss:  0.008721746802330017 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  799 | Train Loss:  0.008760522603988647 | Train Accuracy:  0.86 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  800 | Train Loss:  0.007105260491371155 | Train Accuracy:  0.86 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  801 | Train Loss:  0.008168248534202576 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  802 | Train Loss:  0.00925703227519989 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  803 | Train Loss:  0.008682733178138733 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  804 | Train Loss:  0.007619020938873291 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  805 | Train Loss:  0.008652945160865783 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  806 | Train Loss:  0.008700697422027589 | Train Accuracy:  0.86 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  807 | Train Loss:  0.007032881379127502 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  808 | Train Loss:  0.008090126514434814 | Train Accuracy:  0.86 | Validation Accuracy:  0.52\n",
            "Iteration:  809 | Train Loss:  0.009192875623703002 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  810 | Train Loss:  0.00861180067062378 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  811 | Train Loss:  0.007540986537933349 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  812 | Train Loss:  0.008584489226341247 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  813 | Train Loss:  0.008641040325164795 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  814 | Train Loss:  0.006961111426353455 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  815 | Train Loss:  0.008012564182281494 | Train Accuracy:  0.86 | Validation Accuracy:  0.52\n",
            "Iteration:  816 | Train Loss:  0.00912907838821411 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  817 | Train Loss:  0.008542906045913696 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  818 | Train Loss:  0.007461609840393066 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  819 | Train Loss:  0.00851571261882782 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  820 | Train Loss:  0.008581203222274781 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  821 | Train Loss:  0.006889786720275879 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  822 | Train Loss:  0.007935823798179626 | Train Accuracy:  0.86 | Validation Accuracy:  0.52\n",
            "Iteration:  823 | Train Loss:  0.00906545102596283 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  824 | Train Loss:  0.008470876812934876 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  825 | Train Loss:  0.007384836077690125 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  826 | Train Loss:  0.008447723388671875 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  827 | Train Loss:  0.008521260023117065 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  828 | Train Loss:  0.006820037364959717 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  829 | Train Loss:  0.007859192490577697 | Train Accuracy:  0.86 | Validation Accuracy:  0.52\n",
            "Iteration:  830 | Train Loss:  0.009002299308776855 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  831 | Train Loss:  0.008399473428726196 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  832 | Train Loss:  0.007309539914131164 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  833 | Train Loss:  0.008380849361419678 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  834 | Train Loss:  0.00846219003200531 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  835 | Train Loss:  0.006750602722167969 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  836 | Train Loss:  0.0077829939126968384 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  837 | Train Loss:  0.008939498662948608 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  838 | Train Loss:  0.008328850269317628 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  839 | Train Loss:  0.007235308885574341 | Train Accuracy:  0.86 | Validation Accuracy:  0.56\n",
            "Iteration:  840 | Train Loss:  0.008314892053604125 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  841 | Train Loss:  0.008403852581977844 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  842 | Train Loss:  0.00668140709400177 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  843 | Train Loss:  0.007707321643829345 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  844 | Train Loss:  0.008876955509185791 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  845 | Train Loss:  0.008259636759757995 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  846 | Train Loss:  0.007161255478858947 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  847 | Train Loss:  0.008249446749687195 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  848 | Train Loss:  0.008346002101898193 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  849 | Train Loss:  0.0066124343872070316 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  850 | Train Loss:  0.007632271647453308 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  851 | Train Loss:  0.008814599514007568 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  852 | Train Loss:  0.008191016912460327 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  853 | Train Loss:  0.007087101936340332 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.56\n",
            "Iteration:  854 | Train Loss:  0.008184086084365844 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  855 | Train Loss:  0.008288122415542602 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  856 | Train Loss:  0.00654407799243927 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  857 | Train Loss:  0.007557820081710815 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  858 | Train Loss:  0.008752371072769166 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  859 | Train Loss:  0.008121825456619262 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  860 | Train Loss:  0.007013763189315796 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  861 | Train Loss:  0.00811909258365631 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  862 | Train Loss:  0.008230252265930176 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  863 | Train Loss:  0.006476597785949707 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  864 | Train Loss:  0.007483783960342407 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  865 | Train Loss:  0.008690348863601684 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  866 | Train Loss:  0.008052607178688049 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  867 | Train Loss:  0.006941382884979248 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  868 | Train Loss:  0.008054722547531128 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  869 | Train Loss:  0.00817272424697876 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  870 | Train Loss:  0.006409770250320435 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  871 | Train Loss:  0.007409968376159668 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  872 | Train Loss:  0.008628687858581542 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  873 | Train Loss:  0.0079857337474823 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  874 | Train Loss:  0.006869683265686035 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  875 | Train Loss:  0.007991468906402588 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  876 | Train Loss:  0.008116413950920104 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  877 | Train Loss:  0.006342719793319702 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  878 | Train Loss:  0.007336914539337158 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  879 | Train Loss:  0.00856716513633728 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  880 | Train Loss:  0.007919872403144837 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  881 | Train Loss:  0.006797032952308654 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  882 | Train Loss:  0.007927803993225098 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  883 | Train Loss:  0.008059834837913513 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  884 | Train Loss:  0.0062760567665100095 | Train Accuracy:  0.88 | Validation Accuracy:  0.52\n",
            "Iteration:  885 | Train Loss:  0.00726464331150055 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  886 | Train Loss:  0.008505672216415405 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  887 | Train Loss:  0.00785268247127533 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  888 | Train Loss:  0.006725085377693177 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  889 | Train Loss:  0.0078642076253891 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  890 | Train Loss:  0.008002846240997315 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  891 | Train Loss:  0.00621055006980896 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  892 | Train Loss:  0.00719277024269104 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  893 | Train Loss:  0.008444330096244812 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  894 | Train Loss:  0.007784664034843445 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  895 | Train Loss:  0.006654706001281738 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  896 | Train Loss:  0.007801442146301269 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  897 | Train Loss:  0.007946165204048157 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  898 | Train Loss:  0.006145888566970825 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  899 | Train Loss:  0.007121292352676392 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  900 | Train Loss:  0.008383188843727112 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  901 | Train Loss:  0.007716824412345886 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  902 | Train Loss:  0.006584930419921875 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  903 | Train Loss:  0.007739176750183105 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  904 | Train Loss:  0.007888899445533752 | Train Accuracy:  0.88 | Validation Accuracy:  0.52\n",
            "Iteration:  905 | Train Loss:  0.0060830038785934445 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  906 | Train Loss:  0.007049868106842041 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  907 | Train Loss:  0.008322314620018005 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  908 | Train Loss:  0.007648799419403076 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  909 | Train Loss:  0.006517025232315063 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  910 | Train Loss:  0.007678236365318298 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  911 | Train Loss:  0.007832785248756408 | Train Accuracy:  0.88 | Validation Accuracy:  0.52\n",
            "Iteration:  912 | Train Loss:  0.0060201895236969 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  913 | Train Loss:  0.006978776454925537 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  914 | Train Loss:  0.00826179325580597 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  915 | Train Loss:  0.007584350109100342 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  916 | Train Loss:  0.006448723673820496 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  917 | Train Loss:  0.00761807918548584 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  918 | Train Loss:  0.007777567505836486 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  919 | Train Loss:  0.005957220196723938 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  920 | Train Loss:  0.006908571720123291 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  921 | Train Loss:  0.008201304078102111 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  922 | Train Loss:  0.007519760727882385 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  923 | Train Loss:  0.006380065083503723 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  924 | Train Loss:  0.007557542324066162 | Train Accuracy:  0.88 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  925 | Train Loss:  0.007722768187522888 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  926 | Train Loss:  0.005893750190734863 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  927 | Train Loss:  0.006839411854743957 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  928 | Train Loss:  0.008140804767608643 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  929 | Train Loss:  0.0074547106027603146 | Train Accuracy:  0.88 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  930 | Train Loss:  0.0063109475374221805 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  931 | Train Loss:  0.007496389746665955 | Train Accuracy:  0.88 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  932 | Train Loss:  0.007667197585105896 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  933 | Train Loss:  0.005831313133239746 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  934 | Train Loss:  0.006770842671394348 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  935 | Train Loss:  0.008080375194549561 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  936 | Train Loss:  0.007387641072273255 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  937 | Train Loss:  0.006243550777435302 | Train Accuracy:  0.88 | Validation Accuracy:  0.56\n",
            "Iteration:  938 | Train Loss:  0.007435842752456665 | Train Accuracy:  0.88 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  939 | Train Loss:  0.0076113492250442505 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  940 | Train Loss:  0.005770387053489685 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  941 | Train Loss:  0.006702415347099304 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  942 | Train Loss:  0.008020227551460266 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  943 | Train Loss:  0.007320605516433716 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  944 | Train Loss:  0.006177303194999695 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  945 | Train Loss:  0.0073760849237442016 | Train Accuracy:  0.88 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  946 | Train Loss:  0.007556205987930298 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  947 | Train Loss:  0.005709724426269531 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  948 | Train Loss:  0.006634477376937866 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  949 | Train Loss:  0.007960325479507447 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  950 | Train Loss:  0.0072549813985824585 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  951 | Train Loss:  0.006111175417900085 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  952 | Train Loss:  0.0073167383670806885 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  953 | Train Loss:  0.007501314282417297 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  954 | Train Loss:  0.005649592876434326 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  955 | Train Loss:  0.006567033529281616 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  956 | Train Loss:  0.00790062963962555 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  957 | Train Loss:  0.007189815044403076 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  958 | Train Loss:  0.00604529857635498 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  959 | Train Loss:  0.007257611155509948 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  960 | Train Loss:  0.0074466407299041745 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  961 | Train Loss:  0.0055898714065551755 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  962 | Train Loss:  0.006500104665756226 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  963 | Train Loss:  0.007841143608093262 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  964 | Train Loss:  0.007125346660614013 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  965 | Train Loss:  0.005979681015014648 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  966 | Train Loss:  0.007198755145072937 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  967 | Train Loss:  0.007392226457595825 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  968 | Train Loss:  0.0055305886268615725 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  969 | Train Loss:  0.006433706879615784 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  970 | Train Loss:  0.0077818560600280764 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  971 | Train Loss:  0.007061258554458618 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  972 | Train Loss:  0.0059145474433898925 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  973 | Train Loss:  0.007140238881111145 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.56\n",
            "Iteration:  974 | Train Loss:  0.007337974309921265 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  975 | Train Loss:  0.005471957921981812 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  976 | Train Loss:  0.0063677746057510375 | Train Accuracy:  0.9 | Validation Accuracy:  0.52\n",
            "Iteration:  977 | Train Loss:  0.007722768187522888 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  978 | Train Loss:  0.006997356414794922 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  979 | Train Loss:  0.005849846601486206 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  980 | Train Loss:  0.007081952691078186 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  981 | Train Loss:  0.007283973693847656 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  982 | Train Loss:  0.005413760542869568 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  983 | Train Loss:  0.006302366852760315 | Train Accuracy:  0.9 | Validation Accuracy:  0.52\n",
            "Iteration:  984 | Train Loss:  0.007663877010345459 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  985 | Train Loss:  0.006933817267417907 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  986 | Train Loss:  0.005785621404647827 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  987 | Train Loss:  0.007023980617523193 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.56\n",
            "Iteration:  988 | Train Loss:  0.007230274677276612 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  989 | Train Loss:  0.0053560203313827515 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  990 | Train Loss:  0.006237375140190124 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  991 | Train Loss:  0.007605242133140564 | Train Accuracy:  0.9 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  992 | Train Loss:  0.006871541738510132 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  993 | Train Loss:  0.005721809267997742 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  994 | Train Loss:  0.0069665277004241945 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.56\n",
            "Iteration:  995 | Train Loss:  0.007177127599716187 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  996 | Train Loss:  0.005298648476600647 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  997 | Train Loss:  0.006172875761985779 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  998 | Train Loss:  0.007546830177307129 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  999 | Train Loss:  0.006810114979743958 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1000 | Train Loss:  0.005658012628555298 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  1001 | Train Loss:  0.006909148693084717 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.56\n",
            "Iteration:  1002 | Train Loss:  0.007124149203300476 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1003 | Train Loss:  0.005241886973381043 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1004 | Train Loss:  0.006108770966529846 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1005 | Train Loss:  0.007488866448402405 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1006 | Train Loss:  0.006753988862037659 | Train Accuracy:  0.9 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1007 | Train Loss:  0.005591607689857483 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  1008 | Train Loss:  0.006851036548614502 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  1009 | Train Loss:  0.007071593999862671 | Train Accuracy:  0.9 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1010 | Train Loss:  0.0051844149827957155 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1011 | Train Loss:  0.006046106219291687 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1012 | Train Loss:  0.007430968284606934 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1013 | Train Loss:  0.006690583825111389 | Train Accuracy:  0.9 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1014 | Train Loss:  0.005527589917182923 | Train Accuracy:  0.8942857142857142 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  1015 | Train Loss:  0.00679250955581665 | Train Accuracy:  0.9 | Validation Accuracy:  0.56\n",
            "Iteration:  1016 | Train Loss:  0.007016920447349548 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1017 | Train Loss:  0.0051297593116760255 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1018 | Train Loss:  0.005983469486236573 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1019 | Train Loss:  0.007373286485671997 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1020 | Train Loss:  0.0066237694025039675 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  1021 | Train Loss:  0.005466828346252442 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  1022 | Train Loss:  0.006735466718673706 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  1023 | Train Loss:  0.006962568759918213 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1024 | Train Loss:  0.005076546669006348 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1025 | Train Loss:  0.005920846462249756 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1026 | Train Loss:  0.0073159033060073856 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1027 | Train Loss:  0.006558513045310974 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  1028 | Train Loss:  0.0054081171751022335 | Train Accuracy:  0.8971428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  1029 | Train Loss:  0.006680437326431274 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  1030 | Train Loss:  0.0069100183248519895 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1031 | Train Loss:  0.005023320913314819 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1032 | Train Loss:  0.005858537554740906 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1033 | Train Loss:  0.007258850932121277 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1034 | Train Loss:  0.006497270464897156 | Train Accuracy:  0.9028571428571428 | Validation Accuracy:  0.56\n",
            "Iteration:  1035 | Train Loss:  0.005348462462425232 | Train Accuracy:  0.9 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  1036 | Train Loss:  0.006625716686248779 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  1037 | Train Loss:  0.006858457922935486 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1038 | Train Loss:  0.004969548881053925 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1039 | Train Loss:  0.005796992778778076 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1040 | Train Loss:  0.007201993465423584 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1041 | Train Loss:  0.006437509655952454 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  1042 | Train Loss:  0.005288156270980835 | Train Accuracy:  0.9 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  1043 | Train Loss:  0.0065707570314407346 | Train Accuracy:  0.9057142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  1044 | Train Loss:  0.006806954145431519 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1045 | Train Loss:  0.004915958642959595 | Train Accuracy:  0.92 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1046 | Train Loss:  0.005736103653907776 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1047 | Train Loss:  0.007145320773124695 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1048 | Train Loss:  0.006377491950988769 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  1049 | Train Loss:  0.005227692127227783 | Train Accuracy:  0.9 | Validation Accuracy:  0.5733333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f348dc7ewAJCUE2CUMQFBwBQRFRVHBSZ3Hr19k6+qtWC1pntWJrXa1arXtb0VYURAVRlD2UIcuwQUbYkJD9/v1xzg3hkkBucm/OvTfv5+ORR+4Z99z34SS889miqhhjjDG1FeN1AMYYYyKLJQ5jjDEBscRhjDEmIJY4jDHGBMQShzHGmIBY4jDGGBMQSxzGHISIfC4iVwf7XGMimdg4DhNtRGRPlc0UoBgod7dvUtV3Gj6q+hGRZsDDwAVABrAJ+BR4RFW3eBmbaXysxGGijqo28X0Ba4Bzq+yrTBoiEuddlLUnIgnARKAnMBRoBvQHtgJ963C9iLhvE74scZhGQ0QGicg6EfmjiGwEXhOR5iLymYjki8h293W7Ku/5RkSud19fIyLfi8gT7rkrReTMOp6bIyKTRWS3iEwQkedE5O0aQr8K6ACcr6qLVLVCVTer6p9VdZx7PRWRLlWu/7qIPHKQ+14sIudUOT/O/Tc41t3uJyJTRWSHiMwTkUH1/fc30cMSh2lsWuFU9XQEbsT5HXjN3e4A7AX+eZD3Hw8sBVoAfwVeERGpw7nvAjOBTOBB4MqDfOZpwHhV3XOQcw7F/77fAy6tcnwIsEVV54pIW2As8Ij7nj8AH4lIVj0+30QRSxymsakAHlDVYlXdq6pbVfUjVS1U1d3Ao8DJB3n/alX9t6qWA28ArYHDAjlXRDoAfYD7VbVEVb8HxhzkMzOBDYHd5gH2u2+cxHWeiKS4xy/DSSYAVwDjVHWcW7r5CpgNnFXPGEyUsMRhGpt8VS3ybYhIioi8KCKrRWQXMBlIF5HYGt6/0fdCVQvdl00CPLcNsK3KPoC1B4l5K07SqY/97ltV84DFwLlu8jgPJ5mAUyq52K2m2iEiO4ABQYjBRAlrJDONjX83wjuBbsDxqrpRRI4GfgBqqn4Khg1AhoikVEke7Q9y/gTgERFJVdWCGs4pxOlB5tMKWFdlu7ruk77qqhhgkZtMwElib6nqDYe4D9NIWYnDNHZNcdo1dohIBvBAqD9QVVfjVP08KCIJItIfOPcgb3kL5z/zj0Sku4jEiEimiNwjIr7qox+By0QkVkSGcvDqNp/3gTOA37CvtAHwNk5JZIh7vSS3gb1dtVcxjY4lDtPYPQ0kA1uA6cD4Bvrcy9nXpfYR4AOc8SYHUNVinAbyJcBXwC6chvUWwAz3tN/hJJ8d7rX/d6gAVHUDMA04wf183/61wDDgHiAfJ2ndhf1/YVw2ANCYMCAiHwBLVDXkJR5j6sv+gjDGAyLSR0Q6u9VOQ3H+wj9kKcGYcGCN48Z4oxXwMU5X23XAb1T1B29DMqZ2rKrKGGNMQKyqyhhjTEAaRVVVixYtNDs72+swjDEmosyZM2eLqh4w1UyjSBzZ2dnMnj3b6zCMMSaiiMjq6vZbVZUxxpiAWOIwxhgTEEscxhhjAmKJwxhjTEBCmjhEZKiILBWRPBEZUc3xRBH5wD0+Q0Sy3f2ZIjJJRPaISLWL6ojIGBFZGMr4jTHGHChkicNdz+A54EygB3CpiPTwO+06YLuqdgGeAh539xcB9+GsPFbdtS8A6rMamjHGmDoKZYmjL5CnqitUtQRnCudhfucMw1kZDWA0MFhERFUL3FXRivzOR0SaAHfgzChqjDGmgYVyHEdb9l/VbB3OGszVnqOqZSKyE2funi0Hue6fgb/jLFxTIxG5EWdtZTp06BBQ4IEqLa8gPjaGzbuLaNk0ibzNu+mc1YQf1+6gV7t0Zq7cxnEdmzNtxVb6ZDdn+oqt5GZnMHvVNo5p35y5a7bTq106C9bv4IjWzViyYTddWjZhxZYCsjNTWLttL63Tk9i8q5gWTRLYXlhKs+Q4CorLSYqPobRciRVBBMoqlKT4GApLymmWFMfOvWVkpiawtaCYVmnJbNpVRLv0ZNbv2EvHzFTWbiskJyuVNVsL6ZSVypptheS0SGXd9r1kZ6aycVcRbdKS2FZQQmaTRIpKy0mKr2lxPGNMYxBRAwDd1dk6q+rvfe0hNVHVl4CXAHJzc+s0IZeqsmjDLl78dgW3D+7CsxPzuP6kHB4Y8xO3D+7Kta/N4q8X9eLu0fP549DuPD5+CTeclMO/v1vJr3Pb88HstZzdqzVj52/gtCNaMmHxZk7q2oLvft5Cv04ZTF+xjWM7pDN3zQ56tG7Gog27yGmRysotBbRsmsjm3cWkJMRSWFJel/BrlJYcz869pXTMTGH11kJ6t09n3todDDw8i8nL8itjvrRve96bubbynu48/XD+/tUyHvnVkfzpfwv51xXHcfv7P/Du9cfz4Kc/8czwY3h24s/ce/YRvD1tNTcM7MTXSzYzpGcrVuQX0K1VUwQQAZFQLrBnjAmlkE1y6K5q9qCqDnG3RwKo6mNVzvnCPWeaiMThrNGcpW5QInINkKuqt7rbv8Fp+yjBSXotgamqOuhgseTm5mqgI8fLK5SznvmOpZt2B/S+xig2RiivUJolxbGrqIzWaUls2FlE91ZNWbJxN6d0y2LS0nyu7NeRt6av5tHzj+THNTu47qQc9hSV0b11M5okRtTfMMY0CiIyR1Vz/feH8rd1FtBVRHKA9cBw4DK/c8YAV+OsQnYR8LUeJJOp6gvACwBuieOzQyWNuoqNEY7vlGGJoxbKK5xHtquoDIANO52mqSUbnX+7SUvzAXhrujN7weOfL2FXURnf/byFjbuKOO2Iw5iweBMPndeTzCYJHN0+nXbNU/w/xhgTJkI6rbq7HvLTQCzwqqo+KiIPA7NVdYyIJOGsp3wMsA0Yrqor3PeuApoBCTjLYZ6hqouqXDsbJ3Eceag46lLiAKioUDbvLmboM5P53eCuPPTpIq7q35E3p62mb04GM1duIz0lnh2FpQFf2xwoKT6GotIK2qYns6uolJtP7kxux+a0z0ihTXqy1+EZ0+jUVOJoFOtx1DVx+KuoUERg065iMpsksGTDbjq2SGHO6u10b9WUGSu20aNNM2as2Er31s34cc0OOrdMZfGG3bRrnszqrYVkpCawaVcRiXExFJSUU1ZeQUyMsKOglPTUeNZsLaRjZioL1u+gd7t0vs/bwsCuWYyZ9wu/OqYtr09ZyXUDOvHUhGX84YzDeeLLfd/vOP1wnvxqGbcP7sqzE3/mllM689yk5ZVtFL6kd/Fx7fhwzjrOOqoV4xZsrGx36d0ujXnrdtKpRSorthTQokkiW/YUIwJe/pikJcdzdq/W9MluzpCerYiLiSEhzsauGhNqljiifHZc33MsLVfiY4WCknJSE2LZVlBCRmoC63fspW16Msvz91T2+Dq6fTrfLstnYNcsPp3/C2ce2Zo3p63ikj7tee7rPK49MYdRny/mppM7c+1rs3jwvB7c/Pbcykbyc3u34dN5v9A5K5Xl+QUNdq+926fzt4t6kZIQa1VaxoSQJY4oTxwNxffzsm77Xg5rlsSUvC0c2TaN16eu5NTuLbnwhWlce2I2r01Z5XYDLglpPO9efzwpiXEc3T49pJ9jTGNkicMSR4NavGEXWU0T+WDWWrod1pTr35xd2f03FF64/FjiY2M4rcdhIbm+MY2RJQ5LHJ7aWVhKQlwMn83/hYzUBG56aw4tmiSycdcBkwPUy3s39KNClRO7tAjqdY1pjCxxWOIIK0Wl5cSIMGnpZmJEuOHN4D6fT245kb2l5fTrlBnU6xrTmFjisMQR1rYXlFCuyj+/zmP0nHXsKS4LynWnjjiVwpJyurRsEpTrGdOYWOKwxBFRpq/YyqfzfuGdGWuCcr2Vj51l05wYE6CaEod1hjdhqV+nTB49/ygm3nky15yQXe/rDX9pOl3uGVf/wIwxljhMeOuc1YQHz+vJzHsGc0q3rDpfZ8bKbZRVKNOWb+Vtd+oTY0zdWFWViSibdxfR99GJ9b7Okj8PZW9JOc1TE4IQlTHRydo4LHFEjT3FZazfvpchT0+u97VWjTo7CBEZE52sjcNEjSaJcXRr1ZTXr+3DbwZ1rte1Ji3ZzEuTlwcpMmMaB0scJmIN6taSPw7tTrvmdZ8599rXZ/GXcUtQVSoqor/0bUwwWFWViXh7isvYW1JOn0cn1PtaVnVlzD5WVWWiVpPEOLKaJvK7wV3p1S6tXteav24Hk5ZsDlJkxkQnK3GYqJM9Ymy9r5H36JnExdrfVaZxsxKHaTTevu54fje4a72u8Zt35jLy4/nW7mFMNSxxmKgzoGsLfn/64fW6xleLNvHezLVsCPLsvcZEA0scJmp9eusA7junR72uceKor+k0cixFpeVBisqYyGeJw0Sto9qlcd2AHGLcuQ3rOsdhhcLkZfls3VMcvOCMiWCWOEzU++SWAdx5+uHExdR9dtwb35rDcY9MIH+3JQ9jLHGYqHdUuzRuG9wVwUkcCXF1/7F/asIyZq7cFqzQjIlIljhMo/HKNbmc3uMwUhNiAepUAnl3xhoueXEay/P3BDs8YyKGJQ7TaJzUNYt/X5VLjNvYkViPksdZz3zHmHm/0BjGQRnjzxKHaXRuOrkTAE2T4gFIig/816C4rILb3/uBqcu3BjU2YyKBJQ7T6Nw4sDOrRp1dmTBi6rGk7OUvz+Clycspt4GCphGxxGEard7t0wFnriuAtOT4Ol3nL+OW8PHcdUGLy5hwZ4nDNFqjLujFR7/pT6u0JIB6tVfcNXo+j41bbAMFTaNgicM0WskJsRzXMQNfRZUvbzRNiqvT9V6cvII3p60KRmjGhDVLHKbRe3r4MVyS246j/KZkb5oYeAL5y7gljPx4PjsKS4IVnjFhxxKHafRyWqTy14t6E+s/rqOObebvzVzLq1NW1TsuY8KVJQ5jXAO7ZgHQvnnKfvvrUnX17MSfueD5KVbyMFHJEocxrutPymH6yMHkZKUG5Xpz1+zg4c8W8ePaHUG5njHhwhKHMS4RoVVaUo3jOupS8vh47np+9dwUFm/YVd/wjAkbdes+YkwUu++cI0hNiKW0XPkoSOMzbnl3Lke0bsaTl/QmMS42KNc0xishLXGIyFARWSoieSIyoprjiSLygXt8hohku/szRWSSiOwRkX9WOT9FRMaKyBIR+UlERoUyftM4tWyaxKgLe+2bRdc3vMPXXbcOva1W5Bcwdv4GJi3JZ/XWguAEaoxHQpY4RCQWeA44E+gBXCoi/suxXQdsV9UuwFPA4+7+IuA+4A/VXPoJVe0OHAOcKCJnhiJ+Y3q0aQZAxxb7N5bXtbcVwM1vz+Hkv33Dyi2WPEzkCmWJoy+Qp6orVLUEeB8Y5nfOMOAN9/VoYLCIiKoWqOr3OAmkkqoWquok93UJMBdoF8J7MI3YFcd3YOztAzixS4v9D7glj/rMrjvmx1+4/5OFlJRV1CNCY7wRysTRFlhbZXudu6/ac1S1DNgJZNbm4iKSDpwLTKzh+I0iMltEZufn5wcYujFOY3nPNmn7qqr8xMfWb0GoN6etZtLSzewsLK3zdYzxQkT2qhKROOA94FlVXVHdOar6kqrmqmpuVlZWwwZoosolfdrTNDGOc3q32W9/PSbVrfTUV8vo/fCXLN24u/4XM6aBhDJxrAfaV9lu5+6r9hw3GaQBtVng4CXgZ1V9OghxGnNQnbOasOChIbRrnuzs8EsYB4w4D8ASN2FMWrqZp75aRmm5VV2Z8BfK7rizgK4ikoOTIIYDl/mdMwa4GpgGXAR8rYeYolREHsFJMNcHPWJjDqKZO+16s6R4dheVVVZhxcdKvdfjGPX5EgDapidzcW47JBjFGWNCJGSJQ1XLRORW4AsgFnhVVX8SkYeB2ao6BngFeEtE8oBtOMkFABFZBTQDEkTkV8AZwC7gXmAJMNf95fqnqr4cqvswxufSPu0pL6+gQuHhzxZVljziYmKA4JQUPp3/C3d/NJ/PbhvAkW3TDv0GYzwQ0gGAqjoOGOe37/4qr4uAi2t4b3YNl7U/xYwn4mJjuObEHN6avnq//cH8gfzu5y0AjF+4kR/WbGd43w71aoQ3JhRs5LgxAerR2hnfcXxOJhMWb6rMHPGxQml5cJaQfXHyckrLlb2l5dw4sHNQrmlMsNifMsYE6LiOzZl172mc27u1s8PNFfVpJPfnS0BTl28le8RY5tlEiSaMWOIwpg6ymiYesC8+Jvi/Tt8sdcYgvT9rLeMXbqTMel2ZMGCJw5g6GnR4S7q0bMJtg7uE/LPGL9zAzW/P4dmJP4f8s4w5FEscxtRRWko8E+44ma6HNd1vf3xs8PtvbHdHl89Zs53+j020qivjKUscxtRTaoLTxySrmVN9Fcy2Dn9T8rayYWcRT09YxpzV223AoPGEJQ5j6qlPdnP+elEvHjy3J+Ab1xFaC9bv4sIXpvKXcYtD/lnG+LPEYUw9iQiX5LYnNTHW3Q79Z27ZUwzAzJXb+L/XZ7Fw/c7Qf6gxLkscxgRJm3RnLqvTjzgMgLgQVln5/PTLLr5espk/fDiPlVsKbJp20yAscRgTJK3TkvnhvtP5zSBnwF4o2zr8bdxVxClPfMP9nyxssM80jZclDmOCqHlqQmVVVUOUOHx27nV6XU1cspkHx/xkVVcmpCxxGBNkHTJS6dcpgycu7t1gn+mbU3rrnmJen7qKS/89nfzdxVZ1ZULCEocxQZYQF8P7N/bnuI7NgYYtefhmdy8uraDPoxO488N5DfbZpvGwxGFMiCS4a5If7jdAsCGUuOM7Pp33C89NymPBOqu6MsFjicOYEElPSeD1a/vw76tzPY3jb18s5dx/fk9BcZnNdWWCwhKHMSE0qFtLmqfEex0GAD0f+IKb357jdRgmCljiMCbEEtyFmHzddL00YfFmPpi1xua6MvUih1jiOyrk5ubq7NmzvQ7DNHLlFUrne8Yd+sQGkvfomcSIENOAjfcmsojIHFU9oK7VShzGNBDf/89J8eHxa9fl3s+54pUZXodhIlB4/AQb0wiICA8P68lntw3wOpRKU5dvZfzCjcxds93rUEwEsTXHjWlAV/XP9jqEA/gazFeNOtvjSEyksBKHMR457YiWXoewnx73j2fYc1O8DsNEAEscxnhg3gNn8Pzlx3kdxn4KS8qZt3YH3/+8hdmrtnkdjgljVlVljAfSksNjbEd1fA3mVnVlamIlDmM8dM9Z3fnw5v5eh1Gt0578ltOf/NbrMEwYshKHMR66caD3gwJrkrd5D0Dl2ub9OmV6HJEJF1biMCZM9Mlu7nUI1brwhakMf2m612GYMGKJw5gwsOjhIbx7Qz+vwzioy1+eTv/HJnodhgkDVlVlTBhISQj/X8UpeVsBWLh+J9sLSzipa5bHERmvWInDmDDy3GXH8t/fnuB1GAd1zj++58pXZnodhvGQJQ5jwsjZvVpzTIfwbOvwd8s7c+n2p8+9DsN4wBKHMWGoZdNEBncPr5Hl/sYu2EBxWQXLNu3my582eh2OaUA2rboxYSx7xFivQ6g1GzAYfWxadWNMSP1x9PyISnSm7ixxGBPGxt4+gIl3nux1GLXywey1gDNw8OO56zyOxoRSSBOHiAwVkaUikiciI6o5nigiH7jHZ4hItrs/U0QmicgeEfmn33uOE5EF7nueFRFbvsxErZ5t0uic1cTrMAJy5jOTueM/81BVysorvA7HhEDIEoeIxALPAWcCPYBLRaSH32nXAdtVtQvwFPC4u78IuA/4QzWXfgG4Aejqfg0NfvTGhJf7zunBn391pNdh1EppudNu+uCYn+hyr/W6ikahLHH0BfJUdYWqlgDvA8P8zhkGvOG+Hg0MFhFR1QJV/R4ngVQSkdZAM1Wdrk6r/pvAr0J4D8aEhesG5HBlv45ehxGQN6atBpyqq5e/W+FxNCaYQpk42gJrq2yvc/dVe46qlgE7gYPNpNbWvc7BrgmAiNwoIrNFZHZ+fn6AoRsTntqmJ9OiSYLXYQTkguen8MjYxewqKmVXUanX4ZggiNrGcVV9SVVzVTU3K8umRjDR4fs/nsKse0/zOoyA7CoqA+CxcYvp9eCX7LbkEfFCmTjWA+2rbLdz91V7jojEAWnA1kNcs90hrmlM1BIRIrU/yEdznF/VBet28shni6ioiP4xZNEqlIljFtBVRHJEJAEYDozxO2cMcLX7+iLgaz3IiERV3QDsEpF+bm+qq4BPgh+6MeHtu7tPiZhuuj7l7q/2TW/P4eXvV7Jk427Wbiv0OCpTF7VKHCKSKiIx7uvDReQ8ETno2pdum8WtwBfAYuA/qvqTiDwsIue5p70CZIpIHnAHUNllV0RWAU8C14jIuio9sn4LvAzkAcsB67ZhGp32GSkR10233C1hlLpddJ/8ahkn/XUSq7cWeBmWqYNaTTkiInOAk4DmwBSc0kSJql4e2vCCw6YcMdFq6vItbC8o5ZZ353odSq0lxcdQVFpR+f2xC47i84UbefGK40hOiPU6PFNFfaccEVUtBC4AnlfVi4GewQzQGBO4Ezq34Oxerb0OIyAVfmMCH/r0JyYvy2fyz/nMWrXNm6BMQGqdOESkP3A54JuMxv40MCZMPDysJ5cd38HrMGqlzC9zCE5j//OT8rj4X9OYunyLF2GZANQ2cfw/YCTwX7edohMwKXRhGWMCcVX/bP5y/lFeh1Er/p2pFGfH0k27AZi0ZDOH/+lz1u/Y29ChmVqqVeJQ1W9V9TxVfdxtJN+iqreHODZjTIAuOKYtiXGRMTyrpubVd2asoaSsgs8XbODD2WsrG9VN+Khtr6p3RaSZiKQCC4FFInJXaEMzxgTqyV8fzdJHzqz1+b4hIbExDT82xD9x+KqsfPvfmLaKu0bP572Zaxo2MHNItf3TpIeq7sKZF+pzIAe4MmRRGWPq5biO1S8/658fYtzMEevBoEL/tg5flZXv+5bdJQB8uyyf7BFjmbHiYGODTUOqbeKId8dt/AoYo6qlgJUfjQlT71x/PD/ef/oB+32JIi5m/4QR4/5PkNqA3WFrWwP13c/OXHPjFmzgr+OX2JQlYSCulue9CKwC5gGTRaQjsCtUQRlj6icpPpak+Fg6Zqaweuu+0dlO4lBiYgQq1EkY5VUTSPhUWflv/+/HX9i5t5Q9xWXcdHJn2qQlRez0K5Guto3jz6pqW1U9Sx2rgVNCHJsxpp7+99sTGXf7SQfs9+UHXwnE993333Ba8kEnhggq/8ThX2Xlyw0lZU7V1pzV2zlx1Ne8MXVVQ4Vo/NS2cTxNRJ70TVMuIn8HUkMcmzGmnpqnJtCjTTOymiYC+/4z9pUwfI3i/n+412ZGiWDxb+s4lJVbnClKJi3NZ/hL01i6cXcowjIHUds2jleB3cAl7tcu4LVQBWWMCa5PbjmRf1+VW/nXva9KypcvfFU+/t+bJdW2Nrvuamrr8O9l5W/Wqm1MX7GNhz79ie9+zmdvSXmIIjT+aps4OqvqA+5qfitU9SGgUygDM8YET5v0ZE7vcRgZqc4iUDE1tA34lzQasg2hqLT6kod/lZV/Ilmev4crX5nJvf9dEMrwTBW1TRx7RWSAb0NETgRsWKcxEWb0zScw6oKjKts4fInBP2H4bzdkm0dt+VLarr3OQlE/rttB9oixvG/jPkKutuXQm4E3RSTN3d7OvnU0jDERokNmCh0yO/CPr/PYXnhgt1b/qiov+EoelSWNGqqs/GuwNu0sAuCFb5ezp7iMIT1b0T4jJaSxNla17VU1T1V7A72AXqp6DHBqSCMzxoTMO9cfz91Du5Ge4pQk/BNFTY3jDVny8K+6UvxLRc53/xy3dU8Jj4xdzBWvzGDjziKKy6ztI9gCmtRGVXe5I8jBWXjJGBOBsluk8ttBXYiPDf95rXwrB9bUbXfftqPCPXHbnhL6PTaRO/4zL9QhNjr1+amxkTfGRLhXrs7lllM608GvSqemqipfSaQhSx6+8Ru+yQ593329eP33+76XuCsNjl+4kYv/NZVPflzfYDFHu/r0tbMpR4yJcB0zU7lrSHemLZ8CeDue41DK/BKC/3ffkrS+88qqJJJZq7Yza9V2miXF06VlE2v7qKeDljhEZLeI7KrmazfQpoFiNMaE2D8uO5abTu5Ej9bNDnqef0mkIcZ5HIovt/nGg/iXPKq69vVZDHl6MsVl5TZdez0cNHGoalNVbVbNV1NV9f4nxhgTFG3Tkxl55hGVa3n4d9eNJoUl5XT703iuf2OW16FErPBvGTPGNJjHL+zFTQM70TcnI6D3NeSsusEyaWk+T365lPELN3odSsSxxGGMqdSyWRIjzzqC1ASnQiHuELPlioez6gbDs1/ncfPbc1i4fifrthce+g0GqF/juDEmSt1/bg/aNU9mw84iPpyz7pDn+9JGfKxQWh55bQfn/ON7AFaNOtvjSCKDlTiMMQdIT0ngjjO60TTJ6XabFF+7/ypqmgMrUvS8fzyX/Gua12GEPStxGGNq9Ichh9OiaQJbdpfw6pSVBxz3ddcVv2naI1VBSTkzV23jP7PW0iQpjrOOau11SGHJShzGmBqlJMTx20FdKtfzONTAv5rW94g0d380n9++M5fVWwtYu83aPvxZicMYc0jXn5RDRmo8G3cW89SEZZX7/bvr+qqqYkUoC6PBg3V18t++Aaztw5+VOIwxhxQfG8Ov+3SgbfNkwFnf42AivcrK3wXPT2HIU5O9DiNsWInDGFNrFx7blswmCazeUsCDny464LivzSPaEsfcNTsA+GrRJnbtLeXC49p5HJG3LHEYY2pNRDilW0u+i8kHoGebZkxdvvWA82JlX1tHFNRYVbrhzdkAnNilBYUlZXTKauJxRN6wqipjTMBO6prFV78fyEXuX94HLjnrfI+N9FbyGvR7bCKn/v1br8PwjCUOY0yddD2sKT3bOIuCDj7isP2ORfqI8tr67Ttz6HH/eK/DaHCWOIwxddatVVMWPzyUc3pVP97hUFOWRLpxCzZSWFLOlLwtvPzdCq/DaTCWOIwx9ZKcEEuvdukAXHNizn7HorWqyt/lL8/gkbGLyd9dzML1O70OJ8nKBb4AABNpSURBVORCmjhEZKiILBWRPBEZUc3xRBH5wD0+Q0Syqxwb6e5fKiJDquz/vYj8JCILReQ9EUkK5T0YYw4tq2kiq0adzYAuLfbbX9nWEeUlD58zn5lcOe9VNAtZ4hCRWOA54EygB3CpiPTwO+06YLuqdgGeAh5339sDGA70BIYCz4tIrIi0BW4HclX1SCDWPc8YEwaObp/OWUe14rELjtpvf2NJHFv2lADwp/8tIHvEWI+jCZ1Qljj6AnmqukJVS4D3gWF+5wwD3nBfjwYGi9OqNgx4X1WLVXUlkOdeD5wuxMkiEgekAL+E8B6MMQFIiIvh+cuPo1urpgA0T00AGk+Vlc/b09cAMGf1dh4bt9jjaIIvlImjLbC2yvY6d1+156hqGbATyKzpvaq6HngCWANsAHaq6pfVfbiI3Cgis0Vkdn5+fhBuxxhTW52zmvDQeT3556XHAo2nxOHvwhem8uLkFWwrKOH7n7d4HU7QRFTjuIg0xymN5OCseZ4qIldUd66qvqSquaqam5WV1ZBhGmOAq0/Ipn2GMzXJsR2bA9Hfy6omV74ygytemUFRaTlFpeVeh1NvoUwc64H2VbbbufuqPcetekoDth7kvacBK1U1X1VLgY+BE0ISvTGm3tJTEvj01gE8eUlvIPrHddRk0YZdAIz6fAnd7xtPYUmZxxHVTygTxyygq4jkiEgCTiP2GL9zxgBXu68vAr5WZwjqGGC42+sqB+gKzMSpouonIiluW8hgIPoqEI2JIke1S6ucjv3aE7K9DcYjvoH1789y2j6+WZrPJf+aRklZhYdR1V3I5qpS1TIRuRX4Aqf306uq+pOIPAzMVtUxwCvAWyKSB2zD7SHlnvcfYBFQBtyiquXADBEZDcx19/8AvBSqezDGBEd8bAzL/3IWMQIvTm48A+X8Vbh54q4P51FQUs6C9Tv4edMehvft4G1gARL/OWaiUW5urs6ePdvrMIwxuPX9/Tpy01tzvA6lwcXFCGUVSmpCLAUl5WRnprBqayGf3TaAtOR42mekeB3ifkRkjqrm+u+PqMZxY0zke+u64xnSsxXgdN9tTCrcP9R9f65v3l0MwNMTlnHSXyeRt3m3R5EFpnE9NWNM2Hhm+NF88f8Geh1Gg6pwM4avosfXVcA3Nf3Hc9eTPWIsm3YVNXxwAbDEYYzxxLCj25LTIhWAo9qmeRxNw/Ivefi8PnUVAF8u2sSfP1tEcVl4dt21hZyMMZ6aNvJUmiXF0/OBL7wOpcH4Ny2L3/e/f7mUHYWldM5qQtvmyQzs2uKA9d29ZCUOY4ynWqclk5oYR6esVG45pbPX4TSI8ho6Jfn2lrrddN+ctoqrX53JJz/+ElYDBy1xGGPCwtd3DuKuId29DqNBlFfUrjfr2m2FAIyZ9wvd7xsfNtOWWOIwxoSVZ4Yfzce/bRwTQtRUZeVvxgqn8fx/P67nlCe+YUX+ntAGdgjWxmGMCSvDjt43F2qTxDj2FEf29BwHszfA6qfPF2ygoKSclyavoENmClf260jTpPgQRVczSxzGmLA0857BJMbH0vuhaifAjioFJYElkC8XbWJbQQlrtxVySW57jmqbRlxsw1UgWVWVMSYstWyWRFpyPKf3OIxrGskcV74EcqgWkGK3pDJ9xTbOf34qT3y5DFWloWYCscRhjAlr/74qlwfP6+l1GA2qsJYlkM3uQMFvl+WTM3Ic78xYE8qwKlniMMZEhPdv7NdoGs19aluFtWZrAQDvzljDsOemVDamh4q1cRhjIkK/TpkApCbEUq5KUWlkTkleF4V+jeg1VUit3lpAQUk5I/+7gCv7deSMnq1om54c9HisxGGMiSg/3H8G8x44w+swGlSgTRf5u4t56NNFXPXKjJDEY4nDGBNREuJiSIyL5ZnhR/Po+Ud6HU6Dqm3VVYU7wHBHYWlI4rDEYYyJSMOObsvlx3f0OgxPHKrx3DevVUWIellZ4jDGRLSZ9w7mu7tP8ToMT9RUAvFNaVLLmU0CZonDGBPRWjZNon1GCred2oVTu7es9ftiY5y/yqNhMSlfAilzM0WZu0ZtqEoc1qvKGBMV7jyjGwDZI8bW6vwYgXL3e7QodmfV9SWQUI0HjPxUa4wxVXx71yBG39y/xuO+ZS187QAx7vemSdHzd7QvYVgbhzHG1ELHzFRyszO4bkAOzVMOnAAwpjJh7L/tK3g0i6IEYonDGGMCcN85Pfjh/jNIqGHyv8qEEUVVVf6scdwYY+pg4p0n89o1fSq3fRMB+pc0/EVDySNUkx5a4jDGRLX2GSmc0r1l5bK0vv9K/RNGTf/FpiU3/HoXwWIlDmOMqYe7hnRn1aizaZPmzt1UQ+aQKKq7sjYOY4wJgg9v7s8/LzumMm/UNlFEYsnDuuMaY0wQtElP5pxebbjt1K4ApCTE1up9vvaCaBgwWF/2L2CMaZRuGNiJVaPOpkNGCgDxfgmhppJIcnztEk00s8RhjGnUXrjiOP5x6TG0bJpY7fGaeiZFQ6+rurLEYYxp1DJSEzi3dxtuH+xUXbXPcBrPa9uVNbWWVV3RxBKHMcYAZx3VmlWjzqZn6zQAmiY5jeFSOVDQ+e6fUGKjabKrWrLEYYwxVTw0rCevXJ3LEa2bATWXPPzbQCKx11VdWeIwxpgqkuJjGXzEYdx2ahdaNEmkT3ZGQO9vkhj9bR+WOIwxphq926cz+0+n0a9TJgBt05P3O+5fEvFtJzaC7rrRf4fGGFMP1w3I4ZNbTuT4ToGVPKK5225IE4eIDBWRpSKSJyIjqjmeKCIfuMdniEh2lWMj3f1LRWRIlf3pIjJaRJaIyGIRqXnifWOMqaeYGKF3+3R+N7grFx7bjuF9O+x3vKbxHr5G8yiawaRSyBKHiMQCzwFnAj2AS0Wkh99p1wHbVbUL8BTwuPveHsBwoCcwFHjevR7AM8B4Ve0O9AYWh+oejDHGJz0lgb9f0rtyedr+nTOrPc9XgeXrbBUXhb2uQlni6AvkqeoKVS0B3geG+Z0zDHjDfT0aGCxO+h4GvK+qxaq6EsgD+opIGjAQeAVAVUtUdUcI78EYY/bTr1Mmyx45kzN6tAIgMzVhv+O+iQV9JZFo7K4byub/tsDaKtvrgONrOkdVy0RkJ5Dp7p/u9962wF4gH3hNRHoDc4DfqWqB/4eLyI3AjQAdOnTwP2yMMXWWEBfD+ce0pUKVsgpl5McLaq6yisK6qkhrHI8DjgVeUNVjgALggLYTAFV9SVVzVTU3KyurIWM0xjQCMTHCxbntOaPHYbRrnsyNAzsB+2ak9eWLmJjoK3mEMnGsB9pX2W7n7qv2HBGJA9KArQd57zpgnarOcPePxkkkxhjjicwmiXz/x1M5pZvT9pHbsTmwL4H4VhqMppJHKBPHLKCriOSISAJOY/cYv3PGAFe7ry8CvlanM/QYYLjb6yoH6ArMVNWNwFoR6ea+ZzCwKIT3YIwxtdKjTTO++cMgbh7krDToP4dVTKTV7xxEyNo43DaLW4EvgFjgVVX9SUQeBmar6hicRu63RCQP2IaTXHDP+w9OUigDblHVcvfStwHvuMloBXBtqO7BGGMCkd0ilY6ZKdx5+uH0bp/OVa/OrKyyiouJASoQCd0CSw0lpGPjVXUcMM5v3/1VXhcBF9fw3keBR6vZ/yOQG9xIjTEmOESE2wZ3ZU9xGQC3ntKFR8Yu3q97bml5ZGeOKCo8GWNM+GiSGMeqUWdz4bHtADihcwtgX5tHJIv+2biMMcZDzVMT+PrOk0lPSWD8TxvJTE3gl51FXodVL1biMMaYEOuU1YSM1AT+PKwn798Y+bMkWeIwxpgGcmX/bNpnJNMhI4UnLu7tdTh1ZonDGGMakIgw+e5TuOg4p+3jtCNaehxR4CxxGGOMR36473Sev/w4ILLW8YicSI0xJso0T00gIS6GN/+vLxPvPNnrcGrNEocxxnhs4OFZtGuewu2Du/LaNX28DueQLHEYY0yYuOP0wzmle0uaJMZx/jFtg3JN/yVug8HGcRhjTJhZ+JCz6Ol/f1hPk8S4ylHodVGhEBvkMYdW4jDGmDA1457BTPnjqfW6RnmFlTiMMabROKxZEgDv3dCPpklxnPOP7wN6f+es1MoVCYPJEocxxoQ53/rm9551BCmJsdz734W1et/EOweFJB5LHMYYEyFucFcZHL9wozOQcFm+J3FY4jDGmAjz1nXHA5D7yAS2F5aEpB3jYCxxGGNMhJo28lRU4fA/fd6gn2uJwxhjIlR8rNMxds6fTqOkvIL+j33dIJ9ricMYYyJcZpNEACbcMZAdhaVc9K9pIf08SxzGGBMlurRsCsB/burPqq0FIfscSxzGGBNl+uZk0DcnI2TXt5HjxhhjAmKJwxhjTEAscRhjjAmIJQ5jjDEBscRhjDEmIJY4jDHGBMQShzHGmIBY4jDGGBMQCcV6tOFGRPKB1XV8ewtgSxDDCVd2n9HF7jO6eHWfHVU1y39no0gc9SEis1U11+s4Qs3uM7rYfUaXcLtPq6oyxhgTEEscxhhjAmKJ49Be8jqABmL3GV3sPqNLWN2ntXEYY4wJiJU4jDHGBMQShzHGmIBY4qiBiAwVkaUikiciI7yOpz5EpL2ITBKRRSLyk4j8zt2fISJficjP7vfm7n4RkWfde58vIsd6eweBEZFYEflBRD5zt3NEZIZ7Px+ISIK7P9HdznOPZ3sZdyBEJF1ERovIEhFZLCL9o/F5isjv3Z/ZhSLynogkRcvzFJFXRWSziCyssi/gZygiV7vn/ywiVzdE7JY4qiEiscBzwJlAD+BSEenhbVT1Ugbcqao9gH7ALe79jAAmqmpXYKK7Dc59d3W/bgReaPiQ6+V3wOIq248DT6lqF2A7cJ27/zpgu7v/Kfe8SPEMMF5VuwO9ce43qp6niLQFbgdyVfVIIBYYTvQ8z9eBoX77AnqGIpIBPAAcD/QFHvAlm5BSVfvy+wL6A19U2R4JjPQ6riDe3yfA6cBSoLW7rzWw1H39InBplfMrzwv3L6Adzi/cqcBngOCMuI3zf7bAF0B/93Wce554fQ+1uMc0YKV/rNH2PIG2wFogw30+nwFDoul5AtnAwro+Q+BS4MUq+/c7L1RfVuKonu8H1meduy/iucX3Y4AZwGGqusE9tBE4zH0dyff/NHA3UOFuZwI7VLXM3a56L5X36R7f6Z4f7nKAfOA1t0ruZRFJJcqep6quB54A1gAbcJ7PHKLveVYV6DP05Nla4mhERKQJ8BHw/1R1V9Vj6vy5EtF9s0XkHGCzqs7xOpYQiwOOBV5Q1WOAAvZVaQBR8zybA8NwEmUbIJUDq3aiVjg/Q0sc1VsPtK+y3c7dF7FEJB4nabyjqh+7uzeJSGv3eGtgs7s/Uu//ROA8EVkFvI9TXfUMkC4ice45Ve+l8j7d42nA1oYMuI7WAetUdYa7PRonkUTb8zwNWKmq+apaCnyM84yj7XlWFegz9OTZWuKo3iygq9t7IwGnQW6MxzHVmYgI8AqwWFWfrHJoDODrhXE1TtuHb/9Vbk+OfsDOKsXnsKWqI1W1napm4zyzr1X1cmAScJF7mv99+u7/Ivf8sPwLrypV3QisFZFu7q7BwCKi7HniVFH1E5EU92fYd59R9Tz9BPoMvwDOEJHmbgntDHdfaHndOBSuX8BZwDJgOXCv1/HU814G4BR55wM/ul9n4dT/TgR+BiYAGe75gtOrbDmwAKdXi+f3EeA9DwI+c193AmYCecCHQKK7P8ndznOPd/I67gDu72hgtvtM/wc0j8bnCTwELAEWAm8BidHyPIH3cNpuSnFKkdfV5RkC/+fecx5wbUPEblOOGGOMCYhVVRljjAmIJQ5jjDEBscRhjDEmIJY4jDHGBMQShzHGmIBY4jDmEERkj/s9W0QuC/K17/HbnhrM6xsTCpY4jKm9bCCgxFFlhHNN9kscqnpCgDEZ0+AscRhTe6OAk0TkR3ediFgR+ZuIzHLXSLgJQEQGich3IjIGZ6QzIvI/EZnjri1xo7tvFJDsXu8dd5+vdCPutReKyAIR+XWVa38j+9bieMcdVY2IjBJnzZX5IvJEg//rmEbjUH8NGWP2GQH8QVXPAXATwE5V7SMiicAUEfnSPfdY4EhVXelu/5+qbhORZGCWiHykqiNE5FZVPbqaz7oAZ3R4b6CF+57J7rFjgJ7AL8AU4EQRWQycD3RXVRWR9KDfvTEuK3EYU3dn4Mwf9CPONPWZOAvtAMyskjQAbheRecB0nEnpunJwA4D3VLVcVTcB3wJ9qlx7napW4Ewfk40zhXgR8IqIXAAU1vvujKmBJQ5j6k6A21T1aPcrR1V9JY6CypNEBuHM9NpfVXsDP+DMq1RXxVVel+MsalSGswLcaOAcYHw9rm/MQVniMKb2dgNNq2x/AfzGnbIeETncXVDJXxrOkqaFItIdZ/len1Lf+/18B/zabUfJAgbiTNxXLXetlTRVHQf8HqeKy5iQsDYOY2pvPlDuVjm9jrPWRzYw122gzgd+Vc37xgM3u+0QS3Gqq3xeAuaLyFx1poD3+S/OsqjzcGY2vltVN7qJpzpNgU9EJAmnJHRH3W7RmEOz2XGNMcYExKqqjDHGBMQShzHGmIBY4jDGGBMQSxzGGGMCYonDGGNMQCxxGGOMCYglDmOMMQH5/3H+wP4mrNsCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.9\n",
            "Final Validation Accuracy: 0.5733333333333334\n",
            "Maximum Training Accuracy: 0.92\n",
            "Maximum Validation Accuracy: 0.5866666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "glA2f6kCywgj",
        "outputId": "daa66ccb-d2e4-4f4c-a527-f0a509127633"
      },
      "source": [
        "model = ANN_TS_3L()\r\n",
        "train(model, train_dataset, val_dataset, batch_size = 50, num_epochs=100, learning_rate = 0.0005, momen = 0.6, use_adam = True, save_weights=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.01387050747871399 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1 | Train Loss:  0.013857278823852539 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  2 | Train Loss:  0.01386318564414978 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  3 | Train Loss:  0.01386327862739563 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  4 | Train Loss:  0.01385831356048584 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  5 | Train Loss:  0.013899986743927001 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  6 | Train Loss:  0.013831564188003541 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  7 | Train Loss:  0.013868292570114136 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  8 | Train Loss:  0.013852992057800294 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  9 | Train Loss:  0.013863400220870972 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  10 | Train Loss:  0.013863496780395508 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  11 | Train Loss:  0.013857145309448243 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  12 | Train Loss:  0.013904865980148316 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  13 | Train Loss:  0.01381993293762207 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  14 | Train Loss:  0.013870242834091186 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  15 | Train Loss:  0.013849862813949586 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  16 | Train Loss:  0.013863700628280639 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  17 | Train Loss:  0.013863821029663086 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  18 | Train Loss:  0.013855901956558227 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  19 | Train Loss:  0.013914216756820679 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  20 | Train Loss:  0.013808709383010865 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  21 | Train Loss:  0.013872218132019044 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  22 | Train Loss:  0.013847038745880128 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  23 | Train Loss:  0.013864054679870605 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  24 | Train Loss:  0.013864195346832276 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  25 | Train Loss:  0.01385481357574463 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  26 | Train Loss:  0.01392309308052063 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  27 | Train Loss:  0.013799039125442504 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  28 | Train Loss:  0.013873987197875977 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  29 | Train Loss:  0.0138446843624115 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  30 | Train Loss:  0.013864409923553467 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  31 | Train Loss:  0.013864562511444092 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  32 | Train Loss:  0.013853950500488281 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  33 | Train Loss:  0.013930439949035645 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  34 | Train Loss:  0.013791284561157226 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  35 | Train Loss:  0.013875442743301391 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  36 | Train Loss:  0.013842854499816894 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  37 | Train Loss:  0.013864717483520507 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  38 | Train Loss:  0.013864878416061401 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  39 | Train Loss:  0.013853302001953125 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  40 | Train Loss:  0.013936190605163575 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  41 | Train Loss:  0.01378536581993103 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  42 | Train Loss:  0.01387657642364502 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  43 | Train Loss:  0.01384148359298706 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  44 | Train Loss:  0.0138649582862854 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  45 | Train Loss:  0.013865126371383667 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  46 | Train Loss:  0.01385282278060913 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  47 | Train Loss:  0.013940509557724 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  48 | Train Loss:  0.013780976533889771 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  49 | Train Loss:  0.013877421617507935 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  50 | Train Loss:  0.013840481042861938 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  51 | Train Loss:  0.013865132331848145 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  52 | Train Loss:  0.013865313529968261 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  53 | Train Loss:  0.013852477073669434 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  54 | Train Loss:  0.013943637609481812 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  55 | Train Loss:  0.013777815103530884 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  56 | Train Loss:  0.013878030776977539 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  57 | Train Loss:  0.013839761018753052 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  58 | Train Loss:  0.013865249156951904 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  59 | Train Loss:  0.013865442276000976 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  60 | Train Loss:  0.013852226734161376 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  61 | Train Loss:  0.01394583225250244 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  62 | Train Loss:  0.013775596618652344 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  63 | Train Loss:  0.013878450393676758 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  64 | Train Loss:  0.013839253187179566 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  65 | Train Loss:  0.013865317106246949 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  66 | Train Loss:  0.01386552095413208 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  67 | Train Loss:  0.013852041959762574 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  68 | Train Loss:  0.01394731640815735 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  69 | Train Loss:  0.013774081468582153 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  70 | Train Loss:  0.013878728151321412 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  71 | Train Loss:  0.013838903903961182 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  72 | Train Loss:  0.013865342140197754 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  73 | Train Loss:  0.013865561485290527 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  74 | Train Loss:  0.013851907253265381 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  75 | Train Loss:  0.013948289155960083 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  76 | Train Loss:  0.013773069381713868 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  77 | Train Loss:  0.013878908157348633 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  78 | Train Loss:  0.013838658332824707 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  79 | Train Loss:  0.013865336179733276 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  80 | Train Loss:  0.013865574598312377 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  81 | Train Loss:  0.013851799964904786 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  82 | Train Loss:  0.013948904275894165 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  83 | Train Loss:  0.013772397041320801 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  84 | Train Loss:  0.013879009485244752 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  85 | Train Loss:  0.013838480710983276 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  86 | Train Loss:  0.013865303993225098 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  87 | Train Loss:  0.013865565061569213 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  88 | Train Loss:  0.01385171413421631 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  89 | Train Loss:  0.013949296474456786 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  90 | Train Loss:  0.013771935701370239 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  91 | Train Loss:  0.013879072666168214 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  92 | Train Loss:  0.013838344812393188 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  93 | Train Loss:  0.013865257501602174 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  94 | Train Loss:  0.0138655424118042 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  95 | Train Loss:  0.013851635456085205 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  96 | Train Loss:  0.01394953966140747 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  97 | Train Loss:  0.013771613836288452 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  98 | Train Loss:  0.013879095315933227 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  99 | Train Loss:  0.013838235139846802 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  100 | Train Loss:  0.01386519193649292 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  101 | Train Loss:  0.013865509033203126 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  102 | Train Loss:  0.013851553201675415 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  103 | Train Loss:  0.013949689865112304 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  104 | Train Loss:  0.013771378993988037 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  105 | Train Loss:  0.013879101276397705 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  106 | Train Loss:  0.013838137388229371 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  107 | Train Loss:  0.013865118026733398 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  108 | Train Loss:  0.013865463733673096 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  109 | Train Loss:  0.013851478099822997 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  110 | Train Loss:  0.013949782848358154 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  111 | Train Loss:  0.013771194219589233 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  112 | Train Loss:  0.013879094123840332 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  113 | Train Loss:  0.013838049173355103 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  114 | Train Loss:  0.013865025043487548 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  115 | Train Loss:  0.013865412473678588 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  116 | Train Loss:  0.013851395845413207 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  117 | Train Loss:  0.013949846029281615 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  118 | Train Loss:  0.013771026134490967 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  119 | Train Loss:  0.013879069089889527 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  120 | Train Loss:  0.013837954998016357 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  121 | Train Loss:  0.01386492133140564 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  122 | Train Loss:  0.01386534571647644 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  123 | Train Loss:  0.01385130763053894 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  124 | Train Loss:  0.013949859142303466 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  125 | Train Loss:  0.01377089262008667 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  126 | Train Loss:  0.01387903928756714 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  127 | Train Loss:  0.013837863206863404 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  128 | Train Loss:  0.013864799737930297 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  129 | Train Loss:  0.013865270614624024 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  130 | Train Loss:  0.013851207494735718 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  131 | Train Loss:  0.013949886560440064 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  132 | Train Loss:  0.01377073049545288 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  133 | Train Loss:  0.013879003524780274 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  134 | Train Loss:  0.01383774757385254 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  135 | Train Loss:  0.013864662647247315 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  136 | Train Loss:  0.01386519193649292 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  137 | Train Loss:  0.013851088285446168 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  138 | Train Loss:  0.013949921131134033 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  139 | Train Loss:  0.013770538568496703 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  140 | Train Loss:  0.013878964185714722 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  141 | Train Loss:  0.01383762240409851 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  142 | Train Loss:  0.013864506483078003 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  143 | Train Loss:  0.013865092992782593 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  144 | Train Loss:  0.013850959539413453 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  145 | Train Loss:  0.013949922323226928 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  146 | Train Loss:  0.013770374059677125 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  147 | Train Loss:  0.013878905773162841 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  148 | Train Loss:  0.013837488889694214 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  149 | Train Loss:  0.01386432647705078 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  150 | Train Loss:  0.01386498212814331 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  151 | Train Loss:  0.013850808143615723 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  152 | Train Loss:  0.013949935436248779 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  153 | Train Loss:  0.013770159482955933 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  154 | Train Loss:  0.013878848552703858 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  155 | Train Loss:  0.013837325572967529 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  156 | Train Loss:  0.013864120244979858 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  157 | Train Loss:  0.013864854574203491 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  158 | Train Loss:  0.01385063886642456 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  159 | Train Loss:  0.01394997239112854 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  160 | Train Loss:  0.013769897222518921 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  161 | Train Loss:  0.013878785371780396 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  162 | Train Loss:  0.013837143182754516 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  163 | Train Loss:  0.013863883018493652 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  164 | Train Loss:  0.013864707946777344 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  165 | Train Loss:  0.013850440979003906 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  166 | Train Loss:  0.013949956893920899 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  167 | Train Loss:  0.01376967191696167 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  168 | Train Loss:  0.013878690004348755 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  169 | Train Loss:  0.013836946487426758 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  170 | Train Loss:  0.013863602876663208 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  171 | Train Loss:  0.013864531517028808 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  172 | Train Loss:  0.013850222826004028 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  173 | Train Loss:  0.013949911594390869 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  174 | Train Loss:  0.013769418001174927 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  175 | Train Loss:  0.013878586292266846 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  176 | Train Loss:  0.01383671522140503 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  177 | Train Loss:  0.013863281011581421 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  178 | Train Loss:  0.013864331245422364 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  179 | Train Loss:  0.013849965333938598 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  180 | Train Loss:  0.013949897289276123 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  181 | Train Loss:  0.01376908779144287 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  182 | Train Loss:  0.013878471851348877 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  183 | Train Loss:  0.013836450576782226 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  184 | Train Loss:  0.013862918615341186 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  185 | Train Loss:  0.013864097595214843 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  186 | Train Loss:  0.01384966731071472 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  187 | Train Loss:  0.013949872255325317 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  188 | Train Loss:  0.01376872420310974 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  189 | Train Loss:  0.013878333568572997 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  190 | Train Loss:  0.013836140632629395 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  191 | Train Loss:  0.013862489461898804 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  192 | Train Loss:  0.013863829374313354 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  193 | Train Loss:  0.01384932518005371 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  194 | Train Loss:  0.01394984483718872 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  195 | Train Loss:  0.013768293857574464 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  196 | Train Loss:  0.013878175020217896 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  197 | Train Loss:  0.013835785388946533 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  198 | Train Loss:  0.01386198878288269 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  199 | Train Loss:  0.01386351466178894 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  200 | Train Loss:  0.013848930597305298 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  201 | Train Loss:  0.013949781656265259 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  202 | Train Loss:  0.013767811059951783 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  203 | Train Loss:  0.013877986669540406 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  204 | Train Loss:  0.01383536696434021 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  205 | Train Loss:  0.01386141061782837 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  206 | Train Loss:  0.013863147497177123 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  207 | Train Loss:  0.013848469257354737 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  208 | Train Loss:  0.013949698209762574 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  209 | Train Loss:  0.013767281770706177 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  210 | Train Loss:  0.0138777494430542 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  211 | Train Loss:  0.013834904432296753 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  212 | Train Loss:  0.013860728740692139 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  213 | Train Loss:  0.013862704038619994 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  214 | Train Loss:  0.013847943544387818 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  215 | Train Loss:  0.013949470520019531 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  216 | Train Loss:  0.013766788244247437 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  217 | Train Loss:  0.013877459764480592 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  218 | Train Loss:  0.013834375143051147 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  219 | Train Loss:  0.013859927654266357 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  220 | Train Loss:  0.013862191438674927 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  221 | Train Loss:  0.013847324848175049 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  222 | Train Loss:  0.013949300050735474 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  223 | Train Loss:  0.013766075372695924 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  224 | Train Loss:  0.013877134323120117 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  225 | Train Loss:  0.013833739757537843 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  226 | Train Loss:  0.01385898232460022 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  227 | Train Loss:  0.013861583471298218 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  228 | Train Loss:  0.013846609592437744 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  229 | Train Loss:  0.013948882818222047 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  230 | Train Loss:  0.013765521049499511 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  231 | Train Loss:  0.01387669563293457 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  232 | Train Loss:  0.013833044767379761 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  233 | Train Loss:  0.01385786771774292 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  234 | Train Loss:  0.013860858678817749 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  235 | Train Loss:  0.013845765590667724 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  236 | Train Loss:  0.013948544263839721 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  237 | Train Loss:  0.013764615058898927 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  238 | Train Loss:  0.013876234292984008 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  239 | Train Loss:  0.013832157850265503 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  240 | Train Loss:  0.013856558799743653 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  241 | Train Loss:  0.013860008716583251 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  242 | Train Loss:  0.013844755887985229 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  243 | Train Loss:  0.01394819736480713 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  244 | Train Loss:  0.013763532638549805 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  245 | Train Loss:  0.013875677585601806 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  246 | Train Loss:  0.013831127882003785 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  247 | Train Loss:  0.013855003118515015 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  248 | Train Loss:  0.013859000205993652 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  249 | Train Loss:  0.013843575716018677 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  250 | Train Loss:  0.013947716951370238 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  251 | Train Loss:  0.01376228928565979 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  252 | Train Loss:  0.013875007629394531 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  253 | Train Loss:  0.013829903602600098 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  254 | Train Loss:  0.013853160142898559 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  255 | Train Loss:  0.013857786655426025 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  256 | Train Loss:  0.01384218454360962 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  257 | Train Loss:  0.013947043418884277 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  258 | Train Loss:  0.013760921955108642 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  259 | Train Loss:  0.013874177932739257 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  260 | Train Loss:  0.013828483819961547 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  261 | Train Loss:  0.01385094404220581 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  262 | Train Loss:  0.013856335878372192 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  263 | Train Loss:  0.013840519189834595 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  264 | Train Loss:  0.013946269750595092 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  265 | Train Loss:  0.01375922679901123 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  266 | Train Loss:  0.013873205184936524 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  267 | Train Loss:  0.013826752901077271 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  268 | Train Loss:  0.013848305940628051 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  269 | Train Loss:  0.013854589462280274 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  270 | Train Loss:  0.013838533163070679 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  271 | Train Loss:  0.013945275545120239 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  272 | Train Loss:  0.013757247924804688 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  273 | Train Loss:  0.013872014284133911 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  274 | Train Loss:  0.01382469892501831 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  275 | Train Loss:  0.013845129013061524 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  276 | Train Loss:  0.013852484226226806 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  277 | Train Loss:  0.013836170434951783 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  278 | Train Loss:  0.013944103717803955 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  279 | Train Loss:  0.013754806518554687 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  280 | Train Loss:  0.01387059450149536 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  281 | Train Loss:  0.013822172880172729 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  282 | Train Loss:  0.013841320276260376 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  283 | Train Loss:  0.013849951028823852 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  284 | Train Loss:  0.01383330225944519 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  285 | Train Loss:  0.013943133354187011 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  286 | Train Loss:  0.01375132918357849 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  287 | Train Loss:  0.013868979215621947 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  288 | Train Loss:  0.013819042444229126 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  289 | Train Loss:  0.013836711645126343 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  290 | Train Loss:  0.013846848011016846 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  291 | Train Loss:  0.013829960823059081 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  292 | Train Loss:  0.013940805196762085 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  293 | Train Loss:  0.01374851942062378 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  294 | Train Loss:  0.013866657018661499 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  295 | Train Loss:  0.013815609216690063 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  296 | Train Loss:  0.013831055164337159 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  297 | Train Loss:  0.013843013048171997 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  298 | Train Loss:  0.013825949430465698 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  299 | Train Loss:  0.01393847942352295 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  300 | Train Loss:  0.013744223117828368 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  301 | Train Loss:  0.013864070177078247 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  302 | Train Loss:  0.013811094760894775 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  303 | Train Loss:  0.01382421851158142 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  304 | Train Loss:  0.013838365077972412 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  305 | Train Loss:  0.013821148872375488 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  306 | Train Loss:  0.013935588598251343 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  307 | Train Loss:  0.013739045858383179 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  308 | Train Loss:  0.013860775232315064 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  309 | Train Loss:  0.013805818557739259 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  310 | Train Loss:  0.013815864324569702 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  311 | Train Loss:  0.013832567930221558 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  312 | Train Loss:  0.013815608024597168 | Train Accuracy:  0.5142857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  313 | Train Loss:  0.01393075704574585 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  314 | Train Loss:  0.013734138011932373 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  315 | Train Loss:  0.013856451511383056 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  316 | Train Loss:  0.013799538612365722 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  317 | Train Loss:  0.013805694580078125 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  318 | Train Loss:  0.013825368881225587 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  319 | Train Loss:  0.013808903694152832 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  320 | Train Loss:  0.013925248384475708 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  321 | Train Loss:  0.013727236986160279 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  322 | Train Loss:  0.013851318359375 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  323 | Train Loss:  0.013791487216949463 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  324 | Train Loss:  0.013793368339538575 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  325 | Train Loss:  0.013816511631011963 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  326 | Train Loss:  0.013800663948059082 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  327 | Train Loss:  0.013920103311538696 | Train Accuracy:  0.5342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  328 | Train Loss:  0.013716892004013062 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  329 | Train Loss:  0.013845289945602418 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  330 | Train Loss:  0.013781110048294068 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  331 | Train Loss:  0.013778277635574342 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  332 | Train Loss:  0.013805559873580932 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  333 | Train Loss:  0.013790566921234131 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  334 | Train Loss:  0.013913694620132446 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  335 | Train Loss:  0.013704888820648194 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  336 | Train Loss:  0.013837378025054931 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  337 | Train Loss:  0.013768535852432252 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  338 | Train Loss:  0.013759483098983765 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  339 | Train Loss:  0.013791680335998535 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  340 | Train Loss:  0.013778431415557861 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  341 | Train Loss:  0.013904536962509156 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  342 | Train Loss:  0.013690521717071533 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  343 | Train Loss:  0.0138274347782135 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  344 | Train Loss:  0.013752601146697997 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  345 | Train Loss:  0.01373651385307312 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  346 | Train Loss:  0.013774517774581909 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  347 | Train Loss:  0.01376320481300354 | Train Accuracy:  0.54 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  348 | Train Loss:  0.013894991874694824 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  349 | Train Loss:  0.01367110013961792 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  350 | Train Loss:  0.013815144300460816 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  351 | Train Loss:  0.013732563257217407 | Train Accuracy:  0.5714285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  352 | Train Loss:  0.013707965612411499 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  353 | Train Loss:  0.013753156661987304 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  354 | Train Loss:  0.013744423389434815 | Train Accuracy:  0.5514285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  355 | Train Loss:  0.013882980346679688 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  356 | Train Loss:  0.013646785020828247 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.44\n",
            "Iteration:  357 | Train Loss:  0.013799476623535156 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.44\n",
            "Iteration:  358 | Train Loss:  0.013707667589187622 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  359 | Train Loss:  0.013672469854354859 | Train Accuracy:  0.58 | Validation Accuracy:  0.48\n",
            "Iteration:  360 | Train Loss:  0.013726550340652465 | Train Accuracy:  0.58 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  361 | Train Loss:  0.013721438646316529 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  362 | Train Loss:  0.013867911100387573 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  363 | Train Loss:  0.013616366386413574 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  364 | Train Loss:  0.013779772520065308 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  365 | Train Loss:  0.013676521778106689 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  366 | Train Loss:  0.013628257513046265 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.44\n",
            "Iteration:  367 | Train Loss:  0.013693511486053467 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  368 | Train Loss:  0.013692823648452758 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  369 | Train Loss:  0.01384852170944214 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  370 | Train Loss:  0.01358160138130188 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  371 | Train Loss:  0.013754067420959472 | Train Accuracy:  0.62 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  372 | Train Loss:  0.01363900899887085 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  373 | Train Loss:  0.013573613166809082 | Train Accuracy:  0.6 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  374 | Train Loss:  0.013652964830398559 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  375 | Train Loss:  0.013657873868942261 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  376 | Train Loss:  0.013820642232894897 | Train Accuracy:  0.68 | Validation Accuracy:  0.44\n",
            "Iteration:  377 | Train Loss:  0.013542873859405518 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  378 | Train Loss:  0.013721264600753784 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  379 | Train Loss:  0.0135941743850708 | Train Accuracy:  0.62 | Validation Accuracy:  0.44\n",
            "Iteration:  380 | Train Loss:  0.013505903482437133 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.44\n",
            "Iteration:  381 | Train Loss:  0.013602888584136963 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.44\n",
            "Iteration:  382 | Train Loss:  0.013615983724594116 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  383 | Train Loss:  0.01377778172492981 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  384 | Train Loss:  0.013502609729766846 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  385 | Train Loss:  0.013680593967437744 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.44\n",
            "Iteration:  386 | Train Loss:  0.01353898286819458 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  387 | Train Loss:  0.013423659801483155 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.44\n",
            "Iteration:  388 | Train Loss:  0.013542503118515015 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  389 | Train Loss:  0.01356412649154663 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.44\n",
            "Iteration:  390 | Train Loss:  0.013735594749450684 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  391 | Train Loss:  0.013441468477249146 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  392 | Train Loss:  0.013632454872131348 | Train Accuracy:  0.68 | Validation Accuracy:  0.44\n",
            "Iteration:  393 | Train Loss:  0.013470094203948974 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  394 | Train Loss:  0.013324588537216187 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.44\n",
            "Iteration:  395 | Train Loss:  0.013470500707626343 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.44\n",
            "Iteration:  396 | Train Loss:  0.013502013683319092 | Train Accuracy:  0.64 | Validation Accuracy:  0.44\n",
            "Iteration:  397 | Train Loss:  0.013676403760910035 | Train Accuracy:  0.68 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  398 | Train Loss:  0.013380028009414673 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  399 | Train Loss:  0.013572262525558472 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  400 | Train Loss:  0.013387892246246338 | Train Accuracy:  0.66 | Validation Accuracy:  0.44\n",
            "Iteration:  401 | Train Loss:  0.0132063627243042 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.44\n",
            "Iteration:  402 | Train Loss:  0.013385478258132934 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  403 | Train Loss:  0.01342810869216919 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.44\n",
            "Iteration:  404 | Train Loss:  0.01360344409942627 | Train Accuracy:  0.68 | Validation Accuracy:  0.56\n",
            "Iteration:  405 | Train Loss:  0.013312257528305053 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  406 | Train Loss:  0.013499108552932739 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  407 | Train Loss:  0.013290529251098632 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.44\n",
            "Iteration:  408 | Train Loss:  0.013067070245742798 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.44\n",
            "Iteration:  409 | Train Loss:  0.01328518271446228 | Train Accuracy:  0.66 | Validation Accuracy:  0.44\n",
            "Iteration:  410 | Train Loss:  0.01334153175354004 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.44\n",
            "Iteration:  411 | Train Loss:  0.01352097988128662 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  412 | Train Loss:  0.013221447467803954 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  413 | Train Loss:  0.013411935567855835 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  414 | Train Loss:  0.01317794680595398 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  415 | Train Loss:  0.012904713153839112 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.44\n",
            "Iteration:  416 | Train Loss:  0.01316829800605774 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  417 | Train Loss:  0.013242291212081909 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.44\n",
            "Iteration:  418 | Train Loss:  0.013416937589645385 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  419 | Train Loss:  0.013114825487136841 | Train Accuracy:  0.7 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  420 | Train Loss:  0.013309543132781982 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  421 | Train Loss:  0.013046388626098632 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  422 | Train Loss:  0.012722159624099732 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.44\n",
            "Iteration:  423 | Train Loss:  0.013036237955093384 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  424 | Train Loss:  0.013129659891128541 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  425 | Train Loss:  0.013285948038101196 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  426 | Train Loss:  0.013017020225524902 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  427 | Train Loss:  0.013188983201980592 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  428 | Train Loss:  0.012900476455688476 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  429 | Train Loss:  0.012515299320220948 | Train Accuracy:  0.68 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  430 | Train Loss:  0.012888582944869996 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  431 | Train Loss:  0.013004254102706909 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  432 | Train Loss:  0.013148788213729858 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  433 | Train Loss:  0.012898010015487672 | Train Accuracy:  0.7 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  434 | Train Loss:  0.013051633834838866 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  435 | Train Loss:  0.012738866806030274 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  436 | Train Loss:  0.0122874116897583 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  437 | Train Loss:  0.012725428342819214 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  438 | Train Loss:  0.012867894172668457 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.44\n",
            "Iteration:  439 | Train Loss:  0.012988879680633544 | Train Accuracy:  0.68 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  440 | Train Loss:  0.012761400938034058 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  441 | Train Loss:  0.012898677587509155 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  442 | Train Loss:  0.012559478282928466 | Train Accuracy:  0.7 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  443 | Train Loss:  0.012047683000564574 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  444 | Train Loss:  0.012551531791687012 | Train Accuracy:  0.7 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  445 | Train Loss:  0.012722258567810058 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  446 | Train Loss:  0.012797082662582398 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  447 | Train Loss:  0.012637606859207152 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  448 | Train Loss:  0.012732174396514893 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  449 | Train Loss:  0.012367533445358276 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  450 | Train Loss:  0.01180129885673523 | Train Accuracy:  0.7 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  451 | Train Loss:  0.01237044930458069 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  452 | Train Loss:  0.012570515871047974 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  453 | Train Loss:  0.012598109245300294 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  454 | Train Loss:  0.012515380382537841 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  455 | Train Loss:  0.012558741569519043 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  456 | Train Loss:  0.012168530225753784 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  457 | Train Loss:  0.011550724506378174 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  458 | Train Loss:  0.012184773683547973 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.44\n",
            "Iteration:  459 | Train Loss:  0.012417205572128297 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  460 | Train Loss:  0.01239699125289917 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  461 | Train Loss:  0.012375162839889526 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  462 | Train Loss:  0.012379432916641236 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  463 | Train Loss:  0.0119651460647583 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.44\n",
            "Iteration:  464 | Train Loss:  0.011290589570999146 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  465 | Train Loss:  0.011989694833755494 | Train Accuracy:  0.72 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  466 | Train Loss:  0.012261675596237183 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  467 | Train Loss:  0.012182976007461549 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  468 | Train Loss:  0.01221422791481018 | Train Accuracy:  0.74 | Validation Accuracy:  0.52\n",
            "Iteration:  469 | Train Loss:  0.012193039655685425 | Train Accuracy:  0.74 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  470 | Train Loss:  0.011757895946502686 | Train Accuracy:  0.72 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  471 | Train Loss:  0.011034508943557739 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.44\n",
            "Iteration:  472 | Train Loss:  0.011791599988937378 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  473 | Train Loss:  0.012106544971466064 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  474 | Train Loss:  0.011964930295944214 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  475 | Train Loss:  0.012037724256515503 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  476 | Train Loss:  0.012003867626190186 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  477 | Train Loss:  0.011551556587219238 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  478 | Train Loss:  0.010782692432403564 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  479 | Train Loss:  0.011593289375305176 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  480 | Train Loss:  0.01195184588432312 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  481 | Train Loss:  0.011736699342727662 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  482 | Train Loss:  0.011865818500518798 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  483 | Train Loss:  0.01181513786315918 | Train Accuracy:  0.76 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  484 | Train Loss:  0.011346945762634278 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  485 | Train Loss:  0.010542993545532226 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  486 | Train Loss:  0.011397137641906738 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  487 | Train Loss:  0.011799402236938476 | Train Accuracy:  0.76 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  488 | Train Loss:  0.011509711742401124 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  489 | Train Loss:  0.011692817211151124 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  490 | Train Loss:  0.011632758378982543 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  491 | Train Loss:  0.01114885687828064 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  492 | Train Loss:  0.010309791564941407 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  493 | Train Loss:  0.011202709674835205 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  494 | Train Loss:  0.011651732921600343 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  495 | Train Loss:  0.011294186115264893 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  496 | Train Loss:  0.011507755517959595 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  497 | Train Loss:  0.01145760178565979 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  498 | Train Loss:  0.010958852767944336 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  499 | Train Loss:  0.010081102848052978 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  500 | Train Loss:  0.011009764671325684 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  501 | Train Loss:  0.011507891416549683 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  502 | Train Loss:  0.011086149215698242 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  503 | Train Loss:  0.011303445100784302 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  504 | Train Loss:  0.011287399530410767 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  505 | Train Loss:  0.0107770836353302 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  506 | Train Loss:  0.009858111739158631 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  507 | Train Loss:  0.010816293954849242 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  508 | Train Loss:  0.011369221210479737 | Train Accuracy:  0.78 | Validation Accuracy:  0.52\n",
            "Iteration:  509 | Train Loss:  0.010890783071517944 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  510 | Train Loss:  0.01108237862586975 | Train Accuracy:  0.74 | Validation Accuracy:  0.52\n",
            "Iteration:  511 | Train Loss:  0.011122751235961913 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  512 | Train Loss:  0.010604878664016723 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  513 | Train Loss:  0.009639493823051452 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  514 | Train Loss:  0.01062238097190857 | Train Accuracy:  0.78 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  515 | Train Loss:  0.011233944892883301 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  516 | Train Loss:  0.010700682401657105 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  517 | Train Loss:  0.010852365493774415 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  518 | Train Loss:  0.010962980985641479 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  519 | Train Loss:  0.010441441535949707 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  520 | Train Loss:  0.009428355693817139 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  521 | Train Loss:  0.010427249670028687 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  522 | Train Loss:  0.011099572181701661 | Train Accuracy:  0.78 | Validation Accuracy:  0.52\n",
            "Iteration:  523 | Train Loss:  0.010509204864501954 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  524 | Train Loss:  0.010627758502960206 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  525 | Train Loss:  0.010808402299880981 | Train Accuracy:  0.82 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  526 | Train Loss:  0.0102852463722229 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  527 | Train Loss:  0.009228320121765136 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  528 | Train Loss:  0.010233131647109985 | Train Accuracy:  0.8 | Validation Accuracy:  0.48\n",
            "Iteration:  529 | Train Loss:  0.010970602035522461 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  530 | Train Loss:  0.010326032638549804 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  531 | Train Loss:  0.010407258272171021 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  532 | Train Loss:  0.010667835474014281 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  533 | Train Loss:  0.010141322612762451 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  534 | Train Loss:  0.009030649662017822 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  535 | Train Loss:  0.010041253566741943 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  536 | Train Loss:  0.010848981142044068 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  537 | Train Loss:  0.01016065001487732 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  538 | Train Loss:  0.010179287195205689 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  539 | Train Loss:  0.010535403490066528 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  540 | Train Loss:  0.010012270212173461 | Train Accuracy:  0.8057142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  541 | Train Loss:  0.008822628259658814 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  542 | Train Loss:  0.009847748279571533 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  543 | Train Loss:  0.010733797550201415 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  544 | Train Loss:  0.010024107694625854 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  545 | Train Loss:  0.009926599264144898 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  546 | Train Loss:  0.010404400825500489 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  547 | Train Loss:  0.009898130297660828 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  548 | Train Loss:  0.008603408336639404 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  549 | Train Loss:  0.009650818705558777 | Train Accuracy:  0.8 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  550 | Train Loss:  0.010622740983963012 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  551 | Train Loss:  0.009911232590675355 | Train Accuracy:  0.76 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  552 | Train Loss:  0.00965914011001587 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  553 | Train Loss:  0.010272467136383056 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  554 | Train Loss:  0.009799856543540954 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  555 | Train Loss:  0.00837605118751526 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  556 | Train Loss:  0.00945211946964264 | Train Accuracy:  0.8 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  557 | Train Loss:  0.010517388582229614 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  558 | Train Loss:  0.009830538034439087 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  559 | Train Loss:  0.009368299245834351 | Train Accuracy:  0.76 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  560 | Train Loss:  0.010136191844940185 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  561 | Train Loss:  0.009719451665878296 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  562 | Train Loss:  0.008140764832496643 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  563 | Train Loss:  0.00925173282623291 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  564 | Train Loss:  0.010415114164352417 | Train Accuracy:  0.82 | Validation Accuracy:  0.52\n",
            "Iteration:  565 | Train Loss:  0.009776206016540527 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  566 | Train Loss:  0.00906903326511383 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  567 | Train Loss:  0.00999466836452484 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  568 | Train Loss:  0.00965188205242157 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  569 | Train Loss:  0.007908995747566223 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  570 | Train Loss:  0.00905090630054474 | Train Accuracy:  0.8 | Validation Accuracy:  0.48\n",
            "Iteration:  571 | Train Loss:  0.010308986902236939 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  572 | Train Loss:  0.009730741977691651 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  573 | Train Loss:  0.008774386644363403 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  574 | Train Loss:  0.009837450385093689 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.56\n",
            "Iteration:  575 | Train Loss:  0.00958131194114685 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  576 | Train Loss:  0.00769095778465271 | Train Accuracy:  0.82 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  577 | Train Loss:  0.008852453827857971 | Train Accuracy:  0.8 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  578 | Train Loss:  0.010192028284072875 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  579 | Train Loss:  0.009670748710632324 | Train Accuracy:  0.8114285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  580 | Train Loss:  0.008494012951850892 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  581 | Train Loss:  0.009667884707450867 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  582 | Train Loss:  0.009503111243247986 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  583 | Train Loss:  0.00748378574848175 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  584 | Train Loss:  0.008658746480941773 | Train Accuracy:  0.8028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  585 | Train Loss:  0.010065188407897949 | Train Accuracy:  0.82 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  586 | Train Loss:  0.00959506094455719 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.56\n",
            "Iteration:  587 | Train Loss:  0.008227550387382508 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  588 | Train Loss:  0.009483474493026733 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  589 | Train Loss:  0.009408109784126283 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  590 | Train Loss:  0.007288584709167481 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  591 | Train Loss:  0.008471313714981079 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  592 | Train Loss:  0.009928779602050781 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  593 | Train Loss:  0.009491377472877503 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  594 | Train Loss:  0.007981624007225036 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  595 | Train Loss:  0.00929486632347107 | Train Accuracy:  0.82 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  596 | Train Loss:  0.009295303225517273 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  597 | Train Loss:  0.007106814384460449 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  598 | Train Loss:  0.008291124105453492 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  599 | Train Loss:  0.009789451360702514 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  600 | Train Loss:  0.009355923533439637 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  601 | Train Loss:  0.00776247501373291 | Train Accuracy:  0.8 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  602 | Train Loss:  0.009112635254859924 | Train Accuracy:  0.8228571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  603 | Train Loss:  0.009169071316719055 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  604 | Train Loss:  0.006939756274223327 | Train Accuracy:  0.84 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  605 | Train Loss:  0.008116661310195923 | Train Accuracy:  0.82 | Validation Accuracy:  0.52\n",
            "Iteration:  606 | Train Loss:  0.00965289831161499 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  607 | Train Loss:  0.009195136427879334 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  608 | Train Loss:  0.0075707191228866575 | Train Accuracy:  0.8171428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  609 | Train Loss:  0.008944450616836548 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  610 | Train Loss:  0.009037711620330811 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  611 | Train Loss:  0.006784496903419495 | Train Accuracy:  0.84 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  612 | Train Loss:  0.007945364117622375 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  613 | Train Loss:  0.009521610140800475 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  614 | Train Loss:  0.009020803570747376 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  615 | Train Loss:  0.007398766875267029 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  616 | Train Loss:  0.008789640665054322 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  617 | Train Loss:  0.008906313180923463 | Train Accuracy:  0.86 | Validation Accuracy:  0.52\n",
            "Iteration:  618 | Train Loss:  0.00663846492767334 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  619 | Train Loss:  0.007775707244873047 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  620 | Train Loss:  0.009397493600845337 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  621 | Train Loss:  0.008845445513725281 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  622 | Train Loss:  0.007243266105651855 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  623 | Train Loss:  0.008651291728019714 | Train Accuracy:  0.8285714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  624 | Train Loss:  0.008777049779891967 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  625 | Train Loss:  0.006499742865562439 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  626 | Train Loss:  0.007605316638946533 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  627 | Train Loss:  0.009280823469161988 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  628 | Train Loss:  0.00865649700164795 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  629 | Train Loss:  0.007105973958969117 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  630 | Train Loss:  0.008529167175292968 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  631 | Train Loss:  0.008653517961502075 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  632 | Train Loss:  0.006367291212081909 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  633 | Train Loss:  0.007437350749969482 | Train Accuracy:  0.84 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  634 | Train Loss:  0.00917246401309967 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  635 | Train Loss:  0.008482608199119567 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  636 | Train Loss:  0.006974356174468994 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  637 | Train Loss:  0.008419865369796753 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  638 | Train Loss:  0.008541073799133301 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  639 | Train Loss:  0.006236834526062012 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  640 | Train Loss:  0.007273902893066406 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  641 | Train Loss:  0.009070691466331483 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  642 | Train Loss:  0.008322539329528809 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  643 | Train Loss:  0.0068435949087142945 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  644 | Train Loss:  0.008317899107933045 | Train Accuracy:  0.84 | Validation Accuracy:  0.56\n",
            "Iteration:  645 | Train Loss:  0.008436012864112854 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  646 | Train Loss:  0.006106824278831482 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  647 | Train Loss:  0.007114216685295105 | Train Accuracy:  0.8457142857142858 | Validation Accuracy:  0.56\n",
            "Iteration:  648 | Train Loss:  0.008972774744033813 | Train Accuracy:  0.8542857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  649 | Train Loss:  0.008169920444488525 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  650 | Train Loss:  0.006713201999664306 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  651 | Train Loss:  0.008220070004463197 | Train Accuracy:  0.84 | Validation Accuracy:  0.56\n",
            "Iteration:  652 | Train Loss:  0.008336803317070008 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  653 | Train Loss:  0.005976395606994629 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  654 | Train Loss:  0.006958284974098205 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.56\n",
            "Iteration:  655 | Train Loss:  0.008876980543136596 | Train Accuracy:  0.86 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  656 | Train Loss:  0.00803196668624878 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  657 | Train Loss:  0.006573539972305298 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  658 | Train Loss:  0.008119190335273743 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  659 | Train Loss:  0.008244158029556274 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  660 | Train Loss:  0.005841522216796875 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  661 | Train Loss:  0.006804698705673217 | Train Accuracy:  0.8514285714285714 | Validation Accuracy:  0.56\n",
            "Iteration:  662 | Train Loss:  0.008780505657196045 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  663 | Train Loss:  0.007906559109687804 | Train Accuracy:  0.86 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  664 | Train Loss:  0.006423788666725158 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.56\n",
            "Iteration:  665 | Train Loss:  0.008012455701828004 | Train Accuracy:  0.84 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  666 | Train Loss:  0.008156650066375733 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  667 | Train Loss:  0.005702661871910095 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  668 | Train Loss:  0.006652854681015015 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  669 | Train Loss:  0.008683903217315674 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  670 | Train Loss:  0.007798501849174499 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  671 | Train Loss:  0.006262547969818115 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  672 | Train Loss:  0.007898458242416383 | Train Accuracy:  0.84 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  673 | Train Loss:  0.008075381517410279 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  674 | Train Loss:  0.005558857917785645 | Train Accuracy:  0.88 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  675 | Train Loss:  0.006502043008804321 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.56\n",
            "Iteration:  676 | Train Loss:  0.008586015105247497 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  677 | Train Loss:  0.00770346999168396 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  678 | Train Loss:  0.006092967391014099 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.56\n",
            "Iteration:  679 | Train Loss:  0.007776914238929749 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  680 | Train Loss:  0.007998158931732178 | Train Accuracy:  0.8771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  681 | Train Loss:  0.005413014888763428 | Train Accuracy:  0.88 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  682 | Train Loss:  0.006352711915969849 | Train Accuracy:  0.8571428571428571 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  683 | Train Loss:  0.008487170934677124 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  684 | Train Loss:  0.007618665099143982 | Train Accuracy:  0.88 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  685 | Train Loss:  0.0059201991558074955 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  686 | Train Loss:  0.007650323510169983 | Train Accuracy:  0.8428571428571429 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  687 | Train Loss:  0.007924428582191468 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  688 | Train Loss:  0.00526715874671936 | Train Accuracy:  0.88 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  689 | Train Loss:  0.006205272674560547 | Train Accuracy:  0.86 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  690 | Train Loss:  0.008385809063911438 | Train Accuracy:  0.8714285714285714 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  691 | Train Loss:  0.007539724111557007 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  692 | Train Loss:  0.00574644684791565 | Train Accuracy:  0.8371428571428572 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  693 | Train Loss:  0.007516663074493408 | Train Accuracy:  0.8485714285714285 | Validation Accuracy:  0.5733333333333334\n",
            "Iteration:  694 | Train Loss:  0.007849616408348083 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  695 | Train Loss:  0.005123766660690307 | Train Accuracy:  0.88 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  696 | Train Loss:  0.006060022115707398 | Train Accuracy:  0.8628571428571429 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  697 | Train Loss:  0.008280307054519653 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.5866666666666667\n",
            "Iteration:  698 | Train Loss:  0.007461793422698974 | Train Accuracy:  0.8828571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  699 | Train Loss:  0.005573480129241943 | Train Accuracy:  0.84 | Validation Accuracy:  0.5733333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.84\n",
            "Final Validation Accuracy: 0.5733333333333334\n",
            "Maximum Training Accuracy: 0.8857142857142857\n",
            "Maximum Validation Accuracy: 0.5866666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxXoo9boWHvw"
      },
      "source": [
        "##### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C0U9f11WKQ0"
      },
      "source": [
        "train_dataset = createTensorDataset(X2_train, y2_train)\r\n",
        "val_dataset = createTensorDataset(X2_val, y2_val)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gtY_mDIBWWnS",
        "outputId": "1b15c046-f0e6-4a66-921c-9c456254297a"
      },
      "source": [
        "model = ANN_TS2_2L()\r\n",
        "train(model, train_dataset, val_dataset, batch_size = 75, num_epochs=250, learning_rate = 0.0005, momen = 0.7, use_adam = True, save_weights=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.009290723005930583 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1 | Train Loss:  0.009214986165364583 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  2 | Train Loss:  0.009284895261128743 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  3 | Train Loss:  0.00928237517674764 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  4 | Train Loss:  0.009241214593251546 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  5 | Train Loss:  0.009241077899932861 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  6 | Train Loss:  0.00925434112548828 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  7 | Train Loss:  0.009265748659769694 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  8 | Train Loss:  0.00926353136698405 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  9 | Train Loss:  0.00923569917678833 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  10 | Train Loss:  0.009263714949289958 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  11 | Train Loss:  0.009228691260019939 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  12 | Train Loss:  0.009258979956309001 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  13 | Train Loss:  0.009256663322448731 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  14 | Train Loss:  0.009240997632344565 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  15 | Train Loss:  0.009241131941477458 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  16 | Train Loss:  0.009244623184204102 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  17 | Train Loss:  0.009246361255645753 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  18 | Train Loss:  0.00924453099568685 | Train Accuracy:  0.4757142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  19 | Train Loss:  0.009241674741109212 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  20 | Train Loss:  0.009240609804789225 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  21 | Train Loss:  0.009244840145111084 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  22 | Train Loss:  0.00923659880956014 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  23 | Train Loss:  0.009234630266825358 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  24 | Train Loss:  0.00924325704574585 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  25 | Train Loss:  0.009243640104929606 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  26 | Train Loss:  0.009237836201985677 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  27 | Train Loss:  0.009230466683705647 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  28 | Train Loss:  0.009228983720143635 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  29 | Train Loss:  0.009249616463979085 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  30 | Train Loss:  0.009221203327178955 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  31 | Train Loss:  0.009262219270070393 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  32 | Train Loss:  0.00921799341837565 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  33 | Train Loss:  0.00921645959218343 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  34 | Train Loss:  0.009247439702351888 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  35 | Train Loss:  0.009247970581054688 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  36 | Train Loss:  0.00923377752304077 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  37 | Train Loss:  0.009218433698018391 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  38 | Train Loss:  0.009217408498128256 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  39 | Train Loss:  0.009258104165395102 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  40 | Train Loss:  0.009206740061442058 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  41 | Train Loss:  0.00927800973256429 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  42 | Train Loss:  0.009204594294230144 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  43 | Train Loss:  0.009203572273254395 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  44 | Train Loss:  0.009252082506815593 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  45 | Train Loss:  0.009252629280090331 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  46 | Train Loss:  0.009231913884480794 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  47 | Train Loss:  0.009210445880889893 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  48 | Train Loss:  0.009209737777709961 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  49 | Train Loss:  0.009265576203664144 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  50 | Train Loss:  0.009196819464365642 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  51 | Train Loss:  0.009290817578633627 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  52 | Train Loss:  0.009195446968078613 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  53 | Train Loss:  0.009194809595743815 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  54 | Train Loss:  0.009256277879079183 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  55 | Train Loss:  0.009256776173909504 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  56 | Train Loss:  0.009231237570444743 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  57 | Train Loss:  0.009205370744069418 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  58 | Train Loss:  0.009204912980397542 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  59 | Train Loss:  0.009271266460418702 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  60 | Train Loss:  0.009190526803334554 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  61 | Train Loss:  0.009299879868825276 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  62 | Train Loss:  0.009189793268839518 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  63 | Train Loss:  0.009189483324686686 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  64 | Train Loss:  0.009259284337361654 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  65 | Train Loss:  0.009259641170501709 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  66 | Train Loss:  0.009231081008911133 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  67 | Train Loss:  0.00920262336730957 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  68 | Train Loss:  0.00920235554377238 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  69 | Train Loss:  0.009274574915568034 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  70 | Train Loss:  0.009187277952829996 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  71 | Train Loss:  0.009304739634195964 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  72 | Train Loss:  0.009186995029449464 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  73 | Train Loss:  0.009186897277832031 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  74 | Train Loss:  0.009260829289754231 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  75 | Train Loss:  0.009261140823364258 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  76 | Train Loss:  0.009231061140696207 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  77 | Train Loss:  0.009201306502024333 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  78 | Train Loss:  0.009201117356618245 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  79 | Train Loss:  0.00927623430887858 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  80 | Train Loss:  0.009185677369435628 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  81 | Train Loss:  0.00930717627207438 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  82 | Train Loss:  0.009185616970062255 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  83 | Train Loss:  0.009185637633005778 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  84 | Train Loss:  0.009261577129364014 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  85 | Train Loss:  0.009261837800343831 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  86 | Train Loss:  0.009231038093566894 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  87 | Train Loss:  0.009200754165649415 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  88 | Train Loss:  0.00920061747233073 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  89 | Train Loss:  0.009276800155639649 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  90 | Train Loss:  0.009185100396474202 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  91 | Train Loss:  0.009307933648427328 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  92 | Train Loss:  0.009185170332590739 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  93 | Train Loss:  0.009185255368550619 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  94 | Train Loss:  0.009261732101440429 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  95 | Train Loss:  0.009262008666992188 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  96 | Train Loss:  0.009231002330780029 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  97 | Train Loss:  0.009200589656829834 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  98 | Train Loss:  0.009200456937154135 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  99 | Train Loss:  0.009276885986328125 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  100 | Train Loss:  0.009184919993082682 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  101 | Train Loss:  0.009308090209960937 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  102 | Train Loss:  0.009185018539428711 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  103 | Train Loss:  0.009185129006703695 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  104 | Train Loss:  0.009261728922526042 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  105 | Train Loss:  0.009262024561564127 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  106 | Train Loss:  0.00923095941543579 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  107 | Train Loss:  0.009200538794199626 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  108 | Train Loss:  0.009200402895609538 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  109 | Train Loss:  0.009276821613311767 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  110 | Train Loss:  0.009184869130452473 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  111 | Train Loss:  0.009308039347330729 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  112 | Train Loss:  0.009184971650441487 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  113 | Train Loss:  0.009185100396474202 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  114 | Train Loss:  0.00926166852315267 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  115 | Train Loss:  0.009261994361877442 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  116 | Train Loss:  0.009230912526448568 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  117 | Train Loss:  0.009200522104899089 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  118 | Train Loss:  0.009200380643208822 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  119 | Train Loss:  0.00927671194076538 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  120 | Train Loss:  0.009184850056966147 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  121 | Train Loss:  0.009307945569356282 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  122 | Train Loss:  0.00918494701385498 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  123 | Train Loss:  0.009185086886088054 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  124 | Train Loss:  0.009261594613393149 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  125 | Train Loss:  0.009261955420176188 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  126 | Train Loss:  0.009230867226918538 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  127 | Train Loss:  0.009200506210327149 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  128 | Train Loss:  0.009200353622436524 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  129 | Train Loss:  0.00927660862604777 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  130 | Train Loss:  0.009184827009836832 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  131 | Train Loss:  0.009307863712310792 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  132 | Train Loss:  0.0091849152247111 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  133 | Train Loss:  0.009185059070587158 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  134 | Train Loss:  0.009261536598205566 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  135 | Train Loss:  0.009261929988861084 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  136 | Train Loss:  0.009230822722117105 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  137 | Train Loss:  0.009200480779012045 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  138 | Train Loss:  0.009200315475463867 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  139 | Train Loss:  0.009276525179545084 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  140 | Train Loss:  0.0091847825050354 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  141 | Train Loss:  0.009307817618052164 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  142 | Train Loss:  0.009184858798980712 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  143 | Train Loss:  0.009185012181599934 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  144 | Train Loss:  0.00926149050394694 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  145 | Train Loss:  0.009261916478474935 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  146 | Train Loss:  0.009230777422587077 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  147 | Train Loss:  0.009200446605682373 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  148 | Train Loss:  0.009200267791748047 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  149 | Train Loss:  0.00927645444869995 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  150 | Train Loss:  0.009184722105662029 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  151 | Train Loss:  0.009307794570922852 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  152 | Train Loss:  0.009184794425964355 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  153 | Train Loss:  0.009184955755869547 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  154 | Train Loss:  0.009261452356974283 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  155 | Train Loss:  0.009261907736460368 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  156 | Train Loss:  0.009230732123057047 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  157 | Train Loss:  0.009200402895609538 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  158 | Train Loss:  0.00920021375020345 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  159 | Train Loss:  0.009276400407155355 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  160 | Train Loss:  0.009184651374816895 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  161 | Train Loss:  0.009307800928751627 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  162 | Train Loss:  0.009184711774190267 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  163 | Train Loss:  0.009184880256652832 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  164 | Train Loss:  0.009261423746744792 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  165 | Train Loss:  0.009261914094289144 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  166 | Train Loss:  0.009230686823527018 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  167 | Train Loss:  0.00920034885406494 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  168 | Train Loss:  0.0092001477877299 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  169 | Train Loss:  0.009276359081268311 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  170 | Train Loss:  0.009184566338857015 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  171 | Train Loss:  0.009307820002237956 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  172 | Train Loss:  0.00918462038040161 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  173 | Train Loss:  0.009184796810150147 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  174 | Train Loss:  0.009261402289072672 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  175 | Train Loss:  0.009261925220489502 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  176 | Train Loss:  0.00923064152399699 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  177 | Train Loss:  0.009200287659962973 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  178 | Train Loss:  0.009200077851613362 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  179 | Train Loss:  0.009276320139567057 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  180 | Train Loss:  0.00918447494506836 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  181 | Train Loss:  0.009307847023010254 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  182 | Train Loss:  0.00918452262878418 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  183 | Train Loss:  0.009184712568918865 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  184 | Train Loss:  0.009261378447214762 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  185 | Train Loss:  0.009261933167775472 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  186 | Train Loss:  0.009230597019195557 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  187 | Train Loss:  0.009200232028961182 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  188 | Train Loss:  0.009200012683868409 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  189 | Train Loss:  0.009276274840037029 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  190 | Train Loss:  0.009184388319651286 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  191 | Train Loss:  0.009307867685953776 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  192 | Train Loss:  0.009184431234995525 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  193 | Train Loss:  0.009184633096059163 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  194 | Train Loss:  0.00926135540008545 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  195 | Train Loss:  0.009261941115061442 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  196 | Train Loss:  0.00923055092493693 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  197 | Train Loss:  0.0092001740137736 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  198 | Train Loss:  0.009199941953023275 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  199 | Train Loss:  0.009276235103607177 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  200 | Train Loss:  0.009184297720591227 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  201 | Train Loss:  0.009307894706726074 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  202 | Train Loss:  0.009184333483378092 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  203 | Train Loss:  0.009184542496999105 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  204 | Train Loss:  0.009261330763498943 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  205 | Train Loss:  0.00926195462544759 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  206 | Train Loss:  0.009230501651763916 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  207 | Train Loss:  0.009200109640757242 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  208 | Train Loss:  0.009199868043263754 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  209 | Train Loss:  0.009276196161905925 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  210 | Train Loss:  0.009184204737345377 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  211 | Train Loss:  0.00930792252222697 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  212 | Train Loss:  0.009184236526489259 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  213 | Train Loss:  0.009184456666310629 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  214 | Train Loss:  0.009261306126912434 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  215 | Train Loss:  0.009261964162190755 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  216 | Train Loss:  0.00923045555750529 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  217 | Train Loss:  0.009200054009755453 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  218 | Train Loss:  0.009199798901875814 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  219 | Train Loss:  0.009276146094004314 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  220 | Train Loss:  0.009184114933013916 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  221 | Train Loss:  0.009307939211527507 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  222 | Train Loss:  0.009184141159057618 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  223 | Train Loss:  0.009184373219807944 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  224 | Train Loss:  0.009261277516682943 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  225 | Train Loss:  0.009261972109476725 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  226 | Train Loss:  0.009230404694875082 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  227 | Train Loss:  0.009199992815653483 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  228 | Train Loss:  0.009199725786844888 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  229 | Train Loss:  0.009276100794474284 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  230 | Train Loss:  0.009184019565582275 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  231 | Train Loss:  0.00930796225865682 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  232 | Train Loss:  0.009184038639068604 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  233 | Train Loss:  0.00918428103129069 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  234 | Train Loss:  0.009261251290639242 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  235 | Train Loss:  0.009261980851491292 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  236 | Train Loss:  0.009230355421702066 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  237 | Train Loss:  0.00919993241628011 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  238 | Train Loss:  0.009199651877085368 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  239 | Train Loss:  0.009276050726572673 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  240 | Train Loss:  0.009183932145436604 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  241 | Train Loss:  0.009307974974314372 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  242 | Train Loss:  0.009183947245279949 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  243 | Train Loss:  0.009184202353159587 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  244 | Train Loss:  0.009261213143666585 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  245 | Train Loss:  0.009261980851491292 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  246 | Train Loss:  0.009230299790700277 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  247 | Train Loss:  0.0091998823483785 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  248 | Train Loss:  0.00919959306716919 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  249 | Train Loss:  0.009275978406270344 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  250 | Train Loss:  0.009183853467305502 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  251 | Train Loss:  0.009307956695556641 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  252 | Train Loss:  0.009183869361877442 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  253 | Train Loss:  0.009184134801228842 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  254 | Train Loss:  0.009261166254679362 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  255 | Train Loss:  0.009261971314748128 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  256 | Train Loss:  0.009230247338612874 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  257 | Train Loss:  0.00919983466466268 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  258 | Train Loss:  0.009199527104695638 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  259 | Train Loss:  0.009275903701782226 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  260 | Train Loss:  0.00918377717336019 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  261 | Train Loss:  0.009307945569356282 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  262 | Train Loss:  0.009183776378631592 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  263 | Train Loss:  0.009184054533640544 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  264 | Train Loss:  0.009261127312978108 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  265 | Train Loss:  0.009261972904205322 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  266 | Train Loss:  0.009230193297068277 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  267 | Train Loss:  0.009199771881103515 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  268 | Train Loss:  0.00919945240020752 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  269 | Train Loss:  0.009275845686594645 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  270 | Train Loss:  0.009183679421742757 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  271 | Train Loss:  0.009307965437571208 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  272 | Train Loss:  0.009183673063913982 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  273 | Train Loss:  0.009183962345123291 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  274 | Train Loss:  0.009261097113291423 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  275 | Train Loss:  0.009261979262034098 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  276 | Train Loss:  0.00923014005025228 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  277 | Train Loss:  0.009199709097544351 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  278 | Train Loss:  0.00919937531153361 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  279 | Train Loss:  0.009275785287221273 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  280 | Train Loss:  0.009183581670125325 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  281 | Train Loss:  0.009307971795399984 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  282 | Train Loss:  0.009183572133382162 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  283 | Train Loss:  0.009183875719706218 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  284 | Train Loss:  0.00926105260848999 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  285 | Train Loss:  0.009261977672576905 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  286 | Train Loss:  0.009230082035064697 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  287 | Train Loss:  0.009199650287628173 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  288 | Train Loss:  0.00919930855433146 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  289 | Train Loss:  0.009275709788004557 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  290 | Train Loss:  0.009183493455251058 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  291 | Train Loss:  0.009307966232299805 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  292 | Train Loss:  0.009183475176493327 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  293 | Train Loss:  0.009183792273203532 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  294 | Train Loss:  0.00926101287206014 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  295 | Train Loss:  0.009261981646219889 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  296 | Train Loss:  0.009230020840962729 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  297 | Train Loss:  0.009199589093526205 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  298 | Train Loss:  0.009199228286743164 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  299 | Train Loss:  0.00927564303080241 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  300 | Train Loss:  0.009183395703633626 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  301 | Train Loss:  0.009307971000671387 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  302 | Train Loss:  0.009183369477589924 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  303 | Train Loss:  0.009183698495229086 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  304 | Train Loss:  0.009260968367258707 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  305 | Train Loss:  0.009261979262034098 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  306 | Train Loss:  0.009229961236317953 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  307 | Train Loss:  0.009199525515238444 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  308 | Train Loss:  0.00919914960861206 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  309 | Train Loss:  0.0092755659421285 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  310 | Train Loss:  0.009183296362559 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  311 | Train Loss:  0.009307976563771565 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  312 | Train Loss:  0.009183255036671957 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  313 | Train Loss:  0.009183595180511475 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  314 | Train Loss:  0.009260929425557455 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  315 | Train Loss:  0.009261990388234456 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  316 | Train Loss:  0.009229896068572998 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  317 | Train Loss:  0.009199445247650146 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  318 | Train Loss:  0.00919905185699463 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  319 | Train Loss:  0.009275515079498291 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  320 | Train Loss:  0.009183170000712077 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  321 | Train Loss:  0.009308010737101236 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  322 | Train Loss:  0.009183131059010823 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  323 | Train Loss:  0.009183492660522461 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  324 | Train Loss:  0.00926088571548462 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  325 | Train Loss:  0.009261989593505859 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  326 | Train Loss:  0.009229832490285238 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  327 | Train Loss:  0.009199384053548178 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  328 | Train Loss:  0.009198976357777914 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  329 | Train Loss:  0.009275420506795248 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  330 | Train Loss:  0.009183081785837809 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  331 | Train Loss:  0.00930798371632894 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  332 | Train Loss:  0.009183029333750406 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  333 | Train Loss:  0.009183402856190999 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  334 | Train Loss:  0.00926083246866862 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  335 | Train Loss:  0.009261982440948486 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  336 | Train Loss:  0.00922976573308309 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  337 | Train Loss:  0.009199317296346028 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  338 | Train Loss:  0.009198894500732422 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  339 | Train Loss:  0.009275334676106771 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  340 | Train Loss:  0.00918297290802002 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  341 | Train Loss:  0.009307982921600342 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  342 | Train Loss:  0.009182912508646647 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  343 | Train Loss:  0.009183302720387776 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  344 | Train Loss:  0.009260783195495606 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  345 | Train Loss:  0.009261983235677083 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  346 | Train Loss:  0.009229693412780762 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  347 | Train Loss:  0.009199244976043701 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  348 | Train Loss:  0.009198805491129558 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  349 | Train Loss:  0.009275244871775308 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  350 | Train Loss:  0.009182864824930827 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  351 | Train Loss:  0.00930798371632894 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  352 | Train Loss:  0.009182787736256918 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  353 | Train Loss:  0.009183187484741211 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  354 | Train Loss:  0.00926073948542277 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  355 | Train Loss:  0.009261993567148845 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  356 | Train Loss:  0.009229622681935628 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  357 | Train Loss:  0.009199155966440836 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  358 | Train Loss:  0.009198698997497558 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  359 | Train Loss:  0.009275184472401938 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  360 | Train Loss:  0.009182720184326172 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  361 | Train Loss:  0.009308022658030192 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  362 | Train Loss:  0.009182643095652263 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  363 | Train Loss:  0.00918306271235148 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  364 | Train Loss:  0.00926069180170695 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  365 | Train Loss:  0.00926199515660604 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  366 | Train Loss:  0.009229546387990315 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  367 | Train Loss:  0.009199086825052898 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  368 | Train Loss:  0.009198612372080485 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  369 | Train Loss:  0.009275069236755371 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  370 | Train Loss:  0.009182626406351726 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  371 | Train Loss:  0.009307978947957356 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  372 | Train Loss:  0.009182534217834472 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  373 | Train Loss:  0.009182970523834228 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  374 | Train Loss:  0.009260621865590414 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  375 | Train Loss:  0.009261985619862875 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  376 | Train Loss:  0.009229466120402019 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  377 | Train Loss:  0.009199008146921794 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  378 | Train Loss:  0.00919851303100586 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  379 | Train Loss:  0.009274975458780924 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  380 | Train Loss:  0.009182490507761638 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  381 | Train Loss:  0.009308002789815266 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  382 | Train Loss:  0.009182384014129638 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  383 | Train Loss:  0.009182833830515543 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  384 | Train Loss:  0.009260578950246175 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  385 | Train Loss:  0.00926199992497762 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  386 | Train Loss:  0.009229383468627929 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  387 | Train Loss:  0.009198907216389975 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  388 | Train Loss:  0.009198393026987712 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  389 | Train Loss:  0.009274903138478598 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  390 | Train Loss:  0.009182336330413819 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  391 | Train Loss:  0.009308030605316162 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  392 | Train Loss:  0.009182228247324625 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  393 | Train Loss:  0.009182704289754233 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  394 | Train Loss:  0.009260518550872803 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  395 | Train Loss:  0.00926199992497762 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  396 | Train Loss:  0.009229301611582438 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  397 | Train Loss:  0.00919882615407308 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  398 | Train Loss:  0.009198291301727295 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  399 | Train Loss:  0.00927478551864624 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  400 | Train Loss:  0.009182213147481282 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  401 | Train Loss:  0.009308001995086669 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  402 | Train Loss:  0.009182103474934896 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  403 | Train Loss:  0.009182599385579427 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  404 | Train Loss:  0.009260437488555907 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  405 | Train Loss:  0.009261976877848308 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  406 | Train Loss:  0.00922921101252238 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  407 | Train Loss:  0.009198755423227945 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  408 | Train Loss:  0.009198199113210043 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  409 | Train Loss:  0.009274640083312989 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  410 | Train Loss:  0.009182099501291912 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  411 | Train Loss:  0.00930794636408488 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  412 | Train Loss:  0.009181973934173583 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  413 | Train Loss:  0.00918248732884725 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  414 | Train Loss:  0.00926035483678182 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  415 | Train Loss:  0.00926196257273356 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  416 | Train Loss:  0.009229118824005128 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  417 | Train Loss:  0.009198668003082276 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  418 | Train Loss:  0.009198089440663656 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  419 | Train Loss:  0.009274513721466064 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  420 | Train Loss:  0.009181960423787435 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  421 | Train Loss:  0.00930794318517049 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  422 | Train Loss:  0.00918180783589681 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  423 | Train Loss:  0.009182335535685222 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  424 | Train Loss:  0.009260294437408447 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  425 | Train Loss:  0.009261978467305502 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  426 | Train Loss:  0.009229019482930501 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  427 | Train Loss:  0.009198551177978515 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  428 | Train Loss:  0.009197940826416015 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  429 | Train Loss:  0.009274429480234781 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  430 | Train Loss:  0.009181771278381348 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  431 | Train Loss:  0.00930799166361491 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  432 | Train Loss:  0.009181621074676514 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  433 | Train Loss:  0.009182177384694417 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  434 | Train Loss:  0.00926023006439209 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  435 | Train Loss:  0.009261979262034098 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  436 | Train Loss:  0.009228919347127279 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  437 | Train Loss:  0.009198456605275473 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  438 | Train Loss:  0.009197829564412435 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  439 | Train Loss:  0.00927427609761556 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  440 | Train Loss:  0.009181636174519857 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  441 | Train Loss:  0.009307935237884521 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  442 | Train Loss:  0.00918148120244344 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  443 | Train Loss:  0.009182058175404866 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  444 | Train Loss:  0.009260124365488688 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  445 | Train Loss:  0.009261953035990396 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  446 | Train Loss:  0.00922881046930949 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  447 | Train Loss:  0.009198368390401205 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  448 | Train Loss:  0.009197711149851481 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  449 | Train Loss:  0.009274110794067383 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  450 | Train Loss:  0.009181493123372396 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  451 | Train Loss:  0.009307897090911866 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  452 | Train Loss:  0.009181307951609293 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  453 | Train Loss:  0.009181906382242838 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  454 | Train Loss:  0.009260043303171794 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  455 | Train Loss:  0.009261955420176188 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  456 | Train Loss:  0.009228698412577311 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  457 | Train Loss:  0.009198246796925862 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  458 | Train Loss:  0.009197562535603842 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  459 | Train Loss:  0.009273987611134847 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  460 | Train Loss:  0.009181294441223144 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  461 | Train Loss:  0.009307923316955567 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  462 | Train Loss:  0.009181099732716878 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  463 | Train Loss:  0.009181721210479736 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  464 | Train Loss:  0.00925996462504069 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  465 | Train Loss:  0.00926195780436198 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  466 | Train Loss:  0.00922857920328776 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  467 | Train Loss:  0.009198125998179117 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  468 | Train Loss:  0.00919741153717041 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  469 | Train Loss:  0.00927383820215861 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  470 | Train Loss:  0.009181111653645834 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  471 | Train Loss:  0.009307905038197836 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  472 | Train Loss:  0.00918090581893921 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  473 | Train Loss:  0.009181557496388753 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  474 | Train Loss:  0.009259862105051676 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  475 | Train Loss:  0.009261940320332845 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  476 | Train Loss:  0.009228456020355224 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  477 | Train Loss:  0.009198013941446941 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  478 | Train Loss:  0.009197270075480143 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  479 | Train Loss:  0.009273653825124104 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  480 | Train Loss:  0.009180938402811686 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  481 | Train Loss:  0.009307847023010254 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  482 | Train Loss:  0.00918073018391927 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  483 | Train Loss:  0.009181417624155681 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  484 | Train Loss:  0.009259734153747558 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  485 | Train Loss:  0.009261905352274577 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  486 | Train Loss:  0.009228324095408122 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  487 | Train Loss:  0.009197916984558106 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  488 | Train Loss:  0.009197140534718831 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  489 | Train Loss:  0.009273426532745361 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  490 | Train Loss:  0.009180786609649659 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  491 | Train Loss:  0.009307759602864583 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  492 | Train Loss:  0.009180543422698974 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  493 | Train Loss:  0.009181242783864339 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  494 | Train Loss:  0.00925962209701538 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  495 | Train Loss:  0.009261901378631593 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  496 | Train Loss:  0.009228185017903645 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  497 | Train Loss:  0.009197767575581868 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  498 | Train Loss:  0.009196951389312744 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  499 | Train Loss:  0.00927327791849772 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  500 | Train Loss:  0.009180537064870199 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  501 | Train Loss:  0.009307796955108643 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  502 | Train Loss:  0.009180289109547933 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  503 | Train Loss:  0.009181024233500163 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  504 | Train Loss:  0.009259514808654785 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  505 | Train Loss:  0.009261894226074218 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  506 | Train Loss:  0.009228036403656006 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  507 | Train Loss:  0.00919763724009196 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  508 | Train Loss:  0.009196787675221762 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  509 | Train Loss:  0.009273056189219158 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  510 | Train Loss:  0.009180343945821127 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  511 | Train Loss:  0.009307719866434734 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  512 | Train Loss:  0.009180082480112711 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  513 | Train Loss:  0.00918084462483724 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  514 | Train Loss:  0.009259374936421712 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  515 | Train Loss:  0.009261868000030517 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  516 | Train Loss:  0.009227879842122396 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  517 | Train Loss:  0.009197493394215902 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  518 | Train Loss:  0.009196608861287436 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  519 | Train Loss:  0.009272836049397786 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  520 | Train Loss:  0.009180114269256592 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  521 | Train Loss:  0.009307683308919271 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  522 | Train Loss:  0.009179834524790447 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  523 | Train Loss:  0.009180634021759034 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  524 | Train Loss:  0.009259244600931804 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  525 | Train Loss:  0.009261847337086996 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  526 | Train Loss:  0.009227716128031412 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  527 | Train Loss:  0.009197345574696859 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  528 | Train Loss:  0.009196421305338542 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  529 | Train Loss:  0.009272595246632894 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  530 | Train Loss:  0.009179887771606445 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  531 | Train Loss:  0.009307606220245361 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  532 | Train Loss:  0.00917960007985433 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  533 | Train Loss:  0.009180436929066976 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  534 | Train Loss:  0.009259076118469238 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  535 | Train Loss:  0.009261805216471354 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  536 | Train Loss:  0.009227540493011475 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  537 | Train Loss:  0.009197211265563965 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  538 | Train Loss:  0.009196241696675619 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  539 | Train Loss:  0.009272303581237793 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  540 | Train Loss:  0.00917967398961385 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  541 | Train Loss:  0.009307506879170736 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  542 | Train Loss:  0.00917934020360311 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  543 | Train Loss:  0.009180202484130859 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  544 | Train Loss:  0.009258928298950196 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  545 | Train Loss:  0.00926179567972819 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  546 | Train Loss:  0.009227355321248373 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  547 | Train Loss:  0.009197017351786296 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  548 | Train Loss:  0.009195998509724935 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  549 | Train Loss:  0.009272090593973796 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  550 | Train Loss:  0.00917935609817505 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  551 | Train Loss:  0.009307519594828288 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  552 | Train Loss:  0.00917902946472168 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  553 | Train Loss:  0.009179941018422445 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  554 | Train Loss:  0.009258764584859212 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  555 | Train Loss:  0.009261761506398519 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  556 | Train Loss:  0.009227156639099121 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  557 | Train Loss:  0.00919686237970988 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  558 | Train Loss:  0.009195803801218668 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  559 | Train Loss:  0.009271746476491292 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  560 | Train Loss:  0.009179135958353679 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  561 | Train Loss:  0.009307327270507813 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  562 | Train Loss:  0.009178806940714518 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  563 | Train Loss:  0.009179763793945313 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  564 | Train Loss:  0.00925852616628011 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  565 | Train Loss:  0.00926166534423828 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  566 | Train Loss:  0.009226945241292318 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  567 | Train Loss:  0.009196732838948568 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  568 | Train Loss:  0.009195624192555745 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  569 | Train Loss:  0.009271346728006998 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  570 | Train Loss:  0.009178929328918457 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  571 | Train Loss:  0.009307132562001547 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  572 | Train Loss:  0.00917854070663452 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  573 | Train Loss:  0.00917952299118042 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  574 | Train Loss:  0.00925832192103068 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  575 | Train Loss:  0.009261635144551595 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  576 | Train Loss:  0.009226720333099365 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  577 | Train Loss:  0.009196509520212809 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  578 | Train Loss:  0.009195339679718018 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  579 | Train Loss:  0.009271080493927003 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  580 | Train Loss:  0.009178551038106282 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  581 | Train Loss:  0.009307156403859457 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  582 | Train Loss:  0.009178154468536377 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  583 | Train Loss:  0.009179191589355469 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  584 | Train Loss:  0.009258135954538982 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  585 | Train Loss:  0.009261611302693686 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  586 | Train Loss:  0.009226485093434652 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  587 | Train Loss:  0.009196304480234781 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  588 | Train Loss:  0.009195079803466797 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  589 | Train Loss:  0.009270699818929036 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  590 | Train Loss:  0.009178255399068197 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  591 | Train Loss:  0.009306992689768473 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  592 | Train Loss:  0.009177844524383545 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  593 | Train Loss:  0.009178940455118816 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  594 | Train Loss:  0.009257875283559163 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  595 | Train Loss:  0.009261527856190999 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  596 | Train Loss:  0.00922623078028361 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  597 | Train Loss:  0.009196118513743082 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  598 | Train Loss:  0.009194832642873128 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  599 | Train Loss:  0.009270260334014893 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  600 | Train Loss:  0.009177955786387125 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  601 | Train Loss:  0.009306809107462566 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  602 | Train Loss:  0.009177490870157878 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  603 | Train Loss:  0.009178637663523356 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  604 | Train Loss:  0.009257617791493734 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  605 | Train Loss:  0.00926146666208903 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  606 | Train Loss:  0.00922595183054606 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  607 | Train Loss:  0.009195895195007324 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  608 | Train Loss:  0.009194538593292237 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  609 | Train Loss:  0.009269816875457764 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  610 | Train Loss:  0.009177549680074056 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  611 | Train Loss:  0.009306472142537435 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  612 | Train Loss:  0.00917715867360433 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  613 | Train Loss:  0.009178510506947835 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  614 | Train Loss:  0.00925689458847046 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  615 | Train Loss:  0.009261008898417154 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  616 | Train Loss:  0.009225485324859619 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  617 | Train Loss:  0.00919596513112386 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  618 | Train Loss:  0.009194526672363281 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  619 | Train Loss:  0.009268402258555094 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  620 | Train Loss:  0.009177751541137695 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  621 | Train Loss:  0.00930518627166748 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  622 | Train Loss:  0.009177239735921223 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  623 | Train Loss:  0.009178511301676432 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  624 | Train Loss:  0.009256426493326824 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  625 | Train Loss:  0.009260825316111247 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  626 | Train Loss:  0.00922515869140625 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  627 | Train Loss:  0.009195690155029296 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  628 | Train Loss:  0.009194120566050212 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  629 | Train Loss:  0.009268016815185546 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  630 | Train Loss:  0.009177143573760987 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  631 | Train Loss:  0.009305357138315836 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  632 | Train Loss:  0.009176545143127442 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  633 | Train Loss:  0.009177873134613037 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  634 | Train Loss:  0.009256260395050049 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  635 | Train Loss:  0.009260904788970948 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  636 | Train Loss:  0.009224802652994791 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  637 | Train Loss:  0.009195257027943929 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  638 | Train Loss:  0.009193611939748129 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  639 | Train Loss:  0.009267618656158447 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  640 | Train Loss:  0.009176505406697592 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  641 | Train Loss:  0.009305413564046223 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  642 | Train Loss:  0.0091758926709493 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  643 | Train Loss:  0.009177305698394776 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  644 | Train Loss:  0.009255971908569336 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  645 | Train Loss:  0.00926090161005656 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  646 | Train Loss:  0.009224414825439453 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  647 | Train Loss:  0.009194862047831218 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  648 | Train Loss:  0.009193125565846762 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  649 | Train Loss:  0.009267090161641438 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  650 | Train Loss:  0.00917589505513509 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  651 | Train Loss:  0.00930537780125936 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  652 | Train Loss:  0.009175219535827638 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  653 | Train Loss:  0.009176692167917888 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  654 | Train Loss:  0.009255691369374593 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  655 | Train Loss:  0.00926094690958659 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  656 | Train Loss:  0.009223997592926025 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  657 | Train Loss:  0.009194337526957194 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  658 | Train Loss:  0.009192488193511962 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  659 | Train Loss:  0.009266734917958578 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  660 | Train Loss:  0.00917503833770752 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  661 | Train Loss:  0.00930566708246867 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  662 | Train Loss:  0.00917434851328532 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  663 | Train Loss:  0.009175922870635986 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  664 | Train Loss:  0.009255433877309163 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  665 | Train Loss:  0.009260974725087483 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  666 | Train Loss:  0.00922354777654012 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  667 | Train Loss:  0.009193902810414632 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  668 | Train Loss:  0.00919197161992391 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  669 | Train Loss:  0.009266015688578287 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  670 | Train Loss:  0.0091744597752889 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  671 | Train Loss:  0.009305338859558105 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  672 | Train Loss:  0.009173771540323894 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  673 | Train Loss:  0.009175442854563395 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  674 | Train Loss:  0.009254920482635497 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  675 | Train Loss:  0.009260826905568441 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  676 | Train Loss:  0.009223057428995768 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  677 | Train Loss:  0.00919350544611613 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  678 | Train Loss:  0.00919144868850708 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  679 | Train Loss:  0.009265246391296387 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  680 | Train Loss:  0.009173789819081624 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  681 | Train Loss:  0.009305152098337809 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  682 | Train Loss:  0.009173016548156738 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  683 | Train Loss:  0.009174765745798747 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  684 | Train Loss:  0.009254500071207683 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  685 | Train Loss:  0.009260772069295247 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  686 | Train Loss:  0.009222529729207356 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  687 | Train Loss:  0.009193015893300375 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  688 | Train Loss:  0.009190837542215982 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  689 | Train Loss:  0.009264464378356934 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  690 | Train Loss:  0.009173074563344319 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  691 | Train Loss:  0.009304896195729573 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  692 | Train Loss:  0.009172293345133463 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  693 | Train Loss:  0.009174176057179769 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  694 | Train Loss:  0.009253917535146077 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  695 | Train Loss:  0.009260544776916504 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  696 | Train Loss:  0.009221959114074706 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  697 | Train Loss:  0.009192676544189453 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  698 | Train Loss:  0.009190389315287272 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  699 | Train Loss:  0.009263269106547038 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  700 | Train Loss:  0.00917260487874349 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  701 | Train Loss:  0.009304030736287435 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  702 | Train Loss:  0.009171817302703857 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  703 | Train Loss:  0.009173799355824788 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  704 | Train Loss:  0.009253088633219402 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  705 | Train Loss:  0.009260159333546956 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  706 | Train Loss:  0.009221277236938476 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  707 | Train Loss:  0.009192345142364501 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  708 | Train Loss:  0.009189894994099935 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  709 | Train Loss:  0.009261853694915771 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  710 | Train Loss:  0.009172043005625408 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  711 | Train Loss:  0.0093031644821167 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  712 | Train Loss:  0.009171171188354492 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  713 | Train Loss:  0.00917326291402181 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  714 | Train Loss:  0.00925228754679362 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  715 | Train Loss:  0.009259892304738363 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  716 | Train Loss:  0.009220607280731201 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  717 | Train Loss:  0.009191840489705404 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  718 | Train Loss:  0.009189209938049316 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  719 | Train Loss:  0.009260746637980143 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  720 | Train Loss:  0.009171175956726074 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  721 | Train Loss:  0.009302786986033122 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  722 | Train Loss:  0.009170231819152832 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  723 | Train Loss:  0.009172446727752685 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  724 | Train Loss:  0.009251593748728434 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  725 | Train Loss:  0.00925969918568929 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  726 | Train Loss:  0.009219871362050375 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  727 | Train Loss:  0.009191266695658366 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  728 | Train Loss:  0.009188478787740071 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  729 | Train Loss:  0.009259454409281413 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  730 | Train Loss:  0.009170312881469727 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  731 | Train Loss:  0.00930220365524292 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  732 | Train Loss:  0.009169292449951173 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  733 | Train Loss:  0.009171619415283203 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  734 | Train Loss:  0.009250792662302653 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  735 | Train Loss:  0.009259475866953531 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  736 | Train Loss:  0.009219070275624594 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  737 | Train Loss:  0.009190609455108642 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  738 | Train Loss:  0.009187626838684081 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  739 | Train Loss:  0.009258143107096354 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  740 | Train Loss:  0.009169258276621501 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  741 | Train Loss:  0.009301750659942628 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  742 | Train Loss:  0.009168171882629394 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  743 | Train Loss:  0.00917065143585205 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  744 | Train Loss:  0.009249967734018961 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  745 | Train Loss:  0.009259271621704101 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  746 | Train Loss:  0.009218197663625081 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  747 | Train Loss:  0.009189867973327636 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  748 | Train Loss:  0.00918669064839681 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  749 | Train Loss:  0.00925671100616455 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  750 | Train Loss:  0.009168124198913575 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  751 | Train Loss:  0.009301244417826334 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  752 | Train Loss:  0.009166966279347738 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  753 | Train Loss:  0.00916959285736084 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  754 | Train Loss:  0.009249091148376465 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  755 | Train Loss:  0.00925903876622518 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  756 | Train Loss:  0.009217244784037272 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  757 | Train Loss:  0.00918909470240275 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  758 | Train Loss:  0.00918570915857951 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  759 | Train Loss:  0.009255083401997884 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  760 | Train Loss:  0.00916697343190511 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  761 | Train Loss:  0.009300510883331298 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  762 | Train Loss:  0.009165791670481364 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  763 | Train Loss:  0.00916860024134318 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  764 | Train Loss:  0.009247981707255045 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  765 | Train Loss:  0.009258657296498617 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  766 | Train Loss:  0.009216210047403972 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  767 | Train Loss:  0.009188361962636312 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  768 | Train Loss:  0.009184757868448893 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  769 | Train Loss:  0.009253143469492594 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  770 | Train Loss:  0.009165850480397543 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  771 | Train Loss:  0.009299519856770834 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  772 | Train Loss:  0.009164574146270752 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  773 | Train Loss:  0.009167530536651612 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  774 | Train Loss:  0.009246793588002523 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  775 | Train Loss:  0.00925827980041504 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  776 | Train Loss:  0.009215080738067627 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  777 | Train Loss:  0.00918748696645101 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  778 | Train Loss:  0.009183622201283773 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  779 | Train Loss:  0.009251172542572022 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  780 | Train Loss:  0.009164477189381917 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  781 | Train Loss:  0.009298667112986247 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  782 | Train Loss:  0.009163165887196859 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  783 | Train Loss:  0.009166314601898193 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  784 | Train Loss:  0.009245527585347494 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  785 | Train Loss:  0.009257872899373373 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  786 | Train Loss:  0.009213847319285075 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  787 | Train Loss:  0.009186556339263916 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  788 | Train Loss:  0.009182430108388265 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  789 | Train Loss:  0.009248936176300048 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  790 | Train Loss:  0.009163060983022053 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  791 | Train Loss:  0.009297653039296468 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  792 | Train Loss:  0.009161632061004638 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  793 | Train Loss:  0.009164958794911703 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  794 | Train Loss:  0.009244154294331869 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  795 | Train Loss:  0.009257452487945557 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  796 | Train Loss:  0.00921250581741333 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  797 | Train Loss:  0.009185483455657959 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  798 | Train Loss:  0.009181060791015626 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  799 | Train Loss:  0.009246602058410644 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  800 | Train Loss:  0.00916139841079712 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  801 | Train Loss:  0.00929667075475057 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  802 | Train Loss:  0.00915992259979248 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  803 | Train Loss:  0.009163474241892497 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  804 | Train Loss:  0.009242658615112304 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  805 | Train Loss:  0.009257001876831055 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  806 | Train Loss:  0.009211036364237467 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  807 | Train Loss:  0.009184304078420004 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  808 | Train Loss:  0.00917957623799642 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  809 | Train Loss:  0.009244016806284587 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  810 | Train Loss:  0.009159626166025798 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  811 | Train Loss:  0.009295609792073568 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  812 | Train Loss:  0.009158031940460205 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  813 | Train Loss:  0.009161799748738608 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  814 | Train Loss:  0.00924110492070516 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  815 | Train Loss:  0.009256543318430583 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  816 | Train Loss:  0.009209439754486085 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  817 | Train Loss:  0.009182995160420735 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  818 | Train Loss:  0.009177938302357991 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  819 | Train Loss:  0.009241205851236979 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  820 | Train Loss:  0.009157696564992268 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  821 | Train Loss:  0.00929440975189209 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  822 | Train Loss:  0.009156033992767335 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  823 | Train Loss:  0.00916006326675415 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  824 | Train Loss:  0.009239320755004882 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  825 | Train Loss:  0.009255971908569336 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  826 | Train Loss:  0.009207697709401448 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  827 | Train Loss:  0.00918163537979126 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  828 | Train Loss:  0.009176226456960042 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  829 | Train Loss:  0.009238015015920004 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  830 | Train Loss:  0.009155696233113606 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  831 | Train Loss:  0.009292994340260824 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  832 | Train Loss:  0.009153873920440673 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  833 | Train Loss:  0.009158117771148682 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  834 | Train Loss:  0.009237449963887532 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  835 | Train Loss:  0.009255411624908448 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  836 | Train Loss:  0.009205799102783203 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  837 | Train Loss:  0.009180065790812174 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  838 | Train Loss:  0.009174275398254394 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  839 | Train Loss:  0.009234666029612223 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  840 | Train Loss:  0.009153401851654053 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  841 | Train Loss:  0.009291601975758871 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  842 | Train Loss:  0.009151508808135986 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  843 | Train Loss:  0.009156059424082439 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  844 | Train Loss:  0.009235303401947021 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  845 | Train Loss:  0.009254713853200277 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  846 | Train Loss:  0.009203738371531168 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  847 | Train Loss:  0.009178432623545328 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  848 | Train Loss:  0.009172225793202718 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  849 | Train Loss:  0.009230902194976806 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  850 | Train Loss:  0.009150974750518799 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  851 | Train Loss:  0.009290014902750651 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  852 | Train Loss:  0.009148885409037272 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  853 | Train Loss:  0.009153691132863363 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  854 | Train Loss:  0.009233163992563883 | Train Accuracy:  0.5242857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  855 | Train Loss:  0.009254104296366373 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  856 | Train Loss:  0.009201488494873046 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  857 | Train Loss:  0.009176508585611979 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  858 | Train Loss:  0.009169862270355225 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  859 | Train Loss:  0.009226959546407064 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  860 | Train Loss:  0.009148247241973877 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  861 | Train Loss:  0.009288450876871746 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  862 | Train Loss:  0.009146010875701905 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  863 | Train Loss:  0.009151198069254558 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  864 | Train Loss:  0.009230718612670899 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  865 | Train Loss:  0.00925330638885498 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  866 | Train Loss:  0.00919905424118042 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  867 | Train Loss:  0.009174594084421794 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  868 | Train Loss:  0.009167495568593344 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  869 | Train Loss:  0.00922237237294515 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  870 | Train Loss:  0.009145480791727702 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  871 | Train Loss:  0.009286373456319174 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  872 | Train Loss:  0.009143091042836508 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  873 | Train Loss:  0.009148679574330647 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  874 | Train Loss:  0.009227953751881917 | Train Accuracy:  0.5257142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  875 | Train Loss:  0.009252384503682454 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  876 | Train Loss:  0.009196409384409587 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  877 | Train Loss:  0.009172502358754477 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  878 | Train Loss:  0.009164899984995523 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  879 | Train Loss:  0.00921741803487142 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  880 | Train Loss:  0.009142450491587321 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  881 | Train Loss:  0.009284171263376871 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  882 | Train Loss:  0.00913987636566162 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  883 | Train Loss:  0.009145894050598145 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  884 | Train Loss:  0.009225028355916341 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  885 | Train Loss:  0.00925146738688151 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  886 | Train Loss:  0.009193553924560546 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  887 | Train Loss:  0.009170122146606445 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  888 | Train Loss:  0.009161972204844156 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  889 | Train Loss:  0.009212211767832438 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  890 | Train Loss:  0.00913903554280599 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  891 | Train Loss:  0.009282055695851645 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  892 | Train Loss:  0.009136258761088053 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  893 | Train Loss:  0.0091427214940389 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  894 | Train Loss:  0.009221993287404378 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  895 | Train Loss:  0.009250584443410238 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  896 | Train Loss:  0.009190476735432943 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  897 | Train Loss:  0.009167414506276448 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  898 | Train Loss:  0.009158681233723959 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  899 | Train Loss:  0.009206767876942952 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  900 | Train Loss:  0.009135181109110515 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  901 | Train Loss:  0.00928012450536092 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  902 | Train Loss:  0.00913222074508667 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  903 | Train Loss:  0.009139205614725749 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  904 | Train Loss:  0.009218711058298747 | Train Accuracy:  0.5271428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  905 | Train Loss:  0.009249579906463624 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  906 | Train Loss:  0.009187157154083253 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  907 | Train Loss:  0.009164632161458333 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  908 | Train Loss:  0.009155323505401611 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  909 | Train Loss:  0.009200555483500163 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  910 | Train Loss:  0.009131278196970622 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  911 | Train Loss:  0.009277490774790446 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  912 | Train Loss:  0.00912816047668457 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  913 | Train Loss:  0.009135626157124837 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  914 | Train Loss:  0.009215087095896402 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  915 | Train Loss:  0.009248464107513428 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  916 | Train Loss:  0.009183588027954102 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  917 | Train Loss:  0.009161591529846191 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  918 | Train Loss:  0.009151654243469238 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  919 | Train Loss:  0.009193950494130453 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  920 | Train Loss:  0.009126966794331868 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  921 | Train Loss:  0.009274942874908447 | Train Accuracy:  0.53 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  922 | Train Loss:  0.009123595555623372 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  923 | Train Loss:  0.00913156509399414 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  924 | Train Loss:  0.009211374123891196 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  925 | Train Loss:  0.009247407118479411 | Train Accuracy:  0.53 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  926 | Train Loss:  0.009179742336273193 | Train Accuracy:  0.53 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  927 | Train Loss:  0.009158125718434652 | Train Accuracy:  0.53 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  928 | Train Loss:  0.009147536754608155 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  929 | Train Loss:  0.009187046686808269 | Train Accuracy:  0.53 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  930 | Train Loss:  0.009122207164764404 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  931 | Train Loss:  0.009272356828053793 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  932 | Train Loss:  0.00911885102589925 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  933 | Train Loss:  0.009127533435821534 | Train Accuracy:  0.53 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  934 | Train Loss:  0.009206974506378173 | Train Accuracy:  0.53 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  935 | Train Loss:  0.009245947202046712 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  936 | Train Loss:  0.009175658226013184 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  937 | Train Loss:  0.009154763221740723 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  938 | Train Loss:  0.009143471717834473 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  939 | Train Loss:  0.009179138342539469 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  940 | Train Loss:  0.009117376804351807 | Train Accuracy:  0.5328571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  941 | Train Loss:  0.00926918347676595 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  942 | Train Loss:  0.009113797346750895 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  943 | Train Loss:  0.009122991561889648 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  944 | Train Loss:  0.009202636082967123 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  945 | Train Loss:  0.009244665304819743 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  946 | Train Loss:  0.009171276887257895 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  947 | Train Loss:  0.009150896072387695 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  948 | Train Loss:  0.009138936996459962 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  949 | Train Loss:  0.009170844554901122 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  950 | Train Loss:  0.009112119674682617 | Train Accuracy:  0.5357142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  951 | Train Loss:  0.009265855153401692 | Train Accuracy:  0.5414285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  952 | Train Loss:  0.009108426570892334 | Train Accuracy:  0.54 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  953 | Train Loss:  0.009118217627207438 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  954 | Train Loss:  0.009197807312011719 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  955 | Train Loss:  0.009243152141571044 | Train Accuracy:  0.5414285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  956 | Train Loss:  0.009166639645894368 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  957 | Train Loss:  0.009146877924601237 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  958 | Train Loss:  0.009134195645650227 | Train Accuracy:  0.54 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  959 | Train Loss:  0.009161816438039145 | Train Accuracy:  0.54 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  960 | Train Loss:  0.009106566111246744 | Train Accuracy:  0.54 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  961 | Train Loss:  0.009262059529622396 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  962 | Train Loss:  0.009102891286214193 | Train Accuracy:  0.5414285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  963 | Train Loss:  0.009113369782765706 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  964 | Train Loss:  0.00919252872467041 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  965 | Train Loss:  0.009241549968719483 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  966 | Train Loss:  0.009161717096964518 | Train Accuracy:  0.5414285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  967 | Train Loss:  0.009142470359802247 | Train Accuracy:  0.5414285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  968 | Train Loss:  0.009129048983256022 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  969 | Train Loss:  0.009152385393778483 | Train Accuracy:  0.5385714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  970 | Train Loss:  0.009100401401519775 | Train Accuracy:  0.5371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  971 | Train Loss:  0.009258588155110678 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  972 | Train Loss:  0.009096604983011881 | Train Accuracy:  0.5442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  973 | Train Loss:  0.009107852776845296 | Train Accuracy:  0.54 | Validation Accuracy:  0.52\n",
            "Iteration:  974 | Train Loss:  0.009187179406483968 | Train Accuracy:  0.5414285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  975 | Train Loss:  0.009240025679270427 | Train Accuracy:  0.5414285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  976 | Train Loss:  0.009156463146209716 | Train Accuracy:  0.5442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  977 | Train Loss:  0.009137603441874186 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  978 | Train Loss:  0.009123449325561523 | Train Accuracy:  0.5414285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  979 | Train Loss:  0.009142460823059083 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  980 | Train Loss:  0.009093717734018961 | Train Accuracy:  0.5414285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  981 | Train Loss:  0.009255192279815673 | Train Accuracy:  0.5471428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  982 | Train Loss:  0.009089685281117758 | Train Accuracy:  0.5471428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  983 | Train Loss:  0.009101768334706625 | Train Accuracy:  0.5428571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  984 | Train Loss:  0.00918163537979126 | Train Accuracy:  0.5442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  985 | Train Loss:  0.009238391717274985 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  986 | Train Loss:  0.009150908788045248 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  987 | Train Loss:  0.009132610956827799 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  988 | Train Loss:  0.009117748737335205 | Train Accuracy:  0.5442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  989 | Train Loss:  0.009131310780843099 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  990 | Train Loss:  0.009087076981862386 | Train Accuracy:  0.5442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  991 | Train Loss:  0.009250582853953044 | Train Accuracy:  0.55 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  992 | Train Loss:  0.009082865715026856 | Train Accuracy:  0.55 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  993 | Train Loss:  0.009095784823099771 | Train Accuracy:  0.5457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  994 | Train Loss:  0.009175440470377605 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  995 | Train Loss:  0.009236564636230469 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  996 | Train Loss:  0.009145024617513021 | Train Accuracy:  0.55 | Validation Accuracy:  0.5\n",
            "Iteration:  997 | Train Loss:  0.009127185344696045 | Train Accuracy:  0.55 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  998 | Train Loss:  0.009111560980478923 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  999 | Train Loss:  0.009119709332784018 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1000 | Train Loss:  0.009079756736755372 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1001 | Train Loss:  0.009245867729187012 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1002 | Train Loss:  0.009075601895650228 | Train Accuracy:  0.5557142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1003 | Train Loss:  0.00908962329228719 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1004 | Train Loss:  0.009168504079182942 | Train Accuracy:  0.55 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1005 | Train Loss:  0.009234488010406494 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1006 | Train Loss:  0.00913862148920695 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1007 | Train Loss:  0.009121135870615641 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1008 | Train Loss:  0.009104628562927247 | Train Accuracy:  0.55 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1009 | Train Loss:  0.009107411702473958 | Train Accuracy:  0.5542857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1010 | Train Loss:  0.009071251551310222 | Train Accuracy:  0.55 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1011 | Train Loss:  0.009242144425710043 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1012 | Train Loss:  0.009066801865895589 | Train Accuracy:  0.5642857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1013 | Train Loss:  0.009081928730010987 | Train Accuracy:  0.5557142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1014 | Train Loss:  0.009161670207977295 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1015 | Train Loss:  0.009232457478841145 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1016 | Train Loss:  0.009131805102030436 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1017 | Train Loss:  0.009114890893300375 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1018 | Train Loss:  0.009097675482432047 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1019 | Train Loss:  0.009093179702758789 | Train Accuracy:  0.56 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1020 | Train Loss:  0.009063293933868408 | Train Accuracy:  0.5571428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1021 | Train Loss:  0.009235684871673583 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1022 | Train Loss:  0.009058847427368164 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1023 | Train Loss:  0.009074968496958415 | Train Accuracy:  0.5614285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1024 | Train Loss:  0.00915381908416748 | Train Accuracy:  0.56 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1025 | Train Loss:  0.009230308532714844 | Train Accuracy:  0.5671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1026 | Train Loss:  0.009124500751495361 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.48\n",
            "Iteration:  1027 | Train Loss:  0.009107530117034912 | Train Accuracy:  0.5671428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1028 | Train Loss:  0.0090894349416097 | Train Accuracy:  0.56 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1029 | Train Loss:  0.009079683621724446 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1030 | Train Loss:  0.009053196907043457 | Train Accuracy:  0.5614285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1031 | Train Loss:  0.009232576688130696 | Train Accuracy:  0.5757142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1032 | Train Loss:  0.009048102696736653 | Train Accuracy:  0.5757142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1033 | Train Loss:  0.009065709114074706 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1034 | Train Loss:  0.009146428108215332 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1035 | Train Loss:  0.009228188991546631 | Train Accuracy:  0.5728571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  1036 | Train Loss:  0.009116788705190023 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1037 | Train Loss:  0.009100237687428792 | Train Accuracy:  0.5757142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1038 | Train Loss:  0.009081559975941976 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1039 | Train Loss:  0.009063168366750082 | Train Accuracy:  0.5728571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  1040 | Train Loss:  0.00904454787572225 | Train Accuracy:  0.5685714285714286 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1041 | Train Loss:  0.00922377904256185 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1042 | Train Loss:  0.009040389060974121 | Train Accuracy:  0.5871428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  1043 | Train Loss:  0.009059224128723144 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  1044 | Train Loss:  0.00913622538248698 | Train Accuracy:  0.5757142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1045 | Train Loss:  0.009225003719329834 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1046 | Train Loss:  0.009108855724334716 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1047 | Train Loss:  0.00909254233042399 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1048 | Train Loss:  0.009072828292846679 | Train Accuracy:  0.5728571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  1049 | Train Loss:  0.009047008355458578 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1050 | Train Loss:  0.009033578236897787 | Train Accuracy:  0.5728571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  1051 | Train Loss:  0.009219889640808105 | Train Accuracy:  0.59 | Validation Accuracy:  0.48\n",
            "Iteration:  1052 | Train Loss:  0.0090281875928243 | Train Accuracy:  0.59 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1053 | Train Loss:  0.00904829502105713 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1054 | Train Loss:  0.009128714402516683 | Train Accuracy:  0.5814285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1055 | Train Loss:  0.009223295052846274 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1056 | Train Loss:  0.009100133577982585 | Train Accuracy:  0.59 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1057 | Train Loss:  0.009083378314971923 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1058 | Train Loss:  0.00906335751215617 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  1059 | Train Loss:  0.009029773076375326 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1060 | Train Loss:  0.009022916158040364 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  1061 | Train Loss:  0.009211913744608561 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1062 | Train Loss:  0.009018729527791342 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1063 | Train Loss:  0.009040571053822836 | Train Accuracy:  0.5857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1064 | Train Loss:  0.009117419719696046 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1065 | Train Loss:  0.00921965758005778 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1066 | Train Loss:  0.009091506799062093 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1067 | Train Loss:  0.009075125058492025 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1068 | Train Loss:  0.009054137070973715 | Train Accuracy:  0.5871428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  1069 | Train Loss:  0.00901071866353353 | Train Accuracy:  0.59 | Validation Accuracy:  0.48\n",
            "Iteration:  1070 | Train Loss:  0.009011491934458415 | Train Accuracy:  0.5871428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  1071 | Train Loss:  0.009205766518910726 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1072 | Train Loss:  0.009006312688191732 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1073 | Train Loss:  0.009029514789581299 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1074 | Train Loss:  0.009108528296152751 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1075 | Train Loss:  0.009217619101206461 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1076 | Train Loss:  0.009081955750783284 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1077 | Train Loss:  0.00906466245651245 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1078 | Train Loss:  0.009043437639872233 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1079 | Train Loss:  0.008992110093434652 | Train Accuracy:  0.5885714285714285 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1080 | Train Loss:  0.008999323050181071 | Train Accuracy:  0.59 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1081 | Train Loss:  0.009197761217753092 | Train Accuracy:  0.59 | Validation Accuracy:  0.5\n",
            "Iteration:  1082 | Train Loss:  0.008995404243469238 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1083 | Train Loss:  0.009020880858103434 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1084 | Train Loss:  0.009096324443817139 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1085 | Train Loss:  0.009213813940684 | Train Accuracy:  0.59 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1086 | Train Loss:  0.00907254139582316 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1087 | Train Loss:  0.009055273532867432 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1088 | Train Loss:  0.009033309618631998 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1089 | Train Loss:  0.0089712127049764 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1090 | Train Loss:  0.008986906210581461 | Train Accuracy:  0.59 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1091 | Train Loss:  0.00919016202290853 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1092 | Train Loss:  0.008982490698496501 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1093 | Train Loss:  0.009009808699289957 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1094 | Train Loss:  0.009085594018300374 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1095 | Train Loss:  0.009211095968882243 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1096 | Train Loss:  0.009062278270721435 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  1097 | Train Loss:  0.009044180711110433 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1098 | Train Loss:  0.009022047519683838 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1099 | Train Loss:  0.008950311342875163 | Train Accuracy:  0.59 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1100 | Train Loss:  0.008973800341288248 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1101 | Train Loss:  0.009181406497955322 | Train Accuracy:  0.5985714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1102 | Train Loss:  0.008970243136088053 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1103 | Train Loss:  0.008999848365783691 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1104 | Train Loss:  0.009072766304016114 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1105 | Train Loss:  0.009207268555959066 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1106 | Train Loss:  0.009052033424377442 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1107 | Train Loss:  0.00903356154759725 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1108 | Train Loss:  0.00901092290878296 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1109 | Train Loss:  0.008927723566691081 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1110 | Train Loss:  0.008959716161092122 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1111 | Train Loss:  0.009175116221110027 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1112 | Train Loss:  0.008954416910807292 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1113 | Train Loss:  0.008985838095347087 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1114 | Train Loss:  0.009062422116597494 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1115 | Train Loss:  0.009204888343811035 | Train Accuracy:  0.5957142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1116 | Train Loss:  0.009040871461232503 | Train Accuracy:  0.5957142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1117 | Train Loss:  0.009021090666453043 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1118 | Train Loss:  0.008998800118764241 | Train Accuracy:  0.5914285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1119 | Train Loss:  0.008904627164204915 | Train Accuracy:  0.5942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1120 | Train Loss:  0.008945962587992351 | Train Accuracy:  0.59 | Validation Accuracy:  0.5\n",
            "Iteration:  1121 | Train Loss:  0.009164148966471355 | Train Accuracy:  0.61 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1122 | Train Loss:  0.008942237695058187 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1123 | Train Loss:  0.00897629181543986 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1124 | Train Loss:  0.009047702153523763 | Train Accuracy:  0.5957142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  1125 | Train Loss:  0.00920049508412679 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1126 | Train Loss:  0.009030004342397055 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1127 | Train Loss:  0.00900939702987671 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1128 | Train Loss:  0.008986772696177165 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1129 | Train Loss:  0.008880346616109213 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1130 | Train Loss:  0.008931140899658203 | Train Accuracy:  0.5928571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1131 | Train Loss:  0.009155595302581787 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1132 | Train Loss:  0.008926798502604166 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  1133 | Train Loss:  0.008963184356689453 | Train Accuracy:  0.6 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1134 | Train Loss:  0.009034833908081054 | Train Accuracy:  0.5985714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1135 | Train Loss:  0.009197096824645996 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1136 | Train Loss:  0.009018540382385254 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1137 | Train Loss:  0.008996597131093343 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1138 | Train Loss:  0.008974199295043945 | Train Accuracy:  0.5957142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1139 | Train Loss:  0.008854830265045166 | Train Accuracy:  0.6014285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1140 | Train Loss:  0.008916616439819336 | Train Accuracy:  0.6 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1141 | Train Loss:  0.009143528938293457 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1142 | Train Loss:  0.00891373872756958 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1143 | Train Loss:  0.008952768643697102 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1144 | Train Loss:  0.009019254048665364 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1145 | Train Loss:  0.009192590713500976 | Train Accuracy:  0.6128571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  1146 | Train Loss:  0.009007063706715902 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1147 | Train Loss:  0.008983684380849203 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1148 | Train Loss:  0.00896125872929891 | Train Accuracy:  0.5971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1149 | Train Loss:  0.008829128742218018 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1150 | Train Loss:  0.008900512854258219 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1151 | Train Loss:  0.009134846528371175 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1152 | Train Loss:  0.00889676570892334 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1153 | Train Loss:  0.008938568433125814 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1154 | Train Loss:  0.009005369345347087 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1155 | Train Loss:  0.009188877741495767 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1156 | Train Loss:  0.008995029926300049 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  1157 | Train Loss:  0.008970004717508952 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1158 | Train Loss:  0.008948020140329997 | Train Accuracy:  0.6 | Validation Accuracy:  0.52\n",
            "Iteration:  1159 | Train Loss:  0.008801387151082357 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1160 | Train Loss:  0.008884102503458658 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1161 | Train Loss:  0.009126851558685303 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1162 | Train Loss:  0.008877766927083334 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1163 | Train Loss:  0.008921840190887452 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  1164 | Train Loss:  0.008992830117543538 | Train Accuracy:  0.61 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1165 | Train Loss:  0.009185945987701416 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1166 | Train Loss:  0.008982350826263428 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  1167 | Train Loss:  0.008955252965291342 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1168 | Train Loss:  0.00893429438273112 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1169 | Train Loss:  0.00877240498860677 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1170 | Train Loss:  0.008868529796600341 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1171 | Train Loss:  0.009113651911417643 | Train Accuracy:  0.61 | Validation Accuracy:  0.54\n",
            "Iteration:  1172 | Train Loss:  0.008862769603729248 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1173 | Train Loss:  0.008909592628479004 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1174 | Train Loss:  0.008976147174835206 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1175 | Train Loss:  0.009181118806203207 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1176 | Train Loss:  0.00896988312403361 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1177 | Train Loss:  0.008940757115681966 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1178 | Train Loss:  0.008920406500498454 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1179 | Train Loss:  0.008743245601654053 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1180 | Train Loss:  0.008852007389068604 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1181 | Train Loss:  0.009101356665293376 | Train Accuracy:  0.6128571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1182 | Train Loss:  0.008846389452616373 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1183 | Train Loss:  0.008895947933197021 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  1184 | Train Loss:  0.008959689140319825 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1185 | Train Loss:  0.009176551500956217 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1186 | Train Loss:  0.008957086404164632 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1187 | Train Loss:  0.008925682703653971 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1188 | Train Loss:  0.008906308015187582 | Train Accuracy:  0.61 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1189 | Train Loss:  0.008712523778279623 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1190 | Train Loss:  0.008834924697875977 | Train Accuracy:  0.61 | Validation Accuracy:  0.54\n",
            "Iteration:  1191 | Train Loss:  0.009089546203613281 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1192 | Train Loss:  0.008828360239664714 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1193 | Train Loss:  0.008880759874979655 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  1194 | Train Loss:  0.008943544228871664 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1195 | Train Loss:  0.009172209898630778 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1196 | Train Loss:  0.008943992455800374 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1197 | Train Loss:  0.008909976482391358 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  1198 | Train Loss:  0.008891839186350505 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1199 | Train Loss:  0.008680590788523356 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1200 | Train Loss:  0.008818004131317139 | Train Accuracy:  0.6042857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1201 | Train Loss:  0.009075506528218587 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1202 | Train Loss:  0.008811744848887125 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1203 | Train Loss:  0.008866829872131348 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1204 | Train Loss:  0.008925846417744954 | Train Accuracy:  0.6057142857142858 | Validation Accuracy:  0.54\n",
            "Iteration:  1205 | Train Loss:  0.009167251586914062 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1206 | Train Loss:  0.00893078327178955 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1207 | Train Loss:  0.008893835544586181 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1208 | Train Loss:  0.008876932462056479 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1209 | Train Loss:  0.00864877700805664 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1210 | Train Loss:  0.008799728552500406 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1211 | Train Loss:  0.009063927332560222 | Train Accuracy:  0.6271428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1212 | Train Loss:  0.008792218367258707 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1213 | Train Loss:  0.008850458463033041 | Train Accuracy:  0.61 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1214 | Train Loss:  0.008908735116322836 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1215 | Train Loss:  0.009162447452545165 | Train Accuracy:  0.61 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1216 | Train Loss:  0.008917365868886312 | Train Accuracy:  0.6128571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1217 | Train Loss:  0.008877484798431397 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1218 | Train Loss:  0.008862091700236002 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1219 | Train Loss:  0.008614635467529297 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1220 | Train Loss:  0.008782070477803548 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1221 | Train Loss:  0.009050317605336507 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1222 | Train Loss:  0.008773194948832193 | Train Accuracy:  0.63 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1223 | Train Loss:  0.008834424813588461 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1224 | Train Loss:  0.008890837033589682 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1225 | Train Loss:  0.009157484372456868 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1226 | Train Loss:  0.008903779983520509 | Train Accuracy:  0.6185714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1227 | Train Loss:  0.008860665957132976 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1228 | Train Loss:  0.00884706735610962 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1229 | Train Loss:  0.00857927958170573 | Train Accuracy:  0.6128571428571429 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1230 | Train Loss:  0.00876431385676066 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1231 | Train Loss:  0.00903569459915161 | Train Accuracy:  0.63 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1232 | Train Loss:  0.008754235903422038 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1233 | Train Loss:  0.00881846030553182 | Train Accuracy:  0.61 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1234 | Train Loss:  0.008872238794962566 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1235 | Train Loss:  0.009152154922485351 | Train Accuracy:  0.6185714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1236 | Train Loss:  0.008890018463134766 | Train Accuracy:  0.6214285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1237 | Train Loss:  0.00884331226348877 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1238 | Train Loss:  0.008831641674041747 | Train Accuracy:  0.6071428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1239 | Train Loss:  0.008543744087219238 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1240 | Train Loss:  0.008745698134104411 | Train Accuracy:  0.61 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1241 | Train Loss:  0.009022468725840251 | Train Accuracy:  0.63 | Validation Accuracy:  0.54\n",
            "Iteration:  1242 | Train Loss:  0.008733424345652262 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1243 | Train Loss:  0.008800609906514486 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1244 | Train Loss:  0.008854289054870606 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1245 | Train Loss:  0.009147116343180339 | Train Accuracy:  0.6185714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1246 | Train Loss:  0.008875984350840251 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1247 | Train Loss:  0.00882550875345866 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1248 | Train Loss:  0.008815983136494954 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1249 | Train Loss:  0.008507363001505534 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1250 | Train Loss:  0.00872749408086141 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1251 | Train Loss:  0.009006600379943847 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.54\n",
            "Iteration:  1252 | Train Loss:  0.008714423179626465 | Train Accuracy:  0.63 | Validation Accuracy:  0.54\n",
            "Iteration:  1253 | Train Loss:  0.008784514268239339 | Train Accuracy:  0.6157142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1254 | Train Loss:  0.008834293683369954 | Train Accuracy:  0.61 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1255 | Train Loss:  0.009141198794047038 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1256 | Train Loss:  0.008862014611562092 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  1257 | Train Loss:  0.008807589213053385 | Train Accuracy:  0.62 | Validation Accuracy:  0.54\n",
            "Iteration:  1258 | Train Loss:  0.00880028486251831 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  1259 | Train Loss:  0.00847032388051351 | Train Accuracy:  0.63 | Validation Accuracy:  0.54\n",
            "Iteration:  1260 | Train Loss:  0.008708740870157878 | Train Accuracy:  0.6214285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1261 | Train Loss:  0.008990318775177001 | Train Accuracy:  0.63 | Validation Accuracy:  0.54\n",
            "Iteration:  1262 | Train Loss:  0.00869511604309082 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1263 | Train Loss:  0.008768317699432373 | Train Accuracy:  0.6228571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  1264 | Train Loss:  0.008813440004984538 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1265 | Train Loss:  0.009134960174560548 | Train Accuracy:  0.63 | Validation Accuracy:  0.54\n",
            "Iteration:  1266 | Train Loss:  0.008848114013671875 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  1267 | Train Loss:  0.008789573510487874 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1268 | Train Loss:  0.008784431616465251 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1269 | Train Loss:  0.008432830969492594 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  1270 | Train Loss:  0.008688790798187256 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  1271 | Train Loss:  0.008975435098012288 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1272 | Train Loss:  0.008673872152964274 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1273 | Train Loss:  0.008750476837158204 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1274 | Train Loss:  0.00879286289215088 | Train Accuracy:  0.62 | Validation Accuracy:  0.54\n",
            "Iteration:  1275 | Train Loss:  0.00912902037302653 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.54\n",
            "Iteration:  1276 | Train Loss:  0.008833980560302735 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1277 | Train Loss:  0.008771013418833415 | Train Accuracy:  0.63 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1278 | Train Loss:  0.008768316904703775 | Train Accuracy:  0.6114285714285714 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1279 | Train Loss:  0.008394731680552164 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  1280 | Train Loss:  0.008668882846832275 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  1281 | Train Loss:  0.008959674835205078 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  1282 | Train Loss:  0.00865298589070638 | Train Accuracy:  0.6285714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  1283 | Train Loss:  0.008732986450195313 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.54\n",
            "Iteration:  1284 | Train Loss:  0.008771301905314128 | Train Accuracy:  0.6271428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1285 | Train Loss:  0.009122353394826253 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1286 | Train Loss:  0.008820021947224935 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1287 | Train Loss:  0.008752559026082357 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  1288 | Train Loss:  0.008752368291219075 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  1289 | Train Loss:  0.008355412483215332 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1290 | Train Loss:  0.008648796081542969 | Train Accuracy:  0.6328571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  1291 | Train Loss:  0.008944098154703777 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1292 | Train Loss:  0.008630891640981039 | Train Accuracy:  0.63 | Validation Accuracy:  0.54\n",
            "Iteration:  1293 | Train Loss:  0.008713924090067545 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1294 | Train Loss:  0.008750370343526204 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1295 | Train Loss:  0.009115869204203288 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1296 | Train Loss:  0.00880590836207072 | Train Accuracy:  0.64 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1297 | Train Loss:  0.008733874162038167 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1298 | Train Loss:  0.008736484050750733 | Train Accuracy:  0.62 | Validation Accuracy:  0.54\n",
            "Iteration:  1299 | Train Loss:  0.008314554691314697 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1300 | Train Loss:  0.0086292831103007 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1301 | Train Loss:  0.008927116394042969 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  1302 | Train Loss:  0.008609112898508707 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  1303 | Train Loss:  0.008694722652435302 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1304 | Train Loss:  0.00872933546702067 | Train Accuracy:  0.6314285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1305 | Train Loss:  0.009109568595886231 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1306 | Train Loss:  0.008791585763295492 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1307 | Train Loss:  0.008714597225189209 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1308 | Train Loss:  0.008720269203186035 | Train Accuracy:  0.6185714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1309 | Train Loss:  0.00827305237452189 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1310 | Train Loss:  0.008609751065572102 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1311 | Train Loss:  0.008909095923105875 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1312 | Train Loss:  0.008587815761566163 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1313 | Train Loss:  0.008675997257232665 | Train Accuracy:  0.64 | Validation Accuracy:  0.5533333333333333\n",
            "Iteration:  1314 | Train Loss:  0.008707245190938314 | Train Accuracy:  0.6328571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1315 | Train Loss:  0.009102808634440103 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1316 | Train Loss:  0.008777250448862711 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1317 | Train Loss:  0.008695090611775716 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1318 | Train Loss:  0.008703888257344564 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  1319 | Train Loss:  0.00823208491007487 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1320 | Train Loss:  0.008590551217397054 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1321 | Train Loss:  0.008888912200927735 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1322 | Train Loss:  0.008568573792775471 | Train Accuracy:  0.64 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1323 | Train Loss:  0.008658551375071207 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1324 | Train Loss:  0.00868379275004069 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  1325 | Train Loss:  0.009095447063446045 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1326 | Train Loss:  0.008762987454732259 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1327 | Train Loss:  0.008675270080566407 | Train Accuracy:  0.64 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1328 | Train Loss:  0.00868725061416626 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1329 | Train Loss:  0.008191111087799073 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1330 | Train Loss:  0.00857057015101115 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1331 | Train Loss:  0.008868853251139322 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1332 | Train Loss:  0.008549327850341798 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1333 | Train Loss:  0.008641443252563476 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1334 | Train Loss:  0.00865902821222941 | Train Accuracy:  0.64 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1335 | Train Loss:  0.009087295532226562 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1336 | Train Loss:  0.008749032020568847 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1337 | Train Loss:  0.008655498822530111 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1338 | Train Loss:  0.008670618534088135 | Train Accuracy:  0.6242857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1339 | Train Loss:  0.00815014123916626 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1340 | Train Loss:  0.008549221356709798 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1341 | Train Loss:  0.008851549625396728 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1342 | Train Loss:  0.008526643911997478 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1343 | Train Loss:  0.008621307214101155 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1344 | Train Loss:  0.00863538901011149 | Train Accuracy:  0.6414285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1345 | Train Loss:  0.009079200426737467 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1346 | Train Loss:  0.008735191822052003 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1347 | Train Loss:  0.00863584280014038 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1348 | Train Loss:  0.008654403686523437 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1349 | Train Loss:  0.008106350104014079 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1350 | Train Loss:  0.008529119491577149 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1351 | Train Loss:  0.00883198897043864 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1352 | Train Loss:  0.008504900932312012 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1353 | Train Loss:  0.008601257006327311 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1354 | Train Loss:  0.008611530462900797 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1355 | Train Loss:  0.009071091016133626 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1356 | Train Loss:  0.008721248308817545 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1357 | Train Loss:  0.008615740140279134 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1358 | Train Loss:  0.008637986183166503 | Train Accuracy:  0.6357142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1359 | Train Loss:  0.008063008785247803 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1360 | Train Loss:  0.008507847785949707 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1361 | Train Loss:  0.008814417521158854 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1362 | Train Loss:  0.008480495611826578 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1363 | Train Loss:  0.008579378922780354 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1364 | Train Loss:  0.008588061332702637 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1365 | Train Loss:  0.009062768618265788 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1366 | Train Loss:  0.00870739777882894 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1367 | Train Loss:  0.008595605691274008 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1368 | Train Loss:  0.008621865113576254 | Train Accuracy:  0.6371428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1369 | Train Loss:  0.008017793496449788 | Train Accuracy:  0.65 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1370 | Train Loss:  0.008488461176554362 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1371 | Train Loss:  0.008792671362559 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1372 | Train Loss:  0.008459099928538005 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1373 | Train Loss:  0.00855864683787028 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1374 | Train Loss:  0.008564399878184 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1375 | Train Loss:  0.00905480146408081 | Train Accuracy:  0.65 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1376 | Train Loss:  0.008693226178487142 | Train Accuracy:  0.65 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1377 | Train Loss:  0.008574762344360352 | Train Accuracy:  0.65 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1378 | Train Loss:  0.008605229059855142 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  1379 | Train Loss:  0.007973461151123047 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1380 | Train Loss:  0.008469138940175374 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1381 | Train Loss:  0.008769021034240723 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1382 | Train Loss:  0.008439850012461345 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1383 | Train Loss:  0.008539685408274333 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1384 | Train Loss:  0.008538837432861329 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1385 | Train Loss:  0.009045920372009277 | Train Accuracy:  0.65 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1386 | Train Loss:  0.008679336706797281 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1387 | Train Loss:  0.008553582032521566 | Train Accuracy:  0.65 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1388 | Train Loss:  0.00858822743097941 | Train Accuracy:  0.64 | Validation Accuracy:  0.54\n",
            "Iteration:  1389 | Train Loss:  0.007931163311004638 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1390 | Train Loss:  0.008448077042897543 | Train Accuracy:  0.6457142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1391 | Train Loss:  0.008746626377105713 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1392 | Train Loss:  0.008420510292053223 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1393 | Train Loss:  0.008521985212961833 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1394 | Train Loss:  0.008510976632436117 | Train Accuracy:  0.65 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1395 | Train Loss:  0.009035887718200684 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1396 | Train Loss:  0.0086659042040507 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  1397 | Train Loss:  0.008532437483469645 | Train Accuracy:  0.65 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1398 | Train Loss:  0.008571235338846843 | Train Accuracy:  0.6385714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1399 | Train Loss:  0.007890133062998454 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1400 | Train Loss:  0.008425439198811849 | Train Accuracy:  0.6442857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1401 | Train Loss:  0.008727130889892578 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1402 | Train Loss:  0.00839834451675415 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1403 | Train Loss:  0.008502666155497234 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1404 | Train Loss:  0.008483209609985352 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1405 | Train Loss:  0.009025295575459799 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1406 | Train Loss:  0.008652911186218262 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1407 | Train Loss:  0.00851163625717163 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1408 | Train Loss:  0.008554831345876058 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1409 | Train Loss:  0.007847685019175212 | Train Accuracy:  0.65 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1410 | Train Loss:  0.008403168519337973 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1411 | Train Loss:  0.008708008130391439 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1412 | Train Loss:  0.008374258677164714 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1413 | Train Loss:  0.008480784098307291 | Train Accuracy:  0.6485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1414 | Train Loss:  0.008456845283508301 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1415 | Train Loss:  0.009015063444773356 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1416 | Train Loss:  0.008640096187591553 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1417 | Train Loss:  0.00849077860514323 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1418 | Train Loss:  0.008538936773935954 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  1419 | Train Loss:  0.007803113460540772 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1420 | Train Loss:  0.008382094701131186 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1421 | Train Loss:  0.008686424891153972 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1422 | Train Loss:  0.008351407051086425 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1423 | Train Loss:  0.00845866600672404 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  1424 | Train Loss:  0.00843098243077596 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1425 | Train Loss:  0.009005257288614909 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1426 | Train Loss:  0.008626859188079834 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1427 | Train Loss:  0.0084695299466451 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1428 | Train Loss:  0.008522886435190837 | Train Accuracy:  0.6471428571428571 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1429 | Train Loss:  0.007758993307749431 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1430 | Train Loss:  0.008360482056935629 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1431 | Train Loss:  0.00866665760676066 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1432 | Train Loss:  0.00832615613937378 | Train Accuracy:  0.6514285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1433 | Train Loss:  0.008435014088948568 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1434 | Train Loss:  0.008405338923136394 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1435 | Train Loss:  0.00899507204691569 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1436 | Train Loss:  0.00861407200495402 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1437 | Train Loss:  0.008448464870452881 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  1438 | Train Loss:  0.008507401943206786 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  1439 | Train Loss:  0.0077121273676554365 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1440 | Train Loss:  0.008339803218841552 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1441 | Train Loss:  0.008645101388295492 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1442 | Train Loss:  0.008301684856414795 | Train Accuracy:  0.6528571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1443 | Train Loss:  0.008411033948262533 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1444 | Train Loss:  0.008380228678385417 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1445 | Train Loss:  0.00898520310719808 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1446 | Train Loss:  0.008601109186808268 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1447 | Train Loss:  0.008427047729492187 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1448 | Train Loss:  0.008492048581441243 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1449 | Train Loss:  0.0076641845703125 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1450 | Train Loss:  0.008319907983144125 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1451 | Train Loss:  0.008622589111328125 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1452 | Train Loss:  0.008276661237080893 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1453 | Train Loss:  0.008386148611704508 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1454 | Train Loss:  0.00835593303044637 | Train Accuracy:  0.66 | Validation Accuracy:  0.5\n",
            "Iteration:  1455 | Train Loss:  0.00897524356842041 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  1456 | Train Loss:  0.008588252067565917 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  1457 | Train Loss:  0.008405552705128988 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.5\n",
            "Iteration:  1458 | Train Loss:  0.00847688913345337 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1459 | Train Loss:  0.007616355419158936 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1460 | Train Loss:  0.008301836649576823 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1461 | Train Loss:  0.008594106833140056 | Train Accuracy:  0.6542857142857142 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1462 | Train Loss:  0.00825854460398356 | Train Accuracy:  0.6557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1463 | Train Loss:  0.008366057872772217 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1464 | Train Loss:  0.008328707218170165 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1465 | Train Loss:  0.008964511553446452 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1466 | Train Loss:  0.008575352032979329 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1467 | Train Loss:  0.008383614222208659 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1468 | Train Loss:  0.00846067190170288 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1469 | Train Loss:  0.007571669419606527 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1470 | Train Loss:  0.008281838099161784 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1471 | Train Loss:  0.008568503856658936 | Train Accuracy:  0.6571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1472 | Train Loss:  0.008238587379455566 | Train Accuracy:  0.66 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1473 | Train Loss:  0.008345395723978678 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1474 | Train Loss:  0.008300511837005616 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1475 | Train Loss:  0.00895297924677531 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  1476 | Train Loss:  0.008562963803609212 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1477 | Train Loss:  0.008361780643463134 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1478 | Train Loss:  0.00844455639521281 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1479 | Train Loss:  0.007527686754862467 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1480 | Train Loss:  0.008261046409606933 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1481 | Train Loss:  0.008544260660807292 | Train Accuracy:  0.66 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1482 | Train Loss:  0.00821693499883016 | Train Accuracy:  0.6585714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1483 | Train Loss:  0.008323721090952555 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1484 | Train Loss:  0.00827238400777181 | Train Accuracy:  0.6757142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1485 | Train Loss:  0.008941040833791098 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1486 | Train Loss:  0.008550875186920166 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1487 | Train Loss:  0.008339938322703043 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1488 | Train Loss:  0.008428804079691569 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1489 | Train Loss:  0.007483988602956136 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1490 | Train Loss:  0.008239842255910238 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1491 | Train Loss:  0.008521692752838135 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1492 | Train Loss:  0.008192772865295411 | Train Accuracy:  0.6614285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1493 | Train Loss:  0.008300493558247884 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1494 | Train Loss:  0.008244598706563314 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1495 | Train Loss:  0.008928663730621338 | Train Accuracy:  0.67 | Validation Accuracy:  0.52\n",
            "Iteration:  1496 | Train Loss:  0.008539199829101562 | Train Accuracy:  0.67 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1497 | Train Loss:  0.008318080902099609 | Train Accuracy:  0.6757142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1498 | Train Loss:  0.008413522243499756 | Train Accuracy:  0.67 | Validation Accuracy:  0.5\n",
            "Iteration:  1499 | Train Loss:  0.007438162167867025 | Train Accuracy:  0.67 | Validation Accuracy:  0.52\n",
            "Iteration:  1500 | Train Loss:  0.008218963146209717 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1501 | Train Loss:  0.008499789237976074 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1502 | Train Loss:  0.008166782855987549 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1503 | Train Loss:  0.0082749080657959 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1504 | Train Loss:  0.008218573729197183 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1505 | Train Loss:  0.008916683991750081 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1506 | Train Loss:  0.008527585665384928 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  1507 | Train Loss:  0.008296136061350505 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1508 | Train Loss:  0.00839872439702352 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1509 | Train Loss:  0.007390740712483724 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1510 | Train Loss:  0.008199929396311442 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1511 | Train Loss:  0.008474004268646241 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1512 | Train Loss:  0.008143339157104492 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1513 | Train Loss:  0.008250126838684082 | Train Accuracy:  0.6814285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1514 | Train Loss:  0.008192725976308187 | Train Accuracy:  0.68 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1515 | Train Loss:  0.008904988765716553 | Train Accuracy:  0.6814285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1516 | Train Loss:  0.008515626589457193 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1517 | Train Loss:  0.008273983001708984 | Train Accuracy:  0.6814285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1518 | Train Loss:  0.008383337656656902 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1519 | Train Loss:  0.007344998518625895 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1520 | Train Loss:  0.008180156548817952 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1521 | Train Loss:  0.008449841340382893 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1522 | Train Loss:  0.008118170897165934 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1523 | Train Loss:  0.008224582672119141 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1524 | Train Loss:  0.008166828950246174 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1525 | Train Loss:  0.00889283577601115 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1526 | Train Loss:  0.008504026730855306 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1527 | Train Loss:  0.008251769542694092 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1528 | Train Loss:  0.008368439674377441 | Train Accuracy:  0.68 | Validation Accuracy:  0.5\n",
            "Iteration:  1529 | Train Loss:  0.00729887326558431 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1530 | Train Loss:  0.008162321249643962 | Train Accuracy:  0.6642857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1531 | Train Loss:  0.00842082420984904 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1532 | Train Loss:  0.008097800413767496 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1533 | Train Loss:  0.008201533953348796 | Train Accuracy:  0.68 | Validation Accuracy:  0.52\n",
            "Iteration:  1534 | Train Loss:  0.008139785130818684 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1535 | Train Loss:  0.008880654176076253 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1536 | Train Loss:  0.008492371241251628 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1537 | Train Loss:  0.008229548931121827 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1538 | Train Loss:  0.008352856636047363 | Train Accuracy:  0.6814285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1539 | Train Loss:  0.007253522872924805 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1540 | Train Loss:  0.008143977324167887 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1541 | Train Loss:  0.008392359415690104 | Train Accuracy:  0.6685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1542 | Train Loss:  0.008077366352081299 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1543 | Train Loss:  0.008178808689117432 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1544 | Train Loss:  0.00811175505320231 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1545 | Train Loss:  0.008867713610331217 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1546 | Train Loss:  0.008481152057647705 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1547 | Train Loss:  0.008207401434580486 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1548 | Train Loss:  0.008337322076161703 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1549 | Train Loss:  0.007209739685058594 | Train Accuracy:  0.67 | Validation Accuracy:  0.54\n",
            "Iteration:  1550 | Train Loss:  0.008124533494313559 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1551 | Train Loss:  0.008366167545318604 | Train Accuracy:  0.67 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1552 | Train Loss:  0.008054090340932211 | Train Accuracy:  0.6657142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1553 | Train Loss:  0.008155256907145182 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1554 | Train Loss:  0.00808316946029663 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1555 | Train Loss:  0.008853909174601236 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1556 | Train Loss:  0.008470322291056315 | Train Accuracy:  0.69 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1557 | Train Loss:  0.008185233275095622 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1558 | Train Loss:  0.008321967124938965 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1559 | Train Loss:  0.007167091369628906 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  1560 | Train Loss:  0.008104713757832845 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  1561 | Train Loss:  0.008341115315755208 | Train Accuracy:  0.6671428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1562 | Train Loss:  0.008029413223266602 | Train Accuracy:  0.67 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1563 | Train Loss:  0.008130416075388591 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1564 | Train Loss:  0.008055278460184733 | Train Accuracy:  0.69 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1565 | Train Loss:  0.00884000062942505 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1566 | Train Loss:  0.008459792931874594 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1567 | Train Loss:  0.008163015842437744 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1568 | Train Loss:  0.008306850592295328 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1569 | Train Loss:  0.007123542626698812 | Train Accuracy:  0.6814285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  1570 | Train Loss:  0.008085500399271648 | Train Accuracy:  0.68 | Validation Accuracy:  0.54\n",
            "Iteration:  1571 | Train Loss:  0.008315128485361735 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1572 | Train Loss:  0.008005233605702718 | Train Accuracy:  0.67 | Validation Accuracy:  0.5\n",
            "Iteration:  1573 | Train Loss:  0.008105212052663168 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1574 | Train Loss:  0.008027800718943278 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1575 | Train Loss:  0.008825979232788085 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1576 | Train Loss:  0.00844946304957072 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1577 | Train Loss:  0.008140769004821777 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1578 | Train Loss:  0.00829192876815796 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1579 | Train Loss:  0.007079892158508301 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1580 | Train Loss:  0.008066047032674153 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1581 | Train Loss:  0.008291104634602864 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1582 | Train Loss:  0.007977407773335774 | Train Accuracy:  0.67 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1583 | Train Loss:  0.008077569802602132 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1584 | Train Loss:  0.008001993497212728 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1585 | Train Loss:  0.008812171618143717 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1586 | Train Loss:  0.00843928337097168 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1587 | Train Loss:  0.008118383089701335 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1588 | Train Loss:  0.008277480602264404 | Train Accuracy:  0.7 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1589 | Train Loss:  0.007035576502482097 | Train Accuracy:  0.6842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1590 | Train Loss:  0.008047889868418376 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1591 | Train Loss:  0.008264710108439127 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1592 | Train Loss:  0.007951375643412271 | Train Accuracy:  0.6757142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1593 | Train Loss:  0.008050576051076253 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1594 | Train Loss:  0.007976348400115968 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1595 | Train Loss:  0.00879855235417684 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1596 | Train Loss:  0.0084290877978007 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1597 | Train Loss:  0.008096044858296712 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1598 | Train Loss:  0.008262577056884766 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1599 | Train Loss:  0.006992446581522624 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1600 | Train Loss:  0.00803052266438802 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  1601 | Train Loss:  0.008235188325246175 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1602 | Train Loss:  0.007929291725158692 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1603 | Train Loss:  0.008025836944580079 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1604 | Train Loss:  0.0079495636622111 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1605 | Train Loss:  0.008784953753153484 | Train Accuracy:  0.7 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1606 | Train Loss:  0.008418859640757243 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1607 | Train Loss:  0.00807385762532552 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1608 | Train Loss:  0.008247079054514567 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1609 | Train Loss:  0.006950369675954183 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1610 | Train Loss:  0.00801265557607015 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1611 | Train Loss:  0.008206276893615723 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1612 | Train Loss:  0.007907102902730306 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1613 | Train Loss:  0.008001547654469808 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1614 | Train Loss:  0.007921831607818603 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1615 | Train Loss:  0.008770445982615152 | Train Accuracy:  0.7 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1616 | Train Loss:  0.008409002621968586 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1617 | Train Loss:  0.008051607608795166 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1618 | Train Loss:  0.008231738408406575 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1619 | Train Loss:  0.006909561157226562 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  1620 | Train Loss:  0.007995108763376871 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  1621 | Train Loss:  0.00817699432373047 | Train Accuracy:  0.6728571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1622 | Train Loss:  0.007884589831034343 | Train Accuracy:  0.6814285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1623 | Train Loss:  0.007976840337117513 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1624 | Train Loss:  0.007894670963287354 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1625 | Train Loss:  0.008755911986033121 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1626 | Train Loss:  0.008399447600046794 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1627 | Train Loss:  0.008029420375823975 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1628 | Train Loss:  0.008216203053792318 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1629 | Train Loss:  0.006869362195332845 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  1630 | Train Loss:  0.007977420488993327 | Train Accuracy:  0.69 | Validation Accuracy:  0.52\n",
            "Iteration:  1631 | Train Loss:  0.008148098786671956 | Train Accuracy:  0.6742857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1632 | Train Loss:  0.007861687342325846 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1633 | Train Loss:  0.007952571709950765 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1634 | Train Loss:  0.007866535186767578 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1635 | Train Loss:  0.008740553855895996 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1636 | Train Loss:  0.008390227953592936 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1637 | Train Loss:  0.008007207711537678 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1638 | Train Loss:  0.008200662930806478 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1639 | Train Loss:  0.006829464435577392 | Train Accuracy:  0.69 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1640 | Train Loss:  0.007959405581156412 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1641 | Train Loss:  0.008120582103729249 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1642 | Train Loss:  0.007837106386820475 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1643 | Train Loss:  0.007927041053771972 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1644 | Train Loss:  0.007839265664418539 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1645 | Train Loss:  0.008725121021270751 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1646 | Train Loss:  0.008381098111470541 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1647 | Train Loss:  0.007984949747721353 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1648 | Train Loss:  0.008185415267944337 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1649 | Train Loss:  0.006789382298787435 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1650 | Train Loss:  0.007942329247792562 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1651 | Train Loss:  0.008091687361399333 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1652 | Train Loss:  0.007813234329223633 | Train Accuracy:  0.6857142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1653 | Train Loss:  0.007901523113250732 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1654 | Train Loss:  0.00781270424524943 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1655 | Train Loss:  0.008709789911905925 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1656 | Train Loss:  0.00837218999862671 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1657 | Train Loss:  0.00796280860900879 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1658 | Train Loss:  0.008170108795166015 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  1659 | Train Loss:  0.006749637126922607 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1660 | Train Loss:  0.007924877007802327 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1661 | Train Loss:  0.008064406712849935 | Train Accuracy:  0.6785714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1662 | Train Loss:  0.007786626815795898 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  1663 | Train Loss:  0.007874820232391357 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1664 | Train Loss:  0.007786613305409749 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1665 | Train Loss:  0.008694139321645101 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1666 | Train Loss:  0.008363597393035889 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1667 | Train Loss:  0.007940544287363687 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1668 | Train Loss:  0.008155039151509603 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1669 | Train Loss:  0.006709744930267334 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1670 | Train Loss:  0.007906880378723145 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1671 | Train Loss:  0.008038357893625895 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1672 | Train Loss:  0.007758510112762451 | Train Accuracy:  0.69 | Validation Accuracy:  0.52\n",
            "Iteration:  1673 | Train Loss:  0.007847452163696289 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1674 | Train Loss:  0.007760862509409587 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1675 | Train Loss:  0.008678261439005535 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1676 | Train Loss:  0.008355209032694499 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1677 | Train Loss:  0.007918250560760499 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1678 | Train Loss:  0.008140103022257487 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  1679 | Train Loss:  0.006670135656992595 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1680 | Train Loss:  0.007890631357828776 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1681 | Train Loss:  0.008008159001668295 | Train Accuracy:  0.6828571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1682 | Train Loss:  0.007735341389973958 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  1683 | Train Loss:  0.007822023232777914 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1684 | Train Loss:  0.007735103766123454 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1685 | Train Loss:  0.008662957350413005 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1686 | Train Loss:  0.008346623579661051 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  1687 | Train Loss:  0.00789637804031372 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1688 | Train Loss:  0.00812440315882365 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1689 | Train Loss:  0.006631119251251221 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1690 | Train Loss:  0.007874212265014648 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1691 | Train Loss:  0.00797810157140096 | Train Accuracy:  0.6871428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1692 | Train Loss:  0.00771282434463501 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1693 | Train Loss:  0.007797030607859293 | Train Accuracy:  0.71 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1694 | Train Loss:  0.007708695729573568 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1695 | Train Loss:  0.008647388617197672 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1696 | Train Loss:  0.00833800474802653 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1697 | Train Loss:  0.007874477704366048 | Train Accuracy:  0.71 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1698 | Train Loss:  0.008108848730723064 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1699 | Train Loss:  0.006591981649398804 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1700 | Train Loss:  0.007857757409413656 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1701 | Train Loss:  0.00794837474822998 | Train Accuracy:  0.69 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1702 | Train Loss:  0.007689495881398519 | Train Accuracy:  0.6914285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1703 | Train Loss:  0.007771519819895426 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1704 | Train Loss:  0.007683000564575195 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1705 | Train Loss:  0.008631695906321207 | Train Accuracy:  0.71 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1706 | Train Loss:  0.008329670429229736 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1707 | Train Loss:  0.007852556705474854 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1708 | Train Loss:  0.008093489011128744 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1709 | Train Loss:  0.006553030014038086 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1710 | Train Loss:  0.007841292222340902 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1711 | Train Loss:  0.007919655640920004 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1712 | Train Loss:  0.007663985093434651 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1713 | Train Loss:  0.00774524450302124 | Train Accuracy:  0.71 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1714 | Train Loss:  0.007657647927602132 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1715 | Train Loss:  0.008615597089131673 | Train Accuracy:  0.71 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1716 | Train Loss:  0.008321617444356283 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1717 | Train Loss:  0.007830474376678467 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1718 | Train Loss:  0.00807830572128296 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1719 | Train Loss:  0.006514420906702677 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1720 | Train Loss:  0.007825595537821452 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1721 | Train Loss:  0.007889467080434164 | Train Accuracy:  0.6957142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1722 | Train Loss:  0.007640150388081869 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1723 | Train Loss:  0.0077196693420410155 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1724 | Train Loss:  0.007632505893707275 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1725 | Train Loss:  0.008599678675333658 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1726 | Train Loss:  0.008313437302907309 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  1727 | Train Loss:  0.0078087910016377765 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1728 | Train Loss:  0.008062593936920166 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1729 | Train Loss:  0.006476438442866008 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1730 | Train Loss:  0.00781016747156779 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1731 | Train Loss:  0.007858289082845053 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1732 | Train Loss:  0.007618465423583984 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1733 | Train Loss:  0.007694996198018392 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1734 | Train Loss:  0.007607069810231527 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1735 | Train Loss:  0.008583954175313314 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1736 | Train Loss:  0.00830512523651123 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  1737 | Train Loss:  0.007787213325500488 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1738 | Train Loss:  0.008046750227610271 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1739 | Train Loss:  0.006438490152359009 | Train Accuracy:  0.7 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1740 | Train Loss:  0.007794152100880941 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1741 | Train Loss:  0.007828560670216879 | Train Accuracy:  0.6928571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1742 | Train Loss:  0.007595028082529704 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.5\n",
            "Iteration:  1743 | Train Loss:  0.007669804096221924 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5\n",
            "Iteration:  1744 | Train Loss:  0.007581551869710286 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1745 | Train Loss:  0.008567702770233155 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1746 | Train Loss:  0.00829707940419515 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1747 | Train Loss:  0.007765607833862305 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1748 | Train Loss:  0.008031059106190999 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1749 | Train Loss:  0.0064006622632344565 | Train Accuracy:  0.7 | Validation Accuracy:  0.5\n",
            "Iteration:  1750 | Train Loss:  0.007778183619181315 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  1751 | Train Loss:  0.0077991898854573565 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1752 | Train Loss:  0.007570346196492513 | Train Accuracy:  0.6985714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1753 | Train Loss:  0.007643970648447672 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1754 | Train Loss:  0.00755697250366211 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1755 | Train Loss:  0.008551214536031087 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1756 | Train Loss:  0.00828934907913208 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1757 | Train Loss:  0.007743964989980062 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  1758 | Train Loss:  0.008015553951263427 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1759 | Train Loss:  0.006363279024759929 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1760 | Train Loss:  0.007762832641601563 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5\n",
            "Iteration:  1761 | Train Loss:  0.00776893138885498 | Train Accuracy:  0.6942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1762 | Train Loss:  0.0075469064712524415 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1763 | Train Loss:  0.0076185409228007 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1764 | Train Loss:  0.007532686392466227 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1765 | Train Loss:  0.008535332679748535 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  1766 | Train Loss:  0.008281434377034505 | Train Accuracy:  0.72 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1767 | Train Loss:  0.007722586790720622 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1768 | Train Loss:  0.007999758720397949 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  1769 | Train Loss:  0.0063257559140523275 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1770 | Train Loss:  0.007746276060740153 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1771 | Train Loss:  0.007741217613220215 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1772 | Train Loss:  0.007519932587941488 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1773 | Train Loss:  0.00759196678797404 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  1774 | Train Loss:  0.007508350213368734 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1775 | Train Loss:  0.00851805051167806 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1776 | Train Loss:  0.00827376127243042 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1777 | Train Loss:  0.007700824737548828 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  1778 | Train Loss:  0.00798443078994751 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  1779 | Train Loss:  0.006288754940032959 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1780 | Train Loss:  0.007730671564737956 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1781 | Train Loss:  0.007711431980133057 | Train Accuracy:  0.6971428571428572 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1782 | Train Loss:  0.0074964539210001626 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1783 | Train Loss:  0.007566743691762288 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  1784 | Train Loss:  0.007483980655670166 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1785 | Train Loss:  0.008501218954722086 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1786 | Train Loss:  0.008265906174977621 | Train Accuracy:  0.72 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1787 | Train Loss:  0.007679492632548014 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  1788 | Train Loss:  0.007968735694885255 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  1789 | Train Loss:  0.006251945495605469 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1790 | Train Loss:  0.007715489864349365 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1791 | Train Loss:  0.007681198120117187 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1792 | Train Loss:  0.007473330497741699 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1793 | Train Loss:  0.0075415221850077315 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  1794 | Train Loss:  0.007460157076517741 | Train Accuracy:  0.72 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1795 | Train Loss:  0.008484686215718587 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.5\n",
            "Iteration:  1796 | Train Loss:  0.008258151213328043 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  1797 | Train Loss:  0.0076581343015035 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  1798 | Train Loss:  0.007953268686930338 | Train Accuracy:  0.72 | Validation Accuracy:  0.48\n",
            "Iteration:  1799 | Train Loss:  0.006214809020360311 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1800 | Train Loss:  0.007699244817097981 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1801 | Train Loss:  0.007653744220733643 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1802 | Train Loss:  0.007445243994394938 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1803 | Train Loss:  0.007514544328053792 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1804 | Train Loss:  0.007436962127685547 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1805 | Train Loss:  0.008467071851094564 | Train Accuracy:  0.73 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1806 | Train Loss:  0.008250768979390461 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  1807 | Train Loss:  0.007636460463205973 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  1808 | Train Loss:  0.007938074270884195 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  1809 | Train Loss:  0.00617844025293986 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1810 | Train Loss:  0.007682886918385824 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1811 | Train Loss:  0.007626311779022217 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5\n",
            "Iteration:  1812 | Train Loss:  0.007417649428049723 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1813 | Train Loss:  0.007488021850585938 | Train Accuracy:  0.73 | Validation Accuracy:  0.48\n",
            "Iteration:  1814 | Train Loss:  0.007413656711578369 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1815 | Train Loss:  0.008449389934539794 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1816 | Train Loss:  0.008243358929951986 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1817 | Train Loss:  0.007614748477935791 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  1818 | Train Loss:  0.007922982374827067 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  1819 | Train Loss:  0.0061419856548309325 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1820 | Train Loss:  0.007667030493418376 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1821 | Train Loss:  0.007598121960957845 | Train Accuracy:  0.7028571428571428 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1822 | Train Loss:  0.00739132563273112 | Train Accuracy:  0.7071428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1823 | Train Loss:  0.007462178071339925 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1824 | Train Loss:  0.007390315532684326 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1825 | Train Loss:  0.008431668281555177 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1826 | Train Loss:  0.008236014048258463 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  1827 | Train Loss:  0.007593369483947754 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1828 | Train Loss:  0.007907533645629882 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1829 | Train Loss:  0.006106442213058472 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1830 | Train Loss:  0.007650842666625976 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1831 | Train Loss:  0.007570288976033529 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1832 | Train Loss:  0.007364506721496582 | Train Accuracy:  0.7085714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1833 | Train Loss:  0.007436434427897136 | Train Accuracy:  0.73 | Validation Accuracy:  0.48\n",
            "Iteration:  1834 | Train Loss:  0.007366955280303955 | Train Accuracy:  0.72 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1835 | Train Loss:  0.008413879076639812 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1836 | Train Loss:  0.008228642145792643 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1837 | Train Loss:  0.007571945190429688 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  1838 | Train Loss:  0.007892181078592936 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1839 | Train Loss:  0.006070549885431925 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1840 | Train Loss:  0.007633678913116455 | Train Accuracy:  0.71 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1841 | Train Loss:  0.0075450332959493 | Train Accuracy:  0.7014285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1842 | Train Loss:  0.007333677609761556 | Train Accuracy:  0.71 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1843 | Train Loss:  0.007409494717915853 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1844 | Train Loss:  0.00734355370203654 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1845 | Train Loss:  0.008394823074340821 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1846 | Train Loss:  0.008221590518951416 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1847 | Train Loss:  0.007550145785013835 | Train Accuracy:  0.72 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1848 | Train Loss:  0.007877308527628581 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  1849 | Train Loss:  0.006035215059916179 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1850 | Train Loss:  0.007616727352142334 | Train Accuracy:  0.7142857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1851 | Train Loss:  0.007518954277038574 | Train Accuracy:  0.7042857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1852 | Train Loss:  0.00730452299118042 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1853 | Train Loss:  0.007383434772491455 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1854 | Train Loss:  0.0073198183377583825 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1855 | Train Loss:  0.008376071453094483 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1856 | Train Loss:  0.008214395840962728 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1857 | Train Loss:  0.0075286237398783365 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1858 | Train Loss:  0.007861973444620769 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  1859 | Train Loss:  0.005999916394551595 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1860 | Train Loss:  0.007600314617156982 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1861 | Train Loss:  0.007491762638092041 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1862 | Train Loss:  0.0072779019673665365 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1863 | Train Loss:  0.007358173529307048 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1864 | Train Loss:  0.0072962506612141926 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1865 | Train Loss:  0.008357798258463542 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1866 | Train Loss:  0.008206994533538818 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1867 | Train Loss:  0.0075072447458903 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1868 | Train Loss:  0.007846580346425375 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  1869 | Train Loss:  0.005964627663294474 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1870 | Train Loss:  0.007582880655924479 | Train Accuracy:  0.7157142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1871 | Train Loss:  0.007467230955759684 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1872 | Train Loss:  0.0072468996047973635 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1873 | Train Loss:  0.007331724166870117 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1874 | Train Loss:  0.007272635300954183 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1875 | Train Loss:  0.008338030179341633 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1876 | Train Loss:  0.008200024763743083 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1877 | Train Loss:  0.007485651969909668 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1878 | Train Loss:  0.007831451892852783 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  1879 | Train Loss:  0.005930033922195435 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1880 | Train Loss:  0.007566211223602295 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1881 | Train Loss:  0.007440312703450521 | Train Accuracy:  0.7057142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1882 | Train Loss:  0.007220476468404134 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1883 | Train Loss:  0.007307225863138834 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1884 | Train Loss:  0.007248331705729166 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1885 | Train Loss:  0.008318950335184733 | Train Accuracy:  0.73 | Validation Accuracy:  0.52\n",
            "Iteration:  1886 | Train Loss:  0.008192686239878337 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1887 | Train Loss:  0.0074645153681437175 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1888 | Train Loss:  0.007815259297688802 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  1889 | Train Loss:  0.005895955959955851 | Train Accuracy:  0.72 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1890 | Train Loss:  0.007548677921295166 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1891 | Train Loss:  0.007415452798207601 | Train Accuracy:  0.71 | Validation Accuracy:  0.5\n",
            "Iteration:  1892 | Train Loss:  0.007191408475240072 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1893 | Train Loss:  0.00728211243947347 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1894 | Train Loss:  0.007223674456278483 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1895 | Train Loss:  0.008298978010813396 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1896 | Train Loss:  0.008185663223266602 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  1897 | Train Loss:  0.007443207899729411 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1898 | Train Loss:  0.007799198627471924 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  1899 | Train Loss:  0.005862098137537638 | Train Accuracy:  0.7228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1900 | Train Loss:  0.007531398137410481 | Train Accuracy:  0.73 | Validation Accuracy:  0.5\n",
            "Iteration:  1901 | Train Loss:  0.007389527161916097 | Train Accuracy:  0.7114285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1902 | Train Loss:  0.007164930502573649 | Train Accuracy:  0.73 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1903 | Train Loss:  0.007257797718048096 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1904 | Train Loss:  0.007199049790700277 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1905 | Train Loss:  0.0082796843846639 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1906 | Train Loss:  0.008178238868713378 | Train Accuracy:  0.74 | Validation Accuracy:  0.48\n",
            "Iteration:  1907 | Train Loss:  0.007422076066335042 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  1908 | Train Loss:  0.007782821655273438 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.48\n",
            "Iteration:  1909 | Train Loss:  0.005828183889389038 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1910 | Train Loss:  0.007514399687449137 | Train Accuracy:  0.73 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1911 | Train Loss:  0.007363177140553792 | Train Accuracy:  0.7128571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1912 | Train Loss:  0.0071389571825663245 | Train Accuracy:  0.73 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1913 | Train Loss:  0.007233978907267253 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1914 | Train Loss:  0.007174039681752523 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1915 | Train Loss:  0.008260023593902589 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1916 | Train Loss:  0.008170858224232991 | Train Accuracy:  0.74 | Validation Accuracy:  0.48\n",
            "Iteration:  1917 | Train Loss:  0.0074011278152465824 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1918 | Train Loss:  0.007765916188557943 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1919 | Train Loss:  0.00579489787419637 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1920 | Train Loss:  0.007496351401011149 | Train Accuracy:  0.73 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1921 | Train Loss:  0.007339582443237304 | Train Accuracy:  0.7171428571428572 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1922 | Train Loss:  0.0071097731590270994 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1923 | Train Loss:  0.007209789752960205 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1924 | Train Loss:  0.007148121992746989 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1925 | Train Loss:  0.008238735993703207 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1926 | Train Loss:  0.008164228598276774 | Train Accuracy:  0.74 | Validation Accuracy:  0.47333333333333333\n",
            "Iteration:  1927 | Train Loss:  0.007380093733469645 | Train Accuracy:  0.73 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1928 | Train Loss:  0.007749036153157552 | Train Accuracy:  0.74 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1929 | Train Loss:  0.0057624395688374835 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1930 | Train Loss:  0.007479159832000732 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1931 | Train Loss:  0.007313096523284912 | Train Accuracy:  0.7185714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1932 | Train Loss:  0.00708532174428304 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1933 | Train Loss:  0.0071869953473409015 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1934 | Train Loss:  0.00712248166402181 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1935 | Train Loss:  0.008218870957692465 | Train Accuracy:  0.74 | Validation Accuracy:  0.5\n",
            "Iteration:  1936 | Train Loss:  0.008156511783599853 | Train Accuracy:  0.74 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1937 | Train Loss:  0.00735933780670166 | Train Accuracy:  0.73 | Validation Accuracy:  0.5\n",
            "Iteration:  1938 | Train Loss:  0.007731556097666422 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1939 | Train Loss:  0.005729477405548095 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1940 | Train Loss:  0.007462060451507569 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1941 | Train Loss:  0.007286730607350667 | Train Accuracy:  0.7214285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1942 | Train Loss:  0.007060670057932536 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1943 | Train Loss:  0.007164085706075032 | Train Accuracy:  0.73 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1944 | Train Loss:  0.007096877098083496 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1945 | Train Loss:  0.008199023405710855 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5\n",
            "Iteration:  1946 | Train Loss:  0.008148699601491293 | Train Accuracy:  0.74 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1947 | Train Loss:  0.007338479359944661 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1948 | Train Loss:  0.0077144257227579754 | Train Accuracy:  0.74 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1949 | Train Loss:  0.005696365038553874 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5\n",
            "Iteration:  1950 | Train Loss:  0.007444565296173096 | Train Accuracy:  0.74 | Validation Accuracy:  0.5\n",
            "Iteration:  1951 | Train Loss:  0.007261873086293539 | Train Accuracy:  0.7242857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1952 | Train Loss:  0.007034046649932861 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  1953 | Train Loss:  0.007140746116638183 | Train Accuracy:  0.7271428571428571 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1954 | Train Loss:  0.0070713988939921065 | Train Accuracy:  0.73 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1955 | Train Loss:  0.008178350130716959 | Train Accuracy:  0.74 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1956 | Train Loss:  0.008141403198242187 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1957 | Train Loss:  0.007317771116892496 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1958 | Train Loss:  0.00769692579905192 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1959 | Train Loss:  0.00566417137781779 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1960 | Train Loss:  0.007427450815836589 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1961 | Train Loss:  0.007235548496246338 | Train Accuracy:  0.7257142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1962 | Train Loss:  0.007009843985239665 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1963 | Train Loss:  0.007118290265401205 | Train Accuracy:  0.73 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1964 | Train Loss:  0.007046375274658203 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1965 | Train Loss:  0.008158666292826335 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1966 | Train Loss:  0.0081334122021993 | Train Accuracy:  0.74 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1967 | Train Loss:  0.007297129631042481 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1968 | Train Loss:  0.007679545084635417 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1969 | Train Loss:  0.005631180206934611 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1970 | Train Loss:  0.007410415013631185 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1971 | Train Loss:  0.007210170427958171 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1972 | Train Loss:  0.00698376735051473 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1973 | Train Loss:  0.0070952685674031575 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.4866666666666667\n",
            "Iteration:  1974 | Train Loss:  0.00702145258585612 | Train Accuracy:  0.7285714285714285 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1975 | Train Loss:  0.008138386408487956 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1976 | Train Loss:  0.008125621477762858 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  1977 | Train Loss:  0.0072765723864237465 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1978 | Train Loss:  0.007661731243133545 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  1979 | Train Loss:  0.005599028666814168 | Train Accuracy:  0.74 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1980 | Train Loss:  0.007393327554066976 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1981 | Train Loss:  0.0071840834617614745 | Train Accuracy:  0.73 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1982 | Train Loss:  0.006959431171417237 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1983 | Train Loss:  0.007072967688242594 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1984 | Train Loss:  0.006996815204620361 | Train Accuracy:  0.73 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1985 | Train Loss:  0.008118300437927247 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1986 | Train Loss:  0.00811750094095866 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1987 | Train Loss:  0.007256116072336833 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1988 | Train Loss:  0.0076443115870157875 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1989 | Train Loss:  0.005566509564717611 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5\n",
            "Iteration:  1990 | Train Loss:  0.007376136779785156 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  1991 | Train Loss:  0.007159096399943034 | Train Accuracy:  0.73 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1992 | Train Loss:  0.006933333079020183 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1993 | Train Loss:  0.0070501049359639485 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1994 | Train Loss:  0.006972469488779704 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5\n",
            "Iteration:  1995 | Train Loss:  0.008097943464914957 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1996 | Train Loss:  0.008109656969706218 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1997 | Train Loss:  0.007235593795776367 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1998 | Train Loss:  0.007627006371815999 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  1999 | Train Loss:  0.005534019470214844 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2000 | Train Loss:  0.007359255949656168 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2001 | Train Loss:  0.007133278052012125 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2002 | Train Loss:  0.006908904711405436 | Train Accuracy:  0.74 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2003 | Train Loss:  0.007028084595998128 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2004 | Train Loss:  0.006947675546010335 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5\n",
            "Iteration:  2005 | Train Loss:  0.008077481587727864 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2006 | Train Loss:  0.008101661205291748 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2007 | Train Loss:  0.007215263843536377 | Train Accuracy:  0.74 | Validation Accuracy:  0.5\n",
            "Iteration:  2008 | Train Loss:  0.007609195709228515 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2009 | Train Loss:  0.005502194166183472 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2010 | Train Loss:  0.007342112859090169 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2011 | Train Loss:  0.007108290195465088 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2012 | Train Loss:  0.006883777777353922 | Train Accuracy:  0.74 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2013 | Train Loss:  0.007005925973256429 | Train Accuracy:  0.7314285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2014 | Train Loss:  0.006922970612843832 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2015 | Train Loss:  0.008057253360748291 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2016 | Train Loss:  0.008093310197194418 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2017 | Train Loss:  0.007194894949595134 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2018 | Train Loss:  0.007591435114542643 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2019 | Train Loss:  0.005469836393992106 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2020 | Train Loss:  0.0073252518971761065 | Train Accuracy:  0.75 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2021 | Train Loss:  0.00708198070526123 | Train Accuracy:  0.74 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2022 | Train Loss:  0.0068602403004964195 | Train Accuracy:  0.74 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2023 | Train Loss:  0.006984002590179443 | Train Accuracy:  0.7328571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2024 | Train Loss:  0.006898954709370931 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2025 | Train Loss:  0.008037608464558919 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2026 | Train Loss:  0.008084501425425212 | Train Accuracy:  0.75 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2027 | Train Loss:  0.0071746524175008135 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2028 | Train Loss:  0.007573697566986084 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2029 | Train Loss:  0.005437604188919067 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2030 | Train Loss:  0.007308340072631836 | Train Accuracy:  0.75 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2031 | Train Loss:  0.007056317329406738 | Train Accuracy:  0.74 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2032 | Train Loss:  0.006835799217224121 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2033 | Train Loss:  0.006962021191914876 | Train Accuracy:  0.7342857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2034 | Train Loss:  0.0068750349680582684 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2035 | Train Loss:  0.00801746924718221 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2036 | Train Loss:  0.00807589054107666 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2037 | Train Loss:  0.007154566446940104 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2038 | Train Loss:  0.007555677890777588 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2039 | Train Loss:  0.005405912796656291 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2040 | Train Loss:  0.007291434605916341 | Train Accuracy:  0.75 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2041 | Train Loss:  0.007030535538991293 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2042 | Train Loss:  0.00681179682413737 | Train Accuracy:  0.75 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2043 | Train Loss:  0.006940321127573649 | Train Accuracy:  0.7357142857142858 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2044 | Train Loss:  0.006851174036661784 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2045 | Train Loss:  0.007997036774953207 | Train Accuracy:  0.75 | Validation Accuracy:  0.52\n",
            "Iteration:  2046 | Train Loss:  0.008067166805267334 | Train Accuracy:  0.75 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2047 | Train Loss:  0.007134493192036947 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2048 | Train Loss:  0.007537719408671061 | Train Accuracy:  0.75 | Validation Accuracy:  0.52\n",
            "Iteration:  2049 | Train Loss:  0.005374050935109456 | Train Accuracy:  0.75 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2050 | Train Loss:  0.007274471918741862 | Train Accuracy:  0.75 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2051 | Train Loss:  0.007005079587300619 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2052 | Train Loss:  0.006787581443786621 | Train Accuracy:  0.75 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2053 | Train Loss:  0.00691878080368042 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2054 | Train Loss:  0.006827131112416585 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.52\n",
            "Iteration:  2055 | Train Loss:  0.007976784706115722 | Train Accuracy:  0.75 | Validation Accuracy:  0.52\n",
            "Iteration:  2056 | Train Loss:  0.00805821975072225 | Train Accuracy:  0.75 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2057 | Train Loss:  0.007114508152008057 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2058 | Train Loss:  0.007519659996032715 | Train Accuracy:  0.75 | Validation Accuracy:  0.52\n",
            "Iteration:  2059 | Train Loss:  0.0053423615296681725 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2060 | Train Loss:  0.007257502079010009 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2061 | Train Loss:  0.006979492505391439 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2062 | Train Loss:  0.006763641039530436 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2063 | Train Loss:  0.0068973596890767415 | Train Accuracy:  0.7371428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2064 | Train Loss:  0.006803320248921712 | Train Accuracy:  0.74 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2065 | Train Loss:  0.007956481774648031 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2066 | Train Loss:  0.00804924488067627 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2067 | Train Loss:  0.007094627221425375 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2068 | Train Loss:  0.007501559257507324 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2069 | Train Loss:  0.005310920079549154 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2070 | Train Loss:  0.007240571975708008 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2071 | Train Loss:  0.00695347785949707 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2072 | Train Loss:  0.0067403690020243325 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2073 | Train Loss:  0.0068763065338134765 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2074 | Train Loss:  0.0067795475323994955 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2075 | Train Loss:  0.007936223347981771 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  2076 | Train Loss:  0.008039928277333578 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2077 | Train Loss:  0.0070748321215311685 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2078 | Train Loss:  0.007483414014180501 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2079 | Train Loss:  0.0052794373035430905 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2080 | Train Loss:  0.007223644256591797 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2081 | Train Loss:  0.006927649180094401 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2082 | Train Loss:  0.006716881593068441 | Train Accuracy:  0.75 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2083 | Train Loss:  0.006855200926462809 | Train Accuracy:  0.74 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2084 | Train Loss:  0.0067560752232869465 | Train Accuracy:  0.74 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2085 | Train Loss:  0.00791575829188029 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2086 | Train Loss:  0.008030639489491781 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2087 | Train Loss:  0.007055142720540365 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2088 | Train Loss:  0.007465152740478515 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2089 | Train Loss:  0.005248138507207235 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2090 | Train Loss:  0.007206534544626872 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2091 | Train Loss:  0.00690241813659668 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2092 | Train Loss:  0.006693104108174642 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2093 | Train Loss:  0.0068342367808024084 | Train Accuracy:  0.74 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2094 | Train Loss:  0.006732351779937744 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2095 | Train Loss:  0.007895271778106689 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2096 | Train Loss:  0.008021179835001628 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2097 | Train Loss:  0.007035555839538574 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2098 | Train Loss:  0.007446680068969726 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2099 | Train Loss:  0.005217014948527018 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2100 | Train Loss:  0.0071895178159077965 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2101 | Train Loss:  0.006876235802968343 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2102 | Train Loss:  0.006670636336008708 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2103 | Train Loss:  0.006813646952311198 | Train Accuracy:  0.7385714285714285 | Validation Accuracy:  0.54\n",
            "Iteration:  2104 | Train Loss:  0.006708855628967285 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2105 | Train Loss:  0.007874658902486165 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2106 | Train Loss:  0.008011823495229085 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2107 | Train Loss:  0.0070160380999247235 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2108 | Train Loss:  0.00742847998936971 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2109 | Train Loss:  0.0051859688758850095 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2110 | Train Loss:  0.00717232624689738 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2111 | Train Loss:  0.006851235230763753 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2112 | Train Loss:  0.006646750768025716 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2113 | Train Loss:  0.006792880694071452 | Train Accuracy:  0.7414285714285714 | Validation Accuracy:  0.54\n",
            "Iteration:  2114 | Train Loss:  0.006685350735982259 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2115 | Train Loss:  0.007853983243306478 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2116 | Train Loss:  0.00800216277440389 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2117 | Train Loss:  0.006996685663859049 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2118 | Train Loss:  0.007409938176472982 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2119 | Train Loss:  0.0051550726095835366 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2120 | Train Loss:  0.007155129909515381 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2121 | Train Loss:  0.006826070149739584 | Train Accuracy:  0.7485714285714286 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2122 | Train Loss:  0.006623301903406779 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2123 | Train Loss:  0.006772322654724121 | Train Accuracy:  0.74 | Validation Accuracy:  0.54\n",
            "Iteration:  2124 | Train Loss:  0.006661986112594605 | Train Accuracy:  0.7442857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2125 | Train Loss:  0.007833312352498373 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2126 | Train Loss:  0.007992167472839356 | Train Accuracy:  0.76 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2127 | Train Loss:  0.0069774476687113444 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2128 | Train Loss:  0.0073913780848185225 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2129 | Train Loss:  0.005124362707138061 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2130 | Train Loss:  0.007138014634450277 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2131 | Train Loss:  0.006800474325815837 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2132 | Train Loss:  0.00660028060277303 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2133 | Train Loss:  0.006751890182495117 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.54\n",
            "Iteration:  2134 | Train Loss:  0.006639071305592855 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2135 | Train Loss:  0.00781261682510376 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2136 | Train Loss:  0.007982184092203776 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2137 | Train Loss:  0.006958278020222982 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2138 | Train Loss:  0.007372836271921794 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2139 | Train Loss:  0.0050937581062316896 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2140 | Train Loss:  0.00712084690729777 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2141 | Train Loss:  0.006775279045104981 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2142 | Train Loss:  0.006577119429906209 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2143 | Train Loss:  0.0067315928141276045 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2144 | Train Loss:  0.006615875959396362 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2145 | Train Loss:  0.007791646321614583 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2146 | Train Loss:  0.007972079118092855 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2147 | Train Loss:  0.006939233938852946 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2148 | Train Loss:  0.007353987693786621 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2149 | Train Loss:  0.005063251256942749 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2150 | Train Loss:  0.007103718121846517 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2151 | Train Loss:  0.006749591032663981 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2152 | Train Loss:  0.006554665962855021 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2153 | Train Loss:  0.006711453596750895 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2154 | Train Loss:  0.006593307654062907 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2155 | Train Loss:  0.0077708053588867185 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2156 | Train Loss:  0.007961600621541342 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2157 | Train Loss:  0.006920295556386312 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2158 | Train Loss:  0.007335584163665771 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2159 | Train Loss:  0.005032318433125814 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2160 | Train Loss:  0.007086629072825114 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2161 | Train Loss:  0.00672413428624471 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2162 | Train Loss:  0.006531400680541992 | Train Accuracy:  0.76 | Validation Accuracy:  0.52\n",
            "Iteration:  2163 | Train Loss:  0.006690824031829834 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2164 | Train Loss:  0.00657140572865804 | Train Accuracy:  0.7457142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2165 | Train Loss:  0.007750140825907389 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2166 | Train Loss:  0.007951455116271973 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2167 | Train Loss:  0.006901280085245768 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2168 | Train Loss:  0.007317198117574056 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2169 | Train Loss:  0.0050016566117604576 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2170 | Train Loss:  0.007069279352823893 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2171 | Train Loss:  0.006698993047078451 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2172 | Train Loss:  0.006508475144704183 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2173 | Train Loss:  0.006670730908711751 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2174 | Train Loss:  0.006548657417297364 | Train Accuracy:  0.75 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2175 | Train Loss:  0.007729143301645915 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2176 | Train Loss:  0.00794106642405192 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2177 | Train Loss:  0.006882522106170654 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2178 | Train Loss:  0.0072985076904296875 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2179 | Train Loss:  0.004971467653910319 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2180 | Train Loss:  0.007051863670349121 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2181 | Train Loss:  0.006674700578053792 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2182 | Train Loss:  0.006484856605529785 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2183 | Train Loss:  0.006650708516438802 | Train Accuracy:  0.7471428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2184 | Train Loss:  0.006525643666585286 | Train Accuracy:  0.7514285714285714 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2185 | Train Loss:  0.0077079145113627115 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2186 | Train Loss:  0.00793075164159139 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2187 | Train Loss:  0.006863774458567302 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2188 | Train Loss:  0.007279667059580485 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2189 | Train Loss:  0.004941449165344238 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2190 | Train Loss:  0.007034512360890707 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2191 | Train Loss:  0.006648773749669393 | Train Accuracy:  0.76 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2192 | Train Loss:  0.0064634597301483155 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2193 | Train Loss:  0.006631031433741252 | Train Accuracy:  0.75 | Validation Accuracy:  0.54\n",
            "Iteration:  2194 | Train Loss:  0.00650365948677063 | Train Accuracy:  0.7528571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2195 | Train Loss:  0.007687420050303141 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2196 | Train Loss:  0.007919691403706868 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2197 | Train Loss:  0.00684518575668335 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2198 | Train Loss:  0.0072610735893249515 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2199 | Train Loss:  0.004910904963811239 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2200 | Train Loss:  0.00701714277267456 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2201 | Train Loss:  0.00662374218304952 | Train Accuracy:  0.76 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2202 | Train Loss:  0.006440229018529256 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2203 | Train Loss:  0.0066108512878417965 | Train Accuracy:  0.75 | Validation Accuracy:  0.54\n",
            "Iteration:  2204 | Train Loss:  0.006482253074645996 | Train Accuracy:  0.7542857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2205 | Train Loss:  0.007666480541229248 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2206 | Train Loss:  0.007909010251363119 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2207 | Train Loss:  0.00682668129603068 | Train Accuracy:  0.77 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2208 | Train Loss:  0.007242739200592041 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2209 | Train Loss:  0.00488073468208313 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2210 | Train Loss:  0.006999646822611491 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2211 | Train Loss:  0.006599597930908203 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2212 | Train Loss:  0.0064164884885152184 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2213 | Train Loss:  0.0065908583005269365 | Train Accuracy:  0.75 | Validation Accuracy:  0.54\n",
            "Iteration:  2214 | Train Loss:  0.006459783315658569 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2215 | Train Loss:  0.0076452104250590005 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2216 | Train Loss:  0.007898452281951905 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2217 | Train Loss:  0.006808224519093831 | Train Accuracy:  0.77 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2218 | Train Loss:  0.007223923206329346 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2219 | Train Loss:  0.004851048787434896 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2220 | Train Loss:  0.006982009410858154 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2221 | Train Loss:  0.006574991146723429 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2222 | Train Loss:  0.006394239664077758 | Train Accuracy:  0.77 | Validation Accuracy:  0.52\n",
            "Iteration:  2223 | Train Loss:  0.006571399768193563 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2224 | Train Loss:  0.0064371522267659504 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2225 | Train Loss:  0.0076238671938578285 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2226 | Train Loss:  0.007887585957845052 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2227 | Train Loss:  0.0067899433771769204 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2228 | Train Loss:  0.00720491091410319 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2229 | Train Loss:  0.004821482499440511 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2230 | Train Loss:  0.0069644339879353844 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2231 | Train Loss:  0.006549696127573649 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2232 | Train Loss:  0.006372697750727335 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2233 | Train Loss:  0.00655217965443929 | Train Accuracy:  0.7557142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2234 | Train Loss:  0.006415814161300659 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2235 | Train Loss:  0.007603228886922201 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2236 | Train Loss:  0.007875878810882569 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2237 | Train Loss:  0.006771816412607829 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2238 | Train Loss:  0.007186401685078939 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2239 | Train Loss:  0.004791216452916463 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2240 | Train Loss:  0.006946899890899658 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2241 | Train Loss:  0.006525214910507202 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2242 | Train Loss:  0.006349141995112101 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2243 | Train Loss:  0.006532061894734701 | Train Accuracy:  0.7571428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2244 | Train Loss:  0.006394671599070231 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  2245 | Train Loss:  0.007581886450449626 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2246 | Train Loss:  0.007864779631296793 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2247 | Train Loss:  0.006753725210825602 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2248 | Train Loss:  0.007167690594991048 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2249 | Train Loss:  0.004761570294698079 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2250 | Train Loss:  0.0069291321436564125 | Train Accuracy:  0.77 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2251 | Train Loss:  0.006501736640930175 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2252 | Train Loss:  0.006325830221176148 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2253 | Train Loss:  0.006512800455093384 | Train Accuracy:  0.7585714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2254 | Train Loss:  0.006372106075286865 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.52\n",
            "Iteration:  2255 | Train Loss:  0.007559636433919271 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2256 | Train Loss:  0.007853906154632568 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2257 | Train Loss:  0.006735777854919434 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2258 | Train Loss:  0.007148730754852295 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2259 | Train Loss:  0.004732438325881958 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2260 | Train Loss:  0.006911470890045166 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2261 | Train Loss:  0.006477046012878418 | Train Accuracy:  0.7642857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2262 | Train Loss:  0.006304340362548828 | Train Accuracy:  0.78 | Validation Accuracy:  0.52\n",
            "Iteration:  2263 | Train Loss:  0.006493716239929199 | Train Accuracy:  0.7614285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2264 | Train Loss:  0.006350595951080323 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2265 | Train Loss:  0.007538177172342936 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2266 | Train Loss:  0.00784237782160441 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2267 | Train Loss:  0.006717936992645264 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2268 | Train Loss:  0.007130057017008464 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2269 | Train Loss:  0.004702949126561482 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2270 | Train Loss:  0.006893734137217204 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2271 | Train Loss:  0.006452947457631429 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2272 | Train Loss:  0.00628165602684021 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2273 | Train Loss:  0.006474327246348063 | Train Accuracy:  0.7628571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2274 | Train Loss:  0.006329184373219808 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2275 | Train Loss:  0.007516710758209228 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2276 | Train Loss:  0.007830829620361328 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2277 | Train Loss:  0.006700199445088704 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2278 | Train Loss:  0.007111353874206543 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2279 | Train Loss:  0.004673498868942261 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2280 | Train Loss:  0.00687597910563151 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2281 | Train Loss:  0.006428425312042236 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2282 | Train Loss:  0.006259761651357015 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2283 | Train Loss:  0.006455128987630209 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2284 | Train Loss:  0.006307690938313802 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2285 | Train Loss:  0.007495079040527344 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  2286 | Train Loss:  0.007819382349650066 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2287 | Train Loss:  0.006682548522949219 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2288 | Train Loss:  0.007092655499776205 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2289 | Train Loss:  0.004644312858581543 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2290 | Train Loss:  0.00685813029607137 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2291 | Train Loss:  0.006404753128687541 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2292 | Train Loss:  0.006237290302912394 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2293 | Train Loss:  0.006435951789220174 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2294 | Train Loss:  0.006285995642344157 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2295 | Train Loss:  0.007473405996958415 | Train Accuracy:  0.78 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2296 | Train Loss:  0.007807580629984537 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2297 | Train Loss:  0.006665086348851522 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  2298 | Train Loss:  0.007073690096537272 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2299 | Train Loss:  0.004615190029144287 | Train Accuracy:  0.78 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2300 | Train Loss:  0.00684022585550944 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2301 | Train Loss:  0.006380732456843058 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2302 | Train Loss:  0.006215550899505615 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2303 | Train Loss:  0.006417295138041178 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2304 | Train Loss:  0.0062643539905548095 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2305 | Train Loss:  0.007451474666595459 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  2306 | Train Loss:  0.0077956525484720865 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  2307 | Train Loss:  0.006647746562957763 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  2308 | Train Loss:  0.007054907480875651 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2309 | Train Loss:  0.004586287339528402 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2310 | Train Loss:  0.006822350819905599 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2311 | Train Loss:  0.006356804768244425 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2312 | Train Loss:  0.006193702618281047 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2313 | Train Loss:  0.006398409605026245 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2314 | Train Loss:  0.006242624123891195 | Train Accuracy:  0.7657142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2315 | Train Loss:  0.007429370880126953 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  2316 | Train Loss:  0.00778388500213623 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2317 | Train Loss:  0.006630505323410034 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  2318 | Train Loss:  0.007036033471425374 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2319 | Train Loss:  0.004557744661966959 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2320 | Train Loss:  0.006804478963216146 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2321 | Train Loss:  0.006332308053970337 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2322 | Train Loss:  0.006172924041748047 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2323 | Train Loss:  0.006380204757054647 | Train Accuracy:  0.77 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2324 | Train Loss:  0.006220602591832478 | Train Accuracy:  0.7671428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2325 | Train Loss:  0.007407364845275879 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  2326 | Train Loss:  0.007771557966868083 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2327 | Train Loss:  0.006613447268803915 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2328 | Train Loss:  0.007017079989115397 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2329 | Train Loss:  0.004528797070185344 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2330 | Train Loss:  0.00678663969039917 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2331 | Train Loss:  0.0063074131806691485 | Train Accuracy:  0.78 | Validation Accuracy:  0.52\n",
            "Iteration:  2332 | Train Loss:  0.0061516988277435306 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2333 | Train Loss:  0.006360950469970703 | Train Accuracy:  0.7714285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2334 | Train Loss:  0.006200904051462809 | Train Accuracy:  0.7685714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2335 | Train Loss:  0.007385709285736084 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2336 | Train Loss:  0.007759236494700114 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  2337 | Train Loss:  0.0065964408715566 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2338 | Train Loss:  0.00699876070022583 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2339 | Train Loss:  0.00449997623761495 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2340 | Train Loss:  0.006768655776977539 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2341 | Train Loss:  0.006284718116124471 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2342 | Train Loss:  0.006128592888514201 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2343 | Train Loss:  0.006341976722081502 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2344 | Train Loss:  0.006179271936416626 | Train Accuracy:  0.7728571428571429 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2345 | Train Loss:  0.007363186677296956 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2346 | Train Loss:  0.007747511863708496 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  2347 | Train Loss:  0.0065796156724294026 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2348 | Train Loss:  0.006979810396830241 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2349 | Train Loss:  0.004471973180770874 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2350 | Train Loss:  0.0067505788803100585 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2351 | Train Loss:  0.006260372400283813 | Train Accuracy:  0.78 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2352 | Train Loss:  0.0061082601547241214 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2353 | Train Loss:  0.0063240222136179605 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2354 | Train Loss:  0.0061581659317016604 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2355 | Train Loss:  0.0073414413134257 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2356 | Train Loss:  0.007734533150990804 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2357 | Train Loss:  0.0065630125999450685 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2358 | Train Loss:  0.006961135864257812 | Train Accuracy:  0.78 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2359 | Train Loss:  0.004443363348642985 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2360 | Train Loss:  0.006732513109842936 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2361 | Train Loss:  0.00623668909072876 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2362 | Train Loss:  0.006086746056874593 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.52\n",
            "Iteration:  2363 | Train Loss:  0.0063051501909891765 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2364 | Train Loss:  0.0061375141143798825 | Train Accuracy:  0.7742857142857142 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2365 | Train Loss:  0.007319440046946207 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2366 | Train Loss:  0.00772233247756958 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2367 | Train Loss:  0.006546390851338704 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2368 | Train Loss:  0.0069425479571024575 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  2369 | Train Loss:  0.004415125052134196 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2370 | Train Loss:  0.0067143082618713375 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2371 | Train Loss:  0.00621381163597107 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2372 | Train Loss:  0.006065008640289307 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2373 | Train Loss:  0.006286789178848267 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2374 | Train Loss:  0.006115839878718058 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2375 | Train Loss:  0.007297134399414063 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2376 | Train Loss:  0.007709826628367106 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2377 | Train Loss:  0.006529992818832398 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2378 | Train Loss:  0.006923713684082031 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  2379 | Train Loss:  0.004387221336364746 | Train Accuracy:  0.78 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2380 | Train Loss:  0.0066961375872294105 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2381 | Train Loss:  0.006189882357915242 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2382 | Train Loss:  0.00604464332262675 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  2383 | Train Loss:  0.006268663803736369 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2384 | Train Loss:  0.006094976663589478 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2385 | Train Loss:  0.0072753047943115235 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2386 | Train Loss:  0.007696799437204997 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2387 | Train Loss:  0.006513711214065552 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2388 | Train Loss:  0.006905107498168945 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  2389 | Train Loss:  0.0043589584032694495 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2390 | Train Loss:  0.006677971680959066 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2391 | Train Loss:  0.006166133483250936 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2392 | Train Loss:  0.006023606459299723 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2393 | Train Loss:  0.006250012318293254 | Train Accuracy:  0.7757142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2394 | Train Loss:  0.006074891487757365 | Train Accuracy:  0.78 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2395 | Train Loss:  0.007253375848134359 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2396 | Train Loss:  0.0076840035120646156 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2397 | Train Loss:  0.0064975166320800784 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2398 | Train Loss:  0.006886648337046305 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  2399 | Train Loss:  0.004330954551696777 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2400 | Train Loss:  0.0066597263018290205 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2401 | Train Loss:  0.006143298149108887 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2402 | Train Loss:  0.006002195278803507 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2403 | Train Loss:  0.006231749852498372 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2404 | Train Loss:  0.0060537568728129066 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  2405 | Train Loss:  0.007231051921844482 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2406 | Train Loss:  0.007671254475911458 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2407 | Train Loss:  0.006481476624806722 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2408 | Train Loss:  0.006867857774098715 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  2409 | Train Loss:  0.0043032662073771155 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2410 | Train Loss:  0.00664145310719808 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2411 | Train Loss:  0.0061201349894205725 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2412 | Train Loss:  0.00598162849744161 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2413 | Train Loss:  0.00621370792388916 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2414 | Train Loss:  0.0060331284999847416 | Train Accuracy:  0.7814285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  2415 | Train Loss:  0.007209064960479736 | Train Accuracy:  0.79 | Validation Accuracy:  0.52\n",
            "Iteration:  2416 | Train Loss:  0.007657951513926189 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2417 | Train Loss:  0.00646558960278829 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2418 | Train Loss:  0.0068493262926737465 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  2419 | Train Loss:  0.0042754697799682615 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2420 | Train Loss:  0.006623218456904094 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2421 | Train Loss:  0.006097027063369751 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2422 | Train Loss:  0.0059606031576792395 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2423 | Train Loss:  0.006195263067881266 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2424 | Train Loss:  0.006012518405914307 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2425 | Train Loss:  0.007186948458353678 | Train Accuracy:  0.79 | Validation Accuracy:  0.52\n",
            "Iteration:  2426 | Train Loss:  0.007644803524017334 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2427 | Train Loss:  0.006449795961380005 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2428 | Train Loss:  0.006830615202585856 | Train Accuracy:  0.78 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2429 | Train Loss:  0.004247901837031046 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2430 | Train Loss:  0.006604939699172974 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2431 | Train Loss:  0.006073578596115113 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2432 | Train Loss:  0.005940765937169393 | Train Accuracy:  0.7942857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2433 | Train Loss:  0.006177294254302979 | Train Accuracy:  0.7785714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2434 | Train Loss:  0.00599204699198405 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2435 | Train Loss:  0.0071647906303405765 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2436 | Train Loss:  0.007631560961405436 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2437 | Train Loss:  0.0064341330528259275 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2438 | Train Loss:  0.0068120781580607095 | Train Accuracy:  0.78 | Validation Accuracy:  0.54\n",
            "Iteration:  2439 | Train Loss:  0.004220555623372396 | Train Accuracy:  0.79 | Validation Accuracy:  0.54\n",
            "Iteration:  2440 | Train Loss:  0.006586693127950033 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2441 | Train Loss:  0.0060505322615305585 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2442 | Train Loss:  0.005919981400171916 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2443 | Train Loss:  0.006159112453460693 | Train Accuracy:  0.78 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2444 | Train Loss:  0.005972147782643636 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2445 | Train Loss:  0.0071427265803019205 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2446 | Train Loss:  0.0076178781191507975 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2447 | Train Loss:  0.006418625116348267 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  2448 | Train Loss:  0.006793700059254964 | Train Accuracy:  0.7828571428571428 | Validation Accuracy:  0.54\n",
            "Iteration:  2449 | Train Loss:  0.0041931867599487305 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2450 | Train Loss:  0.006568470398585002 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.52\n",
            "Iteration:  2451 | Train Loss:  0.0060271120071411135 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2452 | Train Loss:  0.005899532238642375 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.54\n",
            "Iteration:  2453 | Train Loss:  0.0061407967408498125 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2454 | Train Loss:  0.005952511231104533 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  2455 | Train Loss:  0.007120606104532878 | Train Accuracy:  0.79 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2456 | Train Loss:  0.007604419390360514 | Train Accuracy:  0.79 | Validation Accuracy:  0.52\n",
            "Iteration:  2457 | Train Loss:  0.006403187910715739 | Train Accuracy:  0.79 | Validation Accuracy:  0.52\n",
            "Iteration:  2458 | Train Loss:  0.006775350570678711 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2459 | Train Loss:  0.004165870348612467 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2460 | Train Loss:  0.0065501268704732255 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2461 | Train Loss:  0.0060054186979929605 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2462 | Train Loss:  0.0058781147003173825 | Train Accuracy:  0.7985714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2463 | Train Loss:  0.006122727394104004 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2464 | Train Loss:  0.005931453307469686 | Train Accuracy:  0.7842857142857143 | Validation Accuracy:  0.54\n",
            "Iteration:  2465 | Train Loss:  0.007097987333933512 | Train Accuracy:  0.7928571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2466 | Train Loss:  0.007591133117675781 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2467 | Train Loss:  0.0063879199822743735 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2468 | Train Loss:  0.006756583054860433 | Train Accuracy:  0.7857142857142857 | Validation Accuracy:  0.54\n",
            "Iteration:  2469 | Train Loss:  0.004139147996902466 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2470 | Train Loss:  0.006531829833984375 | Train Accuracy:  0.79 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2471 | Train Loss:  0.005981261332829793 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2472 | Train Loss:  0.005859657128651937 | Train Accuracy:  0.7985714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2473 | Train Loss:  0.006104789972305298 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2474 | Train Loss:  0.005912331740061442 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2475 | Train Loss:  0.007076222896575928 | Train Accuracy:  0.7928571428571428 | Validation Accuracy:  0.5266666666666666\n",
            "Iteration:  2476 | Train Loss:  0.007577054500579834 | Train Accuracy:  0.79 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2477 | Train Loss:  0.006372719208399455 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.52\n",
            "Iteration:  2478 | Train Loss:  0.006738418738047282 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2479 | Train Loss:  0.0041119412581125895 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2480 | Train Loss:  0.006513520081837972 | Train Accuracy:  0.79 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2481 | Train Loss:  0.005959406693776448 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2482 | Train Loss:  0.0058381748199462895 | Train Accuracy:  0.7985714285714286 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2483 | Train Loss:  0.006086658239364624 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2484 | Train Loss:  0.0058919326464335125 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2485 | Train Loss:  0.00705344041188558 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  2486 | Train Loss:  0.007563733259836833 | Train Accuracy:  0.79 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2487 | Train Loss:  0.006357702016830444 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2488 | Train Loss:  0.006719931761423747 | Train Accuracy:  0.7885714285714286 | Validation Accuracy:  0.54\n",
            "Iteration:  2489 | Train Loss:  0.004085384607315064 | Train Accuracy:  0.79 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2490 | Train Loss:  0.006495207945505778 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2491 | Train Loss:  0.005936255057652791 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  2492 | Train Loss:  0.00581887682278951 | Train Accuracy:  0.8 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  2493 | Train Loss:  0.006069034735361735 | Train Accuracy:  0.79 | Validation Accuracy:  0.54\n",
            "Iteration:  2494 | Train Loss:  0.005872597297032674 | Train Accuracy:  0.7871428571428571 | Validation Accuracy:  0.54\n",
            "Iteration:  2495 | Train Loss:  0.007031265099843343 | Train Accuracy:  0.7971428571428572 | Validation Accuracy:  0.52\n",
            "Iteration:  2496 | Train Loss:  0.0075494909286499025 | Train Accuracy:  0.7928571428571428 | Validation Accuracy:  0.5133333333333333\n",
            "Iteration:  2497 | Train Loss:  0.006342800060908 | Train Accuracy:  0.79 | Validation Accuracy:  0.52\n",
            "Iteration:  2498 | Train Loss:  0.006701734860738119 | Train Accuracy:  0.7914285714285715 | Validation Accuracy:  0.54\n",
            "Iteration:  2499 | Train Loss:  0.00405858318010966 | Train Accuracy:  0.79 | Validation Accuracy:  0.5333333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.79\n",
            "Final Validation Accuracy: 0.5333333333333333\n",
            "Maximum Training Accuracy: 0.8\n",
            "Maximum Validation Accuracy: 0.5533333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6bR9mUTswMS"
      },
      "source": [
        "#### Time-Frequency Domain Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b16_1b6TRUa"
      },
      "source": [
        "##### 5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7-LoLdIs34p"
      },
      "source": [
        "train_dataset = createTensorDataset(X_train_wv, y_train_wv)\r\n",
        "val_dataset = createTensorDataset(X_val_wv, y_val_wv)\r\n",
        "\r\n",
        "#Downsample the height and width to make training easier\r\n",
        "train_dataset = downsampleTensorHW(train_dataset, 2)\r\n",
        "val_dataset = downsampleTensorHW(val_dataset, 2)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tIokMkxolULF",
        "outputId": "54e64518-aaa4-4e51-dede-01ba485a4fe2"
      },
      "source": [
        "model = CNN_WV()\r\n",
        "train(model, train_dataset, val_dataset, batch_size = 15, num_epochs=50, learning_rate = 0.001, momen = 0.7, use_adam = True, save_weights=True)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  0 | Train Loss:  0.0456275224685669 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  1 | Train Loss:  1.1416754404703775 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  2 | Train Loss:  0.4428629239400228 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  3 | Train Loss:  0.1744586149851481 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  4 | Train Loss:  0.21983405749003093 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  5 | Train Loss:  0.07554547786712647 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  6 | Train Loss:  0.10936174392700196 | Train Accuracy:  0.5228571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  7 | Train Loss:  0.047037255764007566 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  8 | Train Loss:  0.09033606052398682 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  9 | Train Loss:  0.05429032643636068 | Train Accuracy:  0.58 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  10 | Train Loss:  0.045694677035013835 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  11 | Train Loss:  0.06323020855585734 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  12 | Train Loss:  0.06876250902811686 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  13 | Train Loss:  0.048919057846069335 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  14 | Train Loss:  0.048423298199971515 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  15 | Train Loss:  0.042740531762441 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  16 | Train Loss:  0.037585663795471194 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  17 | Train Loss:  0.07836189270019531 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  18 | Train Loss:  0.06612523794174194 | Train Accuracy:  0.6142857142857143 | Validation Accuracy:  0.4\n",
            "Iteration:  19 | Train Loss:  0.04673661788304647 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  20 | Train Loss:  0.05128462711970012 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  21 | Train Loss:  0.07023229598999023 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  22 | Train Loss:  0.051201053460439044 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  23 | Train Loss:  0.048328777154286705 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  24 | Train Loss:  0.045795075098673504 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  25 | Train Loss:  0.05608124335606893 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  26 | Train Loss:  0.044794901212056475 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  27 | Train Loss:  0.04638273318608602 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  28 | Train Loss:  0.052464759349823 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  29 | Train Loss:  0.04467149575551351 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  30 | Train Loss:  0.0446918527285258 | Train Accuracy:  0.5742857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  31 | Train Loss:  0.046166149775187175 | Train Accuracy:  0.6428571428571429 | Validation Accuracy:  0.41333333333333333\n",
            "Iteration:  32 | Train Loss:  0.04572100241978963 | Train Accuracy:  0.52 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  33 | Train Loss:  0.04686819712320964 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  34 | Train Loss:  0.04520025650660197 | Train Accuracy:  0.4942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  35 | Train Loss:  0.046199572086334226 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  36 | Train Loss:  0.04642361402511597 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  37 | Train Loss:  0.045500683784484866 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  38 | Train Loss:  0.04439820051193237 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  39 | Train Loss:  0.04769055843353272 | Train Accuracy:  0.49142857142857144 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  40 | Train Loss:  0.048135793209075926 | Train Accuracy:  0.5657142857142857 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  41 | Train Loss:  0.04482891162236532 | Train Accuracy:  0.5828571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  42 | Train Loss:  0.04445904493331909 | Train Accuracy:  0.5028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  43 | Train Loss:  0.04697913328806559 | Train Accuracy:  0.5028571428571429 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  44 | Train Loss:  0.046449708938598636 | Train Accuracy:  0.5028571428571429 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  45 | Train Loss:  0.04812448024749756 | Train Accuracy:  0.7 | Validation Accuracy:  0.41333333333333333\n",
            "Iteration:  46 | Train Loss:  0.04556152820587158 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  47 | Train Loss:  0.045585131645202635 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  48 | Train Loss:  0.04459447463353475 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  49 | Train Loss:  0.048570450146993 | Train Accuracy:  0.5085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  50 | Train Loss:  0.045116027196248375 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  51 | Train Loss:  0.045260028044382734 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  52 | Train Loss:  0.04764075676600139 | Train Accuracy:  0.5114285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  53 | Train Loss:  0.04463950792948405 | Train Accuracy:  0.5171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  54 | Train Loss:  0.04457726875940959 | Train Accuracy:  0.5285714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  55 | Train Loss:  0.04591183662414551 | Train Accuracy:  0.5314285714285715 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  56 | Train Loss:  0.04567549228668213 | Train Accuracy:  0.5485714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  57 | Train Loss:  0.04551995595296224 | Train Accuracy:  0.5628571428571428 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  58 | Train Loss:  0.045726927121480306 | Train Accuracy:  0.6028571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  59 | Train Loss:  0.045526583989461265 | Train Accuracy:  0.6628571428571428 | Validation Accuracy:  0.52\n",
            "Iteration:  60 | Train Loss:  0.04487595955530802 | Train Accuracy:  0.7428571428571429 | Validation Accuracy:  0.48\n",
            "Iteration:  61 | Train Loss:  0.04502196311950683 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  62 | Train Loss:  0.04455923636754354 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.41333333333333333\n",
            "Iteration:  63 | Train Loss:  0.04552348852157593 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  64 | Train Loss:  0.045935964584350585 | Train Accuracy:  0.8742857142857143 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  65 | Train Loss:  0.04498260021209717 | Train Accuracy:  0.8657142857142858 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  66 | Train Loss:  0.04357227087020874 | Train Accuracy:  0.6771428571428572 | Validation Accuracy:  0.48\n",
            "Iteration:  67 | Train Loss:  0.045844121774037676 | Train Accuracy:  0.6085714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  68 | Train Loss:  0.045673886934916176 | Train Accuracy:  0.6257142857142857 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  69 | Train Loss:  0.04779577652613322 | Train Accuracy:  0.8314285714285714 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  70 | Train Loss:  0.043791051705678305 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.44\n",
            "Iteration:  71 | Train Loss:  0.043522763252258304 | Train Accuracy:  0.6885714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  72 | Train Loss:  0.04052940209706624 | Train Accuracy:  0.56 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  73 | Train Loss:  0.048564048608144124 | Train Accuracy:  0.6171428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  74 | Train Loss:  0.04407350222269694 | Train Accuracy:  0.6342857142857142 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  75 | Train Loss:  0.0430686354637146 | Train Accuracy:  0.6714285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  76 | Train Loss:  0.04453276793162028 | Train Accuracy:  0.8085714285714286 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  77 | Train Loss:  0.04244932730992635 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  78 | Train Loss:  0.0429111123085022 | Train Accuracy:  0.8914285714285715 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  79 | Train Loss:  0.04337840080261231 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  80 | Train Loss:  0.04042771657307943 | Train Accuracy:  0.9171428571428571 | Validation Accuracy:  0.41333333333333333\n",
            "Iteration:  81 | Train Loss:  0.04250726302464803 | Train Accuracy:  0.9085714285714286 | Validation Accuracy:  0.41333333333333333\n",
            "Iteration:  82 | Train Loss:  0.03944497108459473 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  83 | Train Loss:  0.03921349843343099 | Train Accuracy:  0.9457142857142857 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  84 | Train Loss:  0.03888704379399618 | Train Accuracy:  0.9485714285714286 | Validation Accuracy:  0.44\n",
            "Iteration:  85 | Train Loss:  0.03792660236358643 | Train Accuracy:  0.9514285714285714 | Validation Accuracy:  0.44\n",
            "Iteration:  86 | Train Loss:  0.036945192019144694 | Train Accuracy:  0.9285714285714286 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  87 | Train Loss:  0.03928595781326294 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  88 | Train Loss:  0.03803715705871582 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.44\n",
            "Iteration:  89 | Train Loss:  0.04115715821584066 | Train Accuracy:  0.9314285714285714 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  90 | Train Loss:  0.035738444328308104 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.48\n",
            "Iteration:  91 | Train Loss:  0.03621132771174113 | Train Accuracy:  0.8142857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  92 | Train Loss:  0.03868569930394491 | Train Accuracy:  0.8257142857142857 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  93 | Train Loss:  0.04256570339202881 | Train Accuracy:  0.9657142857142857 | Validation Accuracy:  0.44\n",
            "Iteration:  94 | Train Loss:  0.028231833378473917 | Train Accuracy:  0.9114285714285715 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  95 | Train Loss:  0.022608975569407146 | Train Accuracy:  0.7771428571428571 | Validation Accuracy:  0.48\n",
            "Iteration:  96 | Train Loss:  0.021954894065856934 | Train Accuracy:  0.7 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  97 | Train Loss:  0.05623100996017456 | Train Accuracy:  0.8342857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  98 | Train Loss:  0.032564661900202435 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.41333333333333333\n",
            "Iteration:  99 | Train Loss:  0.028079408407211303 | Train Accuracy:  0.9685714285714285 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  100 | Train Loss:  0.02479779322942098 | Train Accuracy:  0.8685714285714285 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  101 | Train Loss:  0.037716341018676755 | Train Accuracy:  0.8857142857142857 | Validation Accuracy:  0.48\n",
            "Iteration:  102 | Train Loss:  0.038117011388142906 | Train Accuracy:  0.9628571428571429 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  103 | Train Loss:  0.025013037522633872 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.44\n",
            "Iteration:  104 | Train Loss:  0.018367532889048258 | Train Accuracy:  0.9428571428571428 | Validation Accuracy:  0.41333333333333333\n",
            "Iteration:  105 | Train Loss:  0.026568086942036946 | Train Accuracy:  0.92 | Validation Accuracy:  0.4266666666666667\n",
            "Iteration:  106 | Train Loss:  0.017457719643910727 | Train Accuracy:  0.9342857142857143 | Validation Accuracy:  0.41333333333333333\n",
            "Iteration:  107 | Train Loss:  0.023295275370279946 | Train Accuracy:  0.9742857142857143 | Validation Accuracy:  0.37333333333333335\n",
            "Iteration:  108 | Train Loss:  0.014398454626401266 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  109 | Train Loss:  0.014377230405807495 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.48\n",
            "Iteration:  110 | Train Loss:  0.016361227631568907 | Train Accuracy:  0.9828571428571429 | Validation Accuracy:  0.52\n",
            "Iteration:  111 | Train Loss:  0.013902580738067627 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.52\n",
            "Iteration:  112 | Train Loss:  0.014534194270769756 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  113 | Train Loss:  0.012861682971318563 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.48\n",
            "Iteration:  114 | Train Loss:  0.010925800601641337 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  115 | Train Loss:  0.01637940009435018 | Train Accuracy:  0.98 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  116 | Train Loss:  0.01351265807946523 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  117 | Train Loss:  0.010762815674146017 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  118 | Train Loss:  0.007174290219942729 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.48\n",
            "Iteration:  119 | Train Loss:  0.0012927748262882232 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  120 | Train Loss:  0.002648918330669403 | Train Accuracy:  0.9542857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  121 | Train Loss:  0.018033909797668456 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  122 | Train Loss:  0.010600884755452475 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  123 | Train Loss:  0.004953768849372864 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.52\n",
            "Iteration:  124 | Train Loss:  0.004133634765942891 | Train Accuracy:  0.98 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  125 | Train Loss:  0.009114460150400797 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.52\n",
            "Iteration:  126 | Train Loss:  0.005228314797083537 | Train Accuracy:  1.0 | Validation Accuracy:  0.52\n",
            "Iteration:  127 | Train Loss:  0.0019675044963757197 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  128 | Train Loss:  0.0019532602280378343 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  129 | Train Loss:  0.0028162052234013877 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  130 | Train Loss:  0.0010643209020296733 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  131 | Train Loss:  0.007401757438977559 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  132 | Train Loss:  0.0010611247271299362 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  133 | Train Loss:  0.0005945506195227305 | Train Accuracy:  1.0 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  134 | Train Loss:  0.0022083697219689685 | Train Accuracy:  1.0 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  135 | Train Loss:  0.000579352614780267 | Train Accuracy:  1.0 | Validation Accuracy:  0.5333333333333333\n",
            "Iteration:  136 | Train Loss:  0.0002931542384127776 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  137 | Train Loss:  0.00043701867883404096 | Train Accuracy:  0.9914285714285714 | Validation Accuracy:  0.52\n",
            "Iteration:  138 | Train Loss:  0.00099155493080616 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  139 | Train Loss:  0.0009273555750648181 | Train Accuracy:  0.9857142857142858 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  140 | Train Loss:  0.0010268684476614 | Train Accuracy:  0.9885714285714285 | Validation Accuracy:  0.5466666666666666\n",
            "Iteration:  141 | Train Loss:  0.0012064392367998758 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  142 | Train Loss:  0.0008854699631532033 | Train Accuracy:  0.9971428571428571 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  143 | Train Loss:  0.00018248620132605236 | Train Accuracy:  1.0 | Validation Accuracy:  0.48\n",
            "Iteration:  144 | Train Loss:  0.000932741475601991 | Train Accuracy:  1.0 | Validation Accuracy:  0.48\n",
            "Iteration:  145 | Train Loss:  0.0011772687236467998 | Train Accuracy:  1.0 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  146 | Train Loss:  0.0001272597893451651 | Train Accuracy:  0.9942857142857143 | Validation Accuracy:  0.4533333333333333\n",
            "Iteration:  147 | Train Loss:  0.0013582531362771987 | Train Accuracy:  0.98 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  148 | Train Loss:  0.007927003999551136 | Train Accuracy:  1.0 | Validation Accuracy:  0.4666666666666667\n",
            "Iteration:  149 | Train Loss:  0.003269555668036143 | Train Accuracy:  1.0 | Validation Accuracy:  0.5066666666666667\n",
            "Iteration:  150 | Train Loss:  0.00018316608232756457 | Train Accuracy:  0.98 | Validation Accuracy:  0.49333333333333335\n",
            "Iteration:  151 | Train Loss:  0.0011993357290824254 | Train Accuracy:  0.8885714285714286 | Validation Accuracy:  0.5066666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5aeac8123d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_WV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_adam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-b26df35304af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, val_dataset, batch_size, num_epochs, learning_rate, momen, use_cuda, use_adam, save_weights)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0miters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# compute *average* loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute training accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mval_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# compute validation accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"| Train Loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"| Train Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"| Validation Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-2a2bbc9c2451>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(model, data_loader, train, use_cuda)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-f403dc54e718>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#flatten the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    153\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    154\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 586\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m max_pool2d = boolean_dispatch(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b93VlyYuTxPf"
      },
      "source": [
        "##### 2 x 3.5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn-3yqTTTzL6"
      },
      "source": [
        "train_dataset = createTensorDataset(X_train2_wv, y_train2_wv)\r\n",
        "val_dataset = createTensorDataset(X_val2_wv, y_val2_wv)\r\n",
        "\r\n",
        "#Downsample the height and width to make training easier\r\n",
        "train_dataset = downsampleTensorHW(train_dataset, 2)\r\n",
        "val_dataset = downsampleTensorHW(val_dataset, 2)\r\n",
        "\r\n",
        "print(\"Train Data Shape: \", train_dataset.tensors[0].shape)\r\n",
        "print(\"Train Labels Shape: \", train_dataset.tensors[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YU3KlwRU4pY"
      },
      "source": [
        "model = CNN2_WV()\r\n",
        "train(model, train_dataset, val_dataset, batch_size = 15, num_epochs=15, learning_rate = 0.0005, momen = 0.55, use_adam = True, save_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}